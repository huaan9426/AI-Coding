# 第8章 存储管理

在前面的章节中，我们深入学习了Kubernetes的调度与资源管理机制，掌握了如何高效地将Pod调度到合适的节点上，并通过优先级、亲和性、资源配额等手段实现企业级的资源管理。然而，真实的生产环境中，大部分应用都是**有状态应用**（Stateful Application），它们需要持久化存储来保存数据：

- **数据库**：MySQL、PostgreSQL、MongoDB需要持久化数据库文件
- **消息队列**：Kafka、RabbitMQ需要持久化消息数据
- **文件存储**：MinIO、Ceph需要持久化对象存储
- **日志系统**：Elasticsearch需要持久化日志索引
- **配置中心**：etcd、Consul需要持久化配置数据

容器的本质是**进程**，当Pod被删除或重启时，容器内的数据会随之消失。这对于无状态应用（如Web服务器）不是问题，但对于有状态应用却是致命的。Kubernetes通过强大的**存储管理体系**解决了这一难题，提供了从临时存储到企业级分布式存储的完整解决方案。

本章将系统学习Kubernetes的存储管理机制，从基础概念到高级特性，再到企业级实战，构建完整的存储知识体系。

---

## 本章结构

本章共分为8节，逐步深入Kubernetes存储管理的核心技术：

- **8.1 存储基础概念与架构**：理解Kubernetes存储体系的整体架构，掌握Volume、PV、PVC的核心概念
- **8.2 Volume详解**：深入学习emptyDir、hostPath、configMap、secret等基础Volume类型
- **8.3 持久卷（PersistentVolume）**：掌握PV的生命周期、访问模式、回收策略
- **8.4 持久卷声明（PersistentVolumeClaim）**：理解PVC的绑定机制、存储类选择
- **8.5 存储类（StorageClass）**：学习动态存储供应、参数配置、回收策略
- **8.6 StatefulSet与有状态应用**：掌握StatefulSet的存储管理机制、volumeClaimTemplates
- **8.7 CSI存储插件**：理解Container Storage Interface标准，学习云存储集成
- **8.8 实战项目与本章小结**：通过企业级存储方案实战，总结存储管理最佳实践

---

## 8.1 存储基础概念与架构

在深入具体技术之前，我们需要先建立对Kubernetes存储体系的整体认知。本节将回答以下核心问题：

1. **为什么容器需要持久化存储？** 容器数据的生命周期与存储需求
2. **Kubernetes提供了哪些存储方案？** 临时存储、持久化存储、配置存储的分类
3. **PV、PVC、StorageClass的关系是什么？** 存储抽象的三层架构
4. **存储如何与Pod绑定？** Volume挂载的完整流程

---

### 8.1.1 容器存储的挑战

**问题1：容器数据的临时性**

容器的文件系统是基于镜像的分层文件系统（Union FS），容器内的所有写操作都发生在**可写层**（Writable Layer）：

```
容器文件系统层级结构
┌─────────────────────────┐
│  可写层（Container Layer）  │ ← 容器运行时的所有写操作
├─────────────────────────┤
│  镜像层4（ADD app.jar）    │
├─────────────────────────┤
│  镜像层3（RUN apt update） │
├─────────────────────────┤
│  镜像层2（COPY . /app）    │
├─────────────────────────┤
│  镜像层1（FROM ubuntu）    │ ← 只读基础镜像
└─────────────────────────┘
```

**核心问题：**
- ❌ 容器删除时，可写层数据随之消失
- ❌ 容器重启时，数据重置到镜像初始状态
- ❌ 同一Pod内的多个容器无法共享数据
- ❌ Pod迁移到其他节点时，数据无法跟随

**典型场景的数据丢失：**

```bash
# 场景1：Pod重启导致数据丢失
$ kubectl exec mysql-pod -- mysql -e "CREATE DATABASE test;"
$ kubectl delete pod mysql-pod  # Pod被删除
$ kubectl get pod               # 新Pod被ReplicaSet重建
$ kubectl exec mysql-pod -- mysql -e "SHOW DATABASES;"  # test数据库消失！

# 场景2：容器崩溃导致日志丢失
$ kubectl exec nginx-pod -- sh -c "echo 'important log' >> /var/log/access.log"
$ kubectl exec nginx-pod -- kill 1  # 容器崩溃重启
$ kubectl exec nginx-pod -- cat /var/log/access.log  # 日志文件不存在！
```

---

**问题2：有状态应用的复杂需求**

真实的生产环境中，有状态应用有更复杂的存储需求：

| 应用类型 | 存储需求 | 挑战 |
|---------|---------|------|
| **MySQL主从** | - 主库需要独立持久卷<br>- 从库需要只读访问<br>- 数据目录需要固定路径 | 如何为每个实例分配独立存储？<br>如何保证存储的访问模式正确？ |
| **Elasticsearch集群** | - 每个节点需要独立数据目录<br>- 存储需要高IOPS（SSD）<br>- 需要动态扩容 | 如何根据性能需求选择存储类型？<br>如何支持在线扩容？ |
| **Kafka** | - 日志段需要顺序写入<br>- 消费者offset需要持久化<br>- 存储容量需要动态调整 | 如何保证写入性能？<br>如何处理存储容量不足？ |
| **共享文件服务** | - 多个Pod同时读写<br>- 需要文件锁机制<br>- 跨节点访问 | 如何支持ReadWriteMany模式？<br>如何选择合适的网络存储？ |

---

**问题3：传统存储与容器编排的鸿沟**

在容器化之前，存储管理是运维团队的职责：

```
传统模式（手动管理）
运维团队：创建LUN → 格式化 → 挂载到服务器 → 配置权限
开发团队：在固定路径/data/mysql使用存储
```

容器化后，Pod可能在任意节点启动，传统的手动挂载方式失效：

```
容器化挑战
Pod在node1启动 → 需要自动挂载存储A
Pod被调度到node2 → 需要自动卸载node1并挂载到node2
Pod扩容到3副本 → 需要自动创建3个独立存储
```

**Kubernetes存储体系的设计目标：**
- ✅ **解耦**：应用开发者无需关心底层存储细节（NFS/Ceph/云盘）
- ✅ **自动化**：存储的创建、挂载、卸载、删除全自动
- ✅ **可移植**：同一份YAML可以在不同环境（AWS/阿里云/本地）运行
- ✅ **动态供应**：根据应用需求自动创建存储，无需提前准备

---

### 8.1.2 Kubernetes存储体系架构

Kubernetes通过**三层抽象**解决容器存储难题：

```
┌─────────────────────────────────────────────────────────────┐
│  应用层（Pod）                                                 │
│  ┌──────────────────────────────────────────────────────┐  │
│  │ containers:                                           │  │
│  │   - name: mysql                                       │  │
│  │     volumeMounts:                                     │  │
│  │       - name: data                                    │  │
│  │         mountPath: /var/lib/mysql  ← 应用只关心挂载路径  │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  抽象层（PVC - 存储需求声明）                                    │
│  ┌──────────────────────────────────────────────────────┐  │
│  │ kind: PersistentVolumeClaim                           │  │
│  │ spec:                                                 │  │
│  │   accessModes: [ReadWriteOnce]                        │  │
│  │   resources:                                          │  │
│  │     requests:                                         │  │
│  │       storage: 10Gi           ← 我需要10GB的RWO存储    │  │
│  │   storageClassName: fast-ssd  ← 我需要SSD类型         │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  供应层（StorageClass - 存储供应策略）                           │
│  ┌──────────────────────────────────────────────────────┐  │
│  │ kind: StorageClass                                    │  │
│  │ provisioner: kubernetes.io/aws-ebs                    │  │
│  │ parameters:                                           │  │
│  │   type: gp3                   ← 使用AWS GP3 SSD       │  │
│  │   iopsPerGB: "50"             ← 性能参数              │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  实现层（PV - 真实存储资源）                                     │
│  ┌──────────────────────────────────────────────────────┐  │
│  │ kind: PersistentVolume                                │  │
│  │ spec:                                                 │  │
│  │   capacity:                                           │  │
│  │     storage: 10Gi                                     │  │
│  │   awsElasticBlockStore:                               │  │
│  │     volumeID: vol-0a1b2c3d4e5f  ← 真实的AWS EBS卷ID   │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

**核心概念解析：**

**1. Volume（存储卷）**
- **定义**：Pod中定义的存储抽象，是容器挂载存储的基础单元
- **生命周期**：与Pod绑定，Pod删除时Volume行为取决于类型
- **分类**：
  - **临时卷**：emptyDir（随Pod删除）
  - **节点卷**：hostPath（节点本地路径）
  - **配置卷**：configMap、secret（配置数据）
  - **持久卷**：通过PVC引用PV（独立生命周期）

**2. PersistentVolume（PV，持久卷）**
- **定义**：集群级别的存储资源，由管理员创建或动态供应
- **特点**：
  - 独立于Pod的生命周期（Pod删除后PV依然存在）
  - 包含真实存储的细节（NFS服务器地址、云盘ID等）
  - 有容量、访问模式、回收策略等属性
- **类比**：PV就像数据中心的"存储货架"，是真实的物理资源

**3. PersistentVolumeClaim（PVC，持久卷声明）**
- **定义**：用户对存储的请求声明，描述需要什么样的存储
- **特点**：
  - 命名空间级别（与Pod在同一命名空间）
  - 只描述需求（容量、访问模式、存储类），不关心实现细节
  - 通过绑定机制与PV关联
- **类比**：PVC就像"采购订单"，描述需要多大、什么性能的存储

**4. StorageClass（SC，存储类）**
- **定义**：存储的"配置模板"，定义如何动态创建PV
- **特点**：
  - 包含provisioner（存储供应商插件）
  - 包含parameters（存储参数，如磁盘类型、IOPS）
  - 支持动态供应（PVC创建时自动创建PV）
- **类比**：StorageClass就像"采购合同"，定义了从哪里、如何采购存储

---

### 8.1.3 存储类型分类

Kubernetes支持丰富的存储类型，根据使用场景可以分为以下几类：

**分类1：按生命周期分类**

| 类型 | 生命周期 | 典型场景 | 代表类型 |
|------|---------|---------|---------|
| **临时存储** | 与Pod绑定<br>Pod删除时数据丢失 | - 缓存数据<br>- 临时文件<br>- 容器间共享 | emptyDir |
| **节点存储** | 与节点绑定<br>Pod迁移时数据丢失 | - 节点日志采集<br>- 主机路径访问<br>- DaemonSet数据 | hostPath |
| **持久存储** | 独立生命周期<br>Pod删除后数据保留 | - 数据库数据<br>- 用户上传文件<br>- 持久化队列 | PVC/PV |

**分类2：按访问模式分类**

| 访问模式 | 缩写 | 含义 | 典型场景 | 支持的存储后端 |
|---------|------|------|---------|---------------|
| **ReadWriteOnce** | RWO | 单节点读写 | - 数据库（MySQL/PostgreSQL）<br>- 块存储应用 | AWS EBS、Azure Disk<br>GCE PD、本地磁盘 |
| **ReadOnlyMany** | ROX | 多节点只读 | - 静态资源分发<br>- 共享配置文件 | NFS、CephFS |
| **ReadWriteMany** | RWX | 多节点读写 | - 共享文件服务<br>- 多副本应用共享数据 | NFS、GlusterFS<br>CephFS、Azure File |
| **ReadWriteOncePod** | RWOP | 单Pod读写（K8s 1.22+） | - 独占访问保证<br>- 避免脑裂 | CSI驱动支持 |

**重要提示：**
- ⚠️ **RWO不是指"单个Pod"，而是"单个节点"**：同一节点的多个Pod可以同时挂载RWO卷
- ⚠️ **RWX需要网络存储**：本地磁盘、云盘（EBS/Azure Disk）不支持RWX

**分类3：按存储后端分类**

```
存储后端技术栈
├── 本地存储
│   ├── emptyDir（节点临时目录）
│   ├── hostPath（节点路径）
│   └── local（本地持久卷，1.14+）
├── 网络存储
│   ├── NFS（Network File System）
│   ├── iSCSI（块存储协议）
│   ├── GlusterFS（分布式文件系统）
│   └── CephFS/RBD（Ceph分布式存储）
├── 云存储
│   ├── AWS EBS（Elastic Block Store）
│   ├── Azure Disk（托管磁盘）
│   ├── GCE PD（Persistent Disk）
│   └── 阿里云盘、腾讯云盘
└── 特殊存储
    ├── ConfigMap（配置数据）
    ├── Secret（敏感数据）
    ├── Projected（投射卷，组合多个源）
    └── CSI（Container Storage Interface，统一接口）
```

---

### 8.1.4 PV/PVC绑定机制

**核心流程：**

```
┌──────────────────────────────────────────────────────────────┐
│  步骤1：用户创建PVC（我需要10GB RWO存储）                         │
└────────────────┬─────────────────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────────────────┐
│  步骤2：Controller匹配PV（查找满足条件的PV）                      │
│  匹配条件：                                                     │
│  ✓ 容量 >= PVC请求（10GB）                                     │
│  ✓ 访问模式匹配（RWO）                                          │
│  ✓ StorageClass匹配（或都为空）                                │
│  ✓ Selector标签匹配（如果PVC指定了selector）                    │
└────────────────┬─────────────────────────────────────────────┘
                 │
      ┌──────────┴──────────┐
      │                     │
      ▼                     ▼
┌────────────┐        ┌────────────┐
│ 找到匹配PV  │        │ 未找到PV    │
└─────┬──────┘        └─────┬──────┘
      │                     │
      ▼                     ▼
┌────────────┐        ┌────────────┐
│ 绑定PVC到PV │        │ 触发动态供应 │
│ (Bound状态) │        │ (Pending)   │
└─────┬──────┘        └─────┬──────┘
      │                     │
      │                     ▼
      │              ┌────────────┐
      │              │ SC创建PV   │
      │              └─────┬──────┘
      │                     │
      └──────────┬──────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────────────────┐
│  步骤3：Pod引用PVC（volumeMounts挂载到容器）                      │
└────────────────┬─────────────────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────────────────┐
│  步骤4：Kubelet挂载存储（调用Volume Plugin或CSI驱动）             │
│  - Attach阶段：将存储卷附加到节点（如AWS EBS attach）             │
│  - Mount阶段：将存储卷挂载到容器路径                              │
└──────────────────────────────────────────────────────────────┘
```

**绑定规则详解：**

**规则1：容量匹配**
```yaml
# PVC请求10GB
spec:
  resources:
    requests:
      storage: 10Gi

# 可以绑定到15GB的PV（容量 >= 请求即可）
# 但会浪费5GB空间
# ✅ 推荐：PV容量精确等于PVC请求
```

**规则2：访问模式匹配**
```yaml
# PVC请求RWO
accessModes: [ReadWriteOnce]

# ❌ 无法绑定到只支持ROX的PV
# ✅ 可以绑定到同时支持RWO和RWX的PV
# PV的accessModes必须包含PVC请求的所有模式
```

**规则3：StorageClass匹配**
```yaml
# 场景1：静态绑定（都不指定SC）
PVC: storageClassName: ""  # 明确指定为空
PV:  storageClassName: ""  # 不指定SC
结果: ✅ 可以绑定

# 场景2：动态供应（PVC指定SC）
PVC: storageClassName: "fast-ssd"
结果: 触发StorageClass创建PV

# 场景3：类名匹配
PVC: storageClassName: "fast-ssd"
PV:  storageClassName: "fast-ssd"
结果: ✅ 可以绑定

# 场景4：类名不匹配
PVC: storageClassName: "fast-ssd"
PV:  storageClassName: "standard-hdd"
结果: ❌ 无法绑定
```

**规则4：Selector标签匹配**
```yaml
# PVC通过selector精确选择PV
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 10Gi
  selector:
    matchLabels:
      environment: production  # 只绑定带此标签的PV
      tier: database
```

---

### 8.1.5 Volume基础类型详解

在深入PV/PVC之前,我们先了解Pod中直接使用的基础Volume类型。

**类型1：emptyDir（临时目录）**

**定义：** Pod创建时自动创建的空目录，Pod删除时数据随之删除。

**典型场景：**
1. 容器间共享数据（同一Pod内的多个容器）
2. 临时缓存（如编译产物、下载文件）
3. 检查点文件（Checkpoint）

**示例：容器间共享日志文件**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: log-sharing-pod
spec:
  containers:
  # 容器1：生成日志
  - name: app
    image: nginx:1.21
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx  # Nginx日志写入此目录

  # 容器2：采集日志
  - name: log-collector
    image: busybox:1.35
    command: ['sh', '-c', 'tail -f /logs/access.log']
    volumeMounts:
    - name: shared-logs
      mountPath: /logs  # 读取同一目录的日志

  volumes:
  - name: shared-logs
    emptyDir: {}  # Pod级别的临时存储
```

**高级特性：基于内存的emptyDir**

```yaml
volumes:
- name: cache
  emptyDir:
    medium: Memory  # 使用内存而非磁盘
    sizeLimit: 1Gi  # 限制最大使用1GB内存
```

**使用场景：**
- ✅ 高性能缓存（读写速度快）
- ⚠️ 注意内存限制（会占用Pod的内存资源）

---

**类型2：hostPath（主机路径）**

**定义：** 将宿主机的文件或目录挂载到Pod中。

**典型场景：**
1. 访问宿主机的Docker socket（/var/run/docker.sock）
2. 节点日志采集（/var/log）
3. 时区同步（/etc/localtime）

**⚠️ 安全警告：** hostPath允许Pod访问节点文件系统，具有较大安全风险，生产环境应谨慎使用。

**示例1：Docker-in-Docker（访问Docker守护进程）**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: docker-cli-pod
spec:
  containers:
  - name: docker-cli
    image: docker:20.10
    command: ['sh', '-c', 'docker ps && sleep 3600']
    volumeMounts:
    - name: docker-sock
      mountPath: /var/run/docker.sock  # 容器内访问宿主机Docker

  volumes:
  - name: docker-sock
    hostPath:
      path: /var/run/docker.sock  # 宿主机Docker socket
      type: Socket  # 类型校验：必须是socket文件
```

**示例2：节点日志采集（DaemonSet典型场景）**

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-logger
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.14
        volumeMounts:
        - name: varlog
          mountPath: /var/log  # 读取节点日志
          readOnly: true  # 只读挂载，安全最佳实践

      volumes:
      - name: varlog
        hostPath:
          path: /var/log  # 节点的日志目录
          type: Directory  # 类型校验：必须是已存在的目录
```

**hostPath类型校验（type字段）：**

| type值 | 含义 | 行为 |
|--------|------|------|
| `""` | 默认（不检查） | 无论路径是否存在都挂载 |
| `DirectoryOrCreate` | 目录或创建 | 目录不存在时自动创建 |
| `Directory` | 必须是目录 | 目录不存在时Pod启动失败 |
| `FileOrCreate` | 文件或创建 | 文件不存在时自动创建 |
| `File` | 必须是文件 | 文件不存在时Pod启动失败 |
| `Socket` | 必须是Socket | 不是socket文件时启动失败 |
| `CharDevice` | 字符设备 | 用于设备文件（如/dev/xxx） |
| `BlockDevice` | 块设备 | 用于块设备文件 |

**最佳实践：**
- ✅ 始终指定`type`字段进行类型校验
- ✅ 尽量使用`readOnly: true`只读挂载
- ✅ 避免挂载敏感路径（如/etc/shadow）
- ⚠️ 注意Pod迁移到其他节点时，hostPath路径可能不存在

---

**类型3：configMap（配置数据）**

**定义：** 将ConfigMap的数据以文件形式挂载到Pod中。

**示例：Nginx配置文件注入**

```yaml
# 第一步：创建ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  nginx.conf: |
    server {
        listen 80;
        server_name example.com;

        location / {
            root /usr/share/nginx/html;
            index index.html;
        }

        location /api {
            proxy_pass http://backend:8080;
        }
    }
  index.html: |
    <html>
      <body><h1>Hello from ConfigMap!</h1></body>
    </html>

---
# 第二步：Pod挂载ConfigMap
apiVersion: v1
kind: Pod
metadata:
  name: nginx-with-config
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    volumeMounts:
    - name: config-volume
      mountPath: /etc/nginx/conf.d  # 配置文件目录
    - name: html-volume
      mountPath: /usr/share/nginx/html  # 静态文件目录

  volumes:
  - name: config-volume
    configMap:
      name: nginx-config
      items:  # 选择性挂载
      - key: nginx.conf
        path: default.conf  # 挂载为default.conf文件

  - name: html-volume
    configMap:
      name: nginx-config
      items:
      - key: index.html
        path: index.html
```

**挂载后的文件结构：**
```bash
# 容器内查看
$ kubectl exec nginx-with-config -- ls -la /etc/nginx/conf.d
total 4
drwxrwxrwx 3 root root  80 Jan 13 10:00 .
drwxr-xr-x 1 root root  41 Jan 13 10:00 ..
drwxr-xr-x 2 root root  28 Jan 13 10:00 ..2024_01_13_10_00_00.123456789
lrwxrwxrwx 1 root root  32 Jan 13 10:00 ..data -> ..2024_01_13_10_00_00.123456789
lrwxrwxrwx 1 root root  19 Jan 13 10:00 default.conf -> ..data/default.conf

# ConfigMap更新时，Kubernetes会自动更新挂载的文件（有约60秒延迟）
```

---

**类型4：secret（敏感数据）**

**定义：** 与ConfigMap类似，但用于存储敏感信息（密码、证书、Token），数据以Base64编码存储。

**示例：MySQL密码注入**

```yaml
# 第一步：创建Secret
apiVersion: v1
kind: Secret
metadata:
  name: mysql-credentials
type: Opaque
data:
  # Base64编码后的值
  username: cm9vdA==  # root
  password: bXlzcWwxMjM0NTY=  # mysql123456

---
# 第二步：Pod使用Secret
apiVersion: v1
kind: Pod
metadata:
  name: mysql-pod
spec:
  containers:
  - name: mysql
    image: mysql:8.0
    env:
    # 方式1：通过环境变量注入
    - name: MYSQL_ROOT_PASSWORD
      valueFrom:
        secretKeyRef:
          name: mysql-credentials
          key: password

    # 方式2：通过文件挂载（更安全）
    volumeMounts:
    - name: credentials
      mountPath: /etc/mysql/conf.d
      readOnly: true  # 只读挂载，防止容器篡改

  volumes:
  - name: credentials
    secret:
      secretName: mysql-credentials
      defaultMode: 0400  # 文件权限：仅所有者可读
```

**Secret vs ConfigMap：**

| 特性 | Secret | ConfigMap |
|------|--------|-----------|
| **数据编码** | Base64编码 | 明文 |
| **API权限** | 更严格（RBAC） | 宽松 |
| **加密存储** | 支持etcd加密（需开启） | 不支持 |
| **文件权限** | 默认0644，可配置 | 默认0644 |
| **典型用途** | 密码、证书、Token | 配置文件、环境变量 |

⚠️ **重要提示：** Base64编码≠加密，Secret在etcd中默认是明文存储，需要配置[etcd加密](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/)才能真正加密。

---

### 8.1.6 PV/PVC核心概念深入

现在我们深入学习持久化存储的核心：PV和PVC。

**PersistentVolume（PV）核心属性：**

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-example
  labels:
    type: local
    environment: production
spec:
  # ========== 容量 ==========
  capacity:
    storage: 10Gi  # PV的总容量

  # ========== 访问模式 ==========
  accessModes:
    - ReadWriteOnce  # 单节点读写
    # - ReadOnlyMany   # 多节点只读
    # - ReadWriteMany  # 多节点读写

  # ========== 回收策略 ==========
  persistentVolumeReclaimPolicy: Retain  # PVC删除后的行为
    # Retain：保留数据，手动回收
    # Delete：自动删除PV和底层存储
    # Recycle（废弃）：擦除数据后重新可用

  # ========== 存储类 ==========
  storageClassName: manual  # 关联的StorageClass名称

  # ========== 挂载选项 ==========
  mountOptions:
    - hard
    - nfsvers=4.1

  # ========== 节点亲和性（Local PV必需） ==========
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1  # 此PV只能在node1上使用

  # ========== 具体存储实现（选择其一） ==========
  nfs:  # NFS存储
    server: 192.168.1.100
    path: /data/pv-example

  # 或者其他类型：
  # hostPath:  # 本地路径
  #   path: /mnt/data
  # awsElasticBlockStore:  # AWS EBS
  #   volumeID: vol-0a1b2c3d4e5f
  #   fsType: ext4
  # cephfs:  # CephFS
  #   monitors: [...]
```

**PersistentVolumeClaim（PVC）核心属性：**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-example
  namespace: default  # PVC是命名空间级别资源
spec:
  # ========== 访问模式（必需） ==========
  accessModes:
    - ReadWriteOnce  # 必须与PV的accessModes匹配

  # ========== 资源请求（必需） ==========
  resources:
    requests:
      storage: 8Gi  # 请求8GB存储（PV容量需 >= 8Gi）

  # ========== 存储类（可选） ==========
  storageClassName: manual  # 指定使用哪个StorageClass
    # "" - 明确禁用动态供应，只绑定无StorageClass的PV
    # <不指定> - 使用默认StorageClass（如果集群有默认SC）
    # <类名> - 使用指定的StorageClass

  # ========== 选择器（可选） ==========
  selector:
    matchLabels:
      type: local  # 只绑定带此标签的PV
      environment: production
    # matchExpressions:  # 更复杂的选择逻辑
    #   - key: tier
    #     operator: In
    #     values: [database, cache]

  # ========== 卷模式（可选，1.13+） ==========
  volumeMode: Filesystem  # 文件系统模式（默认）
    # Filesystem - 挂载为文件系统（需要格式化）
    # Block - 块设备模式（直接访问裸设备）
```

---

### 8.1.7 完整实战案例：MySQL持久化存储

让我们通过一个完整的案例，将上述概念串联起来。

**场景：** 部署一个MySQL数据库，数据持久化到NFS存储，即使Pod删除数据也不会丢失。

**前提条件：** 已有NFS服务器（192.168.1.100），共享目录/data/mysql

**步骤1：创建PV（管理员操作）**

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv
  labels:
    app: mysql
    environment: production
spec:
  capacity:
    storage: 20Gi  # 提供20GB存储
  accessModes:
    - ReadWriteOnce  # MySQL需要RWO模式
  persistentVolumeReclaimPolicy: Retain  # 删除PVC后保留数据
  storageClassName: nfs-storage  # 存储类名称
  mountOptions:
    - hard  # NFS硬挂载（推荐）
    - nfsvers=4.1  # NFS版本
  nfs:
    server: 192.168.1.100
    path: /data/mysql  # NFS共享路径
```

```bash
# 创建PV
$ kubectl apply -f mysql-pv.yaml
persistentvolume/mysql-pv created

# 查看PV状态
$ kubectl get pv mysql-pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   AGE
mysql-pv   20Gi       RWO            Retain           Available           nfs-storage    5s
# STATUS=Available 表示PV已就绪，等待PVC绑定
```

**步骤2：创建PVC（开发者操作）**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
  namespace: default
spec:
  accessModes:
    - ReadWriteOnce  # 与PV的accessModes匹配
  resources:
    requests:
      storage: 15Gi  # 请求15GB（小于PV的20GB）
  storageClassName: nfs-storage  # 与PV的storageClassName匹配
  selector:
    matchLabels:
      app: mysql  # 精确选择带mysql标签的PV
      environment: production
```

```bash
# 创建PVC
$ kubectl apply -f mysql-pvc.yaml
persistentvolumeclaim/mysql-pvc created

# 查看PVC状态
$ kubectl get pvc mysql-pvc
NAME        STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
mysql-pvc   Bound    mysql-pv   20Gi       RWO            nfs-storage    3s
# STATUS=Bound 表示PVC已成功绑定到mysql-pv

# 再次查看PV状态
$ kubectl get pv mysql-pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM               STORAGECLASS   AGE
mysql-pv   20Gi       RWO            Retain           Bound    default/mysql-pvc   nfs-storage    2m
# STATUS从Available变为Bound
# CLAIM显示绑定到default/mysql-pvc
```

**步骤3：部署MySQL Pod**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  containers:
  - name: mysql
    image: mysql:8.0
    env:
    - name: MYSQL_ROOT_PASSWORD
      value: "mysql123456"  # 生产环境应使用Secret
    ports:
    - containerPort: 3306
      name: mysql
    volumeMounts:
    - name: mysql-storage
      mountPath: /var/lib/mysql  # MySQL数据目录

  volumes:
  - name: mysql-storage
    persistentVolumeClaim:
      claimName: mysql-pvc  # 引用PVC
```

```bash
# 部署MySQL
$ kubectl apply -f mysql-pod.yaml
pod/mysql created

# 等待Pod运行
$ kubectl get pod mysql
NAME    READY   STATUS    RESTARTS   AGE
mysql   1/1     Running   0          30s

# 进入容器验证挂载
$ kubectl exec -it mysql -- df -h /var/lib/mysql
Filesystem                Size  Used Avail Use% Mounted on
192.168.1.100:/data/mysql  20G  1.2G   18G   6% /var/lib/mysql
# 可以看到NFS存储已成功挂载
```

**步骤4：验证数据持久化**

```bash
# 创建测试数据
$ kubectl exec -it mysql -- mysql -uroot -pmysql123456 -e "
CREATE DATABASE testdb;
USE testdb;
CREATE TABLE users (id INT, name VARCHAR(50));
INSERT INTO users VALUES (1, 'Alice'), (2, 'Bob');
SELECT * FROM users;
"
+------+-------+
| id   | name  |
+------+-------+
|    1 | Alice |
|    2 | Bob   |
+------+-------+

# 删除Pod
$ kubectl delete pod mysql
pod "mysql" deleted

# 重新创建Pod（使用相同的PVC）
$ kubectl apply -f mysql-pod.yaml
pod/mysql created

# 等待Pod运行后验证数据
$ kubectl exec -it mysql -- mysql -uroot -pmysql123456 -e "
USE testdb;
SELECT * FROM users;
"
+------+-------+
| id   | name  |
+------+-------+
|    1 | Alice |
|    2 | Bob   |
+------+-------+
# ✅ 数据完整保留！Pod删除重建后数据依然存在
```

**步骤5：清理资源（注意顺序）**

```bash
# 第一步：删除Pod
$ kubectl delete pod mysql
pod "mysql" deleted

# 第二步：删除PVC
$ kubectl delete pvc mysql-pvc
persistentvolumeclaim "mysql-pvc" deleted

# 查看PV状态
$ kubectl get pv mysql-pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM               STORAGECLASS   AGE
mysql-pv   20Gi       RWO            Retain           Released   default/mysql-pvc   nfs-storage    10m
# STATUS变为Released（已释放，但数据仍保留）

# 第三步：根据需要手动删除PV
$ kubectl delete pv mysql-pv  # 删除PV对象
$ # NFS服务器上的/data/mysql目录数据依然存在（Retain策略）
```

**回收策略的影响：**

| 回收策略 | PVC删除后的行为 | NFS服务器数据 | PV状态 |
|---------|---------------|--------------|--------|
| **Retain** | PV变为Released状态<br>需手动删除PV | 保留 | Released |
| **Delete** | 自动删除PV<br>自动删除底层存储数据 | 删除 | （PV已删除） |
| **Recycle**（废弃） | 执行`rm -rf /volume/*`<br>PV变回Available | 清空 | Available |

---

### 8.1.8 常见问题与排查

**问题1：PVC一直处于Pending状态**

```bash
$ kubectl get pvc
NAME        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
mysql-pvc   Pending                                      nfs-storage    5m
```

**排查步骤：**

```bash
# 1. 查看PVC详细事件
$ kubectl describe pvc mysql-pvc
Events:
  Type     Reason              Message
  ----     ------              -------
  Warning  ProvisioningFailed  Failed to provision volume with StorageClass "nfs-storage": storageclass.storage.k8s.io "nfs-storage" not found

# 可能原因：
# ✓ StorageClass不存在
# ✓ 没有匹配的PV（静态供应场景）
# ✓ PV容量不足
# ✓ 访问模式不匹配
# ✓ 标签选择器不匹配

# 2. 检查是否有可用PV
$ kubectl get pv
# 如果没有PV，需要创建或检查StorageClass是否支持动态供应

# 3. 检查StorageClass是否存在
$ kubectl get storageclass nfs-storage
```

**解决方案：**
- 创建匹配的PV（静态供应）
- 创建/修复StorageClass（动态供应）
- 调整PVC的请求容量或访问模式

---

**问题2：Pod无法挂载PVC**

```bash
$ kubectl get pod mysql
NAME    READY   STATUS              RESTARTS   AGE
mysql   0/1     ContainerCreating   0          2m
```

```bash
$ kubectl describe pod mysql
Events:
  Warning  FailedMount  Unable to attach or mount volumes: failed to attach volume "mysql-pv": rpc error: code = Internal desc = Could not mount "192.168.1.100:/data/mysql"
```

**可能原因：**
1. **NFS服务器不可达**
   ```bash
   # 在节点上测试NFS连接
   $ showmount -e 192.168.1.100
   clnt_create: RPC: Port mapper failure - Unable to receive: errno 113 (No route to host)
   ```
   解决：检查网络连通性、防火墙规则

2. **NFS目录不存在**
   ```bash
   # NFS服务器上检查
   $ ls -la /data/mysql
   ls: cannot access '/data/mysql': No such file or directory
   ```
   解决：创建目录并配置NFS导出

3. **节点缺少NFS客户端工具**
   ```bash
   # 节点上安装NFS客户端
   $ apt-get install -y nfs-common  # Debian/Ubuntu
   $ yum install -y nfs-utils       # CentOS/RHEL
   ```

---

**问题3：多个Pod竞争同一RWO PVC**

```yaml
# Deployment尝试创建2个副本，都使用同一个RWO PVC
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
spec:
  replicas: 2  # ❌ 错误：RWO PVC只能被单节点挂载
  template:
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: mysql-pvc  # RWO PVC
```

**现象：** 第二个Pod无法启动，报错"Multi-Attach error"

```bash
$ kubectl describe pod mysql-xxx
Events:
  Warning  FailedAttachVolume  Multi-Attach error for volume "pvc-xxx": Volume is already exclusively attached to one node and can't be attached to another
```

**解决方案：**
- ✅ 使用StatefulSet代替Deployment（下一节详解）
- ✅ 使用RWX模式的PVC（需要支持的存储后端如NFS）
- ✅ 将replicas设置为1

---

### 8.1.9 最佳实践总结

**1. Volume类型选择决策树**

```
需要持久化数据吗？
├─ 否 → emptyDir（容器间共享）或不使用Volume
└─ 是
   ├─ 数据只在本节点使用？
   │  └─ 是 → hostPath（谨慎使用）或local PV
   └─ 否
      ├─ 需要多节点同时读写（RWX）？
      │  ├─ 是 → NFS、CephFS、GlusterFS
      │  └─ 否 → AWS EBS、Azure Disk、GCE PD（RWO）
      └─ 数据是配置/密钥？
         ├─ 敏感数据 → Secret
         └─ 普通配置 → ConfigMap
```

**2. PV/PVC使用规范**

| 规范 | 说明 | 示例 |
|------|------|------|
| **PV命名** | 描述性名称，包含存储类型和用途 | `mysql-prod-nfs-pv`<br>`redis-cache-local-pv` |
| **PVC命名** | 与应用关联，描述用途 | `mysql-data-pvc`<br>`nginx-logs-pvc` |
| **容量规划** | PV容量略大于PVC请求（10-20%缓冲） | PVC请求10Gi，PV提供12Gi |
| **标签管理** | 使用标签标识环境、应用、团队 | `environment: production`<br>`app: mysql`<br>`team: platform` |
| **回收策略** | 生产环境使用Retain<br>开发环境可用Delete | `persistentVolumeReclaimPolicy: Retain` |
| **访问模式** | 根据应用需求精确选择 | 数据库用RWO<br>共享文件用RWX |

**3. 安全最佳实践**

```yaml
# ✅ 推荐配置
spec:
  containers:
  - name: app
    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true  # 只读挂载配置

  volumes:
  - name: config
    secret:
      secretName: app-secret
      defaultMode: 0400  # 限制文件权限为只读
```

**4. 性能优化建议**

- ✅ 数据库使用SSD后端（设置StorageClass的type参数）
- ✅ 日志数据使用HDD后端（成本优化）
- ✅ 避免在emptyDir中存储大量数据（占用节点空间）
- ✅ 对于高IOPS需求，使用本地SSD（local PV）

---

### 8.1.10 下一节预告

在本节中，我们建立了Kubernetes存储体系的整体认知：

- ✅ 理解了容器存储的挑战和Kubernetes的解决方案
- ✅ 掌握了PV、PVC、StorageClass的三层架构
- ✅ 学习了emptyDir、hostPath、ConfigMap、Secret等基础Volume类型
- ✅ 深入理解了PV/PVC的绑定机制和生命周期
- ✅ 通过MySQL案例完整实践了静态存储供应流程

然而,我们还有很多细节需要深入：

- **emptyDir的高级特性**：内存模式、大小限制
- **hostPath的安全隐患**：如何在生产环境安全使用
- **projected卷**：如何组合多个ConfigMap和Secret
- **downwardAPI卷**：如何将Pod元数据注入容器

**在下一节（8.2 Volume详解）中**，我们将深入学习各种Volume类型的高级特性、使用场景和最佳实践，为理解PV/PVC和StorageClass打下坚实基础。

---

**本节完**

*下一节预告：8.2节《Volume详解》- 深入emptyDir、hostPath、projected、downwardAPI等Volume类型的高级特性。*
## 8.2 Volume详解

在上一节中，我们建立了Kubernetes存储体系的整体认知，初步接触了emptyDir、hostPath、ConfigMap、Secret等基础Volume类型。本节将深入这些Volume的高级特性，探索更多实用的Volume类型，并通过丰富的实战案例掌握它们在生产环境中的应用。

---

### 8.2.1 emptyDir高级特性

emptyDir是Kubernetes中最简单但也最实用的Volume类型。在8.1节中我们了解了它的基本用法，现在深入其高级特性。

**核心特性回顾：**
- **生命周期**：与Pod绑定，Pod删除时数据随之删除
- **存储位置**：默认存储在节点的`/var/lib/kubelet/pods/<pod-uid>/volumes/kubernetes.io~empty-dir/<volume-name>`
- **典型用途**：临时缓存、容器间数据共享、检查点文件

---

#### 特性1：内存模式（Memory-backed emptyDir）

**配置方式：**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: memory-cache-pod
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      limits:
        memory: "512Mi"  # 重要：内存emptyDir会占用容器内存配额
    volumeMounts:
    - name: cache
      mountPath: /cache

  volumes:
  - name: cache
    emptyDir:
      medium: Memory  # 关键配置：使用内存而非磁盘
      sizeLimit: 256Mi  # 限制最大使用256MB内存
```

**工作原理：**

```
传统emptyDir（磁盘模式）
Pod容器 → /cache → emptyDir → 节点磁盘 /var/lib/kubelet/...
                              ↓
                          写入速度：~100-500 MB/s（取决于磁盘类型）

内存emptyDir（medium: Memory）
Pod容器 → /cache → emptyDir → 节点内存 tmpfs
                              ↓
                          写入速度：~5-10 GB/s（内存速度）
```

**性能对比测试：**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: emptydir-benchmark
spec:
  containers:
  - name: benchmark
    image: ubuntu:20.04
    command:
    - bash
    - -c
    - |
      echo "=== 测试磁盘emptyDir性能 ==="
      dd if=/dev/zero of=/disk-cache/test.dat bs=1M count=100
      
      echo ""
      echo "=== 测试内存emptyDir性能 ==="
      dd if=/dev/zero of=/memory-cache/test.dat bs=1M count=100
      
      echo ""
      echo "测试完成，保持运行..."
      sleep 3600
    volumeMounts:
    - name: disk-cache
      mountPath: /disk-cache
    - name: memory-cache
      mountPath: /memory-cache

  volumes:
  - name: disk-cache
    emptyDir: {}  # 默认磁盘模式

  - name: memory-cache
    emptyDir:
      medium: Memory
      sizeLimit: 200Mi
```

**执行测试：**

```bash
# 创建测试Pod
$ kubectl apply -f emptydir-benchmark.yaml
pod/emptydir-benchmark created

# 等待Pod运行
$ kubectl wait --for=condition=Ready pod/emptydir-benchmark --timeout=60s

# 查看测试结果
$ kubectl logs emptydir-benchmark
=== 测试磁盘emptyDir性能 ===
100+0 records in
100+0 records out
104857600 bytes (105 MB, 100 MiB) copied, 0.524876 s, 200 MB/s

=== 测试内存emptyDir性能 ===
100+0 records in
100+0 records out
104857600 bytes (105 MB, 100 MiB) copied, 0.0153821 s, 6.8 GB/s

# 内存模式速度是磁盘模式的 34 倍！
```

**内存模式的注意事项：**

1. **占用Pod内存配额**
   ```yaml
   spec:
     containers:
     - name: app
       resources:
         limits:
           memory: "512Mi"  # emptyDir的256Mi会计入此限制
       volumeMounts:
       - name: cache
         mountPath: /cache
     volumes:
     - name: cache
       emptyDir:
         medium: Memory
         sizeLimit: 256Mi  # 实际Pod可用内存 = 512Mi - 256Mi = 256Mi
   ```

2. **节点内存压力**
   ```bash
   # 如果节点内存不足，内存emptyDir的数据可能被回收
   $ kubectl describe node node1
   Conditions:
     Type             Status  Reason
     ----             ------  ------
     MemoryPressure   True    KubeletHasInsufficientMemory
   
   # 此时内存emptyDir可能被清空，导致数据丢失
   ```

3. **数据丢失风险**
   - ❌ **不要存储关键数据**：内存断电即丢失
   - ❌ **不要超过sizeLimit**：超出限制Pod可能被驱逐
   - ✅ **适用场景**：高频读写的临时缓存、编译产物

**典型应用场景：**

```yaml
# 场景1：Redis缓存加速
apiVersion: v1
kind: Pod
metadata:
  name: redis-with-memory-cache
spec:
  containers:
  - name: redis
    image: redis:7.0
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    # 禁用持久化，纯内存缓存
    volumeMounts:
    - name: redis-data
      mountPath: /data

  volumes:
  - name: redis-data
    emptyDir:
      medium: Memory
      sizeLimit: 1Gi
```

---

#### 特性2：容量限制（sizeLimit）

**作用：** 限制emptyDir的最大使用空间，防止磁盘/内存被耗尽。

**磁盘模式的sizeLimit：**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: disk-limit-test
spec:
  containers:
  - name: writer
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      # 尝试写入150MB数据（超过100Mi限制）
      dd if=/dev/zero of=/data/large-file bs=1M count=150 || echo "写入失败"
      df -h /data
      sleep 3600
    volumeMounts:
    - name: limited-volume
      mountPath: /data

  volumes:
  - name: limited-volume
    emptyDir:
      sizeLimit: 100Mi  # 限制最大100MB
```

**测试结果：**

```bash
$ kubectl logs disk-limit-test
dd: error writing '/data/large-file': No space left on device
写入失败
Filesystem      Size  Used Avail Use% Mounted on
tmpfs           100M  100M     0 100% /data
```

**重要机制：**

1. **Kubelet驱逐机制**
   ```bash
   # 当emptyDir使用超过sizeLimit时
   $ kubectl get pod disk-limit-test
   NAME              READY   STATUS    RESTARTS   AGE
   disk-limit-test   0/1     Evicted   0          2m
   
   $ kubectl describe pod disk-limit-test
   Status:  Failed
   Reason:  Evicted
   Message: Pod ephemeral local storage usage exceeds the total limit of containers 100Mi
   ```

2. **监控emptyDir使用量**
   ```bash
   # 进入Pod查看实际使用量
   $ kubectl exec -it <pod> -- df -h /cache
   Filesystem      Size  Used Avail Use% Mounted on
   overlay         100M   45M   55M  45% /cache
   ```

**最佳实践：**

```yaml
# ✅ 推荐配置
volumes:
- name: build-cache
  emptyDir:
    sizeLimit: 5Gi  # 明确设置限制
    # medium: Memory  # 只有需要极致性能时才用内存模式

# ❌ 不推荐
volumes:
- name: build-cache
  emptyDir: {}  # 没有sizeLimit，可能耗尽节点磁盘
```

---

#### 特性3：容器间数据共享

**场景：** 一个Pod中的多个容器需要共享数据（如日志采集、初始化数据）。

**示例1：Sidecar日志采集模式**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: logging-sidecar
spec:
  containers:
  # 主容器：生成日志
  - name: app
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      while true; do
        echo "$(date) - Application log entry" >> /var/log/app.log
        sleep 1
      done
    volumeMounts:
    - name: logs
      mountPath: /var/log

  # Sidecar容器：采集日志
  - name: log-collector
    image: fluent/fluentd:v1.14
    volumeMounts:
    - name: logs
      mountPath: /var/log
      readOnly: true  # 只读挂载，防止误修改

  volumes:
  - name: logs
    emptyDir:
      sizeLimit: 500Mi
```

**示例2：Init容器准备数据**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-demo
spec:
  # Init容器：下载配置文件
  initContainers:
  - name: config-downloader
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "Downloading config files..."
      echo "server { listen 80; }" > /config/nginx.conf
      echo "Config downloaded successfully"
    volumeMounts:
    - name: config
      mountPath: /config

  # 主容器：使用配置文件
  containers:
  - name: nginx
    image: nginx:1.21
    volumeMounts:
    - name: config
      mountPath: /etc/nginx/conf.d
      readOnly: true

  volumes:
  - name: config
    emptyDir: {}
```

**验证数据共享：**

```bash
# 创建Pod
$ kubectl apply -f init-container-demo.yaml

# 查看Init容器日志
$ kubectl logs init-container-demo -c config-downloader
Downloading config files...
Config downloaded successfully

# 验证主容器是否能访问配置
$ kubectl exec init-container-demo -- cat /etc/nginx/conf.d/nginx.conf
server { listen 80; }
```

---

### 8.2.2 hostPath安全使用指南

hostPath允许Pod访问节点的文件系统，功能强大但风险极大。生产环境必须谨慎使用。

---

#### 安全风险分析

**风险1：容器逃逸**

```yaml
# ❌ 危险示例：挂载Docker socket
apiVersion: v1
kind: Pod
metadata:
  name: dangerous-pod
spec:
  containers:
  - name: hacker
    image: docker:20.10
    command:
    - sh
    - -c
    - |
      # 攻击者可以通过Docker socket控制宿主机
      docker run -v /:/host --privileged alpine chroot /host bash
      # 现在拥有宿主机root权限！
    volumeMounts:
    - name: docker-sock
      mountPath: /var/run/docker.sock

  volumes:
  - name: docker-sock
    hostPath:
      path: /var/run/docker.sock
      type: Socket
```

**风险2：敏感数据泄露**

```yaml
# ❌ 危险示例：挂载系统敏感目录
volumes:
- name: etc-passwd
  hostPath:
    path: /etc  # 暴露整个/etc目录
    type: Directory

# 攻击者可以读取：
# /etc/shadow   - 用户密码哈希
# /etc/ssh/*    - SSH密钥
# /etc/kubernetes/* - K8s证书和配置
```

**风险3：节点资源耗尽**

```yaml
# ❌ 危险示例：写入大量数据到节点磁盘
volumes:
- name: node-disk
  hostPath:
    path: /var/log/pods  # 写入大量日志
    type: DirectoryOrCreate

# 可能导致节点磁盘被填满，影响所有Pod
```

---

#### 安全使用规范

**规范1：最小权限原则**

```yaml
# ✅ 推荐：只读挂载
apiVersion: v1
kind: Pod
metadata:
  name: safe-hostpath-pod
spec:
  containers:
  - name: app
    image: nginx:1.21
    volumeMounts:
    - name: timezone
      mountPath: /etc/localtime
      readOnly: true  # 关键：只读挂载

  volumes:
  - name: timezone
    hostPath:
      path: /etc/localtime
      type: File  # 类型校验：必须是文件
```

**规范2：路径白名单**

```yaml
# ✅ 允许的路径（相对安全）
允许：
  - /etc/localtime           # 时区同步
  - /etc/timezone            # 时区配置
  - /var/log                 # 日志采集（只读）
  - /sys/fs/cgroup           # cgroup信息（只读）

# ❌ 禁止的路径（高危）
禁止：
  - /                        # 根目录
  - /etc                     # 系统配置目录
  - /root                    # root用户目录
  - /var/run/docker.sock     # Docker socket
  - /etc/kubernetes          # K8s配置目录
  - /var/lib/kubelet         # Kubelet数据目录
```

**规范3：使用PodSecurityPolicy限制（K8s 1.21前）**

```yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: restricted-hostpath
spec:
  # 允许的hostPath路径
  allowedHostPaths:
  - pathPrefix: /etc/localtime
    readOnly: true
  - pathPrefix: /var/log
    readOnly: true

  # 禁止挂载Docker socket
  volumes:
  - configMap
  - emptyDir
  - secret
  - hostPath  # 虽然允许hostPath，但通过allowedHostPaths限制路径

  # 禁止特权模式
  privileged: false
  
  # 禁止访问主机网络
  hostNetwork: false
  hostPID: false
  hostIPC: false
```

**规范4：使用Pod Security Standards（K8s 1.23+）**

```yaml
# Namespace级别限制
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

# restricted策略会自动拒绝hostPath（除非特别配置）
```

---

#### 典型安全场景

**场景1：时区同步（安全）**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-timezone
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0
        volumeMounts:
        - name: localtime
          mountPath: /etc/localtime
          readOnly: true  # ✅ 只读

      volumes:
      - name: localtime
        hostPath:
          path: /etc/localtime
          type: File  # ✅ 类型校验
```

**场景2：节点日志采集（DaemonSet专用）**

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: log-collector
  namespace: kube-system  # ✅ 系统命名空间，受严格RBAC控制
spec:
  selector:
    matchLabels:
      app: log-collector
  template:
    metadata:
      labels:
        app: log-collector
    spec:
      serviceAccountName: log-collector  # ✅ 专用ServiceAccount
      
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.14
        volumeMounts:
        - name: varlog
          mountPath: /var/log
          readOnly: true  # ✅ 只读
        - name: containers
          mountPath: /var/lib/docker/containers
          readOnly: true  # ✅ 只读

      volumes:
      - name: varlog
        hostPath:
          path: /var/log
          type: Directory
      - name: containers
        hostPath:
          path: /var/lib/docker/containers
          type: DirectoryOrCreate

      # ✅ 节点选择器（可选）
      nodeSelector:
        logging: enabled
```

**场景3：监控节点指标（安全）**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-exporter
spec:
  hostNetwork: true  # 需要访问主机网络
  hostPID: true      # 需要访问主机进程
  
  containers:
  - name: node-exporter
    image: prom/node-exporter:v1.3.1
    args:
    - --path.procfs=/host/proc
    - --path.sysfs=/host/sys
    - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
    
    volumeMounts:
    - name: proc
      mountPath: /host/proc
      readOnly: true  # ✅ 只读
    - name: sys
      mountPath: /host/sys
      readOnly: true  # ✅ 只读

  volumes:
  - name: proc
    hostPath:
      path: /proc
      type: Directory
  - name: sys
    hostPath:
      path: /sys
      type: Directory
```

---

### 8.2.3 projected卷：组合多个数据源

**定义：** projected卷可以将多个Volume源（ConfigMap、Secret、DownwardAPI、ServiceAccountToken）组合到同一个目录。

**优势：**
- ✅ 统一挂载点，简化配置
- ✅ 避免目录冲突
- ✅ 支持权限统一设置

---

#### 基础语法

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: projected-volume-demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    volumeMounts:
    - name: all-in-one
      mountPath: /projected-volume
      readOnly: true

  volumes:
  - name: all-in-one
    projected:
      defaultMode: 0644  # 统一设置文件权限
      sources:
      # 数据源1：ConfigMap
      - configMap:
          name: app-config
          items:
          - key: app.properties
            path: config/app.properties

      # 数据源2：Secret
      - secret:
          name: db-credentials
          items:
          - key: username
            path: secrets/db-user
          - key: password
            path: secrets/db-pass

      # 数据源3：DownwardAPI
      - downwardAPI:
          items:
          - path: labels
            fieldRef:
              fieldPath: metadata.labels
          - path: namespace
            fieldRef:
              fieldPath: metadata.namespace

      # 数据源4：ServiceAccountToken
      - serviceAccountToken:
          path: token
          expirationSeconds: 3600
          audience: my-service
```

**挂载后的目录结构：**

```bash
$ kubectl exec projected-volume-demo -- tree /projected-volume
/projected-volume
├── config
│   └── app.properties       # 来自ConfigMap
├── secrets
│   ├── db-user              # 来自Secret
│   └── db-pass              # 来自Secret
├── labels                   # 来自DownwardAPI
├── namespace                # 来自DownwardAPI
└── token                    # ServiceAccountToken

2 directories, 5 files
```

---

#### 实战案例：应用配置集中管理

**场景：** 一个Web应用需要：
1. 应用配置文件（ConfigMap）
2. 数据库密码（Secret）
3. Pod元数据（DownwardAPI）
4. 服务间认证Token（ServiceAccountToken）

**步骤1：创建ConfigMap和Secret**

```yaml
# 应用配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: webapp-config
data:
  application.yaml: |
    server:
      port: 8080
    logging:
      level: INFO
    feature-flags:
      new-ui: true

---
# 数据库密码
apiVersion: v1
kind: Secret
metadata:
  name: webapp-secret
type: Opaque
data:
  db-password: bXlzcWwxMjM0NTY=  # mysql123456
  api-key: YWJjZDEyMzQ1Njc4OTA=   # abcd1234567890
```

**步骤2：创建使用projected卷的Pod**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: webapp
  labels:
    app: webapp
    version: v1.0
    environment: production
spec:
  serviceAccountName: webapp-sa  # 专用ServiceAccount
  
  containers:
  - name: app
    image: mywebapp:1.0
    env:
    # 从projected卷读取密码（通过环境变量）
    - name: DB_PASSWORD_FILE
      value: /app-config/secrets/db-password
    - name: API_KEY_FILE
      value: /app-config/secrets/api-key
    
    volumeMounts:
    - name: app-config
      mountPath: /app-config
      readOnly: true

  volumes:
  - name: app-config
    projected:
      defaultMode: 0400  # 只读权限（重要：保护敏感数据）
      sources:
      # 1. 应用配置
      - configMap:
          name: webapp-config
          items:
          - key: application.yaml
            path: config/application.yaml

      # 2. 敏感信息
      - secret:
          name: webapp-secret
          items:
          - key: db-password
            path: secrets/db-password
          - key: api-key
            path: secrets/api-key

      # 3. Pod元数据
      - downwardAPI:
          items:
          - path: metadata/pod-name
            fieldRef:
              fieldPath: metadata.name
          - path: metadata/pod-namespace
            fieldRef:
              fieldPath: metadata.namespace
          - path: metadata/pod-ip
            fieldRef:
              fieldPath: status.podIP
          - path: metadata/labels
            fieldRef:
              fieldPath: metadata.labels
          - path: metadata/annotations
            fieldRef:
              fieldPath: metadata.annotations

      # 4. 服务账户Token（用于调用其他K8s服务）
      - serviceAccountToken:
          path: tokens/api-token
          expirationSeconds: 7200  # 2小时过期
          audience: kubernetes.default.svc
```

**步骤3：应用内读取配置**

```python
# Python应用示例
import os
import yaml

# 读取配置文件
with open('/app-config/config/application.yaml') as f:
    config = yaml.safe_load(f)
    print(f"Server port: {config['server']['port']}")

# 读取Secret
with open('/app-config/secrets/db-password') as f:
    db_password = f.read().strip()
    print(f"DB Password loaded: {'*' * len(db_password)}")

# 读取Pod元数据
with open('/app-config/metadata/pod-name') as f:
    pod_name = f.read().strip()
    print(f"Running in Pod: {pod_name}")

with open('/app-config/metadata/pod-ip') as f:
    pod_ip = f.read().strip()
    print(f"Pod IP: {pod_ip}")

# 读取ServiceAccount Token
with open('/app-config/tokens/api-token') as f:
    token = f.read().strip()
    print(f"Token loaded: {token[:20]}...")
```

**验证：**

```bash
# 创建资源
$ kubectl apply -f webapp-config.yaml
$ kubectl apply -f webapp.yaml

# 查看挂载的文件
$ kubectl exec webapp -- ls -la /app-config
total 0
drwxr-xr-x 5 root root  80 Jan 13 15:30 .
drwxr-xr-x 1 root root  20 Jan 13 15:30 ..
drwxr-xr-x 2 root root  40 Jan 13 15:30 config
drwxr-xr-x 2 root root  40 Jan 13 15:30 metadata
drwxr-xr-x 2 root root  40 Jan 13 15:30 secrets
drwxr-xr-x 2 root root  20 Jan 13 15:30 tokens

# 查看配置文件
$ kubectl exec webapp -- cat /app-config/config/application.yaml
server:
  port: 8080
logging:
  level: INFO
feature-flags:
  new-ui: true

# 查看Pod元数据
$ kubectl exec webapp -- cat /app-config/metadata/pod-name
webapp

$ kubectl exec webapp -- cat /app-config/metadata/labels
app="webapp"
environment="production"
version="v1.0"
```

---

### 8.2.4 downwardAPI卷：Pod元数据注入

**定义：** downwardAPI卷允许将Pod的元数据（labels、annotations、资源限制等）以文件形式暴露给容器。

**支持的字段：**

| 字段类别 | fieldRef可用字段 | resourceFieldRef可用字段 |
|---------|----------------|------------------------|
| **基本信息** | `metadata.name`<br>`metadata.namespace`<br>`metadata.uid` | - |
| **标签和注解** | `metadata.labels`<br>`metadata.annotations` | - |
| **网络信息** | `status.podIP`<br>`status.hostIP` | - |
| **服务账户** | `spec.serviceAccountName` | - |
| **节点信息** | `spec.nodeName` | - |
| **资源信息** | - | `limits.cpu`<br>`limits.memory`<br>`requests.cpu`<br>`requests.memory` |

---

#### 基础示例

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: downwardapi-demo
  labels:
    app: myapp
    tier: frontend
  annotations:
    version: "1.0.0"
    build-id: "20240113-abc123"
spec:
  containers:
  - name: app
    image: busybox:1.35
    command: ['sh', '-c', 'sleep 3600']
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "200m"
        memory: "256Mi"
    volumeMounts:
    - name: podinfo
      mountPath: /etc/podinfo

  volumes:
  - name: podinfo
    downwardAPI:
      items:
      # Pod基本信息
      - path: pod-name
        fieldRef:
          fieldPath: metadata.name
      - path: pod-namespace
        fieldRef:
          fieldPath: metadata.namespace
      - path: pod-ip
        fieldRef:
          fieldPath: status.podIP

      # 标签和注解（以键值对形式）
      - path: labels
        fieldRef:
          fieldPath: metadata.labels
      - path: annotations
        fieldRef:
          fieldPath: metadata.annotations

      # 资源限制
      - path: cpu-limit
        resourceFieldRef:
          containerName: app
          resource: limits.cpu
      - path: memory-limit
        resourceFieldRef:
          containerName: app
          resource: limits.memory
```

**查看注入的数据：**

```bash
# 查看Pod名称
$ kubectl exec downwardapi-demo -- cat /etc/podinfo/pod-name
downwardapi-demo

# 查看Pod IP
$ kubectl exec downwardapi-demo -- cat /etc/podinfo/pod-ip
10.244.1.15

# 查看标签
$ kubectl exec downwardapi-demo -- cat /etc/podinfo/labels
app="myapp"
tier="frontend"

# 查看注解
$ kubectl exec downwardapi-demo -- cat /etc/podinfo/annotations
version="1.0.0"
build-id="20240113-abc123"

# 查看资源限制
$ kubectl exec downwardapi-demo -- cat /etc/podinfo/cpu-limit
1  # 200m转换为CPU核心数 = 0.2（显示为整数1是因为单位转换）

$ kubectl exec downwardapi-demo -- cat /etc/podinfo/memory-limit
268435456  # 256Mi = 256 * 1024 * 1024 字节
```

---

#### 实战案例：应用自适应配置

**场景：** 应用需要根据自身的资源配额自动调整参数（如JVM堆大小、线程池大小）。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: java-app-autotune
  labels:
    app: java-app
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
spec:
  containers:
  - name: app
    image: openjdk:11-jre
    command:
    - bash
    - -c
    - |
      # 读取内存限制
      MEMORY_LIMIT=$(cat /etc/podinfo/memory-limit)
      MEMORY_LIMIT_MB=$((MEMORY_LIMIT / 1024 / 1024))
      
      # 自动计算JVM堆大小（80%的Pod内存限制）
      HEAP_SIZE=$((MEMORY_LIMIT_MB * 80 / 100))
      
      # 读取CPU限制
      CPU_LIMIT=$(cat /etc/podinfo/cpu-limit)
      
      echo "Pod Memory Limit: ${MEMORY_LIMIT_MB}MB"
      echo "JVM Heap Size: ${HEAP_SIZE}MB"
      echo "CPU Limit: ${CPU_LIMIT} cores"
      
      # 启动Java应用
      java -Xmx${HEAP_SIZE}m \
           -XX:+UseG1GC \
           -XX:ParallelGCThreads=${CPU_LIMIT} \
           -jar /app/application.jar

    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "1Gi"

    volumeMounts:
    - name: podinfo
      mountPath: /etc/podinfo
      readOnly: true

  volumes:
  - name: podinfo
    downwardAPI:
      items:
      - path: memory-limit
        resourceFieldRef:
          containerName: app
          resource: limits.memory
          divisor: "1"  # 返回字节数
      - path: cpu-limit
        resourceFieldRef:
          containerName: app
          resource: limits.cpu
          divisor: "1m"  # 返回毫核数
```

**运行结果：**

```bash
$ kubectl logs java-app-autotune
Pod Memory Limit: 1024MB
JVM Heap Size: 819MB
CPU Limit: 1000 cores
```

---

### 8.2.5 subPath和subPathExpr

**问题：** 默认情况下，Volume会覆盖挂载目标目录的所有内容。

```yaml
# ❌ 问题示例
containers:
- name: app
  image: nginx:1.21
  volumeMounts:
  - name: config
    mountPath: /etc/nginx  # 整个/etc/nginx目录被覆盖，原有文件丢失
volumes:
- name: config
  configMap:
    name: nginx-config
```

**解决方案：** 使用`subPath`只挂载Volume中的单个文件。

---

#### subPath基础用法

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  custom.conf: |
    server {
        listen 8080;
        server_name example.com;
    }

---
apiVersion: v1
kind: Pod
metadata:
  name: nginx-subpath
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    volumeMounts:
    - name: config
      mountPath: /etc/nginx/conf.d/custom.conf  # 挂载到具体文件
      subPath: custom.conf  # 只挂载ConfigMap中的custom.conf

  volumes:
  - name: config
    configMap:
      name: nginx-config
```

**验证：**

```bash
# 查看/etc/nginx目录
$ kubectl exec nginx-subpath -- ls -la /etc/nginx
total 40
drwxr-xr-x 1 root root 4096 Jan 13 16:00 .
drwxr-xr-x 1 root root 4096 Jan 13 16:00 ..
drwxr-xr-x 2 root root 4096 Jan 13 16:00 conf.d  # 原有目录保留
-rw-r--r-- 1 root root 1007 Jan  1 12:00 fastcgi_params  # 原有文件保留
-rw-r--r-- 1 root root  648 Jan  1 12:00 mime.types
-rw-r--r-- 1 root root  636 Jan  1 12:00 nginx.conf

# 查看挂载的文件
$ kubectl exec nginx-subpath -- cat /etc/nginx/conf.d/custom.conf
server {
    listen 8080;
    server_name example.com;
}
```

---

#### subPathExpr动态路径

**场景：** 需要根据Pod信息动态生成挂载路径（如按Pod名称隔离日志目录）。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: logger-pod-001
spec:
  containers:
  - name: app
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "Logging from $(hostname)" >> /logs/app.log
      tail -f /logs/app.log
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    volumeMounts:
    - name: logs
      mountPath: /logs
      subPathExpr: $(POD_NAME)  # 动态路径：/var/log/pods/logger-pod-001

  volumes:
  - name: logs
    hostPath:
      path: /var/log/pods
      type: DirectoryOrCreate
```

**验证：**

```bash
# 创建多个Pod
$ kubectl apply -f logger-pod.yaml
$ sed 's/logger-pod-001/logger-pod-002/g' logger-pod.yaml | kubectl apply -f -

# 查看节点目录结构
$ kubectl get pod -o wide  # 找到Pod所在节点
$ ssh node1
$ tree /var/log/pods
/var/log/pods
├── logger-pod-001
│   └── app.log
└── logger-pod-002
    └── app.log

# 每个Pod的日志隔离在独立目录
```

---

### 8.2.6 临时卷（Ephemeral Volumes）

Kubernetes 1.23+引入了更多临时卷类型。

---

#### Generic Ephemeral Volume（通用临时卷）

**定义：** 支持任何StorageClass的临时PVC，Pod删除时自动清理。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ephemeral-volume-demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    volumeMounts:
    - name: scratch
      mountPath: /scratch

  volumes:
  - name: scratch
    ephemeral:
      volumeClaimTemplate:
        metadata:
          labels:
            type: scratch-space
        spec:
          accessModes: [ "ReadWriteOnce" ]
          storageClassName: "fast-ssd"  # 使用SSD StorageClass
          resources:
            requests:
              storage: 1Gi
```

**特点：**
- ✅ 自动创建PVC（命名格式：`<pod-name>-<volume-name>`）
- ✅ Pod删除时自动删除PVC和底层存储
- ✅ 支持所有StorageClass特性（快照、克隆、扩容等）

---

### 8.2.7 完整实战案例：多层Volume组合

**场景：** 部署一个完整的微服务应用，综合使用多种Volume类型。

**应用架构：**
- **应用容器**：Node.js Web服务
- **Sidecar容器**：Nginx反向代理
- **Init容器**：下载静态资源

**存储需求：**
1. 应用配置（ConfigMap）
2. TLS证书（Secret）
3. 临时缓存（emptyDir内存模式）
4. 静态文件（emptyDir共享）
5. 日志存储（hostPath，DaemonSet采集）
6. Pod元数据（downwardAPI）

**完整配置：**

```yaml
# 第一步：创建ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  app.json: |
    {
      "port": 3000,
      "logLevel": "info",
      "cacheEnabled": true
    }
  nginx.conf: |
    upstream app {
        server 127.0.0.1:3000;
    }
    server {
        listen 80;
        location / {
            proxy_pass http://app;
        }
    }

---
# 第二步：创建Secret
apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
type: kubernetes.io/tls
data:
  tls.crt: LS0tLS1CRUdJTi...  # Base64编码的证书
  tls.key: LS0tLS1CRUdJTi...  # Base64编码的私钥

---
# 第三步：部署Pod
apiVersion: v1
kind: Pod
metadata:
  name: microservice-app
  labels:
    app: microservice
    tier: backend
  annotations:
    version: "2.0.0"
    maintainer: "devops@example.com"
spec:
  # Init容器：下载静态资源
  initContainers:
  - name: assets-downloader
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "Downloading assets..."
      mkdir -p /static/css /static/js
      echo "body { color: blue; }" > /static/css/style.css
      echo "console.log('App loaded');" > /static/js/app.js
      echo "Assets downloaded successfully"
    volumeMounts:
    - name: static-files
      mountPath: /static

  # 主容器1：Node.js应用
  containers:
  - name: app
    image: node:16-alpine
    command:
    - node
    - -e
    - |
      const http = require('http');
      const fs = require('fs');
      
      // 读取配置
      const config = JSON.parse(fs.readFileSync('/config/app.json'));
      
      // 读取Pod元数据
      const podName = fs.readFileSync('/podinfo/pod-name', 'utf8');
      const podIP = fs.readFileSync('/podinfo/pod-ip', 'utf8');
      
      const server = http.createServer((req, res) => {
        const log = `${new Date().toISOString()} - ${req.method} ${req.url}\n`;
        fs.appendFileSync('/logs/access.log', log);
        
        res.writeHead(200);
        res.end(`Hello from ${podName} (${podIP})\n`);
      });
      
      server.listen(config.port, () => {
        console.log(`Server running on port ${config.port}`);
      });
    
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "200m"
        memory: "256Mi"
    
    volumeMounts:
    # 配置文件
    - name: app-config
      mountPath: /config
      readOnly: true
    # 临时缓存（内存）
    - name: cache
      mountPath: /cache
    # 静态文件（与Init容器共享）
    - name: static-files
      mountPath: /static
      readOnly: true
    # 日志
    - name: logs
      mountPath: /logs
    # Pod元数据
    - name: podinfo
      mountPath: /podinfo
      readOnly: true

  # 主容器2：Nginx Sidecar
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    # Nginx配置
    - name: nginx-config
      mountPath: /etc/nginx/conf.d/default.conf
      subPath: nginx.conf
    # TLS证书
    - name: tls
      mountPath: /etc/nginx/ssl
      readOnly: true
    # 静态文件（与App容器共享）
    - name: static-files
      mountPath: /usr/share/nginx/html/static
      readOnly: true
    # 日志（与App容器共享）
    - name: logs
      mountPath: /var/log/nginx

  # Volume定义
  volumes:
  # 1. ConfigMap：应用配置
  - name: app-config
    configMap:
      name: app-config
      items:
      - key: app.json
        path: app.json

  # 2. ConfigMap：Nginx配置
  - name: nginx-config
    configMap:
      name: app-config

  # 3. Secret：TLS证书
  - name: tls
    secret:
      secretName: tls-secret
      defaultMode: 0400

  # 4. emptyDir：内存缓存
  - name: cache
    emptyDir:
      medium: Memory
      sizeLimit: 100Mi

  # 5. emptyDir：静态文件共享
  - name: static-files
    emptyDir:
      sizeLimit: 500Mi

  # 6. hostPath：日志持久化
  - name: logs
    hostPath:
      path: /var/log/pods/microservice-app
      type: DirectoryOrCreate

  # 7. downwardAPI：Pod元数据
  - name: podinfo
    downwardAPI:
      items:
      - path: pod-name
        fieldRef:
          fieldPath: metadata.name
      - path: pod-ip
        fieldRef:
          fieldPath: status.podIP
      - path: labels
        fieldRef:
          fieldPath: metadata.labels
```

**部署和验证：**

```bash
# 创建资源
$ kubectl apply -f app-config.yaml
$ kubectl apply -f tls-secret.yaml
$ kubectl apply -f microservice-app.yaml

# 等待Pod运行
$ kubectl wait --for=condition=Ready pod/microservice-app --timeout=60s

# 查看Init容器日志
$ kubectl logs microservice-app -c assets-downloader
Downloading assets...
Assets downloaded successfully

# 查看应用日志
$ kubectl logs microservice-app -c app
Server running on port 3000

# 测试应用
$ kubectl exec microservice-app -c nginx -- curl localhost
Hello from microservice-app (10.244.1.25)

# 验证Volume挂载
$ kubectl exec microservice-app -c app -- ls -la /config
-rw-r--r-- 1 root root  65 Jan 13 17:00 app.json

$ kubectl exec microservice-app -c app -- ls -la /static
drwxr-xr-x 2 root root   40 Jan 13 17:00 css
drwxr-xr-x 2 root root   40 Jan 13 17:00 js

$ kubectl exec microservice-app -c app -- cat /podinfo/labels
app="microservice"
tier="backend"

# 查看日志文件
$ kubectl exec microservice-app -c app -- cat /logs/access.log
2024-01-13T17:05:23.123Z - GET /
2024-01-13T17:05:24.456Z - GET /health
```

---

### 8.2.8 Volume使用最佳实践总结

**1. Volume类型选择决策**

```
需求场景                    → 推荐Volume类型
─────────────────────────────────────────
容器间临时数据共享           → emptyDir
高性能临时缓存               → emptyDir (medium: Memory)
配置文件注入                 → ConfigMap
敏感信息（密码/证书）        → Secret
Pod元数据访问               → downwardAPI
多数据源组合                 → projected
节点文件访问（谨慎）         → hostPath (readOnly: true)
持久化数据                   → PVC (下一节详解)
```

**2. 性能优化建议**

| 场景 | 配置 | 性能提升 |
|------|------|---------|
| **编译缓存** | `emptyDir` + `medium: Memory` | 10-50倍 |
| **静态资源** | `emptyDir` + CDN分发 | 减少网络I/O |
| **日志缓冲** | `emptyDir` + 异步刷盘 | 降低磁盘压力 |
| **大文件读写** | PVC + SSD StorageClass | 2-5倍 |

**3. 安全加固清单**

```yaml
# ✅ 安全配置模板
volumes:
- name: sensitive-config
  secret:
    secretName: app-secret
    defaultMode: 0400  # 只有所有者可读
    
volumeMounts:
- name: sensitive-config
  mountPath: /etc/secrets
  readOnly: true  # 只读挂载

# ✅ hostPath严格限制
- name: logs
  hostPath:
    path: /var/log/app  # 白名单路径
    type: Directory     # 类型校验
volumeMounts:
- name: logs
  mountPath: /logs
  readOnly: true  # 只读（日志采集场景）
```

**4. 资源配额建议**

```yaml
# emptyDir容量规划
volumes:
- name: build-cache
  emptyDir:
    sizeLimit: 5Gi  # ✅ 始终设置限制

containers:
- name: app
  resources:
    limits:
      memory: "1Gi"  # ✅ 内存emptyDir计入此限制
  volumeMounts:
  - name: cache
    mountPath: /cache
    
volumes:
- name: cache
  emptyDir:
    medium: Memory
    sizeLimit: 256Mi  # 实际可用内存 = 1Gi - 256Mi
```

---

### 8.2.9 下一节预告

在本节中，我们深入学习了Volume的高级特性：

- ✅ emptyDir的内存模式和容量限制
- ✅ hostPath的安全风险和使用规范
- ✅ projected卷的多数据源组合
- ✅ downwardAPI卷的Pod元数据注入
- ✅ subPath和subPathExpr的文件级挂载
- ✅ 完整微服务应用的多层Volume组合实战

这些Volume类型适用于临时数据、配置管理和元数据访问。然而，对于需要持久化的数据（如数据库、用户上传文件），我们需要使用**PersistentVolume（PV）和PersistentVolumeClaim（PVC）**。

**在下一节（8.3 持久卷PersistentVolume）中**，我们将深入学习：
- PV的生命周期管理（Available → Bound → Released → Failed）
- 访问模式的深入理解（RWO/RWX/ROX的选择和限制）
- 回收策略的实际影响（Retain/Delete/Recycle）
- 静态供应的完整实战（NFS/iSCSI/Local PV）
- PV容量回收和状态恢复

---

**本节完**

*下一节预告：8.3节《持久卷PersistentVolume》- 深入PV的生命周期、访问模式、回收策略和静态供应实战。*
