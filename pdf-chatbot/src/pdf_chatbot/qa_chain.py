"""é—®ç­”é“¾æ¨¡å—ï¼ˆæ”¯æŒå¯¹è¯è®°å¿†å’Œæµå¼è¾“å‡ºï¼‰"""
import sys
import time
import json
from datetime import datetime
from pathlib import Path
from typing import Tuple, Optional
from langchain.chains import ConversationalRetrievalChain, RetrievalQA
from langchain_openai import ChatOpenAI
from langchain_core.memory import ConversationBufferMemory
from langchain_core.callbacks import BaseCallbackHandler

from .config import Config
from .vector_store import VectorStoreManager


class StreamingCallbackHandler(BaseCallbackHandler):
    """
    æµå¼è¾“å‡ºå›è°ƒå¤„ç†å™¨

    åŠŸèƒ½:
        - å®æ—¶é€å­—ç¬¦/é€è¯æ‰“å° LLM ç”Ÿæˆçš„å†…å®¹
        - æ”¶é›†å®Œæ•´ç­”æ¡ˆç”¨äºä¿å­˜åˆ°å†å²è®°å½•
    """

    def __init__(self):
        self.answer = ""  # æ”¶é›†å®Œæ•´ç­”æ¡ˆ
        self.is_first_token = True  # æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ª token

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """
        æ¯å½“ LLM ç”Ÿæˆæ–° token æ—¶è°ƒç”¨

        å‚æ•°:
            token: æ–°ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        # ç¬¬ä¸€ä¸ª token å‰æ‰“å°æç¤º
        if self.is_first_token:
            print("\nğŸ’¡ ç­”æ¡ˆ: ", end="", flush=True)
            self.is_first_token = False

        # å®æ—¶æ‰“å°
        print(token, end="", flush=True)

        # æ”¶é›†å®Œæ•´ç­”æ¡ˆ
        self.answer += token

    def reset(self):
        """é‡ç½®çŠ¶æ€ï¼Œç”¨äºä¸‹ä¸€æ¬¡é—®ç­”"""
        self.answer = ""
        self.is_first_token = True


def get_confidence_level(distance: float) -> Tuple[str, str, float]:
    """
    æ ¹æ®ä½™å¼¦è·ç¦»åˆ¤æ–­å¯ä¿¡åº¦

    å‚æ•°:
        distance: ä½™å¼¦è·ç¦»ï¼ˆ0-2ï¼ŒChroma è¿”å›å€¼ï¼‰

    è¿”å›:
        (å¯ä¿¡åº¦ç­‰çº§, é¢œè‰²å›¾æ ‡, ç›¸ä¼¼åº¦åˆ†æ•°)
    """
    # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
    similarity = 1 - distance

    if similarity >= 0.85:
        return "é«˜åº¦ç›¸å…³", "ğŸŸ¢", similarity
    elif similarity >= 0.70:
        return "è¾ƒä¸ºç›¸å…³", "ğŸŸ¡", similarity
    elif similarity >= 0.50:
        return "å¯èƒ½ç›¸å…³", "ğŸŸ ", similarity
    else:
        return "ä¸å¤ªç›¸å…³", "ğŸ”´", similarity


class QASystem:
    """é—®ç­”ç³»ç»Ÿç±»ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯å’Œæµå¼è¾“å‡ºï¼‰"""

    def __init__(
        self,
        vector_store_manager: VectorStoreManager,
        enable_memory: bool = True,
        enable_streaming: bool = True
    ):
        """
        åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ

        å‚æ•°:
            vector_store_manager: å‘é‡å­˜å‚¨ç®¡ç†å™¨
            enable_memory: æ˜¯å¦å¯ç”¨å¯¹è¯è®°å¿†ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            enable_streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        """
        self.vector_store_manager = vector_store_manager
        self.enable_memory = enable_memory
        self.enable_streaming = enable_streaming

        # åˆ›å»ºæµå¼å›è°ƒå¤„ç†å™¨
        self.streaming_handler = StreamingCallbackHandler() if enable_streaming else None

        # åˆå§‹åŒ– LLMï¼ˆå¯ç”¨æµå¼è¾“å‡ºï¼‰
        self.llm = ChatOpenAI(
            model=Config.MODEL_NAME,
            temperature=Config.TEMPERATURE,
            openai_api_key=Config.OPENAI_API_KEY,
            streaming=enable_streaming,  # å¯ç”¨æµå¼è¾“å‡º
            callbacks=[self.streaming_handler] if enable_streaming else None
        )

        self.qa_chain = None
        self.memory = None
        self.chat_history = []  # å­˜å‚¨å¯¹è¯å†å²ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰

    def initialize(self):
        """åˆå§‹åŒ–é—®ç­”é“¾"""
        if not self.vector_store_manager.vectorstore:
            raise ValueError("å‘é‡æ•°æ®åº“æœªåŠ è½½ï¼è¯·å…ˆåŠ è½½æˆ–åˆ›å»ºå‘é‡æ•°æ®åº“")

        print(f"ğŸ¤– æ­£åœ¨åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ...")
        print(f"   - è®°å¿†åŠŸèƒ½ï¼š{'âœ… å¼€å¯' if self.enable_memory else 'âŒ å…³é—­'}")
        print(f"   - æµå¼è¾“å‡ºï¼š{'âœ… å¼€å¯' if self.enable_streaming else 'âŒ å…³é—­'}")

        if self.enable_memory:
            # åˆ›å»ºå¯¹è¯è®°å¿†
            self.memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True,
                output_key="answer"  # æŒ‡å®šè¾“å‡ºé”®
            )

            # ä½¿ç”¨ ConversationalRetrievalChainï¼ˆæ”¯æŒè®°å¿†ï¼‰
            self.qa_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=self.vector_store_manager.vectorstore.as_retriever(
                    search_kwargs={"k": 3}
                ),
                memory=self.memory,
                return_source_documents=True
            )
        else:
            # ä½¿ç”¨æ™®é€šçš„ RetrievalQAï¼ˆä¸æ”¯æŒè®°å¿†ï¼‰
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                retriever=self.vector_store_manager.vectorstore.as_retriever(
                    search_kwargs={"k": 3}
                ),
                return_source_documents=True
            )

        print("âœ… é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def ask(self, question: str, show_source: bool = True) -> dict:
        """
        æé—®

        å‚æ•°:
            question: ç”¨æˆ·é—®é¢˜
            show_source: æ˜¯å¦æ˜¾ç¤ºæ¥æºæ–‡æ¡£ï¼ˆé»˜è®¤æ˜¾ç¤ºï¼‰

        è¿”å›:
            åŒ…å«ç­”æ¡ˆå’Œæ¥æºæ–‡æ¡£çš„å­—å…¸

        å¼‚å¸¸:
            ValueError: é—®é¢˜ä¸ºç©ºæˆ–é—®ç­”é“¾æœªåˆå§‹åŒ–
            Exception: API è°ƒç”¨å¤±è´¥
        """
        if not self.qa_chain:
            raise ValueError("é—®ç­”é“¾æœªåˆå§‹åŒ–ï¼è¯·å…ˆè°ƒç”¨ initialize()")

        # éªŒè¯é—®é¢˜
        if not question or not question.strip():
            raise ValueError("é—®é¢˜ä¸èƒ½ä¸ºç©º")

        question = question.strip()

        # é—®é¢˜é•¿åº¦é™åˆ¶
        if len(question) > 1000:
            raise ValueError("é—®é¢˜è¿‡é•¿ï¼ˆè¶…è¿‡ 1000 å­—ç¬¦ï¼‰ï¼Œè¯·ç®€åŒ–é—®é¢˜")

        print(f"\nâ“ é—®é¢˜: {question}")
        print("ğŸ” æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£...")

        max_retries = 3
        retry_delay = 2

        for attempt in range(max_retries):
            try:
                # é‡ç½®æµå¼å¤„ç†å™¨çŠ¶æ€
                if self.enable_streaming and self.streaming_handler:
                    self.streaming_handler.reset()

                # è°ƒç”¨é—®ç­”é“¾
                if self.enable_memory:
                    result = self.qa_chain({"question": question})
                    answer = result['answer']
                else:
                    result = self.qa_chain({"query": question})
                    answer = result['result']

                # æµå¼æ¨¡å¼ä¸‹ï¼Œä» callback è·å–ç­”æ¡ˆ
                if self.enable_streaming and self.streaming_handler:
                    answer = self.streaming_handler.answer
                    print()  # æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
                else:
                    # éæµå¼æ¨¡å¼ï¼Œä¸€æ¬¡æ€§æ‰“å°
                    print(f"\nğŸ’¡ ç­”æ¡ˆ: {answer}")

                # ä¿å­˜åˆ°å†å²è®°å½•
                self.chat_history.append({
                    "question": question,
                    "answer": answer
                })

                # æ˜¾ç¤ºæ¥æºï¼ˆåŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰
                if show_source and result.get('source_documents'):
                    # ä½¿ç”¨ search_with_score è·å–ç›¸ä¼¼åº¦åˆ†æ•°
                    try:
                        docs_with_scores = self.vector_store_manager.search_with_score(
                            question,
                            k=len(result['source_documents'])
                        )

                        print("\nğŸ“š å‚è€ƒæ¥æºï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰:")
                        for i, (doc, score) in enumerate(docs_with_scores, 1):
                            source = doc.metadata.get('source', 'æœªçŸ¥')
                            page = doc.metadata.get('page', '?')

                            # è·å–å¯ä¿¡åº¦ç­‰çº§
                            level, icon, similarity = get_confidence_level(score)

                            print(f"  {i}. {source} (ç¬¬{page}é¡µ) {icon} {level}")
                            print(f"     ç›¸ä¼¼åº¦: {similarity:.1%} | è·ç¦»: {score:.3f}")
                            print(f"     {doc.page_content[:100]}...")

                    except Exception as e:
                        # å¦‚æœè·å–åˆ†æ•°å¤±è´¥ï¼Œå›é€€åˆ°åŸæ¥çš„æ˜¾ç¤ºæ–¹å¼
                        print("\nğŸ“š å‚è€ƒæ¥æº:")
                        for i, doc in enumerate(result['source_documents'], 1):
                            source = doc.metadata.get('source', 'æœªçŸ¥')
                            page = doc.metadata.get('page', '?')
                            print(f"  {i}. {source} (ç¬¬{page}é¡µ)")
                            print(f"     {doc.page_content[:100]}...")

                return result

            except Exception as e:
                error_msg = str(e)

                # æ£€æµ‹å¸¸è§é”™è¯¯ç±»å‹
                if "api key" in error_msg.lower() or "authentication" in error_msg.lower():
                    raise ValueError("OpenAI API Key æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥ .env é…ç½®")
                elif "rate limit" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (attempt + 1)
                        print(f"âš ï¸  API è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œ{wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue
                    else:
                        raise Exception("API è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•æˆ–å‡çº§ API å¥—é¤")
                elif "timeout" in error_msg.lower() or "connection" in error_msg.lower():
                    if attempt < max_retries - 1:
                        print(f"âš ï¸  ç½‘ç»œè¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•ï¼ˆ{attempt + 1}/{max_retries}ï¼‰...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        raise Exception("ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
                elif "insufficient_quota" in error_msg.lower():
                    raise Exception("OpenAI API é¢åº¦ä¸è¶³ï¼Œè¯·å……å€¼æˆ–æ£€æŸ¥è´¦æˆ·çŠ¶æ€")
                else:
                    raise Exception(f"é—®ç­”å¤±è´¥: {error_msg}")

    def get_chat_history(self) -> list:
        """
        è·å–å¯¹è¯å†å²

        è¿”å›:
            å¯¹è¯å†å²åˆ—è¡¨
        """
        return self.chat_history

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.chat_history = []
        if self.memory:
            self.memory.clear()
        print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…ç©º")

    def show_history(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        if not self.chat_history:
            print("ğŸ“ æš‚æ— å¯¹è¯å†å²")
            return

        print("\n" + "=" * 60)
        print("ğŸ“ å¯¹è¯å†å²")
        print("=" * 60)
        for i, item in enumerate(self.chat_history, 1):
            print(f"\nã€ç¬¬ {i} è½®å¯¹è¯ã€‘")
            print(f"â“ é—®: {item['question']}")
            print(f"ğŸ’¡ ç­”: {item['answer'][:200]}{'...' if len(item['answer']) > 200 else ''}")
        print("\n" + "=" * 60)

    def export_to_text(self, output_dir: str = "./exports") -> str:
        """
        å¯¼å‡ºå¯¹è¯è®°å½•ä¸ºçº¯æ–‡æœ¬æ ¼å¼

        å‚æ•°:
            output_dir: å¯¼å‡ºç›®å½•ï¼ˆé»˜è®¤ ./exportsï¼‰

        è¿”å›:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not self.chat_history:
            raise ValueError("å¯¹è¯å†å²ä¸ºç©ºï¼Œæ— æ³•å¯¼å‡º")

        # åˆ›å»ºå¯¼å‡ºç›®å½•
        export_path = Path(output_dir)
        export_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"chat_history_{timestamp}.txt"
        filepath = export_path / filename

        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("=" * 70 + "\n")
            f.write("PDF èŠå¤©æœºå™¨äººå¯¹è¯è®°å½•\n")
            f.write("=" * 70 + "\n")
            f.write(f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¯¹è¯è½®æ•°: {len(self.chat_history)}\n")
            f.write("=" * 70 + "\n\n")

            for i, item in enumerate(self.chat_history, 1):
                f.write(f"ã€ç¬¬ {i} è½®å¯¹è¯ã€‘\n")
                f.write(f"{'â”€' * 70}\n")
                f.write(f"é—®é¢˜: {item['question']}\n\n")
                f.write(f"ç­”æ¡ˆ:\n{item['answer']}\n")
                f.write("\n" + "=" * 70 + "\n\n")

        return str(filepath)

    def export_to_json(self, output_dir: str = "./exports") -> str:
        """
        å¯¼å‡ºå¯¹è¯è®°å½•ä¸º JSON æ ¼å¼

        å‚æ•°:
            output_dir: å¯¼å‡ºç›®å½•ï¼ˆé»˜è®¤ ./exportsï¼‰

        è¿”å›:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not self.chat_history:
            raise ValueError("å¯¹è¯å†å²ä¸ºç©ºï¼Œæ— æ³•å¯¼å‡º")

        # åˆ›å»ºå¯¼å‡ºç›®å½•
        export_path = Path(output_dir)
        export_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"chat_history_{timestamp}.json"
        filepath = export_path / filename

        # æ„å»º JSON æ•°æ®
        data = {
            "export_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "total_conversations": len(self.chat_history),
            "conversations": [
                {
                    "round": i,
                    "question": item['question'],
                    "answer": item['answer']
                }
                for i, item in enumerate(self.chat_history, 1)
            ]
        }

        # å†™å…¥æ–‡ä»¶ï¼ˆç¾åŒ–è¾“å‡ºï¼‰
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        return str(filepath)

    def export_to_markdown(self, output_dir: str = "./exports") -> str:
        """
        å¯¼å‡ºå¯¹è¯è®°å½•ä¸º Markdown æ ¼å¼

        å‚æ•°:
            output_dir: å¯¼å‡ºç›®å½•ï¼ˆé»˜è®¤ ./exportsï¼‰

        è¿”å›:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not self.chat_history:
            raise ValueError("å¯¹è¯å†å²ä¸ºç©ºï¼Œæ— æ³•å¯¼å‡º")

        # åˆ›å»ºå¯¼å‡ºç›®å½•
        export_path = Path(output_dir)
        export_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"chat_history_{timestamp}.md"
        filepath = export_path / filename

        # å†™å…¥ Markdown æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("# PDF èŠå¤©æœºå™¨äººå¯¹è¯è®°å½•\n\n")
            f.write(f"**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**å¯¹è¯è½®æ•°**: {len(self.chat_history)}\n\n")
            f.write("---\n\n")

            for i, item in enumerate(self.chat_history, 1):
                f.write(f"## ç¬¬ {i} è½®å¯¹è¯\n\n")
                f.write(f"### â“ é—®é¢˜\n\n")
                f.write(f"{item['question']}\n\n")
                f.write(f"### ğŸ’¡ ç­”æ¡ˆ\n\n")
                f.write(f"{item['answer']}\n\n")
                f.write("---\n\n")

        return str(filepath)

    def export_history(self, format_type: str = "text", output_dir: str = "./exports") -> str:
        """
        å¯¼å‡ºå¯¹è¯å†å²ï¼ˆç»Ÿä¸€æ¥å£ï¼‰

        å‚æ•°:
            format_type: å¯¼å‡ºæ ¼å¼ ('text', 'json', 'markdown')
            output_dir: å¯¼å‡ºç›®å½•

        è¿”å›:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„

        å¼‚å¸¸:
            ValueError: æ ¼å¼ä¸æ”¯æŒæˆ–å¯¹è¯å†å²ä¸ºç©º
        """
        format_type = format_type.lower()

        if format_type == "text" or format_type == "txt":
            return self.export_to_text(output_dir)
        elif format_type == "json":
            return self.export_to_json(output_dir)
        elif format_type == "markdown" or format_type == "md":
            return self.export_to_markdown(output_dir)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}ï¼Œæ”¯æŒçš„æ ¼å¼: text, json, markdown")
