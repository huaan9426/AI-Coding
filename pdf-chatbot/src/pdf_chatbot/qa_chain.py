"""é—®ç­”é“¾æ¨¡å—"""
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

from .config import Config
from .vector_store import VectorStoreManager


class QASystem:
    """é—®ç­”ç³»ç»Ÿç±»"""

    def __init__(self, vector_store_manager: VectorStoreManager):
        self.vector_store_manager = vector_store_manager
        self.llm = ChatOpenAI(
            model=Config.MODEL_NAME,
            temperature=Config.TEMPERATURE,
            openai_api_key=Config.OPENAI_API_KEY
        )
        self.qa_chain = None

    def initialize(self):
        """åˆå§‹åŒ–é—®ç­”é“¾"""
        if not self.vector_store_manager.vectorstore:
            raise ValueError("å‘é‡æ•°æ®åº“æœªåŠ è½½ï¼è¯·å…ˆåŠ è½½æˆ–åˆ›å»ºå‘é‡æ•°æ®åº“")

        print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ...")

        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            retriever=self.vector_store_manager.vectorstore.as_retriever(
                search_kwargs={"k": 3}
            ),
            return_source_documents=True  # è¿”å›æ¥æºæ–‡æ¡£
        )

        print("âœ… é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def ask(self, question: str) -> dict:
        """
        æé—®

        å‚æ•°:
            question: ç”¨æˆ·é—®é¢˜

        è¿”å›:
            åŒ…å«ç­”æ¡ˆå’Œæ¥æºæ–‡æ¡£çš„å­—å…¸
        """
        if not self.qa_chain:
            raise ValueError("é—®ç­”é“¾æœªåˆå§‹åŒ–ï¼è¯·å…ˆè°ƒç”¨ initialize()")

        print(f"\nâ“ é—®é¢˜: {question}")
        print("ğŸ” æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£...")

        result = self.qa_chain({"query": question})

        print(f"\nğŸ’¡ ç­”æ¡ˆ: {result['result']}")

        # æ˜¾ç¤ºæ¥æº
        print("\nğŸ“š å‚è€ƒæ¥æº:")
        for i, doc in enumerate(result['source_documents'], 1):
            source = doc.metadata.get('source', 'æœªçŸ¥')
            page = doc.metadata.get('page', '?')
            print(f"  {i}. {source} (ç¬¬{page}é¡µ)")
            print(f"     {doc.page_content[:100]}...")

        return result
