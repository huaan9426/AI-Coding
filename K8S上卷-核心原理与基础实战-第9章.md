# ç¬¬9ç«  ç›‘æ§ä¸å¯è§‚æµ‹æ€§

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Kubernetesçš„æ ¸å¿ƒç»„ä»¶ã€å·¥ä½œè´Ÿè½½ç®¡ç†ã€æœåŠ¡å‘ç°ã€é…ç½®ç®¡ç†ã€èµ„æºè°ƒåº¦å’Œå­˜å‚¨ç®¡ç†ã€‚è¿™äº›çŸ¥è¯†è®©æˆ‘ä»¬èƒ½å¤ŸæˆåŠŸéƒ¨ç½²å’Œè¿è¡Œå®¹å™¨åŒ–åº”ç”¨ã€‚ä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä»…ä»…è®©åº”ç”¨è¿è¡Œèµ·æ¥æ˜¯è¿œè¿œä¸å¤Ÿçš„ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å›ç­”ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

**è¿ç»´ä¸‰å¤§çµé­‚æ‹·é—®**ï¼š
1. **ç³»ç»Ÿç°åœ¨æ€ä¹ˆæ ·ï¼Ÿ** - å®æ—¶ç›‘æ§ï¼ˆMetricsï¼‰
2. **å‡ºé—®é¢˜äº†æ€ä¹ˆåŠï¼Ÿ** - æ—¥å¿—è¿½è¸ªï¼ˆLoggingï¼‰
3. **ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ** - é“¾è·¯è¿½è¸ªï¼ˆTracingï¼‰

è€ƒè™‘ä»¥ä¸‹ç”Ÿäº§åœºæ™¯ï¼š

ğŸ“Š **ç›‘æ§åœºæ™¯**ï¼š
- Podå†…å­˜ä½¿ç”¨ç‡çªç„¶ä»30%é£™å‡åˆ°95%ï¼Œä½†æ²¡æœ‰å‘Šè­¦
- èŠ‚ç‚¹CPUæŒç»­é«˜è´Ÿè½½ï¼Œä½†ä¸çŸ¥é“æ˜¯å“ªä¸ªPodå¯¼è‡´çš„
- PVCå­˜å‚¨å®¹é‡å³å°†è€—å°½ï¼Œæ²¡æœ‰æå‰é¢„è­¦
- API Serverè¯·æ±‚å»¶è¿Ÿå¢åŠ 3å€ï¼Œç”¨æˆ·å¼€å§‹æŠ•è¯‰

ğŸ” **æ—¥å¿—åœºæ™¯**ï¼š
- ç”¨æˆ·æŠ¥å‘Šæ”¯ä»˜å¤±è´¥ï¼Œä½†ä¸çŸ¥é“é”™è¯¯å‘ç”Ÿåœ¨å“ªä¸ªå¾®æœåŠ¡
- åº”ç”¨å´©æºƒé‡å¯ï¼Œä½†æ—¥å¿—éšå®¹å™¨æ¶ˆå¤±æ— æ³•æ’æŸ¥
- å¤šä¸ªPodåˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹ï¼Œæ—¥å¿—åˆ†æ•£æ— æ³•ç»Ÿä¸€æŸ¥è¯¢
- æ—¥å¿—é‡å·¨å¤§ï¼ˆTBçº§ï¼‰ï¼Œæœç´¢é€Ÿåº¦æ…¢ä¸”æˆæœ¬é«˜

ğŸ”— **è¿½è¸ªåœºæ™¯**ï¼š
- ä¸€ä¸ªAPIè¯·æ±‚ç»è¿‡10ä¸ªå¾®æœåŠ¡ï¼Œæ€»è€—æ—¶5ç§’ï¼Œç“¶é¢ˆåœ¨å“ªï¼Ÿ
- è®¢å•å¤„ç†å¤±è´¥ï¼Œä½†ä¸çŸ¥é“æ˜¯åº“å­˜æœåŠ¡è¿˜æ˜¯æ”¯ä»˜æœåŠ¡çš„é—®é¢˜
- åˆ†å¸ƒå¼äº‹åŠ¡è·¨è¶Šå¤šä¸ªæœåŠ¡ï¼Œæ— æ³•å®šä½å¤±è´¥åŸå› 

è¿™å°±æ˜¯**å¯è§‚æµ‹æ€§ (Observability)** è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚å¯è§‚æµ‹æ€§æ˜¯ç°ä»£äº‘åŸç”Ÿåº”ç”¨çš„åŸºçŸ³ï¼Œå®ƒè®©æˆ‘ä»¬èƒ½å¤Ÿï¼š
- **ä¸»åŠ¨å‘ç°é—®é¢˜** - åœ¨ç”¨æˆ·æŠ•è¯‰å‰å°±å‘ç°å¼‚å¸¸
- **å¿«é€Ÿå®šä½æ ¹å› ** - åˆ†é’Ÿçº§è€Œéå°æ—¶çº§æ•…éšœæ’æŸ¥
- **ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½** - åŸºäºæ•°æ®é©±åŠ¨çš„æ€§èƒ½è°ƒä¼˜
- **å®¹é‡è§„åˆ’å†³ç­–** - å‡†ç¡®é¢„æµ‹èµ„æºéœ€æ±‚ï¼Œé™ä½æˆæœ¬

## å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±

Kubernetesç”Ÿæ€æä¾›äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§è§£å†³æ–¹æ¡ˆï¼Œéµå¾ªä¸šç•Œå…¬è®¤çš„"ä¸‰å¤§æ”¯æŸ±"ç†å¿µï¼š

### 1ï¸âƒ£ Metrics (æŒ‡æ ‡ç›‘æ§)

**å®šä¹‰**ï¼šèšåˆçš„æ•°å€¼å‹æ—¶åºæ•°æ®ï¼Œç”¨äºé‡åŒ–ç³»ç»ŸçŠ¶æ€

**å…¸å‹æŒ‡æ ‡**ï¼š
- **åŸºç¡€è®¾æ–½å±‚**ï¼šCPUä½¿ç”¨ç‡ã€å†…å­˜å ç”¨ã€ç£ç›˜IOPSã€ç½‘ç»œå¸¦å®½
- **å®¹å™¨å±‚**ï¼šPodé‡å¯æ¬¡æ•°ã€å®¹å™¨OOMæ¬¡æ•°ã€é•œåƒæ‹‰å–æ—¶é•¿
- **åº”ç”¨å±‚**ï¼šHTTPè¯·æ±‚QPSã€APIå»¶è¿ŸP99ã€é”™è¯¯ç‡ã€ä¸šåŠ¡æŒ‡æ ‡ï¼ˆè®¢å•é‡ï¼‰

**æŠ€æœ¯æ ˆ**ï¼šPrometheus + Grafana

### 2ï¸âƒ£ Logging (æ—¥å¿—è¿½è¸ª)

**å®šä¹‰**ï¼šç¦»æ•£çš„äº‹ä»¶è®°å½•ï¼Œç”¨äºæè¿°ç³»ç»Ÿè¡Œä¸º

**æ—¥å¿—ç±»å‹**ï¼š
- **åº”ç”¨æ—¥å¿—**ï¼šä¸šåŠ¡é€»è¾‘è¾“å‡ºï¼ˆè®¢å•åˆ›å»ºã€ç”¨æˆ·ç™»å½•ï¼‰
- **å®¡è®¡æ—¥å¿—**ï¼šå®‰å…¨åˆè§„è®°å½•ï¼ˆAPIè°ƒç”¨ã€æƒé™å˜æ›´ï¼‰
- **ç³»ç»Ÿæ—¥å¿—**ï¼šç»„ä»¶è¿è¡Œæ—¥å¿—ï¼ˆkubeletã€kube-proxyï¼‰

**æŠ€æœ¯æ ˆ**ï¼šEFK (Elasticsearch + Fluentd + Kibana) æˆ– Loki + Promtail

### 3ï¸âƒ£ Tracing (é“¾è·¯è¿½è¸ª)

**å®šä¹‰**ï¼šåˆ†å¸ƒå¼è¯·æ±‚çš„å®Œæ•´è°ƒç”¨é“¾è·¯ï¼Œç”¨äºåˆ†ææœåŠ¡ä¾èµ–

**è¿½è¸ªå†…å®¹**ï¼š
- è¯·æ±‚ä»ç½‘å…³åˆ°æ•°æ®åº“çš„å®Œæ•´è·¯å¾„
- æ¯ä¸ªå¾®æœåŠ¡çš„å¤„ç†è€—æ—¶å’Œä¾èµ–å…³ç³»
- è·¨æœåŠ¡è°ƒç”¨çš„ä¸Šä¸‹æ–‡ä¼ é€’

**æŠ€æœ¯æ ˆ**ï¼šJaeger / Zipkin / Tempo

## æœ¬ç« å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†æŒæ¡ï¼š

âœ… **Metricsç›‘æ§ä½“ç³»**: ç†è§£Prometheusæ¶æ„ï¼ŒæŒæ¡PromQLæŸ¥è¯¢è¯­è¨€ï¼Œé…ç½®Grafanaä»ªè¡¨ç›˜
âœ… **æŒ‡æ ‡é‡‡é›†å®æˆ˜**: éƒ¨ç½²Metrics Serverã€Node Exporterã€kube-state-metrics
âœ… **å‘Šè­¦è§„åˆ™é…ç½®**: ä½¿ç”¨AlertManagerå®ç°å¤šæ¸ é“å‘Šè­¦ï¼ˆé‚®ä»¶/Slack/é’‰é’‰/ä¼ä¸šå¾®ä¿¡ï¼‰
âœ… **æ—¥å¿—æ”¶é›†æ¶æ„**: éƒ¨ç½²EFKæ ˆï¼Œå®ç°å®¹å™¨æ—¥å¿—çš„é›†ä¸­æ”¶é›†ã€ç´¢å¼•å’ŒæŸ¥è¯¢
âœ… **æ—¥å¿—æŸ¥è¯¢åˆ†æ**: æŒæ¡Kibana/LokiæŸ¥è¯¢è¯­æ³•ï¼Œå¿«é€Ÿå®šä½é—®é¢˜æ—¥å¿—
âœ… **åˆ†å¸ƒå¼è¿½è¸ª**: éƒ¨ç½²Jaegerï¼Œå®ç°å¾®æœåŠ¡è°ƒç”¨é“¾è·¯çš„å¯è§†åŒ–åˆ†æ
âœ… **æ€§èƒ½åˆ†æå·¥å…·**: ä½¿ç”¨kubectl topã€PrometheusæŸ¥è¯¢ã€ç«ç„°å›¾åˆ†ææ€§èƒ½ç“¶é¢ˆ
âœ… **ç”Ÿäº§æœ€ä½³å®è·µ**: ç›‘æ§æŒ‡æ ‡ä½“ç³»è®¾è®¡ã€å‘Šè­¦ç­–ç•¥åˆ¶å®šã€æˆæœ¬ä¼˜åŒ–

## æœ¬ç« å†…å®¹æ¦‚è§ˆ

```
ç¬¬9ç« : ç›‘æ§ä¸å¯è§‚æµ‹æ€§
â”œâ”€â”€ 9.1 ç›‘æ§åŸºç¡€ä¸æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ å¯è§‚æµ‹æ€§æ ¸å¿ƒæ¦‚å¿µ
â”‚   â”œâ”€â”€ Kubernetesç›‘æ§æ¶æ„
â”‚   â”œâ”€â”€ Metrics APIä¸èµ„æºæŒ‡æ ‡
â”‚   â””â”€â”€ ç›‘æ§æ•°æ®é‡‡é›†è·¯å¾„
â”‚
â”œâ”€â”€ 9.2 Prometheusæ ¸å¿ƒåŸç†ä¸å®æˆ˜
â”‚   â”œâ”€â”€ Prometheusæ¶æ„ä¸æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ æœåŠ¡å‘ç°ä¸ç›®æ ‡æŠ“å–
â”‚   â”œâ”€â”€ PromQLæŸ¥è¯¢è¯­è¨€è¯¦è§£
â”‚   â”œâ”€â”€ Recording Rulesæ€§èƒ½ä¼˜åŒ–
â”‚   â””â”€â”€ æ•°æ®æŒä¹…åŒ–ä¸é«˜å¯ç”¨
â”‚
â”œâ”€â”€ 9.3 Grafanaå¯è§†åŒ–ä¸ä»ªè¡¨ç›˜
â”‚   â”œâ”€â”€ Grafanaéƒ¨ç½²ä¸é…ç½®
â”‚   â”œâ”€â”€ æ•°æ®æºé›†æˆï¼ˆPrometheus/Loki/Jaegerï¼‰
â”‚   â”œâ”€â”€ ä»ªè¡¨ç›˜è®¾è®¡æœ€ä½³å®è·µ
â”‚   â”œâ”€â”€ å˜é‡ä¸æ¨¡æ¿åº”ç”¨
â”‚   â””â”€â”€ ä¼ä¸šçº§ä»ªè¡¨ç›˜ç¤ºä¾‹
â”‚
â”œâ”€â”€ 9.4 å‘Šè­¦è§„åˆ™ä¸AlertManager
â”‚   â”œâ”€â”€ AlertManageræ¶æ„ä¸é…ç½®
â”‚   â”œâ”€â”€ å‘Šè­¦è§„åˆ™ç¼–å†™ï¼ˆCPU/å†…å­˜/ç£ç›˜/Podï¼‰
â”‚   â”œâ”€â”€ å‘Šè­¦è·¯ç”±ä¸åˆ†ç»„
â”‚   â”œâ”€â”€ æŠ‘åˆ¶ä¸é™é»˜ç­–ç•¥
â”‚   â””â”€â”€ å¤šæ¸ é“é€šçŸ¥é›†æˆï¼ˆé’‰é’‰/ä¼ä¸šå¾®ä¿¡/PagerDutyï¼‰
â”‚
â”œâ”€â”€ 9.5 æ—¥å¿—ç®¡ç†ä¸EFKæ ˆ
â”‚   â”œâ”€â”€ æ—¥å¿—æ”¶é›†æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ Fluentd/Fluent Bitéƒ¨ç½²
â”‚   â”œâ”€â”€ Elasticsearché›†ç¾¤æ­å»º
â”‚   â”œâ”€â”€ Kibanaæ—¥å¿—æŸ¥è¯¢ä¸åˆ†æ
â”‚   â””â”€â”€ Lokiè½»é‡çº§æ—¥å¿—æ–¹æ¡ˆ
â”‚
â”œâ”€â”€ 9.6 åˆ†å¸ƒå¼è¿½è¸ªä¸Jaeger
â”‚   â”œâ”€â”€ OpenTelemetryæ ‡å‡†
â”‚   â”œâ”€â”€ Jaegeræ¶æ„ä¸éƒ¨ç½²
â”‚   â”œâ”€â”€ åº”ç”¨åŸ‹ç‚¹ä¸SDKé›†æˆ
â”‚   â”œâ”€â”€ è°ƒç”¨é“¾è·¯åˆ†æå®æˆ˜
â”‚   â””â”€â”€ æ€§èƒ½ç“¶é¢ˆå®šä½
â”‚
â”œâ”€â”€ 9.7 Kubernetesäº‹ä»¶ç›‘æ§
â”‚   â”œâ”€â”€ Eventsèµ„æºè¯¦è§£
â”‚   â”œâ”€â”€ kube-eventeréƒ¨ç½²
â”‚   â”œâ”€â”€ äº‹ä»¶æŒä¹…åŒ–å­˜å‚¨
â”‚   â””â”€â”€ å…³é”®äº‹ä»¶å‘Šè­¦
â”‚
â””â”€â”€ 9.8 ç›‘æ§æœ€ä½³å®è·µä¸ç”Ÿäº§æ¡ˆä¾‹
    â”œâ”€â”€ ç›‘æ§æŒ‡æ ‡ä½“ç³»è®¾è®¡ï¼ˆUSE/REDæ–¹æ³•ï¼‰
    â”œâ”€â”€ é»„é‡‘æŒ‡æ ‡ä¸SLI/SLO/SLA
    â”œâ”€â”€ æˆæœ¬ä¼˜åŒ–ï¼ˆæ•°æ®ä¿ç•™ç­–ç•¥/é‡‡æ ·ç‡ï¼‰
    â”œâ”€â”€ ç”Ÿäº§æ•…éšœæ¡ˆä¾‹ï¼ˆOOM/ç£ç›˜æ»¡/é›ªå´©ï¼‰
    â””â”€â”€ ä¼ä¸šçº§ç›‘æ§å¹³å°æ¶æ„
```

## å­¦ä¹ è·¯å¾„å»ºè®®

**åˆå­¦è€…è·¯å¾„**ï¼ˆæŒæ¡åŸºç¡€ç›‘æ§ï¼‰ï¼š
1. å…ˆå­¦ä¹  9.1 ç›‘æ§åŸºç¡€ï¼Œç†è§£æ ¸å¿ƒæ¦‚å¿µ
2. éƒ¨ç½² Metrics Serverï¼Œä½¿ç”¨ `kubectl top` æŸ¥çœ‹èµ„æº
3. å­¦ä¹  9.2 Prometheus åŸºç¡€ï¼Œéƒ¨ç½²å•æœºç‰ˆ
4. é…ç½® 9.3 Grafana ä»ªè¡¨ç›˜ï¼Œå¯è§†åŒ–é›†ç¾¤çŠ¶æ€
5. å®è·µ 9.4 ç®€å•å‘Šè­¦è§„åˆ™ï¼ˆCPU/å†…å­˜é˜ˆå€¼ï¼‰

**è¿›é˜¶è·¯å¾„**ï¼ˆæ„å»ºå®Œæ•´å¯è§‚æµ‹æ€§ï¼‰ï¼š
1. æ·±å…¥å­¦ä¹  9.2 PromQLï¼Œç¼–å†™å¤æ‚æŸ¥è¯¢
2. éƒ¨ç½² 9.5 EFK æ ˆï¼Œå®ç°æ—¥å¿—é›†ä¸­ç®¡ç†
3. é…ç½® 9.4 é«˜çº§å‘Šè­¦ï¼ˆåŸºäºå˜åŒ–ç‡/è¶‹åŠ¿é¢„æµ‹ï¼‰
4. å­¦ä¹  9.6 Jaegerï¼Œåˆ†æå¾®æœåŠ¡è°ƒç”¨é“¾
5. æŒæ¡ 9.8 æœ€ä½³å®è·µï¼Œè®¾è®¡ä¼ä¸šçº§ç›‘æ§ä½“ç³»

**ç”Ÿäº§ç¯å¢ƒå‡†å¤‡**ï¼š
- Prometheusé›†ç¾¤é«˜å¯ç”¨ï¼ˆå¤šå‰¯æœ¬+Thanosï¼‰
- æ—¥å¿—å­˜å‚¨æˆæœ¬ä¼˜åŒ–ï¼ˆå†·çƒ­åˆ†ç¦»+ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰
- å‘Šè­¦é™å™ªç­–ç•¥ï¼ˆæŠ‘åˆ¶è§„åˆ™+åˆ†çº§é€šçŸ¥ï¼‰
- ç›‘æ§æ•°æ®å®‰å…¨ï¼ˆRBAC+åŠ å¯†ä¼ è¾“ï¼‰

---

## æŠ€æœ¯æ ˆæ€»è§ˆ

æœ¬ç« æ¶‰åŠçš„æ ¸å¿ƒæŠ€æœ¯æ ˆï¼š

| ç±»åˆ« | å¼€æºæ–¹æ¡ˆ | å•†ä¸šæ–¹æ¡ˆ | äº‘åŸç”Ÿæ–¹æ¡ˆ |
|------|---------|---------|-----------|
| **Metrics** | Prometheus + Grafana | Datadog, New Relic | AWS CloudWatch, GCP Monitoring |
| **Logging** | EFK (Elasticsearch + Fluentd + Kibana) | Splunk, Sumo Logic | AWS CloudWatch Logs, GCP Logging |
| **Tracing** | Jaeger, Zipkin | Datadog APM, Dynatrace | AWS X-Ray, GCP Trace |
| **é›†æˆæ–¹æ¡ˆ** | Loki + Tempo + Grafana (LGTMæ ˆ) | Elastic Observability | - |

**æœ¬ç« é€‰æ‹©å¼€æºæ–¹æ¡ˆçš„åŸå› **ï¼š
- âœ… é›¶æˆæœ¬ï¼Œé€‚åˆå­¦ä¹ å’Œä¸­å°ä¼ä¸š
- âœ… ç¤¾åŒºæ´»è·ƒï¼Œæ–‡æ¡£ä¸°å¯Œ
- âœ… äº‘å‚å•†å…¼å®¹ï¼ˆå¯æ— ç¼è¿ç§»åˆ°æ‰˜ç®¡æœåŠ¡ï¼‰
- âœ… ä¼ä¸šçº§ç”Ÿäº§éªŒè¯ï¼ˆNetflixã€Uberã€Shopifyç­‰ä½¿ç”¨ï¼‰

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿ** è®©æˆ‘ä»¬ä»ç›‘æ§åŸºç¡€å¼€å§‹ï¼Œé€æ­¥æ„å»ºå®Œæ•´çš„Kuberneteså¯è§‚æµ‹æ€§å¹³å°ï¼

---


## 9.1 ç›‘æ§åŸºç¡€ä¸æ¶æ„è®¾è®¡

### 9.1.1 å¯è§‚æµ‹æ€§æ ¸å¿ƒæ¦‚å¿µ

#### ä»€ä¹ˆæ˜¯å¯è§‚æµ‹æ€§ï¼Ÿ

**å¯è§‚æµ‹æ€§ (Observability)** ä¸ç­‰äºç›‘æ§ (Monitoring)ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ›´å¹¿æ³›çš„æ¦‚å¿µï¼š

```
ç›‘æ§ (Monitoring)ï¼š
  - å·²çŸ¥é—®é¢˜çš„æ£€æµ‹ï¼ˆæˆ‘çŸ¥é“å¯èƒ½ä¼šå‡ºç°CPUè¿‡é«˜ï¼Œæ‰€ä»¥è®¾ç½®å‘Šè­¦ï¼‰
  - é¢„å®šä¹‰æŒ‡æ ‡çš„æ”¶é›†ï¼ˆå›ºå®šçš„Dashboardï¼‰
  - è¢«åŠ¨å“åº”ï¼ˆæ”¶åˆ°å‘Šè­¦åæ’æŸ¥ï¼‰

å¯è§‚æµ‹æ€§ (Observability)ï¼š
  - æœªçŸ¥é—®é¢˜çš„æ¢ç´¢ï¼ˆç³»ç»Ÿå‡ºç°ä»æœªè§è¿‡çš„å¼‚å¸¸ï¼Œèƒ½å¿«é€Ÿå®šä½ï¼‰
  - ä»»æ„ç»´åº¦çš„æŸ¥è¯¢ï¼ˆå¯ä»¥è‡ªç”±ç»„åˆå„ç§æ¡ä»¶æŸ¥è¯¢ï¼‰
  - ä¸»åŠ¨æ´å¯Ÿï¼ˆé€šè¿‡æ•°æ®å‘ç°æ½œåœ¨é—®é¢˜ï¼‰
```

**æ ¸å¿ƒåŒºåˆ«ç¤ºä¾‹**ï¼š

å‡è®¾ç”Ÿäº§ç¯å¢ƒå‡ºç°"ç”¨æˆ·æ”¯ä»˜æˆåŠŸç‡ä»99.5%é™åˆ°95%"ï¼š

```
ä¼ ç»Ÿç›‘æ§æ€è·¯ï¼š
1. æŸ¥çœ‹é¢„è®¾çš„Dashboard â†’ æ²¡æœ‰"æ”¯ä»˜æˆåŠŸç‡"è¿™ä¸ªæŒ‡æ ‡
2. ç™»å½•å„ä¸ªPodæŸ¥çœ‹æ—¥å¿— â†’ è€—æ—¶ä¸”åˆ†æ•£
3. çŒœæµ‹å¯èƒ½çš„åŸå›  â†’ æ•°æ®åº“ï¼Ÿç½‘ç»œï¼Ÿä»£ç bugï¼Ÿ
4. é€ä¸ªæ’æŸ¥ â†’ å¯èƒ½éœ€è¦æ•°å°æ—¶

å¯è§‚æµ‹æ€§æ€è·¯ï¼š
1. Metrics: æŸ¥è¯¢æ”¯ä»˜APIçš„P99å»¶è¿Ÿ â†’ å‘ç°ä»200mså‡åˆ°2s
2. Tracing: è°ƒç”¨é“¾åˆ†æ â†’ å®šä½åˆ°"åº“å­˜æŸ¥è¯¢"æ­¥éª¤è€—æ—¶å¢åŠ 
3. Logging: æŸ¥çœ‹åº“å­˜æœåŠ¡æ—¥å¿— â†’ å‘ç°å¤§é‡"connection timeout"
4. æ ¹å› å®šä½ï¼šåº“å­˜æœåŠ¡æ•°æ®åº“è¿æ¥æ± è€—å°½ â†’ 5åˆ†é’Ÿå†…ä¿®å¤
```

#### å¯è§‚æµ‹æ€§çš„ä»·å€¼

**ä¸šåŠ¡ä»·å€¼**ï¼š

| ç»´åº¦ | ä¼ ç»Ÿæ–¹å¼ | å¯è§‚æµ‹æ€§æ–¹å¼ | ä»·å€¼æå‡ |
|------|---------|-------------|---------|
| **æ•…éšœå‘ç°** | ç”¨æˆ·æŠ•è¯‰åè¢«åŠ¨å‘ç° | æå‰5-30åˆ†é’Ÿä¸»åŠ¨å‘Šè­¦ | å‡å°‘ç”¨æˆ·å½±å“é¢80% |
| **æ•…éšœå®šä½** | å¹³å‡2-4å°æ—¶ (MTTR) | å¹³å‡5-15åˆ†é’Ÿ | MTTRé™ä½90% |
| **å®¹é‡è§„åˆ’** | åŸºäºç»éªŒçŒœæµ‹ | åŸºäºå†å²è¶‹åŠ¿é¢„æµ‹ | æˆæœ¬é™ä½30-50% |
| **æ€§èƒ½ä¼˜åŒ–** | æ„Ÿè§‰å“ªé‡Œæ…¢å°±ä¼˜åŒ–å“ªé‡Œ | æ•°æ®é©±åŠ¨ï¼Œç²¾å‡†å®šä½ç“¶é¢ˆ | ä¼˜åŒ–æ•ˆæœæå‡5-10å€ |

**çœŸå®æ¡ˆä¾‹**ï¼š

æŸç”µå•†å…¬å¸åœ¨å¼•å…¥å®Œæ•´å¯è§‚æµ‹æ€§ä½“ç³»åï¼š
- âœ… 99.9% SLAè¾¾æˆç‡ä»92%æå‡åˆ°99.7%
- âœ… å¹³å‡æ•…éšœæ¢å¤æ—¶é—´ä»3.5å°æ—¶é™è‡³12åˆ†é’Ÿ
- âœ… é€šè¿‡å®¹é‡ä¼˜åŒ–èŠ‚çœäº‘æˆæœ¬38%ï¼ˆå¹´çœ200ä¸‡ç¾å…ƒï¼‰
- âœ… æ€§èƒ½é—®é¢˜å®šä½æ—¶é—´ä»å¹³å‡2å¤©é™è‡³1å°æ—¶

#### å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±è¯¦è§£

##### 1. Metrics (æŒ‡æ ‡ç›‘æ§)

**æ•°æ®ç‰¹ç‚¹**ï¼š
- èšåˆçš„æ•°å€¼å‹æ•°æ®ï¼ˆå¦‚ï¼šå¹³å‡å€¼ã€P99ã€ç´¯åŠ å€¼ï¼‰
- æ—¶åºå­˜å‚¨ï¼ˆæ—¶é—´æˆ³ + æ ‡ç­¾ + æ•°å€¼ï¼‰
- ä½å­˜å‚¨æˆæœ¬ï¼ˆæ¯ä¸ªæŒ‡æ ‡çº¦1-2 bytes/sampleï¼‰

**å…¸å‹åº”ç”¨åœºæ™¯**ï¼š
```yaml
# åœºæ™¯1: èµ„æºç›‘æ§
node_cpu_usage{node="node1", cpu="0"} 45.2    # CPUä½¿ç”¨ç‡45.2%
container_memory_usage{pod="nginx-abc", namespace="prod"} 256000000  # å†…å­˜256MB

# åœºæ™¯2: åº”ç”¨æ€§èƒ½
http_requests_total{method="GET", path="/api/users", status="200"} 15840  # è¯·æ±‚æ€»æ•°
http_request_duration_seconds{quantile="0.99"} 0.235  # P99å»¶è¿Ÿ235ms

# åœºæ™¯3: ä¸šåŠ¡æŒ‡æ ‡
order_created_total{region="us-west", payment_method="credit_card"} 3580  # è®¢å•æ•°
payment_success_rate 0.995  # æ”¯ä»˜æˆåŠŸç‡99.5%
```

**ä¼˜åŠ¿**ï¼š
- âœ… æŸ¥è¯¢é€Ÿåº¦å¿«ï¼ˆæ¯«ç§’çº§ï¼‰
- âœ… å­˜å‚¨æˆæœ¬ä½ï¼ˆTBçº§æ•°æ®/æœˆä»…éœ€å‡ GBï¼‰
- âœ… é€‚åˆå®æ—¶å‘Šè­¦ï¼ˆç§’çº§æ£€æµ‹é˜ˆå€¼ï¼‰
- âœ… æ˜“äºå¯è§†åŒ–ï¼ˆæŠ˜çº¿å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ï¼‰

**å±€é™**ï¼š
- âŒ æ— æ³•æŸ¥çœ‹è¯¦ç»†äº‹ä»¶ï¼ˆåªçŸ¥é“é”™è¯¯ç‡å‡é«˜ï¼Œä¸çŸ¥é“å…·ä½“é”™è¯¯ä¿¡æ¯ï¼‰
- âŒ ä¸¢å¤±ä¸Šä¸‹æ–‡ï¼ˆä¸çŸ¥é“æ˜¯å“ªä¸ªç”¨æˆ·ã€å“ªä¸ªè®¢å•å‡ºé”™ï¼‰

##### 2. Logging (æ—¥å¿—è¿½è¸ª)

**æ•°æ®ç‰¹ç‚¹**ï¼š
- ç¦»æ•£çš„äº‹ä»¶è®°å½•ï¼ˆæ¯æ¡æ—¥å¿—æ˜¯ä¸€ä¸ªå®Œæ•´äº‹ä»¶ï¼‰
- åŒ…å«ä¸°å¯Œä¸Šä¸‹æ–‡ï¼ˆæ—¶é—´ã€çº§åˆ«ã€æ¶ˆæ¯ã€å †æ ˆç­‰ï¼‰
- å­˜å‚¨æˆæœ¬é«˜ï¼ˆæ¯GBæ—¥å¿—çº¦å ç”¨1-3GBå­˜å‚¨ï¼‰

**æ—¥å¿—çº§åˆ«**ï¼š
```python
# åº”ç”¨æ—¥å¿—ç¤ºä¾‹
DEBUG: [2024-01-20 10:30:15] User session cache hit: user_id=12345
INFO:  [2024-01-20 10:30:16] Order created: order_id=ORD-789, amount=99.99, user=12345
WARN:  [2024-01-20 10:30:17] Payment retry attempt 2/3: gateway_timeout
ERROR: [2024-01-20 10:30:18] Payment failed: order=ORD-789, error=ConnectionTimeout
FATAL: [2024-01-20 10:30:19] Database connection pool exhausted
```

**ç»“æ„åŒ–æ—¥å¿— vs éç»“æ„åŒ–æ—¥å¿—**ï¼š

```json
// éç»“æ„åŒ–æ—¥å¿— (éš¾ä»¥æŸ¥è¯¢)
"2024-01-20 10:30:16 User john@example.com created order ORD-789 with amount $99.99"

// ç»“æ„åŒ–æ—¥å¿— (æ˜“äºæŸ¥è¯¢å’Œåˆ†æ)
{
  "timestamp": "2024-01-20T10:30:16Z",
  "level": "INFO",
  "message": "Order created",
  "order_id": "ORD-789",
  "user_email": "john@example.com",
  "amount": 99.99,
  "currency": "USD",
  "trace_id": "a1b2c3d4e5f6"  // å…³è”Tracing
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… åŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆèƒ½çœ‹åˆ°è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€å †æ ˆè¿½è¸ªï¼‰
- âœ… æ”¯æŒå…¨æ–‡æœç´¢ï¼ˆå¿«é€Ÿæ‰¾åˆ°ç‰¹å®šé”™è¯¯æ¶ˆæ¯ï¼‰
- âœ… é€‚åˆé—®é¢˜æ’æŸ¥ï¼ˆç»“åˆæ—¶é—´æˆ³ç²¾å‡†å®šä½ï¼‰

**å±€é™**ï¼š
- âŒ å­˜å‚¨æˆæœ¬é«˜ï¼ˆæ—¥å¿—é‡å¤§çš„ç³»ç»Ÿæ¯æœˆæ•°TBï¼‰
- âŒ æŸ¥è¯¢é€Ÿåº¦æ…¢ï¼ˆå…¨æ–‡æœç´¢TBçº§æ•°æ®å¯èƒ½éœ€è¦æ•°ç§’åˆ°æ•°åˆ†é’Ÿï¼‰
- âŒ éš¾ä»¥èšåˆåˆ†æï¼ˆä¸é€‚åˆç»Ÿè®¡è¶‹åŠ¿ï¼‰

##### 3. Tracing (é“¾è·¯è¿½è¸ª)

**æ•°æ®ç‰¹ç‚¹**ï¼š
- åˆ†å¸ƒå¼è¯·æ±‚çš„å®Œæ•´è°ƒç”¨é“¾ï¼ˆä¸€æ¬¡ç”¨æˆ·è¯·æ±‚å¯èƒ½è·¨è¶Š10+æœåŠ¡ï¼‰
- åŒ…å«æ—¶åºå…³ç³»å’Œä¾èµ–ï¼ˆå“ªä¸ªæ­¥éª¤å…ˆæ‰§è¡Œï¼Œå“ªä¸ªæœåŠ¡è°ƒç”¨äº†å“ªä¸ªæœåŠ¡ï¼‰
- é‡‡æ ·å­˜å‚¨ï¼ˆé€šå¸¸åªä¿å­˜1-10%çš„è¯·æ±‚ï¼Œå¦åˆ™æ•°æ®é‡è¿‡å¤§ï¼‰

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š

```
Trace (è¿½è¸ª): ä¸€æ¬¡å®Œæ•´çš„è¯·æ±‚é“¾è·¯
  â””â”€â”€ Span (è·¨åº¦): é“¾è·¯ä¸­çš„ä¸€ä¸ªæ“ä½œæ­¥éª¤
      â”œâ”€â”€ Span ID: å½“å‰æ­¥éª¤çš„å”¯ä¸€æ ‡è¯†
      â”œâ”€â”€ Parent Span ID: çˆ¶çº§æ­¥éª¤çš„ID
      â”œâ”€â”€ Start Time: å¼€å§‹æ—¶é—´
      â”œâ”€â”€ Duration: æŒç»­æ—¶é•¿
      â””â”€â”€ Tags/Logs: é™„åŠ ä¿¡æ¯ï¼ˆHTTPçŠ¶æ€ç ã€é”™è¯¯ä¿¡æ¯ç­‰ï¼‰
```

**å®é™…æ¡ˆä¾‹**ï¼š

ä¸€æ¬¡"ç”¨æˆ·ä¸‹å•"è¯·æ±‚çš„å®Œæ•´Traceï¼š

```
[Trace ID: a1b2c3d4e5f6]
â”‚
â”œâ”€â”€ [Span 1] API Gateway (æ€»è€—æ—¶: 1250ms)
â”‚   â”‚
â”‚   â”œâ”€â”€ [Span 2] ç”¨æˆ·è®¤è¯æœåŠ¡ (100ms)
â”‚   â”‚   â””â”€â”€ [Span 3] RedisæŸ¥è¯¢ç¼“å­˜ (5ms)
â”‚   â”‚
â”‚   â”œâ”€â”€ [Span 4] è®¢å•æœåŠ¡ (1100ms)
â”‚   â”‚   â”œâ”€â”€ [Span 5] åº“å­˜æœåŠ¡ (800ms) â† ç“¶é¢ˆï¼
â”‚   â”‚   â”‚   â””â”€â”€ [Span 6] MySQLæŸ¥è¯¢åº“å­˜ (780ms) â† æ ¹å› ï¼šæ…¢æŸ¥è¯¢
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ [Span 7] ä¼˜æƒ åˆ¸æœåŠ¡ (50ms)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ [Span 8] æ”¯ä»˜æœåŠ¡ (200ms)
â”‚   â”‚       â””â”€â”€ [Span 9] ç¬¬ä¸‰æ–¹æ”¯ä»˜ç½‘å…³ (180ms)
â”‚   â”‚
â”‚   â””â”€â”€ [Span 10] æ—¥å¿—è®°å½• (50ms)
```

é€šè¿‡Tracingå¯ä»¥ä¸€çœ¼çœ‹å‡ºï¼š
- âœ… æ€»è€—æ—¶1250msï¼Œå…¶ä¸­åº“å­˜æœåŠ¡å 64%ï¼ˆ800msï¼‰
- âœ… åº“å­˜æœåŠ¡çš„ç“¶é¢ˆåœ¨MySQLæŸ¥è¯¢ï¼ˆ780msï¼‰
- âœ… ä¼˜åŒ–æ–¹å‘ï¼šä¼˜åŒ–åº“å­˜æŸ¥è¯¢SQLæˆ–å¢åŠ ç¼“å­˜

**ä¼˜åŠ¿**ï¼š
- âœ… å¯è§†åŒ–æœåŠ¡ä¾èµ–ï¼ˆè‡ªåŠ¨ç”ŸæˆæœåŠ¡æ‹“æ‰‘å›¾ï¼‰
- âœ… ç²¾å‡†å®šä½ç“¶é¢ˆï¼ˆæ¯ä¸ªæ­¥éª¤çš„è€—æ—¶ä¸€ç›®äº†ç„¶ï¼‰
- âœ… ç†è§£å¤æ‚è°ƒç”¨é“¾ï¼ˆå¾®æœåŠ¡æ¶æ„ä¸‹å°¤ä¸ºé‡è¦ï¼‰

**å±€é™**ï¼š
- âŒ éœ€è¦åº”ç”¨åŸ‹ç‚¹ï¼ˆä»£ç ä¾µå…¥ï¼Œå¢åŠ å¼€å‘æˆæœ¬ï¼‰
- âŒ é‡‡æ ·ç‡æƒè¡¡ï¼ˆ100%é‡‡æ ·å­˜å‚¨æˆæœ¬é«˜ï¼Œä½é‡‡æ ·ç‡å¯èƒ½æ¼æ‰å…³é”®è¯·æ±‚ï¼‰
- âŒ å­¦ä¹ æ›²çº¿ï¼ˆéœ€è¦ç†è§£åˆ†å¸ƒå¼è¿½è¸ªæ¦‚å¿µï¼‰

#### ä¸‰å¤§æ”¯æŸ±çš„ååŒä½¿ç”¨

**å…¸å‹æ•…éšœæ’æŸ¥æµç¨‹**ï¼š

```
æ­¥éª¤1: Metricså‘ç°å¼‚å¸¸
  â†’ Grafana Dashboardæ˜¾ç¤º"APIé”™è¯¯ç‡ä»0.1%å‡åˆ°5%"

æ­¥éª¤2: Metricså®šä½æ—¶é—´å’ŒèŒƒå›´
  â†’ PromQLæŸ¥è¯¢: rate(http_requests_total{status=~"5.."}[5m])
  â†’ å‘ç°æ˜¯"è®¢å•æœåŠ¡"åœ¨"10:30-10:45"é”™è¯¯ç‡å¼‚å¸¸

æ­¥éª¤3: Tracingå®šä½å…·ä½“æœåŠ¡
  â†’ JaegeræŸ¥è¯¢"è®¢å•æœåŠ¡"åœ¨è¯¥æ—¶é—´æ®µçš„Trace
  â†’ å‘ç°80%çš„æ…¢è¯·æ±‚éƒ½å¡åœ¨"åº“å­˜æŸ¥è¯¢"æ­¥éª¤

æ­¥éª¤4: LoggingæŸ¥çœ‹è¯¦ç»†é”™è¯¯
  â†’ Kibanaæœç´¢: service="inventory" AND level="ERROR" AND time:[10:30 TO 10:45]
  â†’ æ‰¾åˆ°é”™è¯¯æ—¥å¿—: "com.mysql.jdbc.exceptions.MySQLTimeoutException: Connection timeout"

æ­¥éª¤5: æ ¹å› åˆ†æ
  â†’ ç»“åˆMetrics: MySQLè¿æ¥æ•°ä»50çªå¢åˆ°200ï¼ˆè¿æ¥æ± ä¸Šé™ï¼‰
  â†’ ç»“åˆLogging: å‘ç°æŸä¸ªå®šæ—¶ä»»åŠ¡åœ¨10:30å¯åŠ¨ï¼Œæ‰§è¡Œäº†å¤§é‡æ…¢æŸ¥è¯¢
  â†’ è§£å†³æ–¹æ¡ˆ: ä¼˜åŒ–æ…¢æŸ¥è¯¢SQLï¼Œå¢åŠ è¿æ¥æ± å¤§å°

æ€»è€—æ—¶: 5-10åˆ†é’Ÿï¼ˆå¦‚æœåªç”¨Loggingå¯èƒ½éœ€è¦1-2å°æ—¶ï¼‰
```

**ååŒä»·å€¼æ€»ç»“**ï¼š

| é—®é¢˜ç±»å‹ | ä¸»è¦ä½¿ç”¨å·¥å…· | è¾…åŠ©å·¥å…· |
|---------|------------|---------|
| å‘ç°å¼‚å¸¸ | Metrics (Prometheuså‘Šè­¦) | - |
| å®šä½æœåŠ¡ | Tracing (Jaeger) | Metrics (ç¼©å°æ—¶é—´èŒƒå›´) |
| æŸ¥çœ‹è¯¦æƒ… | Logging (Kibana) | Tracing (è·å–Trace ID) |
| è¶‹åŠ¿åˆ†æ | Metrics (Grafana Dashboard) | - |
| å®¹é‡è§„åˆ’ | Metrics (å†å²æ•°æ®åˆ†æ) | Logging (é”™è¯¯æ—¥å¿—ç»Ÿè®¡) |

---

### 9.1.2 Kubernetesç›‘æ§æ¶æ„

#### Kubernetesç›‘æ§å±‚æ¬¡

Kubernetesçš„ç›‘æ§éœ€è¦è¦†ç›–å¤šä¸ªå±‚æ¬¡ï¼Œæ¯ä¸€å±‚éƒ½æœ‰ä¸åŒçš„å…³æ³¨ç‚¹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     åº”ç”¨å±‚ (Application)                      â”‚
â”‚  â— ä¸šåŠ¡æŒ‡æ ‡: è®¢å•é‡ã€æ”¯ä»˜æˆåŠŸç‡ã€ç”¨æˆ·æ´»è·ƒåº¦                     â”‚
â”‚  â— åº”ç”¨æ€§èƒ½: APIå»¶è¿Ÿã€é”™è¯¯ç‡ã€QPS                              â”‚
â”‚  â— è‡ªå®šä¹‰Metrics: /metricsç«¯ç‚¹æš´éœ²çš„ä¸šåŠ¡æŒ‡æ ‡                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   å®¹å™¨å±‚ (Container)                          â”‚
â”‚  â— å®¹å™¨èµ„æº: CPUã€å†…å­˜ã€ç½‘ç»œã€ç£ç›˜IO                            â”‚
â”‚  â— å®¹å™¨çŠ¶æ€: é‡å¯æ¬¡æ•°ã€OOMæ¬¡æ•°ã€é•œåƒæ‹‰å–æ—¶é•¿                     â”‚
â”‚  â— å®¹å™¨æ—¥å¿—: stdout/stderrè¾“å‡º                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Podå±‚ (Pod)                               â”‚
â”‚  â— PodçŠ¶æ€: Running/Pending/Failed/CrashLoopBackOff          â”‚
â”‚  â— Podäº‹ä»¶: è°ƒåº¦å¤±è´¥ã€å¥åº·æ£€æŸ¥å¤±è´¥ã€VolumeæŒ‚è½½å¤±è´¥               â”‚
â”‚  â— Podèµ„æº: requests/limitsè®¾ç½®ã€å®é™…ä½¿ç”¨é‡                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Kubernetesèµ„æºå±‚ (K8s Resources)                â”‚
â”‚  â— Deployment: å‰¯æœ¬æ•°ã€å¯ç”¨å‰¯æœ¬ã€æ›´æ–°çŠ¶æ€                       â”‚
â”‚  â— Service: Endpointæ•°é‡ã€æµé‡åˆ†å¸ƒ                            â”‚
â”‚  â— PVC/PV: å­˜å‚¨ä½¿ç”¨ç‡ã€IOPSã€ååé‡                           â”‚
â”‚  â— Node: èŠ‚ç‚¹çŠ¶æ€ã€å¯è°ƒåº¦èµ„æºã€æ±¡ç‚¹å’Œæ ‡ç­¾                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   èŠ‚ç‚¹å±‚ (Node)                              â”‚
â”‚  â— ç³»ç»Ÿèµ„æº: CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ                             â”‚
â”‚  â— ç³»ç»ŸæœåŠ¡: kubeletã€kube-proxyã€å®¹å™¨è¿è¡Œæ—¶                   â”‚
â”‚  â— ç³»ç»Ÿæ—¥å¿—: /var/log/messagesã€journalctl                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               æ§åˆ¶å¹³é¢å±‚ (Control Plane)                      â”‚
â”‚  â— API Server: è¯·æ±‚å»¶è¿Ÿã€é”™è¯¯ç‡ã€å®¡è®¡æ—¥å¿—                      â”‚
â”‚  â— etcd: æ•°æ®åº“å¤§å°ã€å†™å…¥å»¶è¿Ÿã€Leaderé€‰ä¸¾                      â”‚
â”‚  â— Scheduler: è°ƒåº¦å»¶è¿Ÿã€é˜Ÿåˆ—é•¿åº¦ã€å¤±è´¥æ¬¡æ•°                     â”‚
â”‚  â— Controller Manager: Reconcileå¾ªç¯è€—æ—¶ã€å·¥ä½œé˜Ÿåˆ—æ·±åº¦        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### KubernetesåŸç”Ÿç›‘æ§æ¶æ„

Kubernetesæä¾›äº†ä¸¤å¥—å®˜æ–¹ç›‘æ§APIï¼š

##### 1. Resource Metrics API (èµ„æºæŒ‡æ ‡)

**ç”¨é€”**ï¼šæä¾›Podå’ŒNodeçš„CPU/å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œç”¨äºHPAå’ŒVPA

**æ¶æ„**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubectl top  â”‚  (æŸ¥è¯¢CPU/å†…å­˜)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server (Metrics API)           â”‚
â”‚   /apis/metrics.k8s.io/v1beta1/      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metrics Server                     â”‚  (èšåˆå™¨)
â”‚   - ä»kubeletæŠ“å–æŒ‡æ ‡                 â”‚
â”‚   - å†…å­˜å­˜å‚¨(æœ€è¿‘15åˆ†é’Ÿ)               â”‚
â”‚   - ä¸æŒä¹…åŒ–                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   kubelet (æ¯ä¸ªNode)                 â”‚
â”‚   - cAdvisor: å®¹å™¨èµ„æºæ•°æ®            â”‚
â”‚   - /stats/summary API               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metrics Serverçš„å±€é™**ï¼š
- âŒ åªä¿å­˜æœ€è¿‘15åˆ†é’Ÿæ•°æ®ï¼ˆæ— æ³•æŸ¥çœ‹å†å²è¶‹åŠ¿ï¼‰
- âŒ åªæœ‰CPU/å†…å­˜ï¼ˆæ— æ³•æŸ¥çœ‹ç½‘ç»œã€ç£ç›˜IOï¼‰
- âŒ æ— æ³•è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆåªèƒ½çœ‹èµ„æºï¼Œçœ‹ä¸åˆ°ä¸šåŠ¡æŒ‡æ ‡ï¼‰
- âŒ ä¸æ”¯æŒå‘Šè­¦ï¼ˆéœ€è¦é…åˆå…¶ä»–å·¥å…·ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… HPAè‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆåŸºäºCPU/å†…å­˜ï¼‰
- âœ… å¿«é€ŸæŸ¥çœ‹å½“å‰èµ„æºä½¿ç”¨ï¼ˆkubectl topï¼‰
- âœ… è½»é‡çº§éƒ¨ç½²ï¼ˆå°å‹é›†ç¾¤ï¼‰

##### 2. Custom Metrics API (è‡ªå®šä¹‰æŒ‡æ ‡)

**ç”¨é€”**ï¼šæ”¯æŒä»»æ„è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆå¦‚ï¼šQPSã€é”™è¯¯ç‡ï¼‰ï¼Œç”¨äºé«˜çº§HPA

**æ¶æ„**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HPA Controller                     â”‚
â”‚   (æ ¹æ®è‡ªå®šä¹‰æŒ‡æ ‡æ‰©ç¼©å®¹)               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server                         â”‚
â”‚   /apis/custom.metrics.k8s.io/v1beta1â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prometheus Adapter                 â”‚  (é€‚é…å™¨)
â”‚   - å°†PrometheusæŒ‡æ ‡è½¬æ¢ä¸ºK8s API     â”‚
â”‚   - æ”¯æŒPromQLæŸ¥è¯¢                    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prometheus                         â”‚
â”‚   - æŠ“å–åº”ç”¨çš„/metricsç«¯ç‚¹            â”‚
â”‚   - å­˜å‚¨æ—¶åºæ•°æ®                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç¤ºä¾‹**ï¼šåŸºäºQPSè‡ªåŠ¨æ‰©ç¼©å®¹

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second  # è‡ªå®šä¹‰æŒ‡æ ‡
      target:
        type: AverageValue
        averageValue: "1000"  # æ¯ä¸ªPodå¤„ç†1000 QPSæ—¶æ‰©å®¹
```

#### å®Œæ•´çš„ç”Ÿäº§çº§ç›‘æ§æ¶æ„

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚      å¤–éƒ¨ç”¨æˆ·/è¿ç»´äººå‘˜                â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Grafana      â”‚  â”‚  Kibana    â”‚  â”‚  Jaeger UI     â”‚
            â”‚  (å¯è§†åŒ–)       â”‚  â”‚ (æ—¥å¿—æŸ¥è¯¢)  â”‚  â”‚  (é“¾è·¯è¿½è¸ª)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                 â”‚                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus  â”‚ â”‚ Elasticsearchâ”‚ â”‚ Jaeger Collectorâ”‚
â”‚ (Metrics)   â”‚ â”‚  (æ—¥å¿—å­˜å‚¨)   â”‚ â”‚  (Traceå­˜å‚¨)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚   Fluentd      â”‚  â”‚ Jaeger Agent â”‚
         â”‚  â”‚  (æ—¥å¿—æ”¶é›†)     â”‚  â”‚  (Traceé‡‡é›†) â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚         Kubernetes Cluster                 â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
    â”‚  â”‚ kube-state-metrics (K8sèµ„æºçŠ¶æ€)      â”‚â—„â”€â”˜ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Node Exporter (èŠ‚ç‚¹æŒ‡æ ‡)              â”‚â—„â”€â”€â”€â”¤
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Application Pods (åº”ç”¨æŒ‡æ ‡/æ—¥å¿—)      â”‚â—„â”€â”€â”€â”˜
    â”‚  â”‚  - /metrics (Prometheusæ ¼å¼)          â”‚
    â”‚  â”‚  - stdout/stderræ—¥å¿—                  â”‚
    â”‚  â”‚  - OpenTelemetry SDK (TracingåŸ‹ç‚¹)    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å„ç»„ä»¶èŒè´£**ï¼š

| ç»„ä»¶ | èŒè´£ | æ•°æ®é‡çº§ |
|------|------|---------|
| **Prometheus** | æŠ“å–å’Œå­˜å‚¨Metrics | ä¸­ç­‰ï¼ˆæ¯ç§’æ•°åƒæ ·æœ¬ï¼‰ |
| **kube-state-metrics** | æš´éœ²K8sèµ„æºçŠ¶æ€ä¸ºMetrics | ä½ï¼ˆèµ„æºå¯¹è±¡çº§åˆ«ï¼‰ |
| **Node Exporter** | æš´éœ²èŠ‚ç‚¹ç³»ç»ŸæŒ‡æ ‡ | ä¸­ç­‰ï¼ˆæ¯ä¸ªèŠ‚ç‚¹æ•°ç™¾æŒ‡æ ‡ï¼‰ |
| **Fluentd/Fluent Bit** | æ”¶é›†å®¹å™¨æ—¥å¿—å¹¶è½¬å‘åˆ°ES | é«˜ï¼ˆæ¯ç§’GBçº§åˆ«ï¼‰ |
| **Elasticsearch** | å­˜å‚¨å’Œç´¢å¼•æ—¥å¿— | æé«˜ï¼ˆTBçº§åˆ«ï¼‰ |
| **Kibana** | æ—¥å¿—æŸ¥è¯¢å’Œå¯è§†åŒ– | - |
| **Jaeger Agent** | æ¥æ”¶åº”ç”¨Traceæ•°æ®å¹¶è½¬å‘ | ä¸­ç­‰ï¼ˆé‡‡æ ·åï¼‰ |
| **Jaeger Collector** | èšåˆTraceå¹¶å†™å…¥å­˜å‚¨ | ä¸­ç­‰ |
| **Grafana** | ç»Ÿä¸€å¯è§†åŒ–å¹³å° | - |

---

### 9.1.3 Metrics APIä¸èµ„æºæŒ‡æ ‡

#### Metrics Serverè¯¦è§£

**Metrics Serveræ˜¯ä»€ä¹ˆï¼Ÿ**

Metrics Serveræ˜¯Kuberneteså®˜æ–¹æä¾›çš„è½»é‡çº§ã€çŸ­æœŸçš„èµ„æºæŒ‡æ ‡æ”¶é›†å™¨ã€‚å®ƒä»æ¯ä¸ªèŠ‚ç‚¹çš„kubeletæ”¶é›†CPUå’Œå†…å­˜ä½¿ç”¨æ•°æ®ï¼Œå¹¶é€šè¿‡Metrics APIæš´éœ²ç»™Kubernetesç»„ä»¶ï¼ˆå¦‚HPAã€VPAã€kubectl topï¼‰ã€‚

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š
- âœ… å®˜æ–¹ç»´æŠ¤ï¼Œç¨³å®šå¯é 
- âœ… éƒ¨ç½²ç®€å•ï¼ˆå•ä¸ªDeploymentï¼‰
- âœ… èµ„æºå ç”¨ä½ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ä»…éœ€10-20MBå†…å­˜ï¼‰
- âœ… ä¸kubectlé›†æˆï¼ˆkubectl topå‘½ä»¤ï¼‰
- âŒ åªä¿å­˜æœ€è¿‘æ•°æ®ï¼ˆä¸é€‚åˆå†å²åˆ†æï¼‰
- âŒ åŠŸèƒ½æœ‰é™ï¼ˆä»…CPU/å†…å­˜ï¼‰

**æ¶æ„å›¾**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kubernetes API Server                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Aggregation Layer (APIèšåˆå±‚)                       â”‚   â”‚
â”‚  â”‚  - /apis/metrics.k8s.io/v1beta1/nodes                â”‚   â”‚
â”‚  â”‚  - /apis/metrics.k8s.io/v1beta1/pods                 â”‚   â”‚
â”‚  â”‚  - /apis/metrics.k8s.io/v1beta1/namespaces/{ns}/pods â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Metrics Server           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ In-Memory Storage    â”‚  â”‚ (ä»…ä¿ç•™15åˆ†é’Ÿæ•°æ®)
        â”‚  â”‚ - CPU/Memory         â”‚  â”‚
        â”‚  â”‚ - 60ç§’åˆ·æ–°é—´éš”        â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ Kubelet Client       â”‚  â”‚ (æŠ“å–kubeletæ•°æ®)
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚kubelet â”‚   â”‚kubelet â”‚   â”‚kubelet â”‚
â”‚ Node1  â”‚   â”‚ Node2  â”‚   â”‚ Node3  â”‚
â”‚  â””â”€â”€â”  â”‚   â”‚  â””â”€â”€â”  â”‚   â”‚  â””â”€â”€â”  â”‚
â”‚ cAdvâ”‚  â”‚   â”‚ cAdvâ”‚  â”‚   â”‚ cAdvâ”‚  â”‚ (å®¹å™¨èµ„æºç›‘æ§)
â””â”€â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”€â”˜  â”‚
   Pod1     Pod2        Pod3
```

#### éƒ¨ç½²Metrics Server

**1. å¿«é€Ÿéƒ¨ç½²ï¼ˆå®˜æ–¹YAMLï¼‰**

```bash
# ä¸‹è½½å®˜æ–¹éƒ¨ç½²æ–‡ä»¶
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

**2. è‡ªå®šä¹‰éƒ¨ç½²ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰**

```yaml
# metrics-server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  replicas: 1  # ç”Ÿäº§ç¯å¢ƒå»ºè®®2ä¸ªå‰¯æœ¬ï¼ˆé«˜å¯ç”¨ï¼‰
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      containers:
      - name: metrics-server
        image: registry.k8s.io/metrics-server/metrics-server:v0.7.0
        imagePullPolicy: IfNotPresent
        args:
        - --cert-dir=/tmp
        - --secure-port=10250
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s  # æ•°æ®é‡‡é›†é—´éš”ï¼ˆé»˜è®¤60sï¼Œå¯è°ƒæ•´ä¸º15sæé«˜ç²¾åº¦ï¼‰
        # å¦‚æœkubeletä½¿ç”¨è‡ªç­¾åè¯ä¹¦ï¼Œéœ€è¦æ·»åŠ ä»¥ä¸‹å‚æ•°ï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰
        # - --kubelet-insecure-tls
        ports:
        - containerPort: 10250
          name: https
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /livez
            port: https
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /readyz
            port: https
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 10
          failureThreshold: 3
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
      volumes:
      - name: tmp-dir
        emptyDir: {}
      priorityClassName: system-cluster-critical
      nodeSelector:
        kubernetes.io/os: linux
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    k8s-app: metrics-server
  ports:
  - port: 443
    protocol: TCP
    targetPort: https
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:metrics-server
rules:
- apiGroups:
  - ""
  resources:
  - nodes/metrics
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:metrics-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:metrics-server
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:aggregated-metrics-reader
  labels:
    rbac.authorization.k8s.io/aggregate-to-view: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
rules:
- apiGroups:
  - metrics.k8s.io
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1beta1.metrics.k8s.io
spec:
  service:
    name: metrics-server
    namespace: kube-system
  group: metrics.k8s.io
  version: v1beta1
  insecureSkipTLSVerify: true
  groupPriorityMinimum: 100
  versionPriority: 100
```

**3. éƒ¨ç½²å¹¶éªŒè¯**

```bash
# éƒ¨ç½²
kubectl apply -f metrics-server-deployment.yaml

# æ£€æŸ¥PodçŠ¶æ€
kubectl get pod -n kube-system -l k8s-app=metrics-server

# è¾“å‡ºç¤ºä¾‹:
# NAME                              READY   STATUS    RESTARTS   AGE
# metrics-server-5f8d6b7c9d-7x4ml   1/1     Running   0          2m

# æ£€æŸ¥APIæ³¨å†Œ
kubectl get apiservice v1beta1.metrics.k8s.io

# è¾“å‡ºç¤ºä¾‹:
# NAME                     SERVICE                      AVAILABLE   AGE
# v1beta1.metrics.k8s.io   kube-system/metrics-server   True        2m

# æµ‹è¯•æŸ¥è¯¢ï¼ˆç­‰å¾…1-2åˆ†é’Ÿæ•°æ®é‡‡é›†å®Œæˆï¼‰
kubectl top nodes
kubectl top pods -A
```

**å¸¸è§é—®é¢˜æ’æŸ¥**ï¼š

```bash
# é—®é¢˜1: Metrics Server PodçŠ¶æ€ä¸ºCrashLoopBackOff
kubectl logs -n kube-system -l k8s-app=metrics-server

# å¸¸è§é”™è¯¯: "x509: cannot validate certificate for xxx because it doesn't contain any IP SANs"
# è§£å†³: æ·»åŠ  --kubelet-insecure-tls å‚æ•°ï¼ˆä»…é™æµ‹è¯•ç¯å¢ƒï¼‰

# é—®é¢˜2: kubectl top nodes æŠ¥é”™ "Error from server (ServiceUnavailable): the server is currently unable to handle the request"
# åŸå› : Metrics Serverè¿˜åœ¨é‡‡é›†æ•°æ®ï¼Œç­‰å¾…1-2åˆ†é’Ÿ

# é—®é¢˜3: æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
kubectl logs -n kube-system deploy/metrics-server --tail=100 -f
```

#### ä½¿ç”¨kubectl topæŸ¥çœ‹èµ„æº

**1. æŸ¥çœ‹èŠ‚ç‚¹èµ„æº**

```bash
# æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹çš„CPUå’Œå†…å­˜ä½¿ç”¨
kubectl top nodes

# è¾“å‡ºç¤ºä¾‹:
# NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
# node1      450m         22%    3500Mi          45%
# node2      320m         16%    2800Mi          36%
# node3      580m         29%    4200Mi          54%
```

**è§£è¯»**ï¼š
- `CPU(cores)`: ä½¿ç”¨çš„CPUæ ¸å¿ƒæ•°ï¼ˆ450m = 0.45æ ¸ï¼‰
- `CPU%`: å èŠ‚ç‚¹æ€»CPUçš„ç™¾åˆ†æ¯”ï¼ˆå‡è®¾èŠ‚ç‚¹æœ‰2æ ¸ï¼Œ450m/2000m = 22.5%ï¼‰
- `MEMORY(bytes)`: å†…å­˜ä½¿ç”¨é‡ï¼ˆ3500Mi â‰ˆ 3.5GBï¼‰
- `MEMORY%`: å èŠ‚ç‚¹æ€»å†…å­˜çš„ç™¾åˆ†æ¯”

**2. æŸ¥çœ‹Podèµ„æº**

```bash
# æŸ¥çœ‹æ‰€æœ‰å‘½åç©ºé—´çš„Pod
kubectl top pods -A

# æŸ¥çœ‹ç‰¹å®šå‘½åç©ºé—´
kubectl top pods -n production

# æŸ¥çœ‹ç‰¹å®šPodçš„å®¹å™¨çº§åˆ«èµ„æº
kubectl top pods nginx-deployment-abc123 --containers

# è¾“å‡ºç¤ºä¾‹:
# POD                          CONTAINER    CPU(cores)   MEMORY(bytes)
# nginx-deployment-abc123      nginx        10m          50Mi
# nginx-deployment-abc123      sidecar      2m           20Mi

# æ’åºï¼ˆæŒ‰CPUé™åºï¼‰
kubectl top pods -A --sort-by=cpu

# æ’åºï¼ˆæŒ‰å†…å­˜é™åºï¼‰
kubectl top pods -A --sort-by=memory
```

**3. ç»“åˆå…¶ä»–å‘½ä»¤åˆ†æ**

```bash
# æ‰¾å‡ºå†…å­˜ä½¿ç”¨TOP 10çš„Pod
kubectl top pods -A --sort-by=memory | head -11

# æ‰¾å‡ºCPUä½¿ç”¨è¶…è¿‡100mçš„Pod
kubectl top pods -A | awk '$2 > 100'

# å¯¹æ¯”requests/limitsé…ç½®
kubectl get pods nginx-abc -o json | jq '.spec.containers[].resources'
kubectl top pod nginx-abc
```

#### Metrics APIçš„ç¼–ç¨‹ä½¿ç”¨

**1. ç›´æ¥è°ƒç”¨API**

```bash
# æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹æŒ‡æ ‡
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes | jq .

# è¾“å‡ºç¤ºä¾‹:
# {
#   "kind": "NodeMetricsList",
#   "apiVersion": "metrics.k8s.io/v1beta1",
#   "metadata": {},
#   "items": [
#     {
#       "metadata": {
#         "name": "node1",
#         "creationTimestamp": "2024-01-20T10:30:00Z"
#       },
#       "timestamp": "2024-01-20T10:29:45Z",
#       "window": "30s",
#       "usage": {
#         "cpu": "450m",
#         "memory": "3500Mi"
#       }
#     }
#   ]
# }

# æŸ¥è¯¢ç‰¹å®šPodæŒ‡æ ‡
kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/default/pods/nginx-abc | jq .
```

**2. ä½¿ç”¨client-goè®¿é—®Metrics API (Go)**

```go
package main

import (
    "context"
    "fmt"
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/tools/clientcmd"
    metricsv "k8s.io/metrics/pkg/client/clientset/versioned"
)

func main() {
    // åŠ è½½kubeconfig
    config, err := clientcmd.BuildConfigFromFlags("", "/home/user/.kube/config")
    if err != nil {
        panic(err)
    }

    // åˆ›å»ºMetricså®¢æˆ·ç«¯
    metricsClient, err := metricsv.NewForConfig(config)
    if err != nil {
        panic(err)
    }

    // æŸ¥è¯¢èŠ‚ç‚¹æŒ‡æ ‡
    nodeMetrics, err := metricsClient.MetricsV1beta1().NodeMetricses().List(context.TODO(), metav1.ListOptions{})
    if err != nil {
        panic(err)
    }

    for _, node := range nodeMetrics.Items {
        cpu := node.Usage.Cpu().MilliValue()  // è½¬æ¢ä¸ºæ¯«æ ¸
        memory := node.Usage.Memory().Value() / 1024 / 1024  // è½¬æ¢ä¸ºMiB
        fmt.Printf("Node: %s, CPU: %dm, Memory: %dMi\n", node.Name, cpu, memory)
    }

    // æŸ¥è¯¢PodæŒ‡æ ‡
    podMetrics, err := metricsClient.MetricsV1beta1().PodMetricses("default").List(context.TODO(), metav1.ListOptions{})
    if err != nil {
        panic(err)
    }

    for _, pod := range podMetrics.Items {
        for _, container := range pod.Containers {
            cpu := container.Usage.Cpu().MilliValue()
            memory := container.Usage.Memory().Value() / 1024 / 1024
            fmt.Printf("Pod: %s, Container: %s, CPU: %dm, Memory: %dMi\n",
                pod.Name, container.Name, cpu, memory)
        }
    }
}
```

**3. ä½¿ç”¨Pythonè®¿é—®Metrics API**

```python
from kubernetes import client, config

# åŠ è½½kubeconfig
config.load_kube_config()

# åˆ›å»ºAPIå®¢æˆ·ç«¯
api_client = client.ApiClient()
custom_api = client.CustomObjectsApi(api_client)

# æŸ¥è¯¢èŠ‚ç‚¹æŒ‡æ ‡
node_metrics = custom_api.list_cluster_custom_object(
    group="metrics.k8s.io",
    version="v1beta1",
    plural="nodes"
)

for node in node_metrics['items']:
    name = node['metadata']['name']
    cpu = node['usage']['cpu']
    memory = node['usage']['memory']
    print(f"Node: {name}, CPU: {cpu}, Memory: {memory}")

# æŸ¥è¯¢PodæŒ‡æ ‡
pod_metrics = custom_api.list_namespaced_custom_object(
    group="metrics.k8s.io",
    version="v1beta1",
    namespace="default",
    plural="pods"
)

for pod in pod_metrics['items']:
    pod_name = pod['metadata']['name']
    for container in pod['containers']:
        container_name = container['name']
        cpu = container['usage']['cpu']
        memory = container['usage']['memory']
        print(f"Pod: {pod_name}, Container: {container_name}, CPU: {cpu}, Memory: {memory}")
```

#### HPAåŸºäºMetricsè‡ªåŠ¨æ‰©ç¼©å®¹

**1. åŸºäºCPUçš„HPA**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPUä½¿ç”¨ç‡è¶…è¿‡70%æ—¶æ‰©å®¹
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # ç¼©å®¹å‰ç­‰å¾…5åˆ†é’Ÿè§‚å¯Ÿ
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60  # æ¯åˆ†é’Ÿæœ€å¤šç¼©å®¹50%
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30  # æ¯30ç§’æœ€å¤šæ‰©å®¹100%ï¼ˆç¿»å€ï¼‰
      - type: Pods
        value: 4
        periodSeconds: 30  # æ¯30ç§’æœ€å¤šå¢åŠ 4ä¸ªPod
      selectPolicy: Max  # é€‰æ‹©æ‰©å®¹æœ€å¿«çš„ç­–ç•¥
```

**2. åŸºäºå†…å­˜çš„HPA**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: java-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: java-app
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%æ—¶æ‰©å®¹
```

**3. å¤šæŒ‡æ ‡ç»„åˆHPA**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web
  minReplicas: 5
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # ä»»æ„ä¸€ä¸ªæŒ‡æ ‡è¾¾åˆ°é˜ˆå€¼å°±è§¦å‘æ‰©å®¹
```

**4. éªŒè¯HPA**

```bash
# éƒ¨ç½²HPA
kubectl apply -f nginx-hpa.yaml

# æŸ¥çœ‹HPAçŠ¶æ€
kubectl get hpa nginx-hpa

# è¾“å‡ºç¤ºä¾‹:
# NAME        REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
# nginx-hpa   Deployment/nginx   15%/70%   2         10        2          5m

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
kubectl describe hpa nginx-hpa

# æ¨¡æ‹Ÿè´Ÿè½½æµ‹è¯•ï¼ˆè§¦å‘æ‰©å®¹ï¼‰
kubectl run -it --rm load-generator --image=busybox --restart=Never -- sh -c "while true; do wget -q -O- http://nginx; done"

# è§‚å¯ŸHPAè‡ªåŠ¨æ‰©å®¹
kubectl get hpa nginx-hpa --watch
```

---

### 9.1.4 ç›‘æ§æ•°æ®é‡‡é›†è·¯å¾„

#### kubeletçš„cAdvisor

**cAdvisor (Container Advisor)** æ˜¯kubeletå†…ç½®çš„å®¹å™¨èµ„æºç›‘æ§ç»„ä»¶ï¼Œè´Ÿè´£æ”¶é›†èŠ‚ç‚¹ä¸Šæ‰€æœ‰å®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µã€‚

**cAdvisoræš´éœ²çš„APIç«¯ç‚¹**ï¼š

```bash
# 1. Summary API (Metrics Serverä½¿ç”¨)
# æä¾›èŠ‚ç‚¹å’ŒPodçº§åˆ«çš„èšåˆæ•°æ®
curl -k https://NODE_IP:10250/stats/summary \
  --header "Authorization: Bearer $(kubectl get secret -n kube-system -o jsonpath='{.items[?(@.metadata.annotations.kubernetes\.io/service-account\.name=="default")].data.token}' | base64 -d)"

# è¿”å›ç¤ºä¾‹:
# {
#   "node": {
#     "nodeName": "node1",
#     "cpu": {
#       "time": "2024-01-20T10:30:00Z",
#       "usageNanoCores": 450000000,  // 450m CPU
#       "usageCoreNanoSeconds": 1234567890
#     },
#     "memory": {
#       "time": "2024-01-20T10:30:00Z",
#       "usageBytes": 3670016000,  // 3.5GB
#       "workingSetBytes": 3500000000
#     }
#   },
#   "pods": [...]
# }

# 2. Metrics API (Prometheusä½¿ç”¨)
# æä¾›æ›´è¯¦ç»†çš„å®¹å™¨çº§åˆ«æ•°æ®
curl -k https://NODE_IP:10250/metrics

# è¿”å›Prometheusæ ¼å¼:
# container_cpu_usage_seconds_total{container="nginx",namespace="default",pod="nginx-abc"} 12.34
# container_memory_working_set_bytes{container="nginx",namespace="default",pod="nginx-abc"} 52428800
```

**cAdvisorç›‘æ§çš„æŒ‡æ ‡ç»´åº¦**ï¼š

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | è¯´æ˜ |
|---------|---------|------|
| **CPU** | cpu.usageNanoCores | å½“å‰CPUä½¿ç”¨ï¼ˆçº³æ ¸ï¼‰ |
|  | cpu.usageCoreNanoSeconds | ç´¯è®¡CPUä½¿ç”¨æ—¶é—´ |
| **å†…å­˜** | memory.usageBytes | æ€»å†…å­˜ä½¿ç”¨ï¼ˆåŒ…æ‹¬ç¼“å­˜ï¼‰ |
|  | memory.workingSetBytes | å·¥ä½œé›†å†…å­˜ï¼ˆçœŸå®ä½¿ç”¨ï¼‰ |
|  | memory.rssBytes | RSSå†…å­˜ï¼ˆåŒ¿åå†…å­˜ï¼‰ |
|  | memory.pageFaults | é¡µé¢é”™è¯¯æ¬¡æ•° |
| **ç½‘ç»œ** | network.rxBytes | æ¥æ”¶å­—èŠ‚æ•° |
|  | network.txBytes | å‘é€å­—èŠ‚æ•° |
|  | network.rxErrors | æ¥æ”¶é”™è¯¯æ•° |
| **ç£ç›˜** | fs.usedBytes | æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨é‡ |
|  | fs.capacityBytes | æ–‡ä»¶ç³»ç»Ÿæ€»å®¹é‡ |
| **å®¹å™¨** | startTime | å®¹å™¨å¯åŠ¨æ—¶é—´ |
|  | restartCount | é‡å¯æ¬¡æ•° |

#### Prometheusæ•°æ®é‡‡é›†æµç¨‹

Prometheusé‡‡ç”¨**æ‹‰æ¨¡å¼ (Pull Model)** é‡‡é›†æ•°æ®ï¼Œä¸ä¼ ç»Ÿçš„æ¨æ¨¡å¼ï¼ˆå¦‚StatsDï¼‰ä¸åŒã€‚

**å®Œæ•´çš„æ•°æ®æµ**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Prometheus Server                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Service Discovery (æœåŠ¡å‘ç°)                       â”‚     â”‚
â”‚  â”‚  - Kubernetes API (è‡ªåŠ¨å‘ç°Pod/Service/Node)        â”‚     â”‚
â”‚  â”‚  - é™æ€é…ç½®æ–‡ä»¶                                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Scraper (æŠ“å–å™¨)                                   â”‚     â”‚
â”‚  â”‚  - å®šæœŸHTTP GET /metrics                            â”‚     â”‚
â”‚  â”‚  - é»˜è®¤é—´éš”: 15s-60s                                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  TSDB (æ—¶åºæ•°æ®åº“)                                  â”‚     â”‚
â”‚  â”‚  - å‹ç¼©å­˜å‚¨ (æ¯ä¸ªæ ·æœ¬çº¦1-2å­—èŠ‚)                      â”‚     â”‚
â”‚  â”‚  - é»˜è®¤ä¿ç•™15å¤©                                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ HTTP GET /metrics (æ¯15s)
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚                â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚kubelet   â”‚    â”‚kube-stateâ”‚    â”‚  Node    â”‚      â”‚  App     â”‚
    â”‚/metrics  â”‚    â”‚-metrics  â”‚    â”‚ Exporter â”‚      â”‚ /metrics â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    (å®¹å™¨èµ„æº)       (K8sèµ„æºçŠ¶æ€)   (èŠ‚ç‚¹ç³»ç»ŸæŒ‡æ ‡)     (åº”ç”¨æŒ‡æ ‡)
```

**Prometheusé…ç½®ç¤ºä¾‹**ï¼š

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s  # å…¨å±€æŠ“å–é—´éš”
      evaluation_interval: 15s  # è§„åˆ™è¯„ä¼°é—´éš”
      external_labels:
        cluster: 'production'
        region: 'us-west-2'

    # æŠ“å–é…ç½®
    scrape_configs:
    # 1. æŠ“å–kubelet (å®¹å™¨èµ„æºæŒ‡æ ‡)
    - job_name: 'kubernetes-kubelet'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node  # æœåŠ¡å‘ç°: æ‰€æœ‰èŠ‚ç‚¹
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

    # 2. æŠ“å–kube-state-metrics (K8sèµ„æºçŠ¶æ€)
    - job_name: 'kube-state-metrics'
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
        action: keep
        regex: kube-state-metrics

    # 3. æŠ“å–Node Exporter (èŠ‚ç‚¹ç³»ç»ŸæŒ‡æ ‡)
    - job_name: 'node-exporter'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__

    # 4. æŠ“å–åº”ç”¨Pod (è‡ªå®šä¹‰æŒ‡æ ‡)
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      # åªæŠ“å–å¸¦æœ‰ prometheus.io/scrape=true æ³¨è§£çš„Pod
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      # è‡ªå®šä¹‰æŠ“å–ç«¯å£ (é»˜è®¤/metrics)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: (.+)
        replacement: $1
      # è‡ªå®šä¹‰æŠ“å–è·¯å¾„
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      # æ·»åŠ å‘½åç©ºé—´æ ‡ç­¾
      - source_labels: [__meta_kubernetes_namespace]
        target_label: kubernetes_namespace
      # æ·»åŠ Podåç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: kubernetes_pod_name
```

**åº”ç”¨å¦‚ä½•æš´éœ²Metrics**ï¼š

```yaml
# ç¤ºä¾‹: Goåº”ç”¨æš´éœ²PrometheusæŒ‡æ ‡
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  annotations:
    prometheus.io/scrape: "true"  # å‘Šè¯‰PrometheusæŠ“å–æ­¤Pod
    prometheus.io/port: "8080"    # æŒ‡æ ‡ç«¯å£
    prometheus.io/path: "/metrics"  # æŒ‡æ ‡è·¯å¾„
spec:
  containers:
  - name: app
    image: my-app:v1.0
    ports:
    - containerPort: 8080
      name: metrics
```

```go
// Goåº”ç”¨ä»£ç ç¤ºä¾‹
package main

import (
    "net/http"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    // è‡ªå®šä¹‰CounteræŒ‡æ ‡
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    // è‡ªå®šä¹‰HistogramæŒ‡æ ‡
    httpRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request latency",
            Buckets: []float64{0.01, 0.05, 0.1, 0.5, 1, 2, 5},
        },
        []string{"method", "endpoint"},
    )
)

func init() {
    // æ³¨å†ŒæŒ‡æ ‡
    prometheus.MustRegister(httpRequestsTotal)
    prometheus.MustRegister(httpRequestDuration)
}

func main() {
    // æš´éœ²/metricsç«¯ç‚¹
    http.Handle("/metrics", promhttp.Handler())
    
    // ä¸šåŠ¡Handler
    http.HandleFunc("/api/users", func(w http.ResponseWriter, r *http.Request) {
        timer := prometheus.NewTimer(httpRequestDuration.WithLabelValues(r.Method, "/api/users"))
        defer timer.ObserveDuration()

        // ä¸šåŠ¡é€»è¾‘...
        
        httpRequestsTotal.WithLabelValues(r.Method, "/api/users", "200").Inc()
        w.Write([]byte("OK"))
    })

    http.ListenAndServe(":8080", nil)
}
```

**è®¿é—®/metricsç«¯ç‚¹çš„è¾“å‡º**ï¼š

```
# HELP http_requests_total Total number of HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",endpoint="/api/users",status="200"} 15840

# HELP http_request_duration_seconds HTTP request latency
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.01"} 8500
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.05"} 14200
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.1"} 15600
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.5"} 15820
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="1"} 15838
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="+Inf"} 15840
http_request_duration_seconds_sum{method="GET",endpoint="/api/users"} 458.92
http_request_duration_seconds_count{method="GET",endpoint="/api/users"} 15840
```

#### æ—¥å¿—é‡‡é›†æµç¨‹

**å®¹å™¨æ—¥å¿—çš„ç”Ÿå‘½å‘¨æœŸ**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Pod                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Application Container                          â”‚     â”‚
â”‚  â”‚  - stdout: æ ‡å‡†è¾“å‡º                              â”‚     â”‚
â”‚  â”‚  - stderr: æ ‡å‡†é”™è¯¯                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Container Runtime (Docker/containerd) â”‚
  â”‚  - å†™å…¥æ—¥å¿—æ–‡ä»¶:                     â”‚
  â”‚    /var/log/pods/<namespace>_<pod>_<uid>/<container>/0.log  â”‚
  â”‚  - JSONæ ¼å¼:                         â”‚
  â”‚    {"log":"[INFO] User logged in\n", "stream":"stdout", "time":"2024-01-20T10:30:00Z"} â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  kubelet (æ—¥å¿—è½®è½¬)                 â”‚
  â”‚  - é»˜è®¤å•æ–‡ä»¶ä¸Šé™: 10MB              â”‚
  â”‚  - é»˜è®¤ä¿ç•™æ–‡ä»¶æ•°: 5                â”‚
  â”‚  - è¶…è¿‡é™åˆ¶è‡ªåŠ¨è½®è½¬                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Fluentd/Fluent Bit (DaemonSet)    â”‚
  â”‚  - ä½¿ç”¨tail -fç›‘å¬æ—¥å¿—æ–‡ä»¶           â”‚
  â”‚  - è§£æJSONæ ¼å¼                     â”‚
  â”‚  - æ·»åŠ K8så…ƒæ•°æ®(Podå/å‘½åç©ºé—´)     â”‚
  â”‚  - è¿‡æ»¤/è½¬æ¢/è·¯ç”±                   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Elasticsearch / Loki              â”‚
  â”‚  - ç´¢å¼•å’Œå­˜å‚¨æ—¥å¿—                   â”‚
  â”‚  - æ”¯æŒå…¨æ–‡æœç´¢                     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluentdé…ç½®ç¤ºä¾‹**ï¼š

```yaml
# fluentd-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.monitoring.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_UID
          value: "0"  # ä»¥rootè¿è¡Œï¼ˆéœ€è¦è¯»å–æ—¥å¿—æ–‡ä»¶ï¼‰
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 1000m
            memory: 512Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluentd-config
          mountPath: /fluentd/etc/
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluentd-config
        configMap:
          name: fluentd-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
data:
  fluent.conf: |
    # è¾“å…¥: å®¹å™¨æ—¥å¿—
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    # è¿‡æ»¤: æ·»åŠ Kuberneteså…ƒæ•°æ®
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
    </filter>

    # è¿‡æ»¤: æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´çš„DEBUGæ—¥å¿—
    <filter kubernetes.**>
      @type grep
      <exclude>
        key log
        pattern /DEBUG/
      </exclude>
      <exclude>
        key $.kubernetes.namespace_name
        pattern /^(kube-system|kube-public)$/
      </exclude>
    </filter>

    # è¾“å‡º: å‘é€åˆ°Elasticsearch
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.monitoring.svc.cluster.local
      port 9200
      logstash_format true
      logstash_prefix kubernetes
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.buffer
        flush_mode interval
        flush_interval 5s
        flush_at_shutdown true
        retry_max_interval 30
      </buffer>
    </match>
```

---

**ğŸ“Š 9.1èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Kubernetesç›‘æ§çš„åŸºç¡€æ¦‚å¿µå’Œæ¶æ„è®¾è®¡ï¼š

âœ… **å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±**ï¼š
- Metrics: èšåˆçš„æ—¶åºæ•°æ®ï¼Œå¿«é€Ÿå‘ç°å¼‚å¸¸
- Logging: ç¦»æ•£çš„äº‹ä»¶è®°å½•ï¼ŒæŸ¥çœ‹è¯¦ç»†ä¸Šä¸‹æ–‡
- Tracing: åˆ†å¸ƒå¼è°ƒç”¨é“¾è·¯ï¼Œå®šä½æ€§èƒ½ç“¶é¢ˆ

âœ… **Kubernetesç›‘æ§æ¶æ„**ï¼š
- 6å±‚ç›‘æ§ä½“ç³»ï¼ˆåº”ç”¨â†’å®¹å™¨â†’Podâ†’K8sèµ„æºâ†’èŠ‚ç‚¹â†’æ§åˆ¶å¹³é¢ï¼‰
- Metrics Serveræä¾›åŸºç¡€èµ„æºæŒ‡æ ‡
- Prometheusç”Ÿæ€æä¾›å®Œæ•´ç›‘æ§æ–¹æ¡ˆ

âœ… **Metrics APIå®æˆ˜**ï¼š
- éƒ¨ç½²Metrics Server
- ä½¿ç”¨kubectl topæŸ¥çœ‹èµ„æº
- é…ç½®HPAè‡ªåŠ¨æ‰©ç¼©å®¹
- ç¼–ç¨‹è®¿é—®Metrics API

âœ… **ç›‘æ§æ•°æ®é‡‡é›†**ï¼š
- kubeletçš„cAdvisoræš´éœ²å®¹å™¨æŒ‡æ ‡
- Prometheusæ‹‰æ¨¡å¼é‡‡é›†æ•°æ®
- Fluentdæ”¶é›†å’Œè½¬å‘æ—¥å¿—

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ Prometheusçš„æ ¸å¿ƒåŸç†ï¼ŒåŒ…æ‹¬æ•°æ®æ¨¡å‹ã€PromQLæŸ¥è¯¢è¯­è¨€ã€æœåŠ¡å‘ç°æœºåˆ¶ï¼Œä»¥åŠå¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²é«˜å¯ç”¨çš„Prometheusé›†ç¾¤ã€‚

---

## 9.2 Prometheusæ ¸å¿ƒåŸç†ä¸å®æˆ˜

åœ¨9.1èŠ‚ä¸­ï¼Œæˆ‘ä»¬äº†è§£äº†Kubernetesç›‘æ§çš„æ•´ä½“æ¶æ„ï¼Œä»¥åŠMetrics APIçš„åŸºç¡€ç”¨æ³•ã€‚ä½†Metrics Serverçš„åŠŸèƒ½éå¸¸æœ‰é™ï¼ˆä»…CPU/å†…å­˜ï¼Œä»…ä¿ç•™15åˆ†é’Ÿï¼‰ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ã€å¯æ‰©å±•çš„ç›‘æ§è§£å†³æ–¹æ¡ˆï¼Œè¿™å°±æ˜¯**Prometheus**ã€‚

Prometheusæ˜¯ç”±SoundCloudå¼€å‘å¹¶äº2016å¹´åŠ å…¥CNCFçš„å¼€æºç›‘æ§ç³»ç»Ÿï¼Œç›®å‰å·²æˆä¸ºäº‘åŸç”Ÿç›‘æ§çš„äº‹å®æ ‡å‡†ã€‚å®ƒè¢«Netflixã€Uberã€DigitalOceanã€GitLabç­‰æ•°åƒå®¶å…¬å¸åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚

**ä¸ºä»€ä¹ˆé€‰æ‹©Prometheusï¼Ÿ**

| ç‰¹æ€§ | Prometheus | ä¼ ç»Ÿç›‘æ§(Zabbix/Nagios) |
|------|-----------|----------------------|
| **æ•°æ®æ¨¡å‹** | å¤šç»´æ—¶åºæ•°æ®(æ ‡ç­¾) | å•ç»´æ•°æ®(ä¸»æœº+æŒ‡æ ‡) |
| **æŸ¥è¯¢è¯­è¨€** | PromQL(çµæ´»å¼ºå¤§) | å›ºå®šæ¨¡æ¿ |
| **æœåŠ¡å‘ç°** | åŸç”Ÿæ”¯æŒK8s | éœ€æ‰‹åŠ¨é…ç½® |
| **å­˜å‚¨** | æœ¬åœ°æ—¶åºæ•°æ®åº“ | å…³ç³»å‹æ•°æ®åº“ |
| **å‘Šè­¦** | å†…ç½®AlertManager | ä¾èµ–å¤–éƒ¨æ’ä»¶ |
| **ç”Ÿæ€** | Grafana/Exportersä¸°å¯Œ | ç”Ÿæ€è¾ƒå° |

### 9.2.1 Prometheusæ¶æ„ä¸æ•°æ®æ¨¡å‹

#### Prometheusæ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Prometheusç”Ÿæ€ç³»ç»Ÿ                          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚               Prometheus Server                        â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  Retrieval (æ•°æ®æŠ“å–)                         â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - Service Discovery (æœåŠ¡å‘ç°)               â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - HTTP Pull (æ‹‰å–/metricsç«¯ç‚¹)               â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - Scrapeé—´éš”: 15s-60s                       â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                 â”‚                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  TSDB (æ—¶åºæ•°æ®åº“)                            â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - æœ¬åœ°å­˜å‚¨ (é»˜è®¤15å¤©)                        â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - å‹ç¼©ç®—æ³• (æ¯æ ·æœ¬1-2å­—èŠ‚)                   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - å—å­˜å‚¨ (2å°æ—¶ä¸€ä¸ªå—)                       â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                 â”‚                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  PromQL Engine (æŸ¥è¯¢å¼•æ“)                     â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - å³æ—¶æŸ¥è¯¢ (instant query)                   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - èŒƒå›´æŸ¥è¯¢ (range query)                     â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                 â”‚                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  HTTP Server (APIæœåŠ¡å™¨)                      â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - /api/v1/query (å³æ—¶æŸ¥è¯¢)                   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - /api/v1/query_range (èŒƒå›´æŸ¥è¯¢)             â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - /api/v1/series (æ—¶é—´åºåˆ—å…ƒæ•°æ®)            â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                    â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚                 â”‚                            â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  â”‚  Grafana            â”‚  â”‚  AlertManager         â”‚        â”‚
â”‚  â”‚  â”‚  (å¯è§†åŒ–)            â”‚  â”‚  (å‘Šè­¦ç®¡ç†)            â”‚        â”‚
â”‚  â”‚  â”‚  - Dashboard        â”‚  â”‚  - å‘Šè­¦è·¯ç”±            â”‚        â”‚
â”‚  â”‚  â”‚  - å›¾è¡¨/é¢æ¿         â”‚  â”‚  - åˆ†ç»„/æŠ‘åˆ¶/é™é»˜      â”‚        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â”‚                                        â”‚                    â”‚
â”‚  â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         â”‚  é€šçŸ¥æ¸ é“                    â”‚     â”‚
â”‚  â”‚                         â”‚  - Email / Slack / é’‰é’‰     â”‚     â”‚
â”‚  â”‚                         â”‚  - PagerDuty / Webhook     â”‚     â”‚
â”‚  â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚               ç›‘æ§ç›®æ ‡ (Targets)                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ Exporters  â”‚  â”‚ K8sèµ„æº    â”‚  â”‚ åº”ç”¨ç¨‹åº          â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - Node     â”‚  â”‚ - kubelet  â”‚  â”‚ - /metricsç«¯ç‚¹   â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - MySQL    â”‚  â”‚ - kube-    â”‚  â”‚ - Prometheus SDK â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - Redis    â”‚  â”‚   state-   â”‚  â”‚                  â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - Nginx    â”‚  â”‚   metrics  â”‚  â”‚                  â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒç»„ä»¶è¯´æ˜**ï¼š

1. **Prometheus Server**: æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£æŠ“å–ã€å­˜å‚¨å’ŒæŸ¥è¯¢æŒ‡æ ‡
2. **Exporters**: ç¬¬ä¸‰æ–¹æœåŠ¡çš„æŒ‡æ ‡æš´éœ²å™¨ï¼ˆå¦‚MySQL Exporterï¼‰
3. **Pushgateway**: æ”¯æŒçŸ­ç”Ÿå‘½å‘¨æœŸä»»åŠ¡çš„æ¨é€ï¼ˆéK8såœºæ™¯ï¼‰
4. **AlertManager**: å‘Šè­¦ç®¡ç†å’Œé€šçŸ¥
5. **Grafana**: å¯è§†åŒ–å¹³å°

#### Prometheusæ•°æ®æ¨¡å‹

Prometheusçš„æ•°æ®æ¨¡å‹æ˜¯å…¶å¼ºå¤§çš„æ ¸å¿ƒã€‚å®ƒé‡‡ç”¨**å¤šç»´æ—¶åºæ•°æ®**æ¨¡å‹ï¼Œæ¯ä¸ªæŒ‡æ ‡ç”±**æŒ‡æ ‡å**å’Œ**æ ‡ç­¾é›†**å”¯ä¸€æ ‡è¯†ã€‚

**1. æŒ‡æ ‡æ ¼å¼**

```
<metric_name>{<label_name>=<label_value>, ...} <sample_value> [<timestamp>]
```

ç¤ºä¾‹ï¼š

```
# HTTPè¯·æ±‚æ€»æ•°
http_requests_total{method="GET", endpoint="/api/users", status="200"} 15840 1705752000000

# ç»„ä»¶æ‹†è§£:
# - metric_name: http_requests_total (æŒ‡æ ‡å)
# - labels: method="GET", endpoint="/api/users", status="200" (æ ‡ç­¾)
# - value: 15840 (æ ·æœ¬å€¼)
# - timestamp: 1705752000000 (æ—¶é—´æˆ³,æ¯«ç§’,å¯é€‰)
```

**2. æŒ‡æ ‡ç±»å‹**

Prometheuså®šä¹‰äº†4ç§æŒ‡æ ‡ç±»å‹ï¼š

##### (1) Counter (è®¡æ•°å™¨)

**ç‰¹ç‚¹**ï¼š
- å•è°ƒé€’å¢ï¼ˆåªèƒ½å¢åŠ ï¼Œä¸èƒ½å‡å°‘ï¼‰
- é‡å¯åå½’é›¶
- å¸¸ç”¨äºç´¯è®¡å‹æŒ‡æ ‡

**å…¸å‹åœºæ™¯**ï¼š
```
# HTTPè¯·æ±‚æ€»æ•°
http_requests_total{method="GET", endpoint="/api/users", status="200"} 15840

# é”™è¯¯æ€»æ•°
http_errors_total{type="timeout"} 127

# æ•°æ®åº“æŸ¥è¯¢æ€»æ•°
db_queries_total{database="users", operation="select"} 892340
```

**PromQLæŸ¥è¯¢**ï¼š
```promql
# æŸ¥è¯¢Counteré€šå¸¸ä½¿ç”¨rate()æˆ–irate()è®¡ç®—é€Ÿç‡

# æ¯ç§’è¯·æ±‚æ•° (QPS)
rate(http_requests_total[5m])

# æ¯ç§’é”™è¯¯ç‡
rate(http_errors_total[5m])

# 5åˆ†é’Ÿå†…çš„è¯·æ±‚å¢é‡
increase(http_requests_total[5m])
```

##### (2) Gauge (ä»ªè¡¨ç›˜)

**ç‰¹ç‚¹**ï¼š
- å¯å¢å¯å‡
- è¡¨ç¤ºå½“å‰çŠ¶æ€
- å¯ç›´æ¥ä½¿ç”¨

**å…¸å‹åœºæ™¯**ï¼š
```
# å½“å‰å†…å­˜ä½¿ç”¨é‡ (å­—èŠ‚)
node_memory_usage_bytes 3670016000

# å½“å‰è¿æ¥æ•°
mysql_connections_active 42

# CPUæ¸©åº¦
node_cpu_temperature_celsius{cpu="0"} 56.7

# é˜Ÿåˆ—é•¿åº¦
queue_length{queue="orders"} 1523
```

**PromQLæŸ¥è¯¢**ï¼š
```promql
# Gaugeå¯ä»¥ç›´æ¥ä½¿ç”¨,ä¹Ÿå¯ä»¥ç”¨èšåˆå‡½æ•°

# å½“å‰å†…å­˜ä½¿ç”¨ç‡
node_memory_usage_bytes / node_memory_total_bytes * 100

# æœ€å¤§è¿æ¥æ•°
max_over_time(mysql_connections_active[1h])

# å¹³å‡é˜Ÿåˆ—é•¿åº¦
avg_over_time(queue_length[5m])
```

##### (3) Histogram (ç›´æ–¹å›¾)

**ç‰¹ç‚¹**ï¼š
- ç»Ÿè®¡æ•°æ®åˆ†å¸ƒ
- è‡ªåŠ¨è®¡ç®—å¤šä¸ªåˆ†ä½æ•°æ¡¶
- é€‚åˆå»¶è¿Ÿ/å¤§å°ç­‰æŒ‡æ ‡

**æ•°æ®ç»“æ„**ï¼š
```
# å‡è®¾APIå»¶è¿Ÿçš„HistogramæŒ‡æ ‡
http_request_duration_seconds_bucket{le="0.01"} 8500     # â‰¤10msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="0.05"} 14200   # â‰¤50msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="0.1"} 15600    # â‰¤100msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="0.5"} 15820    # â‰¤500msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="1"} 15838      # â‰¤1sçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="+Inf"} 15840   # æ‰€æœ‰è¯·æ±‚æ•°
http_request_duration_seconds_sum 458.92                # æ€»è€—æ—¶
http_request_duration_seconds_count 15840               # è¯·æ±‚æ€»æ•°
```

**PromQLæŸ¥è¯¢**ï¼š
```promql
# P99å»¶è¿Ÿ (99%çš„è¯·æ±‚å»¶è¿Ÿä½äºæ­¤å€¼)
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

# P95å»¶è¿Ÿ
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# å¹³å‡å»¶è¿Ÿ
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])

# è¶…è¿‡500msçš„è¯·æ±‚å æ¯”
(http_request_duration_seconds_bucket{le="+Inf"} - http_request_duration_seconds_bucket{le="0.5"}) 
/ http_request_duration_seconds_bucket{le="+Inf"}
```

##### (4) Summary (æ‘˜è¦)

**ç‰¹ç‚¹**ï¼š
- ç±»ä¼¼Histogramï¼Œä½†åœ¨å®¢æˆ·ç«¯è®¡ç®—åˆ†ä½æ•°
- ä¸éœ€è¦é¢„å®šä¹‰æ¡¶
- è®¡ç®—æˆæœ¬é«˜

**æ•°æ®ç»“æ„**ï¼š
```
# Goåº”ç”¨çš„GCå»¶è¿ŸSummary
go_gc_duration_seconds{quantile="0.5"} 0.000123   # P50 (ä¸­ä½æ•°)
go_gc_duration_seconds{quantile="0.9"} 0.000456   # P90
go_gc_duration_seconds{quantile="0.99"} 0.001234  # P99
go_gc_duration_seconds_sum 12.456                 # æ€»è€—æ—¶
go_gc_duration_seconds_count 8234                 # GCæ€»æ¬¡æ•°
```

**Histogram vs Summaryå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | Histogram | Summary |
|------|----------|---------|
| **åˆ†ä½æ•°è®¡ç®—** | æœåŠ¡ç«¯(PromQL) | å®¢æˆ·ç«¯(åº”ç”¨) |
| **èšåˆèƒ½åŠ›** | å¯è·¨å®ä¾‹èšåˆ | ä¸å¯èšåˆ |
| **æ€§èƒ½å¼€é”€** | ä½(å®¢æˆ·ç«¯) | é«˜(å®¢æˆ·ç«¯) |
| **çµæ´»æ€§** | é«˜(å¯æŸ¥ä»»æ„åˆ†ä½æ•°) | ä½(å›ºå®šåˆ†ä½æ•°) |
| **æ¨èåœºæ™¯** | å¤§éƒ¨åˆ†åœºæ™¯ | å·²çŸ¥åˆ†ä½æ•°éœ€æ±‚ |

**æ¨èï¼šä¼˜å…ˆä½¿ç”¨Histogramï¼Œå®ƒæ›´çµæ´»ä¸”æ”¯æŒèšåˆ**

**3. æ ‡ç­¾ (Labels) çš„æœ€ä½³å®è·µ**

**è‰¯å¥½çš„æ ‡ç­¾è®¾è®¡**ï¼š

```promql
# âœ… å¥½çš„æ ‡ç­¾è®¾è®¡ (åŸºæ•°å¯æ§)
http_requests_total{
  method="GET",           # åŸºæ•°: ~10 (GET/POST/PUT/DELETE...)
  endpoint="/api/users",  # åŸºæ•°: ~100 (APIç«¯ç‚¹æ•°é‡)
  status="200",           # åŸºæ•°: ~20 (HTTPçŠ¶æ€ç )
  service="order",        # åŸºæ•°: ~50 (å¾®æœåŠ¡æ•°é‡)
  environment="prod"      # åŸºæ•°: 3 (dev/staging/prod)
}
# æ€»åŸºæ•°: 10 * 100 * 20 * 50 * 3 = 3,000,000 (å¯æ¥å—)
```

**é”™è¯¯çš„æ ‡ç­¾è®¾è®¡**ï¼š

```promql
# âŒ é”™è¯¯çš„æ ‡ç­¾è®¾è®¡ (åŸºæ•°çˆ†ç‚¸)
http_requests_total{
  user_id="12345",        # åŸºæ•°: ç™¾ä¸‡çº§ (ç”¨æˆ·æ•°é‡)
  request_id="uuid-...",  # åŸºæ•°: æ— é™ (æ¯æ¬¡è¯·æ±‚å”¯ä¸€)
  timestamp="1705752000"  # åŸºæ•°: æ— é™ (æ¯ç§’ä¸€ä¸ª)
}
# å¯¼è‡´: æ•°ç™¾ä¸‡ä¸ªæ—¶é—´åºåˆ—,å†…å­˜çˆ†ç‚¸,æŸ¥è¯¢ææ…¢
```

**æ ‡ç­¾è®¾è®¡åŸåˆ™**ï¼š

1. **ä½åŸºæ•°**: æ¯ä¸ªæ ‡ç­¾çš„å”¯ä¸€å€¼åº”æ§åˆ¶åœ¨æ•°ç™¾ä»¥å†…
2. **æœ‰æ„ä¹‰**: æ ‡ç­¾åº”è¯¥æ˜¯èšåˆ/è¿‡æ»¤çš„ç»´åº¦ï¼ˆå¦‚serviceã€ç¯å¢ƒï¼‰
3. **é¿å…é«˜åŸºæ•°**: ä¸è¦ç”¨user_idã€IPåœ°å€ã€UUIDä½œä¸ºæ ‡ç­¾
4. **ä¸€è‡´æ€§**: åŒä¸€æŒ‡æ ‡çš„æ ‡ç­¾ååº”ä¿æŒä¸€è‡´

**4. æŒ‡æ ‡å‘½åè§„èŒƒ**

Prometheuså®˜æ–¹æ¨èçš„å‘½åè§„èŒƒï¼š

```
<namespace>_<subsystem>_<name>_<unit>

ç¤ºä¾‹:
- node_cpu_seconds_total          # namespace=node, subsystem=cpu, name=seconds, unit=total
- http_request_duration_seconds   # namespace=http, subsystem=request, name=duration, unit=seconds
- mysql_slave_lag_seconds         # namespace=mysql, subsystem=slave, name=lag, unit=seconds
```

**å‘½åè§„åˆ™**ï¼š

1. **ä½¿ç”¨ä¸‹åˆ’çº¿**: ä¸è¦ç”¨é©¼å³°æˆ–è¿å­—ç¬¦
2. **åŒ…å«å•ä½**: ä½¿ç”¨åŸºç¡€å•ä½ï¼ˆseconds, bytes, ratioï¼‰
3. **CounteråŠ _total**: æ‰€æœ‰CounteræŒ‡æ ‡åº”ä»¥_totalç»“å°¾
4. **é¿å…é‡å¤**: ä¸è¦åœ¨æŒ‡æ ‡åä¸­é‡å¤æ ‡ç­¾ä¿¡æ¯

```promql
# âœ… è‰¯å¥½å‘½å
http_requests_total{method="GET"}
node_memory_bytes{type="free"}

# âŒ é”™è¯¯å‘½å
httpRequestsGET              # é©¼å³° + æ ‡ç­¾ä¿¡æ¯åœ¨åç§°ä¸­
node_memory_mb               # éåŸºç¡€å•ä½
requests                     # Counterç¼ºå°‘_total
```

#### æ•°æ®å­˜å‚¨æœºåˆ¶

**1. æ—¶åºæ•°æ®åº“ (TSDB) åŸç†**

Prometheusä½¿ç”¨è‡ªç ”çš„æ—¶åºæ•°æ®åº“ï¼Œé‡‡ç”¨**å—å­˜å‚¨**å’Œ**é«˜æ•ˆå‹ç¼©**ï¼š

```
æ•°æ®ç›®å½•ç»“æ„:
/data/prometheus/
â”œâ”€â”€ 01HQXXX/                    # å—ID (2å°æ—¶ä¸€ä¸ªå—)
â”‚   â”œâ”€â”€ chunks/                 # å‹ç¼©çš„æ—¶åºæ•°æ®
â”‚   â”‚   â””â”€â”€ 000001
â”‚   â”œâ”€â”€ index                   # å€’æ’ç´¢å¼• (æ ‡ç­¾â†’åºåˆ—ID)
â”‚   â”œâ”€â”€ meta.json               # å—å…ƒæ•°æ®
â”‚   â””â”€â”€ tombstones              # åˆ é™¤æ ‡è®°
â”œâ”€â”€ 01HQYYY/
â”œâ”€â”€ wal/                        # WAL (Write-Ahead Log)
â”‚   â”œâ”€â”€ 00000000
â”‚   â””â”€â”€ checkpoint.00000001
â””â”€â”€ queries.active              # æ´»è·ƒæŸ¥è¯¢
```

**å­˜å‚¨æµç¨‹**ï¼š

```
1. æ•°æ®å†™å…¥WAL (é¢„å†™æ—¥å¿—)
   â†’ é˜²æ­¢è¿›ç¨‹å´©æºƒä¸¢å¤±æ•°æ®

2. å†…å­˜ä¸­æ„å»ºå— (2å°æ—¶)
   â†’ é«˜æ€§èƒ½æŸ¥è¯¢æœ€è¿‘æ•°æ®

3. å—è½ç›˜ (æ¯2å°æ—¶)
   â†’ æŒä¹…åŒ–åˆ°ç£ç›˜

4. å‹ç¼©åˆå¹¶ (åå°)
   â†’ åˆå¹¶å¤šä¸ªå°å—ä¸ºå¤§å—
   â†’ å‹ç¼©æ¯”å¯è¾¾10:1

5. åˆ é™¤è¿‡æœŸæ•°æ®
   â†’ è¶…è¿‡ä¿ç•™æœŸé™è‡ªåŠ¨åˆ é™¤
```

**2. å‹ç¼©ç®—æ³•**

Prometheusä½¿ç”¨**Delta-of-Delta + XORç¼–ç **ï¼š

```
åŸå§‹æ•°æ® (æ—¶é—´æˆ³ + å€¼):
1705752000  100.5
1705752060  102.3
1705752120  101.8
1705752180  103.1

å‹ç¼©åå­˜å‚¨:
- ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³: 1705752000 (å®Œæ•´å­˜å‚¨)
- åç»­æ—¶é—´æˆ³: å­˜å‚¨å·®å€¼çš„å·®å€¼
  60, 0, 0, ... (å¤§éƒ¨åˆ†æ˜¯0,é«˜åº¦å‹ç¼©)
  
- ç¬¬ä¸€ä¸ªå€¼: 100.5 (å®Œæ•´å­˜å‚¨)
- åç»­å€¼: XORç¼–ç 
  1.8 XOR 100.5 = xxx (å­˜å‚¨XORç»“æœçš„å‰å¯¼é›¶å‹ç¼©)

å‹ç¼©æ¯”: å¹³å‡1.37å­—èŠ‚/æ ·æœ¬ (åŸå§‹éœ€è¦16å­—èŠ‚)
```

**3. æ•°æ®ä¿ç•™ç­–ç•¥**

```yaml
# Prometheusé…ç½®
global:
  scrape_interval: 15s

# å­˜å‚¨é…ç½®
storage:
  tsdb:
    path: /prometheus/data
    retention.time: 15d      # ä¿ç•™15å¤© (é»˜è®¤)
    retention.size: 50GB     # æˆ–è€…æŒ‰å¤§å°é™åˆ¶
```

**å­˜å‚¨å®¹é‡ä¼°ç®—**ï¼š

```
å…¬å¼:
needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample

ç¤ºä¾‹è®¡ç®—:
- ä¿ç•™æ—¶é—´: 15å¤© = 1,296,000ç§’
- æ¯ç§’é‡‡æ ·: 10,000ä¸ªæŒ‡æ ‡ * 1ä¸ªå€¼ = 10,000 samples/s
- æ¯æ ·æœ¬å¤§å°: 1.5å­—èŠ‚ (å‹ç¼©å)

å­˜å‚¨éœ€æ±‚ = 1,296,000 * 10,000 * 1.5 / 1024 / 1024 / 1024
         â‰ˆ 18 GB

å»ºè®®é¢„ç•™50%ç©ºé—´: 18 * 1.5 = 27 GB
```

**ç›‘æ§Prometheusè‡ªèº«çš„å­˜å‚¨**ï¼š

```promql
# ç£ç›˜ä½¿ç”¨é‡
prometheus_tsdb_storage_blocks_bytes

# å†…å­˜ä¸­åºåˆ—æ•°
prometheus_tsdb_head_series

# æ¯ç§’é‡‡æ ·é€Ÿç‡
rate(prometheus_tsdb_head_samples_appended_total[5m])

# å‹ç¼©è€—æ—¶
prometheus_tsdb_compaction_duration_seconds
```

---

### 9.2.2 æœåŠ¡å‘ç°ä¸ç›®æ ‡æŠ“å–

#### KubernetesæœåŠ¡å‘ç°æœºåˆ¶

PrometheusåŸç”Ÿæ”¯æŒKubernetesæœåŠ¡å‘ç°ï¼Œå¯ä»¥è‡ªåŠ¨å‘ç°é›†ç¾¤ä¸­çš„ç›‘æ§ç›®æ ‡ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

**æ”¯æŒçš„å‘ç°ç±»å‹**ï¼š

| å‘ç°ç±»å‹ | ç”¨é€” | å…¸å‹ç›®æ ‡ |
|---------|------|---------|
| **node** | å‘ç°æ‰€æœ‰èŠ‚ç‚¹ | Node Exporter, kubelet |
| **pod** | å‘ç°æ‰€æœ‰Pod | åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡ |
| **service** | å‘ç°æ‰€æœ‰Service | kube-state-metrics |
| **endpoints** | å‘ç°Serviceçš„Endpoint | è´Ÿè½½å‡è¡¡åçš„Pod |
| **ingress** | å‘ç°æ‰€æœ‰Ingress | Ingress Controller |

**å®Œæ•´çš„æœåŠ¡å‘ç°é…ç½®ç¤ºä¾‹**ï¼š

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: 'k8s-prod'
        region: 'us-west-2'

    # ============= 1. æŠ“å–èŠ‚ç‚¹æŒ‡æ ‡ (Node Exporter) =============
    scrape_configs:
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      
      # Relabelé…ç½® (é‡å†™æ ‡ç­¾)
      relabel_configs:
      # ä¿ç•™æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾ä¸º__meta_kubernetes_node_label_*
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      
      # å°†èŠ‚ç‚¹åè®¾ç½®ä¸ºinstanceæ ‡ç­¾
      - source_labels: [__meta_kubernetes_node_name]
        target_label: instance
      
      # è®¾ç½®æŠ“å–è·¯å¾„ä¸ºNode Exporterçš„ç«¯å£
      - source_labels: [__address__]
        regex: '([^:]+):.*'      # æå–IPéƒ¨åˆ†
        replacement: '${1}:9100'  # æ·»åŠ Node Exporterç«¯å£
        target_label: __address__

    # ============= 2. æŠ“å–kubelet (å®¹å™¨æŒ‡æ ‡) =============
    - job_name: 'kubernetes-kubelet'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
      kubernetes_sd_configs:
      - role: node
      
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

    # ============= 3. æŠ“å–cAdvisor (å®¹å™¨èµ„æº) =============
    - job_name: 'kubernetes-cadvisor'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
      kubernetes_sd_configs:
      - role: node
      
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

    # ============= 4. æŠ“å–kube-state-metrics (K8sèµ„æºçŠ¶æ€) =============
    - job_name: 'kube-state-metrics'
      kubernetes_sd_configs:
      - role: service
      
      relabel_configs:
      # åªæŠ“å–kube-state-metricsæœåŠ¡
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
        action: keep
        regex: kube-state-metrics
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_service_name]
        target_label: service

    # ============= 5. æŠ“å–Pod (åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡) =============
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      
      relabel_configs:
      # åªæŠ“å–å¸¦æœ‰prometheus.io/scrape=trueæ³¨è§£çš„Pod
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      
      # è‡ªå®šä¹‰æŠ“å–ç«¯å£ (é»˜è®¤ä½¿ç”¨Podçš„ç¬¬ä¸€ä¸ªç«¯å£)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
        action: replace
        regex: ([^;]+);(.+)
        replacement: ${2}:${1}
        target_label: __address__
      
      # è‡ªå®šä¹‰æŠ“å–è·¯å¾„ (é»˜è®¤/metrics)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      
      # æ·»åŠ å‘½åç©ºé—´æ ‡ç­¾
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      
      # æ·»åŠ Podåç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      
      # æ·»åŠ å®¹å™¨åç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container
      
      # ä¿ç•™Podçš„æ‰€æœ‰æ ‡ç­¾
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)

    # ============= 6. æŠ“å–Service (é€šè¿‡Serviceå‘ç°) =============
    - job_name: 'kubernetes-services'
      kubernetes_sd_configs:
      - role: service
      
      metrics_path: /probe
      params:
        module: [http_2xx]  # é»‘ç›’ç›‘æ§æ¨¡å—
      
      relabel_configs:
      # åªæŠ“å–å¸¦æœ‰prometheus.io/probe=trueæ³¨è§£çš„Service
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
        action: keep
        regex: true
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: __address__
        replacement: blackbox-exporter:9115
      - source_labels: [__param_target]
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
```

**Relabelé…ç½®è¯¦è§£**ï¼š

Relabelæ˜¯Prometheusæœ€å¼ºå¤§ä¹Ÿæœ€å¤æ‚çš„åŠŸèƒ½ä¹‹ä¸€ï¼Œå®ƒå¯ä»¥åœ¨æŠ“å–å‰é‡å†™æ ‡ç­¾ã€‚

**å¸¸ç”¨çš„Relabelæ“ä½œ**ï¼š

1. **keep**: åªä¿ç•™åŒ¹é…çš„ç›®æ ‡

```yaml
- source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
  action: keep
  regex: true
# å«ä¹‰: åªæŠ“å–annotationsä¸­prometheus.io/scrape=trueçš„Pod
```

2. **drop**: ä¸¢å¼ƒåŒ¹é…çš„ç›®æ ‡

```yaml
- source_labels: [__meta_kubernetes_namespace]
  action: drop
  regex: (kube-system|kube-public)
# å«ä¹‰: ä¸æŠ“å–kube-systemå’Œkube-publicå‘½åç©ºé—´çš„Pod
```

3. **replace**: æ›¿æ¢æ ‡ç­¾å€¼

```yaml
- source_labels: [__meta_kubernetes_pod_name]
  target_label: pod
  action: replace
# å«ä¹‰: å°†__meta_kubernetes_pod_nameçš„å€¼å¤åˆ¶åˆ°podæ ‡ç­¾
```

4. **labelmap**: æ‰¹é‡æ˜ å°„æ ‡ç­¾

```yaml
- action: labelmap
  regex: __meta_kubernetes_pod_label_(.+)
# å«ä¹‰: å°†Podçš„æ‰€æœ‰æ ‡ç­¾ (å¦‚app=nginx) æ˜ å°„ä¸ºPrometheusæ ‡ç­¾
```

5. **labeldrop**: åˆ é™¤æ ‡ç­¾

```yaml
- action: labeldrop
  regex: __meta_kubernetes_pod_.*
# å«ä¹‰: åˆ é™¤æ‰€æœ‰ä»¥__meta_kubernetes_pod_å¼€å¤´çš„ä¸´æ—¶æ ‡ç­¾
```

**åº”ç”¨å¦‚ä½•é…ç½®è¢«PrometheusæŠ“å–**ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  namespace: production
  annotations:
    prometheus.io/scrape: "true"    # å¯ç”¨æŠ“å–
    prometheus.io/port: "8080"      # æŒ‡æ ‡ç«¯å£
    prometheus.io/path: "/metrics"  # æŒ‡æ ‡è·¯å¾„ (å¯é€‰,é»˜è®¤/metrics)
  labels:
    app: my-app
    version: v1.0.0
    team: backend
spec:
  containers:
  - name: app
    image: my-app:v1.0.0
    ports:
    - containerPort: 8080
      name: metrics
```

Prometheusä¼šè‡ªåŠ¨å‘ç°è¿™ä¸ªPodå¹¶æŠ“å– `http://POD_IP:8080/metrics`ã€‚

#### ç›®æ ‡æŠ“å–æœºåˆ¶

**1. æŠ“å–æµç¨‹**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Prometheus Scrape Lifecycle                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. æœåŠ¡å‘ç° (Service Discovery)
   â†“
   å‘ç°ç›®æ ‡: Pod IP, ç«¯å£, æ ‡ç­¾ç­‰å…ƒæ•°æ®
   
2. Relabel (é‡å†™æ ‡ç­¾)
   â†“
   åº”ç”¨relabel_configsè§„åˆ™
   - keep/dropè¿‡æ»¤ç›®æ ‡
   - ä¿®æ”¹__address__, __metrics_path__ç­‰
   
3. HTTP GETè¯·æ±‚
   â†“
   GET http://<target>:<port>/<path>
   Headers: 
     - User-Agent: Prometheus/2.x
     - Accept: application/openmetrics-text
   
4. è§£æå“åº”
   â†“
   è§£æPrometheusæ–‡æœ¬æ ¼å¼:
   # HELP http_requests_total Total requests
   # TYPE http_requests_total counter
   http_requests_total{method="GET"} 123
   
5. å­˜å‚¨åˆ°TSDB
   â†“
   å†™å…¥æ—¶åºæ•°æ®åº“
   
6. ç­‰å¾…ä¸‹ä¸€ä¸ªscrape_interval
   â†“
   é»˜è®¤15ç§’åé‡å¤
```

**2. æŠ“å–é…ç½®å‚æ•°**

```yaml
scrape_configs:
- job_name: 'my-app'
  scrape_interval: 30s       # æŠ“å–é—´éš” (è¦†ç›–global)
  scrape_timeout: 10s        # è¶…æ—¶æ—¶é—´ (å¿…é¡» < scrape_interval)
  metrics_path: '/metrics'   # æŠ“å–è·¯å¾„
  scheme: http               # åè®® (http/https)
  
  # åŸºæœ¬è®¤è¯
  basic_auth:
    username: admin
    password: secret
  
  # Bearer Tokenè®¤è¯
  bearer_token_file: /var/run/secrets/token
  
  # TLSé…ç½®
  tls_config:
    ca_file: /etc/prometheus/ca.crt
    cert_file: /etc/prometheus/client.crt
    key_file: /etc/prometheus/client.key
    insecure_skip_verify: false
  
  # é™æ€ç›®æ ‡
  static_configs:
  - targets:
    - 'localhost:9090'
    - '192.168.1.10:9100'
    labels:
      environment: production
      region: us-west-2
```

**3. æŠ“å–çŠ¶æ€ç›‘æ§**

Prometheusæä¾›äº†ä¸°å¯Œçš„æŒ‡æ ‡æ¥ç›‘æ§è‡ªèº«çš„æŠ“å–çŠ¶æ€ï¼š

```promql
# å½“å‰æŠ“å–ç›®æ ‡æ•°é‡
count(up)

# æŠ“å–å¤±è´¥çš„ç›®æ ‡
count(up == 0)

# æŠ“å–å¤±è´¥ç‡
(count(up == 0) / count(up)) * 100

# æŠ“å–è€—æ—¶ (P99)
histogram_quantile(0.99, rate(prometheus_target_scrape_duration_seconds_bucket[5m]))

# æ¯ç§’æŠ“å–çš„æ ·æœ¬æ•°
rate(prometheus_target_scrapes_sample_scraped_total[5m])

# æŠ“å–è¶…æ—¶æ¬¡æ•°
rate(prometheus_target_scrapes_exceeded_sample_limit_total[5m])
```

**æŸ¥çœ‹æŠ“å–ç›®æ ‡çŠ¶æ€**ï¼š

è®¿é—®Prometheus Web UI: `http://<prometheus>:9090/targets`

å¯ä»¥çœ‹åˆ°ï¼š
- æ‰€æœ‰ç›®æ ‡çš„å¥åº·çŠ¶æ€ (UP/DOWN)
- æœ€åæŠ“å–æ—¶é—´
- æŠ“å–è€—æ—¶
- é”™è¯¯ä¿¡æ¯

---

### 9.2.3 PromQLæŸ¥è¯¢è¯­è¨€è¯¦è§£

PromQL (Prometheus Query Language) æ˜¯Prometheusçš„æŸ¥è¯¢è¯­è¨€ï¼Œå®ƒåŠŸèƒ½å¼ºå¤§ä½†å­¦ä¹ æ›²çº¿è¾ƒé™¡ã€‚æŒæ¡PromQLæ˜¯ä½¿ç”¨Prometheusçš„å…³é”®ã€‚

#### PromQLåŸºç¡€è¯­æ³•

**1. å³æ—¶å‘é‡é€‰æ‹©å™¨ (Instant Vector Selector)**

é€‰æ‹©æŸä¸ªæ—¶é—´ç‚¹çš„æ‰€æœ‰æ—¶é—´åºåˆ—ï¼š

```promql
# æœ€ç®€å•çš„æŸ¥è¯¢: é€‰æ‹©æ‰€æœ‰http_requests_totalåºåˆ—
http_requests_total

# å¸¦æ ‡ç­¾è¿‡æ»¤: ç²¾ç¡®åŒ¹é…
http_requests_total{method="GET", status="200"}

# æ ‡ç­¾åŒ¹é…æ“ä½œç¬¦:
=   # ç²¾ç¡®ç›¸ç­‰
!=  # ä¸ç›¸ç­‰
=~  # æ­£åˆ™åŒ¹é…
!~  # æ­£åˆ™ä¸åŒ¹é…

# ç¤ºä¾‹:
http_requests_total{status=~"2..", method!="POST"}
# å«ä¹‰: statusæ˜¯2xx, ä¸”methodä¸æ˜¯POST
```

**2. èŒƒå›´å‘é‡é€‰æ‹©å™¨ (Range Vector Selector)**

é€‰æ‹©ä¸€æ®µæ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰æ ·æœ¬ï¼š

```promql
# é€‰æ‹©æœ€è¿‘5åˆ†é’Ÿçš„æ‰€æœ‰æ ·æœ¬
http_requests_total[5m]

# æ—¶é—´å•ä½:
s  # ç§’
m  # åˆ†é’Ÿ
h  # å°æ—¶
d  # å¤©
w  # å‘¨
y  # å¹´

# ç¤ºä¾‹:
http_requests_total{method="GET"}[1h]  # æœ€è¿‘1å°æ—¶
node_cpu_seconds_total[30s]            # æœ€è¿‘30ç§’
```

**3. åç§»ä¿®é¥°ç¬¦ (Offset Modifier)**

æŸ¥è¯¢è¿‡å»æŸä¸ªæ—¶é—´ç‚¹çš„æ•°æ®ï¼š

```promql
# æŸ¥è¯¢5åˆ†é’Ÿå‰çš„å³æ—¶å€¼
http_requests_total offset 5m

# æŸ¥è¯¢1å°æ—¶å‰çš„5åˆ†é’ŸèŒƒå›´æ•°æ®
rate(http_requests_total[5m] offset 1h)

# æŸ¥è¯¢æ˜¨å¤©åŒä¸€æ—¶é—´çš„å€¼
http_requests_total offset 1d
```

#### PromQLèšåˆæ“ä½œç¬¦

**1. èšåˆå‡½æ•°**

| å‡½æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **sum** | æ±‚å’Œ | `sum(http_requests_total)` |
| **min** | æœ€å°å€¼ | `min(node_memory_free_bytes)` |
| **max** | æœ€å¤§å€¼ | `max(node_cpu_temperature)` |
| **avg** | å¹³å‡å€¼ | `avg(http_request_duration_seconds)` |
| **count** | è®¡æ•° | `count(up == 1)` |
| **stddev** | æ ‡å‡†å·® | `stddev(http_request_duration_seconds)` |
| **topk** | å‰Kä¸ªæœ€å¤§å€¼ | `topk(5, http_requests_total)` |
| **bottomk** | å‰Kä¸ªæœ€å°å€¼ | `bottomk(5, node_memory_free_bytes)` |
| **quantile** | åˆ†ä½æ•° | `quantile(0.95, http_request_duration_seconds)` |

**by / without å­å¥**ï¼š

```promql
# æŒ‰methodå’Œstatusåˆ†ç»„æ±‚å’Œ
sum(http_requests_total) by (method, status)

# ç»“æœç¤ºä¾‹:
# {method="GET", status="200"} 15000
# {method="GET", status="404"} 120
# {method="POST", status="200"} 8000

# without: æ’é™¤æŸäº›æ ‡ç­¾,ä¿ç•™å…¶ä»–æ‰€æœ‰æ ‡ç­¾
sum(http_requests_total) without (instance, pod)
# å«ä¹‰: èšåˆæ—¶ä¸åŒºåˆ†instanceå’Œpod,ä¿ç•™method/statusç­‰æ ‡ç­¾
```

**2. é€Ÿç‡å‡½æ•° (æœ€å¸¸ç”¨)**

```promql
# rate(): è®¡ç®—æ¯ç§’å¹³å‡å¢é•¿ç‡ (ç”¨äºCounter)
rate(http_requests_total[5m])
# å«ä¹‰: è¿‡å»5åˆ†é’Ÿçš„å¹³å‡æ¯ç§’è¯·æ±‚æ•° (QPS)

# irate(): è®¡ç®—ç¬æ—¶å¢é•¿ç‡ (æ›´æ•æ„Ÿ,ç”¨äºå¿«é€Ÿå˜åŒ–çš„æŒ‡æ ‡)
irate(http_requests_total[5m])
# å«ä¹‰: ä½¿ç”¨æœ€è¿‘ä¸¤ä¸ªæ•°æ®ç‚¹è®¡ç®—å¢é•¿ç‡

# increase(): è®¡ç®—æ—¶é—´èŒƒå›´å†…çš„å¢é‡
increase(http_requests_total[1h])
# å«ä¹‰: è¿‡å»1å°æ—¶çš„è¯·æ±‚æ€»å¢é‡

# rate vs irate:
# rate: å¹³æ»‘,é€‚åˆå‘Šè­¦
# irate: æ•æ„Ÿ,é€‚åˆå¿«é€Ÿå‘ç°å³°å€¼
```

**3. æ—¶é—´èšåˆå‡½æ•°**

```promql
# è¿‡å»ä¸€æ®µæ—¶é—´çš„æœ€å¤§å€¼
max_over_time(http_request_duration_seconds[1h])

# è¿‡å»ä¸€æ®µæ—¶é—´çš„æœ€å°å€¼
min_over_time(node_memory_free_bytes[1h])

# è¿‡å»ä¸€æ®µæ—¶é—´çš„å¹³å‡å€¼
avg_over_time(cpu_usage[5m])

# å…¶ä»–:
sum_over_time()    # æ±‚å’Œ
count_over_time()  # è®¡æ•°
stddev_over_time() # æ ‡å‡†å·®
quantile_over_time(0.95, http_request_duration_seconds[1h])  # P95
```

**4. äºŒå…ƒæ“ä½œç¬¦**

**ç®—æœ¯æ“ä½œç¬¦**ï¼š

```promql
# åŠ å‡ä¹˜é™¤
node_memory_total_bytes - node_memory_free_bytes  # å·²ç”¨å†…å­˜

# å†…å­˜ä½¿ç”¨ç‡
(node_memory_total_bytes - node_memory_free_bytes) / node_memory_total_bytes * 100

# å¹‚è¿ç®—
cpu_usage ^ 2

# æ¨¡è¿ç®—
node_time_seconds % 3600  # å½“å‰å°æ—¶å†…çš„ç§’æ•°
```

**æ¯”è¾ƒæ“ä½œç¬¦**ï¼š

```promql
# è¿”å›å¸ƒå°”å€¼ (0æˆ–1)
http_requests_total > 1000      # å¤§äº1000çš„åºåˆ—
node_memory_free_bytes < 1e9    # å°äº1GBçš„èŠ‚ç‚¹

# ä½œä¸ºè¿‡æ»¤å™¨ (ä¿ç•™åŸå€¼)
http_requests_total > bool 1000  # è¿”å›0æˆ–1
```

**é€»è¾‘æ“ä½œç¬¦**ï¼š

```promql
# and: äº¤é›†
http_requests_total > 1000 and http_errors_total > 10

# or: å¹¶é›†
up{job="api"} or up{job="web"}

# unless: å·®é›†
up unless on(instance) disk_full
# å«ä¹‰: è¿”å›upä¸­å­˜åœ¨ä½†disk_fullä¸­ä¸å­˜åœ¨çš„åºåˆ—
```

**å‘é‡åŒ¹é…**ï¼š

```promql
# one-to-oneåŒ¹é… (é»˜è®¤)
method:http_requests:rate5m / on(method) group_left method:http_requests:total

# many-to-oneåŒ¹é…
sum(rate(http_requests_total[5m])) by (method, status)
  /
sum(rate(http_requests_total[5m])) by (method)
# group_left: å·¦ä¾§å¤šä¸ªåºåˆ—åŒ¹é…å³ä¾§ä¸€ä¸ªåºåˆ—
```

#### å®ç”¨PromQLæŸ¥è¯¢ç¤ºä¾‹

**1. ç³»ç»Ÿèµ„æºç›‘æ§**

```promql
# CPUä½¿ç”¨ç‡ (%)
100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# å†…å­˜ä½¿ç”¨ç‡ (%)
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# ç£ç›˜ä½¿ç”¨ç‡ (%)
(node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100

# ç£ç›˜IO (IOPS)
rate(node_disk_reads_completed_total[5m]) + rate(node_disk_writes_completed_total[5m])

# ç½‘ç»œæµé‡ (MB/s)
rate(node_network_receive_bytes_total[5m]) / 1024 / 1024
```

**2. å®¹å™¨ç›‘æ§**

```promql
# å®¹å™¨CPUä½¿ç”¨ç‡ (%)
sum(rate(container_cpu_usage_seconds_total{pod!=""}[5m])) by (pod, namespace) * 100

# å®¹å™¨å†…å­˜ä½¿ç”¨é‡ (GB)
sum(container_memory_working_set_bytes{pod!=""}) by (pod, namespace) / 1024 / 1024 / 1024

# å®¹å™¨é‡å¯æ¬¡æ•°
kube_pod_container_status_restarts_total

# OOMæ¬¡æ•°
sum(increase(container_oom_events_total[1h])) by (pod, namespace)
```

**3. åº”ç”¨æ€§èƒ½ç›‘æ§ (REDæ–¹æ³•)**

REDæ–¹æ³•æ˜¯æœåŠ¡ç›‘æ§çš„é»„é‡‘æ ‡å‡†ï¼š
- **R**ate: è¯·æ±‚é€Ÿç‡
- **E**rrors: é”™è¯¯ç‡
- **D**uration: è¯·æ±‚å»¶è¿Ÿ

```promql
# Rate: æ¯ç§’è¯·æ±‚æ•° (QPS)
sum(rate(http_requests_total[5m])) by (service, method)

# Errors: é”™è¯¯ç‡ (%)
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
  /
sum(rate(http_requests_total[5m])) by (service)
  * 100

# Duration: P95å»¶è¿Ÿ (ç§’)
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)

# Duration: P99å»¶è¿Ÿ
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)
```

**4. Kubernetesèµ„æºç›‘æ§**

```promql
# Podæ•°é‡ (æŒ‰çŠ¶æ€)
count(kube_pod_status_phase{phase="Running"}) by (namespace)

# Deploymentå‰¯æœ¬æ•° vs æœŸæœ›å‰¯æœ¬æ•°
kube_deployment_status_replicas_available / kube_deployment_spec_replicas * 100

# PVCä½¿ç”¨ç‡
kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100

# èŠ‚ç‚¹çŠ¶æ€ (ReadyèŠ‚ç‚¹æ•°)
count(kube_node_status_condition{condition="Ready", status="true"})

# èŠ‚ç‚¹å¯è°ƒåº¦èµ„æº (CPU)
sum(kube_node_status_allocatable{resource="cpu"}) - sum(kube_pod_container_resource_requests{resource="cpu"})
```

**5. ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§**

```promql
# è®¢å•åˆ›å»ºé€Ÿç‡ (æ¯åˆ†é’Ÿ)
rate(order_created_total[5m]) * 60

# æ”¯ä»˜æˆåŠŸç‡ (%)
sum(rate(payment_total{status="success"}[5m]))
  /
sum(rate(payment_total[5m]))
  * 100

# æ´»è·ƒç”¨æˆ·æ•° (å»é‡è®¡æ•°)
count(sum by (user_id) (rate(user_activity_total[5m]) > 0))

# è¥æ”¶é€Ÿç‡ (ç¾å…ƒ/ç§’)
rate(revenue_dollars_total[5m])
```

#### PromQLæ€§èƒ½ä¼˜åŒ–

**1. é¿å…é«˜åŸºæ•°æŸ¥è¯¢**

```promql
# âŒ é”™è¯¯: æŸ¥è¯¢æ‰€æœ‰user_id (ç™¾ä¸‡çº§åŸºæ•°)
sum by (user_id) (http_requests_total)

# âœ… æ­£ç¡®: æŒ‰æœåŠ¡èšåˆ
sum by (service, method) (rate(http_requests_total[5m]))
```

**2. ä½¿ç”¨Recording Rulesé¢„è®¡ç®—**

å¯¹äºå¤æ‚çš„æŸ¥è¯¢ï¼Œå¯ä»¥ä½¿ç”¨Recording Rulesé¢„å…ˆè®¡ç®—å¹¶å­˜å‚¨ç»“æœï¼š

```yaml
# recording_rules.yml
groups:
- name: api_performance
  interval: 15s
  rules:
  # é¢„è®¡ç®—QPS
  - record: job:http_requests:rate5m
    expr: sum(rate(http_requests_total[5m])) by (job, method)
  
  # é¢„è®¡ç®—é”™è¯¯ç‡
  - record: job:http_errors:ratio
    expr: |
      sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
        /
      sum(rate(http_requests_total[5m])) by (job)
```

ä¹‹åå¯ä»¥ç›´æ¥æŸ¥è¯¢é¢„è®¡ç®—çš„ç»“æœï¼š

```promql
# ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—ç»“æœ (æ›´å¿«)
job:http_requests:rate5m{job="api"}

# è€Œä¸æ˜¯æ¯æ¬¡éƒ½è®¡ç®— (æ›´æ…¢)
sum(rate(http_requests_total{job="api"}[5m])) by (method)
```

**3. åˆç†ä½¿ç”¨æ—¶é—´èŒƒå›´**

```promql
# âŒ é”™è¯¯: èŒƒå›´è¿‡å¤§,æŸ¥è¯¢æ…¢
rate(http_requests_total[1d])

# âœ… æ­£ç¡®: 5åˆ†é’Ÿè¶³å¤Ÿè®¡ç®—é€Ÿç‡
rate(http_requests_total[5m])

# è§„åˆ™: rate()çš„èŒƒå›´åº”è¯¥æ˜¯scrape_intervalçš„4å€ä»¥ä¸Š
# å¦‚æœscrape_interval=15s, åˆ™rangeè‡³å°‘60s, æ¨è5m
```

---

### 9.2.4 Prometheuséƒ¨ç½²ä¸é…ç½®

#### åœ¨Kubernetesä¸­éƒ¨ç½²Prometheus

**æ–¹å¼1: ä½¿ç”¨Helm Chart (æ¨è)**

```bash
# æ·»åŠ Prometheusç¤¾åŒºHelmä»“åº“
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace monitoring

# å®‰è£…kube-prometheus-stack (åŒ…å«Prometheus + Grafana + AlertManager)
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set prometheus.prometheusSpec.retention=30d \
  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi \
  --set prometheus.prometheusSpec.resources.requests.memory=2Gi \
  --set prometheus.prometheusSpec.resources.limits.memory=4Gi \
  --set grafana.adminPassword=admin123

# æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
kubectl get pods -n monitoring
```

**æ–¹å¼2: æ‰‹åŠ¨éƒ¨ç½² (å®Œæ•´ç†è§£)**

ä¸‹é¢å±•ç¤ºå®Œæ•´çš„æ‰‹åŠ¨éƒ¨ç½²é…ç½®ï¼š

**1. åˆ›å»ºServiceAccountå’ŒRBAC**

```yaml
# prometheus-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
# è¯»å–èŠ‚ç‚¹ä¿¡æ¯
- apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
# è¯»å–é…ç½®
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]
# è¯»å–Ingress
- apiGroups: ["networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
# éèµ„æºURL (ç”¨äºå¥åº·æ£€æŸ¥)
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
```

**2. åˆ›å»ºConfigMap (Prometheusé…ç½®)**

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: 'k8s-production'
        region: 'us-west-2'

    # AlertManageré…ç½®
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    # è§„åˆ™æ–‡ä»¶
    rule_files:
    - '/etc/prometheus/rules/*.yml'

    # æŠ“å–é…ç½® (å‰é¢å·²è¯¦ç»†ä»‹ç»)
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - source_labels: [__address__]
        regex: '([^:]+):.*'
        replacement: '${1}:9100'
        target_label: __address__
    
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
        action: replace
        regex: ([^;]+);(.+)
        replacement: ${2}:${1}
        target_label: __address__
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
```

**3. åˆ›å»ºDeployment**

```yaml
# prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1  # å•å®ä¾‹ (é«˜å¯ç”¨éœ€è¦ä½¿ç”¨StatefulSet + Thanos)
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.48.0
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--storage.tsdb.retention.time=30d'      # ä¿ç•™30å¤©
        - '--storage.tsdb.retention.size=50GB'     # æˆ–50GBä¸Šé™
        - '--web.enable-lifecycle'                 # å…è®¸çƒ­é‡è½½
        - '--web.enable-admin-api'                 # å¯ç”¨ç®¡ç†API
        ports:
        - containerPort: 9090
          name: web
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: data
          mountPath: /prometheus
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: data
        persistentVolumeClaim:
          claimName: prometheus-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-data
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: gp3  # AWS EBS gp3
```

**4. åˆ›å»ºService**

```yaml
# prometheus-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  type: ClusterIP
  ports:
  - port: 9090
    targetPort: 9090
    name: web
  selector:
    app: prometheus
---
# å¦‚æœéœ€è¦å¤–éƒ¨è®¿é—®,åˆ›å»ºIngress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: prometheus
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
spec:
  ingressClassName: nginx
  rules:
  - host: prometheus.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus
            port:
              number: 9090
  tls:
  - hosts:
    - prometheus.example.com
    secretName: prometheus-tls
```

**5. éƒ¨ç½²**

```bash
# éƒ¨ç½²æ‰€æœ‰èµ„æº
kubectl apply -f prometheus-rbac.yaml
kubectl apply -f prometheus-config.yaml
kubectl apply -f prometheus-deployment.yaml
kubectl apply -f prometheus-service.yaml

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n monitoring
kubectl logs -n monitoring -l app=prometheus --tail=100

# ç«¯å£è½¬å‘è®¿é—® (å¦‚æœæ²¡æœ‰Ingress)
kubectl port-forward -n monitoring svc/prometheus 9090:9090

# è®¿é—®: http://localhost:9090
```

#### Prometheusé…ç½®çƒ­é‡è½½

Prometheusæ”¯æŒé…ç½®çƒ­é‡è½½ï¼Œæ— éœ€é‡å¯å®¹å™¨ï¼š

```bash
# æ–¹æ³•1: ä½¿ç”¨API (éœ€è¦å¯ç”¨--web.enable-lifecycle)
curl -X POST http://prometheus:9090/-/reload

# æ–¹æ³•2: å‘é€SIGHUPä¿¡å·
kubectl exec -n monitoring prometheus-xxx -- kill -HUP 1

# æ–¹æ³•3: ä¿®æ”¹ConfigMapåè‡ªåŠ¨é‡è½½ (éœ€è¦é…ç½®ConfigMap Reloader)
# ä½¿ç”¨kube-prometheus-stackæ—¶è‡ªåŠ¨åŒ…å«æ­¤åŠŸèƒ½
```

#### Prometheusé«˜å¯ç”¨æ¶æ„

å•å®ä¾‹Prometheuså­˜åœ¨å•ç‚¹æ•…éšœé£é™©ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨é«˜å¯ç”¨æ¶æ„ï¼š

**æ–¹æ¡ˆ1: Prometheusè”é‚¦ (Federation)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus 1 â”‚    â”‚ Prometheus 2 â”‚  (å¤šä¸ªç‹¬ç«‹Prometheus)
â”‚ (shard 1)    â”‚    â”‚ (shard 2)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Prometheus  â”‚  (å…¨å±€Prometheus)
        â”‚  (Global)    â”‚  (è”é‚¦èšåˆ)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ–¹æ¡ˆ2: Thanos (æ¨è)**

Thanosæä¾›é•¿æœŸå­˜å‚¨ã€å…¨å±€æŸ¥è¯¢ã€æ•°æ®å»é‡ç­‰é«˜çº§åŠŸèƒ½ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Thanosæ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Prometheus 1 â”‚     â”‚ Prometheus 2 â”‚                 â”‚
â”‚  â”‚ + Sidecar    â”‚     â”‚ + Sidecar    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                     â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚ Object      â”‚  (S3/GCS/MinIO)                â”‚
â”‚         â”‚ Storage     â”‚  (é•¿æœŸå­˜å‚¨)                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚ Thanos      â”‚  (æŸ¥è¯¢æ‰€æœ‰æ•°æ®æº)               â”‚
â”‚         â”‚ Query       â”‚                                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚  Grafana    â”‚                                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**éƒ¨ç½²Thanos (ä½¿ç”¨Helm)**

```bash
helm install thanos bitnami/thanos \
  --namespace monitoring \
  --set query.enabled=true \
  --set query.dnsDiscovery.enabled=true \
  --set query.dnsDiscovery.sidecarsService=prometheus-thanos-discovery \
  --set query.dnsDiscovery.sidecarsNamespace=monitoring \
  --set objstoreConfig.type=S3 \
  --set objstoreConfig.config.bucket=thanos-metrics \
  --set objstoreConfig.config.endpoint=s3.amazonaws.com \
  --set objstoreConfig.config.region=us-west-2
```

---

### 9.2.5 Recording Rulesä¸æ€§èƒ½ä¼˜åŒ–

#### Recording Rulesè¯¦è§£

Recording Ruleså…è®¸é¢„å…ˆè®¡ç®—å¤æ‚æŸ¥è¯¢å¹¶å­˜å‚¨ç»“æœï¼Œå¤§å¹…æå‡æŸ¥è¯¢æ€§èƒ½ã€‚

**1. Recording Rulesé…ç½®**

```yaml
# prometheus-rules.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  recording_rules.yml: |
    groups:
    # APIæ€§èƒ½æŒ‡æ ‡
    - name: api_performance
      interval: 15s  # è®¡ç®—é—´éš”
      rules:
      # QPS (æ¯ç§’è¯·æ±‚æ•°)
      - record: job:http_requests:rate5m
        expr: sum(rate(http_requests_total[5m])) by (job, method, status)
        labels:
          metric_type: rate
      
      # é”™è¯¯ç‡ (%)
      - record: job:http_errors:ratio
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
            /
          sum(rate(http_requests_total[5m])) by (job)
      
      # P95å»¶è¿Ÿ
      - record: job:http_request_duration:p95
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)
          )
      
      # P99å»¶è¿Ÿ
      - record: job:http_request_duration:p99
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)
          )

    # èŠ‚ç‚¹èµ„æºæŒ‡æ ‡
    - name: node_resources
      interval: 30s
      rules:
      # CPUä½¿ç”¨ç‡
      - record: instance:node_cpu:usage
        expr: |
          100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
      
      # å†…å­˜ä½¿ç”¨ç‡
      - record: instance:node_memory:usage_ratio
        expr: |
          1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)
      
      # ç£ç›˜ä½¿ç”¨ç‡
      - record: instance:node_disk:usage_ratio
        expr: |
          (node_filesystem_size_bytes - node_filesystem_free_bytes) 
            / node_filesystem_size_bytes

    # å®¹å™¨èµ„æºæŒ‡æ ‡
    - name: container_resources
      interval: 15s
      rules:
      # å®¹å™¨CPUä½¿ç”¨ (millicores)
      - record: namespace_pod_container:cpu_usage:rate5m
        expr: |
          sum(rate(container_cpu_usage_seconds_total{pod!=""}[5m])) 
            by (namespace, pod, container) * 1000
      
      # å®¹å™¨å†…å­˜ä½¿ç”¨ (bytes)
      - record: namespace_pod_container:memory_usage:bytes
        expr: |
          sum(container_memory_working_set_bytes{pod!=""}) 
            by (namespace, pod, container)
      
      # å®¹å™¨ç½‘ç»œæ¥æ”¶é€Ÿç‡ (bytes/s)
      - record: namespace_pod:network_receive:rate5m
        expr: |
          sum(rate(container_network_receive_bytes_total[5m])) 
            by (namespace, pod)
```

**2. åº”ç”¨Recording Rules**

```yaml
# ä¿®æ”¹Prometheus Deployment,æŒ‚è½½rules
spec:
  template:
    spec:
      containers:
      - name: prometheus
        volumeMounts:
        - name: rules
          mountPath: /etc/prometheus/rules
      volumes:
      - name: rules
        configMap:
          name: prometheus-rules

# ä¿®æ”¹prometheus.yml,å¼•ç”¨è§„åˆ™æ–‡ä»¶
rule_files:
- '/etc/prometheus/rules/*.yml'
```

```bash
# åº”ç”¨é…ç½®
kubectl apply -f prometheus-rules.yaml

# çƒ­é‡è½½Prometheus
curl -X POST http://prometheus:9090/-/reload

# éªŒè¯è§„åˆ™åŠ è½½
# è®¿é—®: http://prometheus:9090/rules
```

**3. ä½¿ç”¨Recording RulesæŸ¥è¯¢**

```promql
# ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—ç»“æœ (å¿«é€Ÿ)
job:http_requests:rate5m{job="api-server"}

# å¯¹æ¯”åŸå§‹æŸ¥è¯¢ (æ…¢)
sum(rate(http_requests_total{job="api-server"}[5m])) by (method, status)

# æ€§èƒ½å¯¹æ¯”:
# Recording Rule: ~10ms
# åŸå§‹æŸ¥è¯¢: ~500ms (50å€æå‡)
```

#### Prometheusæ€§èƒ½è°ƒä¼˜

**1. èµ„æºé…ç½®ä¼˜åŒ–**

```yaml
# æ ¹æ®æŒ‡æ ‡è§„æ¨¡è°ƒæ•´èµ„æº
spec:
  containers:
  - name: prometheus
    resources:
      requests:
        cpu: 2000m       # 2æ ¸èµ·æ­¥
        memory: 4Gi      # 4GBå†…å­˜èµ·æ­¥
      limits:
        cpu: 4000m
        memory: 8Gi

# ç»éªŒå…¬å¼:
# å†…å­˜éœ€æ±‚ = æ´»è·ƒæ—¶é—´åºåˆ—æ•° * 1KB + ç£ç›˜æ•°æ® * 0.0001
# ç¤ºä¾‹: 100ä¸‡åºåˆ— + 50GBç£ç›˜æ•°æ® = 1GB + 5MB â‰ˆ 1GBå†…å­˜
```

**2. å­˜å‚¨ä¼˜åŒ–**

```yaml
# è°ƒæ•´æ•°æ®ä¿ç•™ç­–ç•¥
args:
- '--storage.tsdb.retention.time=30d'  # ä¿ç•™30å¤©
- '--storage.tsdb.retention.size=50GB'  # æˆ–50GBä¸Šé™(äºŒé€‰ä¸€ç”Ÿæ•ˆ)

# è°ƒæ•´å—å¤§å° (é»˜è®¤2å°æ—¶)
- '--storage.tsdb.min-block-duration=2h'
- '--storage.tsdb.max-block-duration=36h'

# å‹ç¼©è®¾ç½®
- '--storage.tsdb.wal-compression'  # å¯ç”¨WALå‹ç¼©(èŠ‚çœ50%ç©ºé—´)
```

**3. æŸ¥è¯¢ä¼˜åŒ–**

```promql
# âŒ æ…¢æŸ¥è¯¢ (æ‰«æå¤§é‡æ•°æ®)
rate(http_requests_total[1d])

# âœ… ä¼˜åŒ– (ç¼©å°æ—¶é—´èŒƒå›´)
rate(http_requests_total[5m])

# âŒ æ…¢æŸ¥è¯¢ (é«˜åŸºæ•°æ ‡ç­¾)
sum by (user_id) (http_requests_total)

# âœ… ä¼˜åŒ– (ä½åŸºæ•°æ ‡ç­¾)
sum by (service, method) (http_requests_total)
```

**4. é‡‡æ ·ç‡ä¼˜åŒ–**

```yaml
# è°ƒæ•´é‡‡æ ·é—´éš”
scrape_configs:
- job_name: 'low-priority'
  scrape_interval: 60s    # ä½ä¼˜å…ˆçº§ç›®æ ‡: 60ç§’
  
- job_name: 'high-priority'
  scrape_interval: 15s    # é«˜ä¼˜å…ˆçº§ç›®æ ‡: 15ç§’
```

**5. ç›‘æ§Prometheusè‡ªèº«**

```promql
# Prometheuså†…å­˜ä½¿ç”¨
process_resident_memory_bytes / 1024 / 1024 / 1024

# æ´»è·ƒæ—¶é—´åºåˆ—æ•°
prometheus_tsdb_head_series

# æ¯ç§’é‡‡æ ·é€Ÿç‡
rate(prometheus_tsdb_head_samples_appended_total[5m])

# æŸ¥è¯¢å»¶è¿ŸP99
histogram_quantile(0.99, rate(prometheus_http_request_duration_seconds_bucket[5m]))

# WALæŸåæ¬¡æ•° (åº”è¯¥ä¸º0)
prometheus_tsdb_wal_corruptions_total
```

---

**ğŸ“Š 9.2èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Prometheusçš„æ ¸å¿ƒåŸç†ä¸å®æˆ˜éƒ¨ç½²ï¼š

âœ… **Prometheusæ¶æ„**ï¼š
- æ•´ä½“æ¶æ„ä¸æ ¸å¿ƒç»„ä»¶
- æ—¶åºæ•°æ®åº“TSDBåŸç†
- é«˜æ•ˆå‹ç¼©ç®—æ³• (Delta-of-Delta + XOR)

âœ… **æ•°æ®æ¨¡å‹**ï¼š
- 4ç§æŒ‡æ ‡ç±»å‹ (Counter/Gauge/Histogram/Summary)
- æ ‡ç­¾è®¾è®¡æœ€ä½³å®è·µ
- æŒ‡æ ‡å‘½åè§„èŒƒ

âœ… **æœåŠ¡å‘ç°**ï¼š
- KubernetesåŸç”ŸæœåŠ¡å‘ç°
- Relabelé…ç½®è¯¦è§£
- ç›®æ ‡æŠ“å–æœºåˆ¶

âœ… **PromQLæŸ¥è¯¢**ï¼š
- åŸºç¡€è¯­æ³• (å³æ—¶/èŒƒå›´å‘é‡)
- èšåˆæ“ä½œç¬¦ä¸é€Ÿç‡å‡½æ•°
- REDæ–¹æ³•å®ç”¨æŸ¥è¯¢
- æ€§èƒ½ä¼˜åŒ–æŠ€å·§

âœ… **ç”Ÿäº§éƒ¨ç½²**ï¼š
- Helm Chartå¿«é€Ÿéƒ¨ç½²
- æ‰‹åŠ¨éƒ¨ç½²å®Œæ•´é…ç½®
- é«˜å¯ç”¨æ¶æ„ (Federation/Thanos)
- Recording Rulesæ€§èƒ½ä¼˜åŒ–

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ Grafanaå¯è§†åŒ–å¹³å°ï¼ŒåŒ…æ‹¬æ•°æ®æºé›†æˆã€ä»ªè¡¨ç›˜è®¾è®¡æœ€ä½³å®è·µã€å˜é‡ä¸æ¨¡æ¿åº”ç”¨ï¼Œä»¥åŠä¼ä¸šçº§ç›‘æ§ä»ªè¡¨ç›˜çš„æ„å»ºã€‚

---

## 9.3 Grafanaå¯è§†åŒ–ä¸ä»ªè¡¨ç›˜

åœ¨9.2èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Prometheusçš„æ ¸å¿ƒåŸç†å’ŒPromQLæŸ¥è¯¢ã€‚è™½ç„¶Prometheusè‡ªå¸¦Web UIå¯ä»¥æŸ¥è¯¢æ•°æ®ï¼Œä½†å®ƒçš„å¯è§†åŒ–èƒ½åŠ›éå¸¸æœ‰é™ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¼ºå¤§çš„å¯è§†åŒ–å¹³å°æ¥ï¼š

- ğŸ“Š åˆ›å»ºç¾è§‚çš„å®æ—¶ç›‘æ§ä»ªè¡¨ç›˜
- ğŸ“ˆ å±•ç¤ºå¤šç»´åº¦çš„æŒ‡æ ‡è¶‹åŠ¿å›¾è¡¨
- ğŸ¯ é›†ä¸­ç®¡ç†å¤šä¸ªæ•°æ®æº
- ğŸš¨ å¯è§†åŒ–å‘Šè­¦çŠ¶æ€
- ğŸ‘¥ æ”¯æŒå›¢é˜Ÿåä½œå’Œæƒé™ç®¡ç†

**Grafana**æ˜¯ä¸šç•Œæœ€æµè¡Œçš„å¼€æºå¯è§†åŒ–å¹³å°ï¼Œå®ƒä¸Prometheuså®Œç¾é›†æˆï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾è¡¨ç±»å‹å’Œå¼ºå¤§çš„å®šåˆ¶èƒ½åŠ›ã€‚

**Grafanaæ ¸å¿ƒä¼˜åŠ¿**ï¼š

| ç‰¹æ€§ | è¯´æ˜ | ä»·å€¼ |
|------|------|------|
| **å¤šæ•°æ®æº** | æ”¯æŒ60+æ•°æ®æº (Prometheus/Loki/Jaeger/ES/MySQLç­‰) | ç»Ÿä¸€ç›‘æ§å¹³å° |
| **ä¸°å¯Œå›¾è¡¨** | æŠ˜çº¿å›¾/æŸ±çŠ¶å›¾/çƒ­åŠ›å›¾/Gauge/Table/Stat/Logsé¢æ¿ç­‰ | æ»¡è¶³å„ç§å±•ç¤ºéœ€æ±‚ |
| **å˜é‡æ¨¡æ¿** | åŠ¨æ€Dashboard (åˆ‡æ¢é›†ç¾¤/å‘½åç©ºé—´/æœåŠ¡ç­‰) | ä¸€ä¸ªDashboardé€‚é…å¤šç¯å¢ƒ |
| **å‘Šè­¦é›†æˆ** | åŸç”Ÿå‘Šè­¦è§„åˆ™+å¤šæ¸ é“é€šçŸ¥ | ç‹¬ç«‹äºPrometheusçš„å‘Šè­¦ |
| **æƒé™ç®¡ç†** | Organization/Team/Userä¸‰çº§æƒé™ | ä¼ä¸šçº§å¤šç§Ÿæˆ·æ”¯æŒ |
| **æ’ä»¶ç”Ÿæ€** | æ•°ç™¾ä¸ªç¤¾åŒºæ’ä»¶ | é«˜åº¦å¯æ‰©å±• |

### 9.3.1 Grafanaéƒ¨ç½²ä¸é…ç½®

#### åœ¨Kubernetesä¸­éƒ¨ç½²Grafana

**æ–¹å¼1: ä½¿ç”¨Helm Chart (æ¨è)**

```bash
# ä½¿ç”¨kube-prometheus-stack (å·²åŒ…å«Grafana)
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set grafana.enabled=true \
  --set grafana.adminPassword=admin123 \
  --set grafana.persistence.enabled=true \
  --set grafana.persistence.size=10Gi \
  --set grafana.ingress.enabled=true \
  --set grafana.ingress.hosts[0]=grafana.example.com

# æˆ–å•ç‹¬å®‰è£…Grafana
helm repo add grafana https://grafana.github.io/helm-charts
helm install grafana grafana/grafana \
  --namespace monitoring \
  --set adminPassword=admin123 \
  --set persistence.enabled=true \
  --set persistence.size=10Gi
```

**æ–¹å¼2: æ‰‹åŠ¨éƒ¨ç½²**

```yaml
# grafana-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
    # Prometheusæ•°æ®æº
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
      editable: true
      jsonData:
        timeInterval: 15s
        queryTimeout: 60s
    
    # Lokiæ•°æ®æº (å¦‚æœéƒ¨ç½²äº†Loki)
    - name: Loki
      type: loki
      access: proxy
      url: http://loki:3100
      editable: true
    
    # Jaegeræ•°æ®æº (å¦‚æœéƒ¨ç½²äº†Jaeger)
    - name: Jaeger
      type: jaeger
      access: proxy
      url: http://jaeger-query:16686
      editable: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: monitoring
data:
  grafana.ini: |
    [server]
    protocol = http
    http_port = 3000
    domain = grafana.example.com
    root_url = %(protocol)s://%(domain)s/
    
    [security]
    admin_user = admin
    admin_password = admin123
    secret_key = SW2YcwTIb9zpOOhoPsMm
    
    [auth]
    disable_login_form = false
    disable_signout_menu = false
    
    [auth.anonymous]
    enabled = false
    
    [users]
    allow_sign_up = false
    allow_org_create = false
    auto_assign_org = true
    auto_assign_org_role = Viewer
    
    [log]
    mode = console
    level = info
    
    [alerting]
    enabled = true
    execute_alerts = true
    
    [unified_alerting]
    enabled = true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      securityContext:
        fsGroup: 472
        runAsUser: 472
      containers:
      - name: grafana
        image: grafana/grafana:10.2.0
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: GF_SECURITY_ADMIN_USER
          value: admin
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-admin
              key: password
        volumeMounts:
        - name: config
          mountPath: /etc/grafana
        - name: datasources
          mountPath: /etc/grafana/provisioning/datasources
        - name: data
          mountPath: /var/lib/grafana
        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: grafana-config
      - name: datasources
        configMap:
          name: grafana-datasources
      - name: data
        persistentVolumeClaim:
          claimName: grafana-data
---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-admin
  namespace: monitoring
type: Opaque
stringData:
  password: admin123
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-data
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp3
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
    name: http
  selector:
    app: grafana
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: nginx
  rules:
  - host: grafana.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000
  tls:
  - hosts:
    - grafana.example.com
    secretName: grafana-tls
```

**éƒ¨ç½²å¹¶è®¿é—®**ï¼š

```bash
# éƒ¨ç½²Grafana
kubectl apply -f grafana-deployment.yaml

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n monitoring -l app=grafana
kubectl logs -n monitoring -l app=grafana --tail=50

# ç«¯å£è½¬å‘è®¿é—® (å¦‚æœæ²¡æœ‰Ingress)
kubectl port-forward -n monitoring svc/grafana 3000:3000

# æµè§ˆå™¨è®¿é—®: http://localhost:3000
# é»˜è®¤è´¦å·: admin / admin123
```

#### Grafanaé…ç½®è¯¦è§£

**1. é…ç½®æ–‡ä»¶ç»“æ„**

```
/etc/grafana/
â”œâ”€â”€ grafana.ini              # ä¸»é…ç½®æ–‡ä»¶
â””â”€â”€ provisioning/            # è‡ªåŠ¨é…ç½®ç›®å½•
    â”œâ”€â”€ datasources/         # æ•°æ®æºé…ç½®
    â”‚   â””â”€â”€ datasources.yaml
    â”œâ”€â”€ dashboards/          # Dashboardé…ç½®
    â”‚   â””â”€â”€ dashboards.yaml
    â”œâ”€â”€ notifiers/           # å‘Šè­¦é€šçŸ¥é…ç½®
    â”‚   â””â”€â”€ notifiers.yaml
    â””â”€â”€ plugins/             # æ’ä»¶é…ç½®
        â””â”€â”€ plugins.yaml
```

**2. é‡è¦é…ç½®é¡¹**

```ini
# grafana.ini

# æœåŠ¡å™¨é…ç½®
[server]
protocol = http             # httpæˆ–https
http_port = 3000           # ç›‘å¬ç«¯å£
domain = grafana.example.com
root_url = %(protocol)s://%(domain)s/
enable_gzip = true

# æ•°æ®åº“é…ç½® (é»˜è®¤SQLite,ç”Ÿäº§å»ºè®®MySQL/PostgreSQL)
[database]
type = mysql
host = mysql:3306
name = grafana
user = grafana
password = secret
max_open_conn = 100
max_idle_conn = 50

# å®‰å…¨é…ç½®
[security]
admin_user = admin
admin_password = $__env{GF_SECURITY_ADMIN_PASSWORD}  # ä»ç¯å¢ƒå˜é‡è¯»å–
secret_key = $__env{GF_SECURITY_SECRET_KEY}
disable_gravatar = false
cookie_secure = true
cookie_samesite = lax

# ç”¨æˆ·ç®¡ç†
[users]
allow_sign_up = false          # ç¦æ­¢è‡ªæ³¨å†Œ
allow_org_create = false       # ç¦æ­¢åˆ›å»ºOrganization
auto_assign_org = true
auto_assign_org_role = Viewer  # æ–°ç”¨æˆ·é»˜è®¤è§’è‰²

# è®¤è¯é…ç½®
[auth]
disable_login_form = false
disable_signout_menu = false
oauth_auto_login = false

# LDAPè®¤è¯ (ä¼ä¸šç¯å¢ƒ)
[auth.ldap]
enabled = false
config_file = /etc/grafana/ldap.toml

# åŒ¿åè®¿é—® (å…¬å…±Dashboard)
[auth.anonymous]
enabled = false
org_name = Main Org.
org_role = Viewer

# æ—¥å¿—é…ç½®
[log]
mode = console file
level = info
filters = rendering:debug

# å‘Šè­¦é…ç½®
[alerting]
enabled = true
execute_alerts = true
error_or_timeout = alerting
nodata_or_nullvalues = no_data
concurrent_render_limit = 5

# ç»Ÿä¸€å‘Šè­¦ (Grafana 8.0+)
[unified_alerting]
enabled = true
execute_alerts = true
evaluation_timeout = 30s
max_attempts = 3

# SMTPé…ç½® (é‚®ä»¶å‘Šè­¦)
[smtp]
enabled = true
host = smtp.gmail.com:587
user = alerts@example.com
password = secret
from_address = alerts@example.com
from_name = Grafana Alerts

# æ’ä»¶é…ç½®
[plugins]
enable_alpha = false
app_tls_skip_verify_insecure = false
```

---

### 9.3.2 æ•°æ®æºé›†æˆ

Grafanaæ”¯æŒ60+ç§æ•°æ®æºï¼Œä¸‹é¢ä»‹ç»Kubernetesç›‘æ§æœ€å¸¸ç”¨çš„å‡ ç§ã€‚

#### Prometheusæ•°æ®æºé…ç½®

**1. é€šè¿‡UIæ·»åŠ **

```
1. ç™»å½•Grafana
2. å·¦ä¾§èœå• â†’ Configuration â†’ Data Sources
3. ç‚¹å‡» "Add data source"
4. é€‰æ‹© "Prometheus"
5. å¡«å†™é…ç½®:
   - Name: Prometheus
   - URL: http://prometheus:9090 (K8så†…éƒ¨Serviceåœ°å€)
   - Access: Server (default)
   - Scrape interval: 15s
6. ç‚¹å‡» "Save & Test"
```

**2. é€šè¿‡Provisioningè‡ªåŠ¨é…ç½® (æ¨è)**

```yaml
# datasources.yaml
apiVersion: 1
datasources:
- name: Prometheus
  type: prometheus
  access: proxy
  url: http://prometheus:9090
  isDefault: true
  editable: true
  jsonData:
    timeInterval: 15s        # æŸ¥è¯¢é—´éš”
    queryTimeout: 60s        # æŸ¥è¯¢è¶…æ—¶
    httpMethod: POST         # ä½¿ç”¨POST (æ”¯æŒæ›´é•¿æŸ¥è¯¢)
    customQueryParameters: '' # è‡ªå®šä¹‰å‚æ•°
    manageAlerts: false      # ä¸ç®¡ç†Prometheuså‘Šè­¦
  version: 1
```

**3. Prometheusæ•°æ®æºé«˜çº§é…ç½®**

```yaml
datasources:
- name: Prometheus
  type: prometheus
  access: proxy
  url: http://prometheus:9090
  isDefault: true
  jsonData:
    # åŸºç¡€é…ç½®
    timeInterval: 15s
    queryTimeout: 60s
    httpMethod: POST
    
    # è®¤è¯é…ç½® (å¦‚æœPrometheuså¯ç”¨äº†è®¤è¯)
    basicAuth: true
    basicAuthUser: admin
  secureJsonData:
    basicAuthPassword: secret
    
    # TLSé…ç½®
    tlsAuth: true
    tlsCACert: |
      -----BEGIN CERTIFICATE-----
      ...
      -----END CERTIFICATE-----
    tlsClientCert: |
      -----BEGIN CERTIFICATE-----
      ...
      -----END CERTIFICATE-----
    tlsClientKey: |
      -----BEGIN PRIVATE KEY-----
      ...
      -----END PRIVATE KEY-----
    
    # è‡ªå®šä¹‰HTTPå¤´
    httpHeaderName1: X-Custom-Header
  secureJsonData:
    httpHeaderValue1: custom-value
```

**4. æµ‹è¯•Prometheusè¿æ¥**

```bash
# åœ¨Grafana Podä¸­æµ‹è¯•
kubectl exec -n monitoring -it grafana-xxx -- sh

# æµ‹è¯•è¿æ¥
curl http://prometheus:9090/api/v1/query?query=up

# åº”è¯¥è¿”å›JSONæ•°æ®
```

#### Lokiæ•°æ®æºé…ç½® (æ—¥å¿—)

Lokiæ˜¯Grafana Labså¼€å‘çš„è½»é‡çº§æ—¥å¿—èšåˆç³»ç»Ÿï¼Œä¸Prometheusæ¶æ„ç›¸ä¼¼ã€‚

```yaml
datasources:
- name: Loki
  type: loki
  access: proxy
  url: http://loki:3100
  editable: true
  jsonData:
    maxLines: 1000           # æœ€å¤§è¿”å›è¡Œæ•°
    timeout: 60              # æŸ¥è¯¢è¶…æ—¶ (ç§’)
    derivedFields:           # ä»æ—¥å¿—æå–å­—æ®µ
    - datasourceUid: jaeger  # å…³è”åˆ°Jaeger
      matcherRegex: "traceID=(\\w+)"
      name: TraceID
      url: "$${__value.raw}"
```

**LokiæŸ¥è¯¢ç¤ºä¾‹**ï¼š

```logql
# æŸ¥è¯¢ç‰¹å®šå‘½åç©ºé—´çš„æ—¥å¿—
{namespace="production"}

# æŸ¥è¯¢ç‰¹å®šPodçš„é”™è¯¯æ—¥å¿—
{namespace="production", pod=~"api-.*"} |= "ERROR"

# æ­£åˆ™è¿‡æ»¤
{app="nginx"} |~ "HTTP.*5[0-9]{2}"

# ç»Ÿè®¡é”™è¯¯ç‡
rate({namespace="production"} |= "ERROR" [5m])
```

#### Jaegeræ•°æ®æºé…ç½® (é“¾è·¯è¿½è¸ª)

```yaml
datasources:
- name: Jaeger
  type: jaeger
  access: proxy
  url: http://jaeger-query:16686
  editable: true
  jsonData:
    tracesToLogs:            # å…³è”æ—¥å¿—
      datasourceUid: loki
      tags: ['pod', 'namespace']
      spanStartTimeShift: '-1h'
      spanEndTimeShift: '1h'
```

#### Elasticsearchæ•°æ®æºé…ç½®

```yaml
datasources:
- name: Elasticsearch
  type: elasticsearch
  access: proxy
  url: http://elasticsearch:9200
  database: "[logstash-]YYYY.MM.DD"  # ç´¢å¼•æ¨¡å¼
  jsonData:
    esVersion: "7.10.0"
    timeField: "@timestamp"
    logMessageField: message
    logLevelField: level
    interval: Daily
```

#### å¤šPrometheusæ•°æ®æº (å¤šé›†ç¾¤ç›‘æ§)

```yaml
datasources:
# ç”Ÿäº§ç¯å¢ƒPrometheus
- name: Prometheus-Prod
  type: prometheus
  access: proxy
  url: http://prometheus-prod:9090
  isDefault: true
  jsonData:
    timeInterval: 15s
    customQueryParameters: 'cluster=production'

# æµ‹è¯•ç¯å¢ƒPrometheus
- name: Prometheus-Staging
  type: prometheus
  access: proxy
  url: http://prometheus-staging:9090
  jsonData:
    timeInterval: 15s
    customQueryParameters: 'cluster=staging'

# å¼€å‘ç¯å¢ƒPrometheus
- name: Prometheus-Dev
  type: prometheus
  access: proxy
  url: http://prometheus-dev:9090
  jsonData:
    timeInterval: 30s
    customQueryParameters: 'cluster=development'
```

---

### 9.3.3 ä»ªè¡¨ç›˜è®¾è®¡æœ€ä½³å®è·µ

#### DashboardåŸºç¡€æ¦‚å¿µ

**Dashboardç»“æ„**ï¼š

```
Dashboard (ä»ªè¡¨ç›˜)
â”œâ”€â”€ Rows (è¡Œ)
â”‚   â”œâ”€â”€ Panel 1 (é¢æ¿1: æŠ˜çº¿å›¾)
â”‚   â”œâ”€â”€ Panel 2 (é¢æ¿2: Gauge)
â”‚   â””â”€â”€ Panel 3 (é¢æ¿3: Table)
â”œâ”€â”€ Variables (å˜é‡)
â”‚   â”œâ”€â”€ $cluster
â”‚   â”œâ”€â”€ $namespace
â”‚   â””â”€â”€ $pod
â””â”€â”€ Settings (è®¾ç½®)
    â”œâ”€â”€ General (é€šç”¨)
    â”œâ”€â”€ Annotations (æ³¨é‡Š)
    â”œâ”€â”€ Variables (å˜é‡)
    â”œâ”€â”€ Links (é“¾æ¥)
    â””â”€â”€ JSON Model (JSONæ¨¡å‹)
```

#### åˆ›å»ºç¬¬ä¸€ä¸ªDashboard

**1. Kubernetesé›†ç¾¤æ¦‚è§ˆDashboard**

```
æ­¥éª¤1: åˆ›å»ºDashboard
- å·¦ä¾§èœå• â†’ Dashboards â†’ New Dashboard
- ç‚¹å‡» "Add visualization"
- é€‰æ‹©æ•°æ®æº: Prometheus

æ­¥éª¤2: æ·»åŠ é›†ç¾¤èŠ‚ç‚¹æ•°é¢æ¿
- Panel Title: Cluster Nodes
- Visualization: Stat (ç»Ÿè®¡)
- Query:
  count(kube_node_info)
- è®¾ç½®:
  - Value options â†’ Show: Calculate â†’ Last (éç©º)
  - Standard options â†’ Unit: none
  - Standard options â†’ Color scheme: Green
  - Thresholds: æ­£å¸¸(ç»¿è‰²), <3 è­¦å‘Š(é»„è‰²), <2 ä¸¥é‡(çº¢è‰²)

æ­¥éª¤3: æ·»åŠ Podæ•°é‡é¢æ¿
- Panel Title: Running Pods
- Visualization: Stat
- Query:
  count(kube_pod_status_phase{phase="Running"})

æ­¥éª¤4: æ·»åŠ CPUä½¿ç”¨ç‡é¢æ¿
- Panel Title: Cluster CPU Usage
- Visualization: Time series (æ—¶åºå›¾)
- Query:
  100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
- Legend: Hide (å› ä¸ºåªæœ‰ä¸€æ¡çº¿)

æ­¥éª¤5: æ·»åŠ å†…å­˜ä½¿ç”¨ç‡é¢æ¿
- Panel Title: Cluster Memory Usage
- Visualization: Time series
- Query:
  (1 - (sum(node_memory_MemAvailable_bytes) / sum(node_memory_MemTotal_bytes))) * 100
```

**2. Dashboardå®Œæ•´JSONç¤ºä¾‹**

```json
{
  "dashboard": {
    "title": "Kubernetes Cluster Overview",
    "tags": ["kubernetes", "cluster"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
        "type": "stat",
        "title": "Cluster Nodes",
        "targets": [
          {
            "expr": "count(kube_node_info)",
            "refId": "A"
          }
        ],
        "options": {
          "colorMode": "background",
          "graphMode": "none",
          "textMode": "value_and_name"
        },
        "fieldConfig": {
          "defaults": {
            "unit": "none",
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": null, "color": "red"},
                {"value": 3, "color": "yellow"},
                {"value": 5, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0},
        "type": "stat",
        "title": "Running Pods",
        "targets": [
          {
            "expr": "count(kube_pod_status_phase{phase=\"Running\"})",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "thresholds"},
            "thresholds": {
              "steps": [
                {"value": null, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "id": 3,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4},
        "type": "timeseries",
        "title": "CPU Usage",
        "targets": [
          {
            "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage %",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "color": {"mode": "palette-classic"}
          }
        }
      }
    ],
    "time": {
      "from": "now-6h",
      "to": "now"
    },
    "timepicker": {
      "refresh_intervals": ["5s", "10s", "30s", "1m", "5m"]
    },
    "refresh": "30s"
  }
}
```

#### å›¾è¡¨ç±»å‹é€‰æ‹©æŒ‡å—

| å›¾è¡¨ç±»å‹ | é€‚ç”¨åœºæ™¯ | å…¸å‹æŒ‡æ ‡ |
|---------|---------|---------|
| **Time series** | å±•ç¤ºæ—¶åºè¶‹åŠ¿ | CPUä½¿ç”¨ç‡ã€å†…å­˜ã€ç½‘ç»œæµé‡ |
| **Stat** | æ˜¾ç¤ºå•ä¸€æ•°å€¼ | èŠ‚ç‚¹æ•°ã€Podæ•°ã€å½“å‰QPS |
| **Gauge** | æ˜¾ç¤ºç™¾åˆ†æ¯” | CPUä½¿ç”¨ç‡ã€ç£ç›˜ä½¿ç”¨ç‡ |
| **Bar gauge** | å¤šä¸ªæ¡å½¢å¯¹æ¯” | å„èŠ‚ç‚¹å†…å­˜ä½¿ç”¨å¯¹æ¯” |
| **Table** | å±•ç¤ºæ˜ç»†æ•°æ® | Podåˆ—è¡¨ã€å‘Šè­¦åˆ—è¡¨ |
| **Heatmap** | å±•ç¤ºåˆ†å¸ƒ | å»¶è¿Ÿåˆ†å¸ƒã€é”™è¯¯ç åˆ†å¸ƒ |
| **Pie chart** | å±•ç¤ºå æ¯” | å„å‘½åç©ºé—´Podå æ¯” |
| **Logs** | æ—¥å¿—æµ | åº”ç”¨æ—¥å¿—ã€é”™è¯¯æ—¥å¿— |
| **Node Graph** | æœåŠ¡æ‹“æ‰‘ | å¾®æœåŠ¡è°ƒç”¨å…³ç³» |

#### Dashboardè®¾è®¡åŸåˆ™

**1. ä¿¡æ¯å±‚æ¬¡ (é‡‘å­—å¡”åŸåˆ™)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 1: å…¨å±€çŠ¶æ€ (é¡¶éƒ¨)                â”‚
â”‚  - å…³é”®æŒ‡æ ‡ (Stat/Gauge)                â”‚
â”‚  - ä¸€çœ¼çœ‹å‡ºç³»ç»Ÿå¥åº·çŠ¶æ€                  â”‚
â”‚  - ç¤ºä¾‹: èŠ‚ç‚¹æ•°ã€CPUã€å†…å­˜ã€å‘Šè­¦æ•°       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 2: æ ¸å¿ƒè¶‹åŠ¿ (ä¸­éƒ¨)                â”‚
â”‚  - æ—¶åºå›¾ (Time series)                 â”‚
â”‚  - å±•ç¤ºå…³é”®æŒ‡æ ‡çš„å†å²è¶‹åŠ¿                â”‚
â”‚  - ç¤ºä¾‹: CPU/å†…å­˜è¶‹åŠ¿ã€ç½‘ç»œæµé‡ã€QPS    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 3: è¯¦ç»†æ•°æ® (åº•éƒ¨)                â”‚
â”‚  - è¡¨æ ¼/æ˜ç»† (Table)                    â”‚
â”‚  - ç”¨äºæ·±å…¥åˆ†æå’Œæ’æŸ¥é—®é¢˜                â”‚
â”‚  - ç¤ºä¾‹: Podåˆ—è¡¨ã€Top 10 CPU Pod        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç¤ºä¾‹å¸ƒå±€**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Nodes: 10] [Pods: 127] [CPU: 45%] [Memory: 62%] [ğŸ”´ Alerts: 3] â”‚  â† Level 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   CPU Usage %       â”‚  â”‚   Memory Usage %    â”‚        â”‚  â† Level 2
â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Network I/O        â”‚  â”‚   Disk I/O          â”‚        â”‚
â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Top 10 Pods by CPU Usage                            â”‚ â”‚  â† Level 3
â”‚  â”‚  [Table: Podåç§° | å‘½åç©ºé—´ | CPU | å†…å­˜ | çŠ¶æ€]      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**2. é…è‰²åŸåˆ™**

```yaml
# ä½¿ç”¨è¯­ä¹‰åŒ–é¢œè‰²
å¥åº·çŠ¶æ€: ç»¿è‰² (#73BF69)
è­¦å‘ŠçŠ¶æ€: é»„è‰² (#F2CC0C)
é”™è¯¯çŠ¶æ€: çº¢è‰² (#E02F44)
ä¿¡æ¯å±•ç¤º: è“è‰² (#5794F2)

# é¿å…:
- è¿‡å¤šé¢œè‰² (ä¸è¶…è¿‡5ç§ä¸»è‰²)
- é¥±å’Œåº¦è¿‡é«˜ (åˆºçœ¼)
- çº¢ç»¿è‰²ç›²ä¸å‹å¥½çš„é…è‰²
```

**3. æ—¶é—´èŒƒå›´è®¾ç½®**

```yaml
é»˜è®¤æ—¶é—´èŒƒå›´å»ºè®®:
- å®æ—¶ç›‘æ§: Last 15 minutes (å¿«é€Ÿå‘ç°é—®é¢˜)
- è¶‹åŠ¿åˆ†æ: Last 6 hours (æŸ¥çœ‹æ—¥å†…è¶‹åŠ¿)
- å®¹é‡è§„åˆ’: Last 7 days (å‘¨æœŸæ€§åˆ†æ)
- æœˆåº¦æŠ¥å‘Š: Last 30 days

åˆ·æ–°é—´éš”å»ºè®®:
- å®æ—¶ç›‘æ§: 5s-10s
- æ™®é€šç›‘æ§: 30s-1m
- å†å²åˆ†æ: å…³é—­è‡ªåŠ¨åˆ·æ–° (Manual)
```

**4. Panelä¼˜åŒ–æŠ€å·§**

```yaml
# å‡å°‘æŸ¥è¯¢æ•°é‡
âŒ é”™è¯¯: æ¯ä¸ªPanelä¸€ä¸ªæŸ¥è¯¢
âœ… æ­£ç¡®: ä½¿ç”¨å¤šä¸ªSeriesåœ¨ä¸€ä¸ªPanelä¸­

# ä½¿ç”¨åˆç†çš„æ—¶é—´èŒƒå›´
âŒ é”™è¯¯: rate(http_requests_total[1d])
âœ… æ­£ç¡®: rate(http_requests_total[5m])

# æ·»åŠ æœ‰æ„ä¹‰çš„Legend
âŒ é”™è¯¯: {{instance}}
âœ… æ­£ç¡®: {{namespace}}/{{pod}} - {{container}}

# è®¾ç½®åˆç†çš„Yè½´èŒƒå›´
æ—¶é—´åºåˆ—: Min=0, Max=Auto (é¿å…Yè½´æŠ–åŠ¨)
ç™¾åˆ†æ¯”: Min=0, Max=100
```

---

### 9.3.4 å˜é‡ä¸æ¨¡æ¿åº”ç”¨

å˜é‡ (Variables) æ˜¯Grafanaæœ€å¼ºå¤§çš„åŠŸèƒ½ä¹‹ä¸€ï¼Œå®ƒè®©ä¸€ä¸ªDashboardå¯ä»¥é€‚é…å¤šä¸ªç¯å¢ƒ/é›†ç¾¤/æœåŠ¡ã€‚

#### å˜é‡ç±»å‹

**1. Queryå˜é‡ (ä»æ•°æ®æºæŸ¥è¯¢)**

æœ€å¸¸ç”¨çš„å˜é‡ç±»å‹ï¼Œä»PrometheusæŸ¥è¯¢æ ‡ç­¾å€¼ã€‚

```yaml
# å˜é‡å: cluster
# ç±»å‹: Query
# æ•°æ®æº: Prometheus
# Query:
label_values(kube_node_info, cluster)

# ç”¨æ³•: åœ¨Panelä¸­ä½¿ç”¨ $cluster
up{cluster="$cluster"}
```

**å®Œæ•´é…ç½®ç¤ºä¾‹**ï¼š

```json
{
  "name": "namespace",
  "type": "query",
  "datasource": "Prometheus",
  "query": "label_values(kube_pod_info, namespace)",
  "regex": "",
  "sort": 1,
  "refresh": 2,
  "multi": true,
  "includeAll": true,
  "allValue": ".*",
  "current": {
    "selected": true,
    "text": "All",
    "value": "$__all"
  }
}
```

**å…³é”®é…ç½®é¡¹**ï¼š

| é…ç½®é¡¹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|
| **multi** | æ˜¯å¦å…è®¸å¤šé€‰ | true: å¯é€‰å¤šä¸ªå‘½åç©ºé—´ |
| **includeAll** | æ˜¯å¦åŒ…å«"All"é€‰é¡¹ | true: æ˜¾ç¤ºæ‰€æœ‰å‘½åç©ºé—´ |
| **allValue** | "All"çš„å®é™…å€¼ | ".*" (æ­£åˆ™åŒ¹é…æ‰€æœ‰) |
| **refresh** | åˆ·æ–°ç­–ç•¥ | On Dashboard Load (åŠ è½½æ—¶) |
| **sort** | æ’åºæ–¹å¼ | 1: Alphabetical (å­—æ¯åº) |
| **regex** | è¿‡æ»¤ç»“æœ | /^prod-.*/ (åªæ˜¾ç¤ºprodå¼€å¤´) |

**2. Customå˜é‡ (è‡ªå®šä¹‰åˆ—è¡¨)**

æ‰‹åŠ¨å®šä¹‰çš„å›ºå®šåˆ—è¡¨ã€‚

```json
{
  "name": "environment",
  "type": "custom",
  "query": "production,staging,development",
  "current": {
    "text": "production",
    "value": "production"
  }
}
```

**3. Constantå˜é‡ (å¸¸é‡)**

å›ºå®šå€¼ï¼Œé€šå¸¸ç”¨äºå…¨å±€é…ç½®ã€‚

```json
{
  "name": "alert_threshold",
  "type": "constant",
  "query": "80",
  "hide": 2  // 0: æ˜¾ç¤º, 1: æ˜¾ç¤ºæ ‡ç­¾, 2: å®Œå…¨éšè—
}
```

**4. Intervalå˜é‡ (æ—¶é—´é—´éš”)**

åŠ¨æ€è°ƒæ•´æŸ¥è¯¢æ—¶é—´èŒƒå›´ã€‚

```json
{
  "name": "interval",
  "type": "interval",
  "query": "1m,5m,10m,30m,1h,6h,12h,1d",
  "auto": true,
  "auto_count": 30,
  "auto_min": "10s"
}
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```promql
# ä½¿ç”¨$intervalå˜é‡
rate(http_requests_total[$interval])

# Grafanaä¼šæ ¹æ®æ—¶é—´èŒƒå›´è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„interval
# æ—¶é—´èŒƒå›´: 1å°æ—¶ â†’ interval: 1m
# æ—¶é—´èŒƒå›´: 7å¤©  â†’ interval: 1h
```

**5. Data sourceå˜é‡ (æ•°æ®æº)**

åœ¨å¤šä¸ªæ•°æ®æºé—´åˆ‡æ¢ã€‚

```json
{
  "name": "datasource",
  "type": "datasource",
  "query": "prometheus",
  "current": {
    "text": "Prometheus-Prod",
    "value": "Prometheus-Prod"
  }
}
```

#### å˜é‡é«˜çº§ç”¨æ³•

**1. çº§è”å˜é‡ (Chained Variables)**

ä¸€ä¸ªå˜é‡ä¾èµ–å¦ä¸€ä¸ªå˜é‡çš„å€¼ã€‚

```yaml
# å˜é‡1: cluster
Query: label_values(kube_node_info, cluster)

# å˜é‡2: namespace (ä¾èµ–cluster)
Query: label_values(kube_pod_info{cluster="$cluster"}, namespace)

# å˜é‡3: pod (ä¾èµ–namespace)
Query: label_values(kube_pod_info{cluster="$cluster", namespace="$namespace"}, pod)
```

**ä½¿ç”¨æ•ˆæœ**ï¼š
```
é€‰æ‹© cluster=production â†’ namespaceä¸‹æ‹‰åˆ—è¡¨åªæ˜¾ç¤ºproductioné›†ç¾¤çš„å‘½åç©ºé—´
é€‰æ‹© namespace=api â†’ podä¸‹æ‹‰åˆ—è¡¨åªæ˜¾ç¤ºapiå‘½åç©ºé—´çš„Pod
```

**2. æ­£åˆ™è¿‡æ»¤**

```yaml
# åªæ˜¾ç¤ºä»¥"prod-"å¼€å¤´çš„å‘½åç©ºé—´
Query: label_values(kube_pod_info, namespace)
Regex: /^prod-.*/

# æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´
Query: label_values(kube_pod_info, namespace)
Regex: /^(?!kube-|default).*/
```

**3. å˜é‡æ ¼å¼åŒ–**

åœ¨æŸ¥è¯¢ä¸­ä½¿ç”¨å˜é‡æ—¶ï¼Œå¯ä»¥ç”¨ä¸åŒçš„æ ¼å¼ï¼š

```promql
# åŸå§‹å€¼
up{namespace="$namespace"}

# æ­£åˆ™åŒ¹é… (å¤šé€‰æ—¶)
up{namespace=~"$namespace"}

# Pipeåˆ†éš” (ç”¨äºLoki)
{namespace=~"${namespace:pipe}"}
# ç»“æœ: {namespace=~"api|web|worker"}

# CSVæ ¼å¼
# ç»“æœ: "api","web","worker"

# JSONæ ¼å¼
# ç»“æœ: ["api","web","worker"]
```

**å¸¸ç”¨æ ¼å¼åŒ–é€‰é¡¹**ï¼š

| æ ¼å¼ | è¯­æ³• | è¾“å‡ºç¤ºä¾‹ | ç”¨é€” |
|------|------|---------|------|
| **regex** | `${var:regex}` | `api\|web` | Prometheusæ ‡ç­¾åŒ¹é… |
| **pipe** | `${var:pipe}` | `api\|web` | LokiæŸ¥è¯¢ |
| **csv** | `${var:csv}` | `"api","web"` | SQL INæŸ¥è¯¢ |
| **json** | `${var:json}` | `["api","web"]` | JSON API |
| **raw** | `${var:raw}` | `$__all` | è·å–åŸå§‹å€¼ |

#### å®æˆ˜: å¤šé›†ç¾¤å¤šç¯å¢ƒé€šç”¨Dashboard

**å˜é‡é…ç½®**ï¼š

```yaml
# 1. æ•°æ®æºå˜é‡
Name: datasource
Type: Data source
Query: prometheus
Label: Prometheusæ•°æ®æº

# 2. é›†ç¾¤å˜é‡
Name: cluster
Type: Query
Datasource: $datasource
Query: label_values(kube_node_info, cluster)
Label: é›†ç¾¤
Multi-value: true
Include All: true

# 3. å‘½åç©ºé—´å˜é‡
Name: namespace
Type: Query
Datasource: $datasource
Query: label_values(kube_pod_info{cluster=~"$cluster"}, namespace)
Label: å‘½åç©ºé—´
Multi-value: true
Include All: true
Regex: /^(?!kube-|default).*/  # æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´

# 4. åº”ç”¨å˜é‡
Name: app
Type: Query
Datasource: $datasource
Query: label_values(kube_pod_labels{cluster=~"$cluster", namespace=~"$namespace"}, label_app)
Label: åº”ç”¨
Multi-value: true
Include All: true

# 5. æ—¶é—´é—´éš”å˜é‡
Name: interval
Type: Interval
Query: 1m,5m,10m,30m,1h
Auto: true
Auto min: 30s
```

**PanelæŸ¥è¯¢ç¤ºä¾‹**ï¼š

```promql
# CPUä½¿ç”¨ç‡ (æ”¯æŒå¤šé›†ç¾¤/å¤šå‘½åç©ºé—´/å¤šåº”ç”¨)
sum(rate(container_cpu_usage_seconds_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  pod=~"$app.*"
}[$interval])) by (pod)

# å†…å­˜ä½¿ç”¨
sum(container_memory_working_set_bytes{
  cluster=~"$cluster",
  namespace=~"$namespace",
  pod=~"$app.*"
}) by (pod) / 1024 / 1024 / 1024

# QPS
sum(rate(http_requests_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app, method)

# é”™è¯¯ç‡
sum(rate(http_requests_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  app=~"$app",
  status=~"5.."
}[$interval])) by (app)
  /
sum(rate(http_requests_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app)
  * 100
```

**ä½¿ç”¨ä½“éªŒ**ï¼š

```
é¡¶éƒ¨å˜é‡æ :
[Prometheusæ•°æ®æº â–¼] [é›†ç¾¤: All â–¼] [å‘½åç©ºé—´: All â–¼] [åº”ç”¨: All â–¼] [é—´éš”: Auto â–¼]

ç”¨æˆ·æ“ä½œ:
1. é€‰æ‹©æ•°æ®æº: Prometheus-Prod
2. é€‰æ‹©é›†ç¾¤: production
3. é€‰æ‹©å‘½åç©ºé—´: api, web (å¤šé€‰)
4. é€‰æ‹©åº”ç”¨: user-service, order-service (å¤šé€‰)

â†’ Dashboardè‡ªåŠ¨åˆ·æ–°ï¼Œåªæ˜¾ç¤ºé€‰ä¸­çš„Podæ•°æ®
â†’ ä¸€ä¸ªDashboardé€‚é…æ‰€æœ‰ç¯å¢ƒï¼
```

---

### 9.3.5 ä¼ä¸šçº§ä»ªè¡¨ç›˜ç¤ºä¾‹

#### Dashboard 1: Kubernetesé›†ç¾¤æ€»è§ˆ

**ç›®æ ‡å—ä¼—**: è¿ç»´å›¢é˜Ÿã€ç®¡ç†å±‚
**åˆ·æ–°é—´éš”**: 30ç§’
**æ—¶é—´èŒƒå›´**: æœ€è¿‘6å°æ—¶

**å¸ƒå±€è®¾è®¡**ï¼š

```yaml
Row 1: å…³é”®æŒ‡æ ‡ (Stat)
- é›†ç¾¤èŠ‚ç‚¹æ•° (Ready/Total)
- è¿è¡Œä¸­çš„Podæ•°é‡
- å½“å‰CPUä½¿ç”¨ç‡
- å½“å‰å†…å­˜ä½¿ç”¨ç‡
- æ´»è·ƒå‘Šè­¦æ•°é‡

Row 2: èµ„æºè¶‹åŠ¿ (Time series)
- CPUä½¿ç”¨ç‡è¶‹åŠ¿ (6å°æ—¶)
- å†…å­˜ä½¿ç”¨ç‡è¶‹åŠ¿ (6å°æ—¶)
- ç½‘ç»œI/O (æ¥æ”¶/å‘é€)
- ç£ç›˜I/O (è¯»/å†™)

Row 3: èŠ‚ç‚¹çŠ¶æ€ (Table)
- èŠ‚ç‚¹åˆ—è¡¨ (åç§°/çŠ¶æ€/CPU/å†…å­˜/Podæ•°/å¹´é¾„)
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# èŠ‚ç‚¹Readyæ•°é‡
count(kube_node_status_condition{condition="Ready", status="true"})

# æ€»èŠ‚ç‚¹æ•°
count(kube_node_info)

# é›†ç¾¤CPUä½¿ç”¨ç‡
(1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100

# é›†ç¾¤å†…å­˜ä½¿ç”¨ç‡
(1 - sum(node_memory_MemAvailable_bytes) / sum(node_memory_MemTotal_bytes)) * 100

# è¿è¡Œä¸­çš„Pod
count(kube_pod_status_phase{phase="Running"})

# æ´»è·ƒå‘Šè­¦
count(ALERTS{alertstate="firing"})

# èŠ‚ç‚¹è¯¦æƒ…è¡¨æ ¼
sort_desc(
  (1 - avg by (node) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100
)
```

#### Dashboard 2: åº”ç”¨æ€§èƒ½ç›‘æ§ (REDæ–¹æ³•)

**ç›®æ ‡å—ä¼—**: å¼€å‘å›¢é˜Ÿã€SRE
**åˆ·æ–°é—´éš”**: 10ç§’
**æ—¶é—´èŒƒå›´**: æœ€è¿‘1å°æ—¶

**å¸ƒå±€è®¾è®¡**ï¼š

```yaml
Row 1: REDæŒ‡æ ‡ (Stat + Gauge)
- å½“å‰QPS
- å¹³å‡å»¶è¿Ÿ
- P95å»¶è¿Ÿ
- P99å»¶è¿Ÿ
- é”™è¯¯ç‡ (%)
- æˆåŠŸç‡ (%)

Row 2: è¶‹åŠ¿å›¾ (Time series)
- QPSè¶‹åŠ¿ (æŒ‰methodåˆ†ç»„)
- å»¶è¿Ÿè¶‹åŠ¿ (P50/P95/P99)
- é”™è¯¯ç‡è¶‹åŠ¿

Row 3: è¯¦ç»†åˆ†æ
- HTTPçŠ¶æ€ç åˆ†å¸ƒ (é¥¼å›¾)
- æ…¢è¯·æ±‚Top 10 (Table)
- é”™è¯¯æ—¥å¿— (Logsé¢æ¿)
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# Rate: QPS
sum(rate(http_requests_total{
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app, method)

# Errors: é”™è¯¯ç‡
sum(rate(http_requests_total{
  namespace=~"$namespace",
  app=~"$app",
  status=~"5.."
}[$interval])) by (app)
  /
sum(rate(http_requests_total{
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app)
  * 100

# Duration: P95å»¶è¿Ÿ
histogram_quantile(0.95,
  sum(rate(http_request_duration_seconds_bucket{
    namespace=~"$namespace",
    app=~"$app"
  }[$interval])) by (le, app)
)

# Duration: P99å»¶è¿Ÿ
histogram_quantile(0.99,
  sum(rate(http_request_duration_seconds_bucket{
    namespace=~"$namespace",
    app=~"$app"
  }[$interval])) by (le, app)
)

# HTTPçŠ¶æ€ç åˆ†å¸ƒ
sum by (status) (
  increase(http_requests_total{
    namespace=~"$namespace",
    app=~"$app"
  }[1h])
)
```

#### Dashboard 3: èŠ‚ç‚¹è¯¦ç»†ç›‘æ§

**ç›®æ ‡å—ä¼—**: è¿ç»´å›¢é˜Ÿ
**åˆ·æ–°é—´éš”**: 30ç§’
**æ—¶é—´èŒƒå›´**: æœ€è¿‘6å°æ—¶

```yaml
Variables:
- node: label_values(kube_node_info, node)

Row 1: èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯
- èŠ‚ç‚¹åç§°
- èŠ‚ç‚¹IP
- å†…æ ¸ç‰ˆæœ¬
- kubeletç‰ˆæœ¬
- è¿è¡Œæ—¶é—´

Row 2: CPUè¯¦æƒ…
- CPUä½¿ç”¨ç‡ (%)
- CPUå„æ¨¡å¼æ—¶é—´ (user/system/iowait/idle)
- CPUè´Ÿè½½ (1m/5m/15m)
- CPUæ ¸å¿ƒä½¿ç”¨åˆ†å¸ƒ

Row 3: å†…å­˜è¯¦æƒ…
- å†…å­˜ä½¿ç”¨ç‡ (%)
- å†…å­˜ä½¿ç”¨æ˜ç»† (used/free/buffers/cached)
- Swapä½¿ç”¨ç‡

Row 4: ç£ç›˜è¯¦æƒ…
- ç£ç›˜ä½¿ç”¨ç‡ (æŒ‰æŒ‚è½½ç‚¹)
- ç£ç›˜IOPS (è¯»/å†™)
- ç£ç›˜ååé‡ (è¯»/å†™ MB/s)

Row 5: ç½‘ç»œè¯¦æƒ…
- ç½‘ç»œæµé‡ (æ¥æ”¶/å‘é€ MB/s)
- ç½‘ç»œé”™è¯¯ç‡
- TCPè¿æ¥çŠ¶æ€åˆ†å¸ƒ
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# èŠ‚ç‚¹CPUä½¿ç”¨ç‡
100 - (avg by (instance) (
  irate(node_cpu_seconds_total{
    instance="$node",
    mode="idle"
  }[5m])
) * 100)

# èŠ‚ç‚¹å†…å­˜ä½¿ç”¨ç‡
(1 - (
  node_memory_MemAvailable_bytes{instance="$node"}
    /
  node_memory_MemTotal_bytes{instance="$node"}
)) * 100

# ç£ç›˜ä½¿ç”¨ç‡
(node_filesystem_size_bytes{instance="$node", fstype!~"tmpfs|fuse.*"}
  -
node_filesystem_free_bytes{instance="$node", fstype!~"tmpfs|fuse.*"})
  /
node_filesystem_size_bytes{instance="$node", fstype!~"tmpfs|fuse.*"}
  * 100

# ç½‘ç»œæ¥æ”¶é€Ÿç‡ (MB/s)
rate(node_network_receive_bytes_total{instance="$node", device!="lo"}[5m]) / 1024 / 1024

# ç½‘ç»œå‘é€é€Ÿç‡ (MB/s)
rate(node_network_transmit_bytes_total{instance="$node", device!="lo"}[5m]) / 1024 / 1024
```

#### Dashboard 4: Podè¯¦ç»†ç›‘æ§

```yaml
Variables:
- namespace
- pod

Row 1: PodåŸºæœ¬ä¿¡æ¯
- PodçŠ¶æ€
- é‡å¯æ¬¡æ•°
- Nodeä½ç½®
- IPåœ°å€
- åˆ›å»ºæ—¶é—´

Row 2: å®¹å™¨èµ„æºä½¿ç”¨
- CPUä½¿ç”¨ (millicores)
- å†…å­˜ä½¿ç”¨ (MB)
- CPUä½¿ç”¨ vs Requests/Limits
- å†…å­˜ä½¿ç”¨ vs Requests/Limits

Row 3: ç½‘ç»œä¸å­˜å‚¨
- ç½‘ç»œæµé‡
- æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨
- Volumeä½¿ç”¨ç‡

Row 4: æ—¥å¿—ä¸äº‹ä»¶
- å®¹å™¨æ—¥å¿— (Loki)
- Podäº‹ä»¶
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# Pod CPUä½¿ç”¨ (millicores)
sum(rate(container_cpu_usage_seconds_total{
  namespace="$namespace",
  pod="$pod",
  container!=""
}[5m])) by (container) * 1000

# Podå†…å­˜ä½¿ç”¨ (MB)
sum(container_memory_working_set_bytes{
  namespace="$namespace",
  pod="$pod",
  container!=""
}) by (container) / 1024 / 1024

# Podé‡å¯æ¬¡æ•°
kube_pod_container_status_restarts_total{
  namespace="$namespace",
  pod="$pod"
}

# Pod CPU Requests
sum(kube_pod_container_resource_requests{
  namespace="$namespace",
  pod="$pod",
  resource="cpu"
}) by (container)

# Pod CPU Limits
sum(kube_pod_container_resource_limits{
  namespace="$namespace",
  pod="$pod",
  resource="cpu"
}) by (container)
```

---

### 9.3.6 Dashboardå¯¼å…¥å¯¼å‡ºä¸å…±äº«

#### å¯¼å‡ºDashboard

**æ–¹å¼1: é€šè¿‡UIå¯¼å‡º**

```
1. æ‰“å¼€Dashboard
2. ç‚¹å‡»å³ä¸Šè§’ "Share" å›¾æ ‡
3. é€‰æ‹© "Export" æ ‡ç­¾
4. ç‚¹å‡» "Save to file" ä¸‹è½½JSONæ–‡ä»¶
```

**æ–¹å¼2: é€šè¿‡APIå¯¼å‡º**

```bash
# è·å–Dashboard UID
DASHBOARD_UID="abc123"

# å¯¼å‡ºDashboard JSON
curl -u admin:admin123 \
  http://grafana:3000/api/dashboards/uid/$DASHBOARD_UID \
  | jq '.dashboard' > dashboard.json
```

#### å¯¼å…¥Dashboard

**æ–¹å¼1: é€šè¿‡UIå¯¼å…¥**

```
1. å·¦ä¾§èœå• â†’ Dashboards â†’ Import
2. ä¸Šä¼ JSONæ–‡ä»¶æˆ–ç²˜è´´JSONå†…å®¹
3. é€‰æ‹©æ•°æ®æº
4. ç‚¹å‡» "Import"
```

**æ–¹å¼2: é€šè¿‡Provisioningè‡ªåŠ¨å¯¼å…¥**

```yaml
# dashboards.yaml
apiVersion: 1
providers:
- name: 'default'
  orgId: 1
  folder: ''
  type: file
  disableDeletion: false
  updateIntervalSeconds: 30
  allowUiUpdates: true
  options:
    path: /etc/grafana/provisioning/dashboards
```

```yaml
# åœ¨Kubernetesä¸­æŒ‚è½½Dashboard JSON
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: monitoring
data:
  k8s-cluster.json: |
    {
      "dashboard": {
        "title": "Kubernetes Cluster",
        ...
      }
    }
---
# åœ¨Deploymentä¸­æŒ‚è½½
spec:
  volumes:
  - name: dashboards
    configMap:
      name: grafana-dashboards
  containers:
  - name: grafana
    volumeMounts:
    - name: dashboards
      mountPath: /etc/grafana/provisioning/dashboards
```

#### ä»å®˜æ–¹åº“å¯¼å…¥Dashboard

Grafanaå®˜æ–¹æä¾›äº†æ•°åƒä¸ªç¤¾åŒºDashboardï¼šhttps://grafana.com/grafana/dashboards

**æ¨èçš„Kubernetes Dashboard**ï¼š

| Dashboard ID | åç§° | è¯´æ˜ |
|-------------|------|------|
| **315** | Kubernetes cluster monitoring | é›†ç¾¤æ•´ä½“ç›‘æ§ |
| **747** | Kubernetes Deployment | Deploymentç›‘æ§ |
| **1860** | Node Exporter Full | èŠ‚ç‚¹è¯¦ç»†ç›‘æ§ |
| **3119** | Kubernetes Cluster (Prometheus) | é›†ç¾¤èµ„æºç›‘æ§ |
| **6417** | Kubernetes Cluster Monitoring | å…¨é¢çš„é›†ç¾¤ç›‘æ§ |
| **7249** | Kubernetes Cluster | ç®€æ´çš„é›†ç¾¤è§†å›¾ |
| **12114** | Kubernetes Nodes | èŠ‚ç‚¹ç›‘æ§ |
| **13770** | Kubernetes / Views / Pods | Podè¯¦ç»†ç›‘æ§ |

**å¯¼å…¥æ­¥éª¤**ï¼š

```
1. è®¿é—® https://grafana.com/grafana/dashboards/315
2. å¤åˆ¶Dashboard ID: 315
3. åœ¨Grafanaä¸­: Dashboards â†’ Import
4. è¾“å…¥Dashboard ID: 315
5. é€‰æ‹©Prometheusæ•°æ®æº
6. ç‚¹å‡»Import
```

#### Dashboardæƒé™ç®¡ç†

**1. Organizationçº§åˆ«æƒé™**

```
Admin: å®Œå…¨æ§åˆ¶ (åˆ›å»º/ç¼–è¾‘/åˆ é™¤Dashboard)
Editor: å¯ç¼–è¾‘Dashboard
Viewer: åªè¯»è®¿é—®
```

**2. Dashboardçº§åˆ«æƒé™**

```yaml
# é€šè¿‡UIè®¾ç½®:
Dashboard â†’ Settings â†’ Permissions

# æ·»åŠ æƒé™:
- User: alice@example.com, Role: Editor
- Team: SRE Team, Role: Admin
- Organization: Main Org, Role: Viewer
```

**3. æ–‡ä»¶å¤¹æƒé™**

```yaml
# åˆ›å»ºæ–‡ä»¶å¤¹å¹¶è®¾ç½®æƒé™
Dashboards â†’ New Folder â†’ "Production"

# è®¾ç½®æƒé™:
- Team: SRE Team â†’ Admin
- Team: Dev Team â†’ Editor
- Everyone Else â†’ Viewer
```

---

**ğŸ“Š 9.3èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Grafanaå¯è§†åŒ–å¹³å°çš„éƒ¨ç½²ä¸ä½¿ç”¨ï¼š

âœ… **Grafanaéƒ¨ç½²**ï¼š
- Helm Chartå¿«é€Ÿéƒ¨ç½²
- æ‰‹åŠ¨éƒ¨ç½²å®Œæ•´é…ç½®
- é…ç½®æ–‡ä»¶è¯¦è§£ (grafana.ini)

âœ… **æ•°æ®æºé›†æˆ**ï¼š
- Prometheusæ•°æ®æºé…ç½® (åŸºç¡€/é«˜çº§/å¤šé›†ç¾¤)
- Lokiæ—¥å¿—æ•°æ®æº
- Jaegeré“¾è·¯è¿½è¸ªæ•°æ®æº
- Elasticsearchæ•°æ®æº

âœ… **ä»ªè¡¨ç›˜è®¾è®¡**ï¼š
- DashboardåŸºç¡€æ¦‚å¿µä¸ç»“æ„
- å›¾è¡¨ç±»å‹é€‰æ‹©æŒ‡å—
- è®¾è®¡åŸåˆ™ (ä¿¡æ¯å±‚æ¬¡/é…è‰²/æ—¶é—´èŒƒå›´)
- Panelä¼˜åŒ–æŠ€å·§

âœ… **å˜é‡ä¸æ¨¡æ¿**ï¼š
- 5ç§å˜é‡ç±»å‹ (Query/Custom/Constant/Interval/Data source)
- å˜é‡é«˜çº§ç”¨æ³• (çº§è”/æ­£åˆ™/æ ¼å¼åŒ–)
- å¤šé›†ç¾¤å¤šç¯å¢ƒé€šç”¨Dashboard

âœ… **ä¼ä¸šçº§Dashboard**ï¼š
- é›†ç¾¤æ€»è§ˆDashboard
- REDæ–¹æ³•åº”ç”¨æ€§èƒ½ç›‘æ§
- èŠ‚ç‚¹è¯¦ç»†ç›‘æ§
- Podè¯¦ç»†ç›‘æ§

âœ… **Dashboardç®¡ç†**ï¼š
- å¯¼å…¥å¯¼å‡ºæ–¹æ³•
- å®˜æ–¹Dashboardåº“æ¨è
- æƒé™ç®¡ç†

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ AlertManagerå‘Šè­¦ç®¡ç†ï¼ŒåŒ…æ‹¬å‘Šè­¦è§„åˆ™ç¼–å†™ã€å‘Šè­¦è·¯ç”±ä¸åˆ†ç»„ã€æŠ‘åˆ¶ä¸é™é»˜ç­–ç•¥ï¼Œä»¥åŠå¤šæ¸ é“é€šçŸ¥é›†æˆï¼ˆé’‰é’‰/ä¼ä¸šå¾®ä¿¡/PagerDutyï¼‰ã€‚

---

## 9.4 å‘Šè­¦è§„åˆ™ä¸AlertManager

åœ¨9.2èŠ‚å’Œ9.3èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†Prometheusçš„æ•°æ®é‡‡é›†å’ŒGrafanaçš„å¯è§†åŒ–ã€‚ä½†ç›‘æ§çš„æœ€ç»ˆç›®çš„ä¸ä»…æ˜¯"çœ‹åˆ°é—®é¢˜"ï¼Œæ›´é‡è¦çš„æ˜¯"ä¸»åŠ¨é€šçŸ¥é—®é¢˜"ã€‚è¿™å°±æ˜¯å‘Šè­¦ç³»ç»Ÿçš„æ ¸å¿ƒä»·å€¼ã€‚

æƒ³è±¡ä»¥ä¸‹åœºæ™¯ï¼š
- ğŸ”¥ å‡Œæ™¨3ç‚¹ï¼Œæ•°æ®åº“CPUä½¿ç”¨ç‡é£™å‡åˆ°95%ï¼Œä½†æ²¡äººçŸ¥é“
- ğŸ’¥ Podå› OOMè¢«å¼ºåˆ¶æ€æ­»ï¼Œä¸šåŠ¡ä¸­æ–­5åˆ†é’Ÿæ‰è¢«ç”¨æˆ·åé¦ˆ
- ğŸ“‰ APIé”™è¯¯ç‡ä»0.1%å‡åˆ°10%ï¼Œè¿ç»´å›¢é˜Ÿè¿˜åœ¨ç¡è§‰

**å‘Šè­¦ç³»ç»Ÿçš„ä»·å€¼**ï¼š

| ç»´åº¦ | æ— å‘Šè­¦ | æœ‰å‘Šè­¦ | ä»·å€¼æå‡ |
|------|--------|--------|---------|
| **æ•…éšœå‘ç°** | è¢«åŠ¨ç­‰å¾…ç”¨æˆ·æŠ•è¯‰ | ä¸»åŠ¨é€šçŸ¥è¿ç»´ | æå‰5-30åˆ†é’Ÿ |
| **å“åº”é€Ÿåº¦** | å¹³å‡10-60åˆ†é’Ÿ | å¹³å‡1-5åˆ†é’Ÿ | å¿«10å€ä»¥ä¸Š |
| **ä¸šåŠ¡å½±å“** | å½±å“æ•°åƒç”¨æˆ· | å½±å“æ•°åç”¨æˆ· | é™ä½99% |
| **SLAè¾¾æˆ** | éš¾ä»¥ä¿è¯ | å¯é‡åŒ–ä¿è¯ | 99.9% SLA |

### 9.4.1 Prometheuså‘Šè­¦è§„åˆ™

#### å‘Šè­¦è§„åˆ™åŸºç¡€

Prometheuså‘Šè­¦è§„åˆ™å®šä¹‰åœ¨**Ruleæ–‡ä»¶**ä¸­ï¼Œç”±Prometheus Serverå®šæœŸè¯„ä¼°ï¼ˆé»˜è®¤æ¯åˆ†é’Ÿï¼‰ã€‚

**å‘Šè­¦è§„åˆ™ç»“æ„**ï¼š

```yaml
groups:
- name: example                    # è§„åˆ™ç»„åç§°
  interval: 30s                    # è¯„ä¼°é—´éš” (è¦†ç›–å…¨å±€é…ç½®)
  rules:
  - alert: HighCPUUsage           # å‘Šè­¦åç§°
    expr: |                        # PromQLè¡¨è¾¾å¼
      100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m                        # æŒç»­æ—¶é—´ (å¯é€‰)
    labels:                        # è‡ªå®šä¹‰æ ‡ç­¾
      severity: warning
      team: infrastructure
    annotations:                   # æ³¨é‡Š (å‘Šè­¦è¯¦æƒ…)
      summary: "CPU usage is above 80%"
      description: "CPU usage is {{ $value }}% on instance {{ $labels.instance }}"
```

**å…³é”®å­—æ®µè¯´æ˜**ï¼š

| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **alert** | å‘Šè­¦åç§° | HighCPUUsage |
| **expr** | PromQLè¡¨è¾¾å¼ | cpu_usage > 80 |
| **for** | æŒç»­æ—¶é—´é˜ˆå€¼ | 5m (æŒç»­5åˆ†é’Ÿæ‰è§¦å‘) |
| **labels** | å‘Šè­¦æ ‡ç­¾ | severity: critical |
| **annotations** | å‘Šè­¦è¯¦æƒ… | summary/description |

#### å‘Šè­¦è§„åˆ™ç¼–å†™æœ€ä½³å®è·µ

**1. èµ„æºç›‘æ§å‘Šè­¦**

```yaml
groups:
- name: node_alerts
  interval: 30s
  rules:
  # CPUä½¿ç”¨ç‡å‘Šè­¦
  - alert: HighNodeCPU
    expr: |
      (1 - avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100 > 80
    for: 5m
    labels:
      severity: warning
      component: node
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage is {{ $value | humanize }}% (threshold: 80%)"
      runbook_url: "https://wiki.example.com/runbooks/high-cpu"
  
  # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
  - alert: HighNodeMemory
    expr: |
      (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
      component: node
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage is {{ $value | humanize }}% (threshold: 85%)"
  
  # ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦
  - alert: HighDiskUsage
    expr: |
      (node_filesystem_size_bytes - node_filesystem_free_bytes) 
        / node_filesystem_size_bytes * 100 > 85
    for: 10m
    labels:
      severity: warning
      component: node
    annotations:
      summary: "High disk usage on {{ $labels.instance }}"
      description: |
        Disk usage is {{ $value | humanize }}% on {{ $labels.mountpoint }}
        Instance: {{ $labels.instance }}
        Device: {{ $labels.device }}
  
  # ç£ç›˜å°†åœ¨4å°æ—¶å†…è€—å°½ (é¢„æµ‹æ€§å‘Šè­¦)
  - alert: DiskWillFillIn4Hours
    expr: |
      predict_linear(node_filesystem_free_bytes{fstype!~"tmpfs|fuse.*"}[1h], 4*3600) < 0
    for: 30m
    labels:
      severity: critical
      component: node
    annotations:
      summary: "Disk will fill in 4 hours on {{ $labels.instance }}"
      description: "Based on current trend, disk {{ $labels.mountpoint }} will be full in 4 hours"
  
  # èŠ‚ç‚¹ä¸å¯è¾¾
  - alert: NodeDown
    expr: up{job="node-exporter"} == 0
    for: 1m
    labels:
      severity: critical
      component: node
    annotations:
      summary: "Node {{ $labels.instance }} is down"
      description: "Node exporter on {{ $labels.instance }} has been down for more than 1 minute"
```

**2. Kubernetesé›†ç¾¤å‘Šè­¦**

```yaml
groups:
- name: kubernetes_alerts
  interval: 30s
  rules:
  # PodæŒç»­é‡å¯
  - alert: PodCrashLooping
    expr: |
      rate(kube_pod_container_status_restarts_total[15m]) > 0
    for: 5m
    labels:
      severity: critical
      component: kubernetes
    annotations:
      summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
      description: |
        Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) 
        is restarting {{ $value | humanize }} times per second
  
  # Podå¤„äºéRunningçŠ¶æ€
  - alert: PodNotRunning
    expr: |
      kube_pod_status_phase{phase!~"Running|Succeeded"} > 0
    for: 10m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} not running"
      description: "Pod is in {{ $labels.phase }} phase for more than 10 minutes"
  
  # Deploymentå‰¯æœ¬æ•°ä¸è¶³
  - alert: DeploymentReplicasMismatch
    expr: |
      kube_deployment_status_replicas_available 
        != 
      kube_deployment_spec_replicas
    for: 10m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} replica mismatch"
      description: |
        Deployment has {{ $value }} available replicas, 
        but {{ $labels.deployment }} should have {{ $labels.spec_replicas }}
  
  # PVCä½¿ç”¨ç‡é«˜
  - alert: HighPVCUsage
    expr: |
      kubelet_volume_stats_used_bytes 
        / kubelet_volume_stats_capacity_bytes * 100 > 85
    for: 10m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "PVC {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} usage high"
      description: "PVC usage is {{ $value | humanize }}% (threshold: 85%)"
  
  # èŠ‚ç‚¹èµ„æºå‹åŠ›
  - alert: NodeMemoryPressure
    expr: kube_node_status_condition{condition="MemoryPressure", status="true"} == 1
    for: 5m
    labels:
      severity: critical
      component: kubernetes
    annotations:
      summary: "Node {{ $labels.node }} has memory pressure"
      description: "Node is under memory pressure and may start evicting pods"
  
  - alert: NodeDiskPressure
    expr: kube_node_status_condition{condition="DiskPressure", status="true"} == 1
    for: 5m
    labels:
      severity: critical
      component: kubernetes
    annotations:
      summary: "Node {{ $labels.node }} has disk pressure"
      description: "Node is under disk pressure and may start evicting pods"
```

**3. åº”ç”¨æ€§èƒ½å‘Šè­¦ (REDæ–¹æ³•)**

```yaml
groups:
- name: application_alerts
  interval: 15s
  rules:
  # é«˜é”™è¯¯ç‡
  - alert: HighErrorRate
    expr: |
      (sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
        /
      sum(rate(http_requests_total[5m])) by (service)) * 100 > 5
    for: 5m
    labels:
      severity: critical
      component: application
    annotations:
      summary: "High error rate on {{ $labels.service }}"
      description: |
        Service {{ $labels.service }} has {{ $value | humanize }}% error rate
        (threshold: 5%)
  
  # é«˜å»¶è¿Ÿ (P95 > 1ç§’)
  - alert: HighLatency
    expr: |
      histogram_quantile(0.95, 
        sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
      ) > 1
    for: 5m
    labels:
      severity: warning
      component: application
    annotations:
      summary: "High latency on {{ $labels.service }}"
      description: |
        Service {{ $labels.service }} P95 latency is {{ $value | humanize }}s
        (threshold: 1s)
  
  # QPSå¼‚å¸¸ä¸‹é™
  - alert: QPSDrop
    expr: |
      (sum(rate(http_requests_total[5m])) by (service)
        /
      sum(rate(http_requests_total[5m] offset 1h)) by (service)) < 0.5
    for: 10m
    labels:
      severity: warning
      component: application
    annotations:
      summary: "QPS dropped on {{ $labels.service }}"
      description: |
        Service {{ $labels.service }} QPS dropped by {{ (1 - $value) * 100 | humanize }}%
        compared to 1 hour ago
  
  # æ•°æ®åº“è¿æ¥æ± è€—å°½
  - alert: DatabaseConnectionPoolExhausted
    expr: |
      (db_connections_active / db_connections_max) * 100 > 90
    for: 5m
    labels:
      severity: critical
      component: database
    annotations:
      summary: "Database connection pool nearly exhausted"
      description: |
        Database connection pool usage is {{ $value | humanize }}%
        ({{ $labels.database }})
```

**4. å‘Šè­¦ä¸¥é‡çº§åˆ«å®šä¹‰**

```yaml
# å»ºè®®çš„severityçº§åˆ«æ ‡å‡†
labels:
  severity: critical    # éœ€è¦ç«‹å³å¤„ç† (å½±å“æ ¸å¿ƒä¸šåŠ¡)
  severity: warning     # éœ€è¦å…³æ³¨ (å¯èƒ½å½±å“ä¸šåŠ¡)
  severity: info        # ä»…é€šçŸ¥ (ä¸å½±å“ä¸šåŠ¡)

# ä¸¥é‡çº§åˆ«å¯¹åº”çš„å“åº”æ—¶é—´SLA
critical: ç«‹å³å“åº” (5åˆ†é’Ÿå†…)
warning:  1å°æ—¶å†…å“åº”
info:     å·¥ä½œæ—¶é—´å¤„ç†

# ä¸¥é‡çº§åˆ«å¯¹åº”çš„é€šçŸ¥æ¸ é“
critical: ç”µè¯ + SMS + Slack + Email + PagerDuty
warning:  Slack + Email
info:     Email only
```

#### å‘Šè­¦è§„åˆ™è°ƒè¯•

**1. æµ‹è¯•å‘Šè­¦è¡¨è¾¾å¼**

```bash
# åœ¨Prometheus UIä¸­æµ‹è¯•
http://prometheus:9090/graph

# è¾“å…¥è¡¨è¾¾å¼:
(1 - avg(irate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100 > 80

# æŸ¥çœ‹ç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
```

**2. æ£€æŸ¥å‘Šè­¦çŠ¶æ€**

```bash
# è®¿é—®Prometheuså‘Šè­¦é¡µé¢
http://prometheus:9090/alerts

# å‘Šè­¦çŠ¶æ€:
- Inactive: è¡¨è¾¾å¼ä¸ºfalse
- Pending: è¡¨è¾¾å¼ä¸ºtrue, ä½†æœªæ»¡è¶³foræŒç»­æ—¶é—´
- Firing: è¡¨è¾¾å¼ä¸ºtrueä¸”æ»¡è¶³foræŒç»­æ—¶é—´, å·²è§¦å‘å‘Šè­¦
```

**3. ä½¿ç”¨promtooléªŒè¯è§„åˆ™**

```bash
# ä¸‹è½½è§„åˆ™æ–‡ä»¶
kubectl get configmap prometheus-rules -n monitoring -o yaml > rules.yaml

# éªŒè¯è¯­æ³•
promtool check rules rules.yaml

# è¾“å‡ºç¤ºä¾‹:
# Checking rules.yaml
#   SUCCESS: 15 rules found
```

**4. æŸ¥è¯¢å½“å‰è§¦å‘çš„å‘Šè­¦**

```promql
# æŸ¥è¯¢æ‰€æœ‰firingçŠ¶æ€çš„å‘Šè­¦
ALERTS{alertstate="firing"}

# æŸ¥è¯¢ç‰¹å®šseverityçš„å‘Šè­¦
ALERTS{severity="critical", alertstate="firing"}

# ç»Ÿè®¡å‘Šè­¦æ•°é‡
count(ALERTS{alertstate="firing"}) by (severity)
```

---

### 9.4.2 AlertManageræ¶æ„ä¸é…ç½®

#### AlertManageræ¶æ„

AlertManageræ˜¯Prometheusç”Ÿæ€çš„ç‹¬ç«‹å‘Šè­¦ç®¡ç†ç»„ä»¶ï¼Œè´Ÿè´£æ¥æ”¶Prometheuså‘é€çš„å‘Šè­¦ï¼Œè¿›è¡Œå»é‡ã€åˆ†ç»„ã€è·¯ç”±å’Œé€šçŸ¥ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AlertManageræ¶æ„                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prometheus 1    â”‚  (å‘é€å‘Šè­¦)
â”‚  Prometheus 2    â”‚  (å‘é€å‘Šè­¦)
â”‚  Prometheus 3    â”‚  (å‘é€å‘Šè­¦)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AlertManager                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  1. Deduplication (å»é‡)                            â”‚     â”‚
â”‚  â”‚     - åŒä¸€å‘Šè­¦ä»å¤šä¸ªPrometheusæ¥æ”¶                  â”‚     â”‚
â”‚  â”‚     - åªä¿ç•™ä¸€ä»½                                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                 â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  2. Grouping (åˆ†ç»„)                                 â”‚     â”‚
â”‚  â”‚     - æŒ‰æ ‡ç­¾åˆ†ç»„ (å¦‚: namespace, severity)          â”‚     â”‚
â”‚  â”‚     - å‡å°‘å‘Šè­¦é€šçŸ¥æ•°é‡                               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                 â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  3. Inhibition (æŠ‘åˆ¶)                               â”‚     â”‚
â”‚  â”‚     - é«˜ä¼˜å…ˆçº§å‘Šè­¦æŠ‘åˆ¶ä½ä¼˜å…ˆçº§                       â”‚     â”‚
â”‚  â”‚     - ç¤ºä¾‹: èŠ‚ç‚¹DownæŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šçš„Podå‘Šè­¦           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                 â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  4. Silencing (é™é»˜)                                â”‚     â”‚
â”‚  â”‚     - ä¸´æ—¶å±è”½å‘Šè­¦                                   â”‚     â”‚
â”‚  â”‚     - ç»´æŠ¤çª—å£æœŸä½¿ç”¨                                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                 â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  5. Routing (è·¯ç”±)                                  â”‚     â”‚
â”‚  â”‚     - æ ¹æ®æ ‡ç­¾è·¯ç”±åˆ°ä¸åŒæ¥æ”¶å™¨                       â”‚     â”‚
â”‚  â”‚     - ç¤ºä¾‹: team=frontend â†’ Slack #frontend        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                 â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  6. Notification (é€šçŸ¥)                             â”‚     â”‚
â”‚  â”‚     - å‘é€åˆ°å¤šä¸ªæ¸ é“                                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚           â”‚            â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Email   â”‚ â”‚ Slack  â”‚ â”‚  é’‰é’‰     â”‚ â”‚ PagerDuty   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### éƒ¨ç½²AlertManager

**1. ä½¿ç”¨Helméƒ¨ç½² (kube-prometheus-stackå·²åŒ…å«)**

```bash
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set alertmanager.enabled=true \
  --set alertmanager.alertmanagerSpec.replicas=3 \
  --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.resources.requests.storage=10Gi
```

**2. æ‰‹åŠ¨éƒ¨ç½²AlertManager**

```yaml
# alertmanager-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      # å…¨å±€é…ç½®
      resolve_timeout: 5m        # å‘Šè­¦æ¢å¤è¶…æ—¶æ—¶é—´
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@example.com'
      smtp_auth_username: 'alerts@example.com'
      smtp_auth_password: 'password'
      smtp_require_tls: true
    
    # æ¨¡æ¿æ–‡ä»¶
    templates:
    - '/etc/alertmanager/templates/*.tmpl'
    
    # è·¯ç”±é…ç½®
    route:
      # é»˜è®¤æ¥æ”¶å™¨
      receiver: 'default'
      
      # åˆ†ç»„é…ç½®
      group_by: ['alertname', 'cluster', 'namespace']
      group_wait: 10s           # é¦–æ¬¡å‘Šè­¦ç­‰å¾…æ—¶é—´ (æ”¶é›†æ›´å¤šå‘Šè­¦)
      group_interval: 10s       # åˆ†ç»„å†…å‘Šè­¦å‘é€é—´éš”
      repeat_interval: 12h      # é‡å¤å‘Šè­¦é—´éš”
      
      # å­è·¯ç”±
      routes:
      # Criticalå‘Šè­¦ â†’ PagerDuty + Slack
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 10s
        group_interval: 5m
        repeat_interval: 4h
      
      # Frontendå›¢é˜Ÿå‘Šè­¦ â†’ Slack #frontend
      - match:
          team: frontend
        receiver: 'frontend-team'
        group_by: ['alertname', 'namespace']
      
      # æ•°æ®åº“å‘Šè­¦ â†’ DBAå›¢é˜Ÿ
      - match_re:
          alertname: '^(Database|MySQL|PostgreSQL).*'
        receiver: 'dba-team'
    
    # æŠ‘åˆ¶è§„åˆ™
    inhibit_rules:
    # èŠ‚ç‚¹Downæ—¶ï¼ŒæŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰Podå‘Šè­¦
    - source_match:
        alertname: 'NodeDown'
      target_match_re:
        alertname: 'Pod.*'
      equal: ['instance']
    
    # Criticalå‘Šè­¦æŠ‘åˆ¶Warningå‘Šè­¦
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'namespace']
    
    # æ¥æ”¶å™¨é…ç½®
    receivers:
    # é»˜è®¤æ¥æ”¶å™¨ (Email)
    - name: 'default'
      email_configs:
      - to: 'ops@example.com'
        headers:
          Subject: '[Alert] {{ .GroupLabels.alertname }}'
    
    # Criticalå‘Šè­¦æ¥æ”¶å™¨
    - name: 'critical-alerts'
      pagerduty_configs:
      - service_key: 'your-pagerduty-key'
        description: '{{ .CommonAnnotations.summary }}'
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'
        channel: '#alerts-critical'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    
    # Frontendå›¢é˜Ÿæ¥æ”¶å™¨
    - name: 'frontend-team'
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'
        channel: '#frontend-alerts'
    
    # DBAå›¢é˜Ÿæ¥æ”¶å™¨
    - name: 'dba-team'
      email_configs:
      - to: 'dba@example.com'
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'
        channel: '#database-alerts'
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  serviceName: alertmanager
  replicas: 3  # é«˜å¯ç”¨ (3ä¸ªå‰¯æœ¬)
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        args:
        - '--config.file=/etc/alertmanager/alertmanager.yml'
        - '--storage.path=/alertmanager'
        - '--cluster.listen-address=0.0.0.0:9094'  # é›†ç¾¤é€šä¿¡ç«¯å£
        - '--cluster.peer=alertmanager-0.alertmanager:9094'
        - '--cluster.peer=alertmanager-1.alertmanager:9094'
        - '--cluster.peer=alertmanager-2.alertmanager:9094'
        ports:
        - containerPort: 9093
          name: http
        - containerPort: 9094
          name: cluster
        volumeMounts:
        - name: config
          mountPath: /etc/alertmanager
        - name: data
          mountPath: /alertmanager
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  clusterIP: None  # Headless Service (for StatefulSet)
  ports:
  - port: 9093
    targetPort: 9093
    name: http
  - port: 9094
    targetPort: 9094
    name: cluster
  selector:
    app: alertmanager
---
# å¯¹å¤–è®¿é—®çš„Service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-external
  namespace: monitoring
spec:
  type: ClusterIP
  ports:
  - port: 9093
    targetPort: 9093
    name: http
  selector:
    app: alertmanager
```

**3. é…ç½®Prometheusè¿æ¥AlertManager**

```yaml
# prometheus-config.yaml (æ·»åŠ alertingé…ç½®)
global:
  scrape_interval: 15s

# AlertManageré…ç½®
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager-0.alertmanager:9093
      - alertmanager-1.alertmanager:9093
      - alertmanager-2.alertmanager:9093

# è§„åˆ™æ–‡ä»¶
rule_files:
- '/etc/prometheus/rules/*.yml'
```

#### å‘Šè­¦è·¯ç”±è¯¦è§£

**1. è·¯ç”±æ ‘ç»“æ„**

```yaml
route:
  receiver: 'default'  # æ ¹è·¯ç”±é»˜è®¤æ¥æ”¶å™¨
  group_by: ['alertname']
  
  routes:
  # Level 1: æŒ‰ä¸¥é‡çº§åˆ«è·¯ç”±
  - match:
      severity: critical
    receiver: 'pagerduty'
    routes:
    # Level 2: Criticalä¸­æŒ‰å›¢é˜Ÿè·¯ç”±
    - match:
        team: frontend
      receiver: 'frontend-critical'
    - match:
        team: backend
      receiver: 'backend-critical'
  
  # Level 1: æŒ‰ç»„ä»¶è·¯ç”±
  - match:
      component: database
    receiver: 'dba-team'
    group_by: ['alertname', 'database']
  
  # Level 1: å·¥ä½œæ—¶é—´ vs éå·¥ä½œæ—¶é—´
  - match_re:
      severity: 'warning|info'
    receiver: 'working-hours'
    # å¯ä»¥ç»“åˆæ—¶é—´è·¯ç”± (éœ€è¦è‡ªå®šä¹‰å®ç°)
```

**2. åˆ†ç»„ç­–ç•¥**

```yaml
# ç­–ç•¥1: æŒ‰å‘Šè­¦åç§°åˆ†ç»„
group_by: ['alertname']
# æ•ˆæœ: æ‰€æœ‰HighCPUå‘Šè­¦åˆå¹¶ä¸ºä¸€æ¡é€šçŸ¥

# ç­–ç•¥2: æŒ‰å‘½åç©ºé—´åˆ†ç»„
group_by: ['namespace']
# æ•ˆæœ: åŒä¸€å‘½åç©ºé—´çš„æ‰€æœ‰å‘Šè­¦åˆå¹¶

# ç­–ç•¥3: å¤šç»´åº¦åˆ†ç»„
group_by: ['alertname', 'cluster', 'namespace']
# æ•ˆæœ: ç›¸åŒå‘Šè­¦åç§°+é›†ç¾¤+å‘½åç©ºé—´çš„åˆå¹¶

# ç­–ç•¥4: ä¸åˆ†ç»„ (æ¯ä¸ªå‘Šè­¦å•ç‹¬é€šçŸ¥)
group_by: ['...']  # ç‰¹æ®Šè¯­æ³•,åŒ…å«æ‰€æœ‰æ ‡ç­¾
```

**3. æ—¶é—´å‚æ•°è°ƒä¼˜**

```yaml
route:
  group_wait: 30s        # é¦–æ¬¡å‘Šè­¦ç­‰å¾…æ—¶é—´
  group_interval: 5m     # åˆ†ç»„å†…åç»­å‘Šè­¦å‘é€é—´éš”
  repeat_interval: 4h    # é‡å¤æœªæ¢å¤å‘Šè­¦çš„é—´éš”
```

**æ—¶é—´å‚æ•°å¯¹æ¯”**ï¼š

| åœºæ™¯ | group_wait | group_interval | repeat_interval |
|------|-----------|----------------|-----------------|
| **ç´§æ€¥å‘Šè­¦** | 10s | 5m | 1h |
| **æ™®é€šå‘Šè­¦** | 30s | 10m | 4h |
| **ä¿¡æ¯å‘Šè­¦** | 5m | 30m | 12h |

**æ•ˆæœæ¼”ç¤º**ï¼š

```
æ—¶é—´è½´:
00:00 - å‘Šè­¦1è§¦å‘ (å¼€å§‹group_wait=30s)
00:10 - å‘Šè­¦2è§¦å‘ (åŠ å…¥åŒä¸€åˆ†ç»„)
00:20 - å‘Šè­¦3è§¦å‘ (åŠ å…¥åŒä¸€åˆ†ç»„)
00:30 - å‘é€ç¬¬1æ¬¡é€šçŸ¥ (åŒ…å«å‘Šè­¦1/2/3)
05:30 - å‘é€ç¬¬2æ¬¡é€šçŸ¥ (group_interval=5m, å¦‚æœå‘Šè­¦ä»åœ¨è§¦å‘)
09:30 - å‘é€ç¬¬3æ¬¡é€šçŸ¥
...
```

#### æŠ‘åˆ¶è§„åˆ™ (Inhibition)

æŠ‘åˆ¶è§„åˆ™ç”¨äºåœ¨æŸäº›å‘Šè­¦è§¦å‘æ—¶ï¼Œæš‚æ—¶å±è”½å…¶ä»–ç›¸å…³å‘Šè­¦ï¼Œé¿å…å‘Šè­¦é£æš´ã€‚

**å¸¸ç”¨æŠ‘åˆ¶è§„åˆ™**ï¼š

```yaml
inhibit_rules:
# 1. èŠ‚ç‚¹Downæ—¶ï¼ŒæŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰å‘Šè­¦
- source_match:
    alertname: 'NodeDown'
  target_match_re:
    alertname: '.*'
  equal: ['instance']

# 2. é›†ç¾¤çº§åˆ«æ•…éšœæŠ‘åˆ¶å•èŠ‚ç‚¹å‘Šè­¦
- source_match:
    alertname: 'ClusterDown'
  target_match:
    alertname: 'NodeDown'
  equal: ['cluster']

# 3. æ•°æ®åº“ä¸»åº“DownæŠ‘åˆ¶ä»åº“å‘Šè­¦
- source_match:
    alertname: 'MysqlMasterDown'
  target_match:
    alertname: 'MysqlSlaveDown'
  equal: ['cluster']

# 4. Criticalå‘Šè­¦æŠ‘åˆ¶Warningå‘Šè­¦
- source_match:
    severity: 'critical'
  target_match:
    severity: 'warning'
  equal: ['alertname', 'namespace', 'pod']

# 5. çˆ¶æœåŠ¡å‘Šè­¦æŠ‘åˆ¶å­æœåŠ¡å‘Šè­¦
- source_match:
    alertname: 'APIGatewayDown'
  target_match_re:
    alertname: '(Frontend|Backend)ServiceDown'
  equal: ['cluster']
```

**æŠ‘åˆ¶è§„åˆ™é…ç½®è¯´æ˜**ï¼š

| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **source_match** | æºå‘Šè­¦åŒ¹é…æ¡ä»¶ (ç²¾ç¡®åŒ¹é…) | alertname: 'NodeDown' |
| **source_match_re** | æºå‘Šè­¦åŒ¹é…æ¡ä»¶ (æ­£åˆ™) | alertname: '^Node.*' |
| **target_match** | ç›®æ ‡å‘Šè­¦åŒ¹é…æ¡ä»¶ (ç²¾ç¡®) | severity: 'warning' |
| **target_match_re** | ç›®æ ‡å‘Šè­¦åŒ¹é…æ¡ä»¶ (æ­£åˆ™) | alertname: '.*Pod.*' |
| **equal** | ç›¸åŒæ ‡ç­¾æ‰æŠ‘åˆ¶ | ['instance'] |

#### é™é»˜è§„åˆ™ (Silencing)

é™é»˜ç”¨äºä¸´æ—¶å±è”½å‘Šè­¦ï¼Œå¸¸ç”¨äºç»´æŠ¤çª—å£æœŸã€‚

**1. é€šè¿‡UIåˆ›å»ºé™é»˜**

```
è®¿é—® AlertManager UI: http://alertmanager:9093
â†’ Silences
â†’ New Silence
â†’ å¡«å†™:
   - Matchers: alertname=HighCPU, instance=node1
   - Start: 2024-01-20 22:00
   - End: 2024-01-21 02:00
   - Creator: ops@example.com
   - Comment: Database maintenance window
â†’ Create
```

**2. é€šè¿‡APIåˆ›å»ºé™é»˜**

```bash
# åˆ›å»ºé™é»˜
curl -X POST http://alertmanager:9093/api/v2/silences \
  -H 'Content-Type: application/json' \
  -d '{
    "matchers": [
      {
        "name": "alertname",
        "value": "HighCPU",
        "isRegex": false
      },
      {
        "name": "instance",
        "value": "node1",
        "isRegex": false
      }
    ],
    "startsAt": "2024-01-20T22:00:00Z",
    "endsAt": "2024-01-21T02:00:00Z",
    "createdBy": "ops@example.com",
    "comment": "Database maintenance window"
  }'

# æŸ¥è¯¢æ‰€æœ‰é™é»˜
curl http://alertmanager:9093/api/v2/silences

# åˆ é™¤é™é»˜
curl -X DELETE http://alertmanager:9093/api/v2/silence/{silence_id}
```

**3. ä½¿ç”¨amtool CLI**

```bash
# å®‰è£…amtool
go install github.com/prometheus/alertmanager/cmd/amtool@latest

# åˆ›å»ºé™é»˜ (4å°æ—¶)
amtool silence add alertname=HighCPU instance=node1 \
  --duration=4h \
  --author=ops@example.com \
  --comment="Maintenance window"

# æŸ¥è¯¢é™é»˜
amtool silence query

# è¾“å‡º:
# ID                                    Matchers              Ends At                 Created By       Comment
# 8e6f0c3a-1234-5678-9abc-def012345678  alertname=HighCPU...  2024-01-20 22:00:00 UTC ops@example.com  Maintenance...

# åˆ é™¤é™é»˜
amtool silence expire 8e6f0c3a-1234-5678-9abc-def012345678
```

---

### 9.4.3 å¤šæ¸ é“é€šçŸ¥é›†æˆ

AlertManageræ”¯æŒå¤šç§é€šçŸ¥æ¸ é“ï¼Œä¸‹é¢ä»‹ç»æœ€å¸¸ç”¨çš„å‡ ç§ã€‚

#### Emailé€šçŸ¥

```yaml
receivers:
- name: 'email-alerts'
  email_configs:
  - to: 'ops@example.com,dev@example.com'
    from: 'alertmanager@example.com'
    smarthost: 'smtp.gmail.com:587'
    auth_username: 'alertmanager@example.com'
    auth_password: 'app-specific-password'
    require_tls: true
    headers:
      Subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
    html: |
      <h2>{{ .GroupLabels.alertname }}</h2>
      <p><b>Status:</b> {{ .Status }}</p>
      <p><b>Severity:</b> {{ .CommonLabels.severity }}</p>
      <p><b>Summary:</b> {{ .CommonAnnotations.summary }}</p>
      <h3>Alerts:</h3>
      <ul>
      {{ range .Alerts }}
        <li>
          <b>{{ .Labels.instance }}</b>: {{ .Annotations.description }}
          <br/>Started at: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
        </li>
      {{ end }}
      </ul>
```

#### Slacké€šçŸ¥

```yaml
receivers:
- name: 'slack-alerts'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX'
    channel: '#alerts'
    username: 'AlertManager'
    icon_emoji: ':fire:'
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    title: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
    title_link: 'http://alertmanager:9093'
    text: |
      {{ range .Alerts }}
      *Alert:* {{ .Labels.alertname }}
      *Severity:* {{ .Labels.severity }}
      *Instance:* {{ .Labels.instance }}
      *Summary:* {{ .Annotations.summary }}
      *Description:* {{ .Annotations.description }}
      ---
      {{ end }}
    send_resolved: true
```

**Slackæ¶ˆæ¯æ•ˆæœ**ï¼š

```
[FIRING] HighCPUUsage
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Alert: HighCPUUsage
Severity: warning
Instance: node1.example.com
Summary: High CPU usage on node1
Description: CPU usage is 85.3% (threshold: 80%)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

#### é’‰é’‰é€šçŸ¥

AlertManageråŸç”Ÿä¸æ”¯æŒé’‰é’‰ï¼Œéœ€è¦ä½¿ç”¨Webhook + é’‰é’‰æœºå™¨äººã€‚

**1. åˆ›å»ºé’‰é’‰æœºå™¨äºº**

```
1. æ‰“å¼€é’‰é’‰ç¾¤ â†’ ç¾¤è®¾ç½® â†’ æ™ºèƒ½ç¾¤åŠ©æ‰‹ â†’ æ·»åŠ æœºå™¨äºº
2. é€‰æ‹©"è‡ªå®šä¹‰"æœºå™¨äºº
3. è®¾ç½®å®‰å…¨æ–¹å¼: åŠ ç­¾ (è·å–secret)
4. å¤åˆ¶Webhookåœ°å€
```

**2. éƒ¨ç½²é’‰é’‰Webhooké€‚é…å™¨**

```yaml
# dingtalk-webhook.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dingtalk-webhook
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: dingtalk-webhook
  template:
    metadata:
      labels:
        app: dingtalk-webhook
    spec:
      containers:
      - name: webhook
        image: timonwong/prometheus-webhook-dingtalk:v2.1.0
        args:
        - --web.listen-address=:8060
        - --config.file=/etc/dingtalk/config.yml
        ports:
        - containerPort: 8060
        volumeMounts:
        - name: config
          mountPath: /etc/dingtalk
      volumes:
      - name: config
        configMap:
          name: dingtalk-webhook-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: dingtalk-webhook-config
  namespace: monitoring
data:
  config.yml: |
    targets:
      webhook1:
        url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN
        secret: YOUR_SECRET
---
apiVersion: v1
kind: Service
metadata:
  name: dingtalk-webhook
  namespace: monitoring
spec:
  ports:
  - port: 8060
    targetPort: 8060
  selector:
    app: dingtalk-webhook
```

**3. é…ç½®AlertManagerä½¿ç”¨é’‰é’‰**

```yaml
receivers:
- name: 'dingtalk-alerts'
  webhook_configs:
  - url: 'http://dingtalk-webhook:8060/dingtalk/webhook1/send'
    send_resolved: true
```

**é’‰é’‰æ¶ˆæ¯æ•ˆæœ**ï¼š

```
ã€å‘Šè­¦ã€‘HighCPUUsage

çº§åˆ«: warning
é›†ç¾¤: production
å®ä¾‹: node1.example.com
æ‘˜è¦: High CPU usage on node1
æè¿°: CPU usage is 85.3% (threshold: 80%)
å¼€å§‹æ—¶é—´: 2024-01-20 10:30:00

[æŸ¥çœ‹è¯¦æƒ…](http://alertmanager:9093)
```

#### ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```yaml
# éƒ¨ç½²ä¼ä¸šå¾®ä¿¡Webhooké€‚é…å™¨
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wechat-webhook
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: wechat-webhook
  template:
    metadata:
      labels:
        app: wechat-webhook
    spec:
      containers:
      - name: webhook
        image: daixiang0/prometheus-webhook-wechat:v1.0.0
        env:
        - name: WECHAT_CORP_ID
          value: "your-corp-id"
        - name: WECHAT_AGENT_ID
          value: "your-agent-id"
        - name: WECHAT_API_SECRET
          value: "your-api-secret"
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: wechat-webhook
  namespace: monitoring
spec:
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: wechat-webhook
```

```yaml
# AlertManageré…ç½®
receivers:
- name: 'wechat-alerts'
  webhook_configs:
  - url: 'http://wechat-webhook:8080/send'
    send_resolved: true
```

#### PagerDutyé›†æˆ (ä¸“ä¸šOn-CallæœåŠ¡)

```yaml
receivers:
- name: 'pagerduty-critical'
  pagerduty_configs:
  - service_key: 'your-pagerduty-integration-key'
    description: '{{ .CommonAnnotations.summary }}'
    severity: '{{ .CommonLabels.severity }}'
    details:
      firing: '{{ .Alerts.Firing | len }}'
      resolved: '{{ .Alerts.Resolved | len }}'
      alertname: '{{ .GroupLabels.alertname }}'
      cluster: '{{ .CommonLabels.cluster }}'
    client: 'AlertManager'
    client_url: 'http://alertmanager:9093'
```

#### Webhooké€šç”¨é›†æˆ

```yaml
receivers:
- name: 'webhook-custom'
  webhook_configs:
  - url: 'https://your-webhook-endpoint.com/alerts'
    send_resolved: true
    http_config:
      bearer_token: 'your-api-token'
    max_alerts: 0  # 0 = å‘é€æ‰€æœ‰å‘Šè­¦
```

**Webhookæ¥æ”¶ç¤ºä¾‹ (Go)**ï¼š

```go
package main

import (
    "encoding/json"
    "fmt"
    "io/ioutil"
    "net/http"
)

type Alert struct {
    Status       string            `json:"status"`
    Labels       map[string]string `json:"labels"`
    Annotations  map[string]string `json:"annotations"`
    StartsAt     string            `json:"startsAt"`
    EndsAt       string            `json:"endsAt"`
    GeneratorURL string            `json:"generatorURL"`
}

type WebhookMessage struct {
    Version           string            `json:"version"`
    GroupKey          string            `json:"groupKey"`
    Status            string            `json:"status"`
    Receiver          string            `json:"receiver"`
    GroupLabels       map[string]string `json:"groupLabels"`
    CommonLabels      map[string]string `json:"commonLabels"`
    CommonAnnotations map[string]string `json:"commonAnnotations"`
    ExternalURL       string            `json:"externalURL"`
    Alerts            []Alert           `json:"alerts"`
}

func webhookHandler(w http.ResponseWriter, r *http.Request) {
    body, _ := ioutil.ReadAll(r.Body)
    var msg WebhookMessage
    json.Unmarshal(body, &msg)

    fmt.Printf("Received %d alerts\n", len(msg.Alerts))
    for _, alert := range msg.Alerts {
        fmt.Printf("Alert: %s, Severity: %s, Status: %s\n",
            alert.Labels["alertname"],
            alert.Labels["severity"],
            alert.Status,
        )
    }

    w.WriteHeader(http.StatusOK)
}

func main() {
    http.HandleFunc("/alerts", webhookHandler)
    http.ListenAndServe(":8080", nil)
}
```

---

### 9.4.4 å‘Šè­¦æ¨¡æ¿å®šåˆ¶

AlertManageræ”¯æŒä½¿ç”¨Goæ¨¡æ¿è¯­è¨€è‡ªå®šä¹‰å‘Šè­¦æ¶ˆæ¯æ ¼å¼ã€‚

#### æ¨¡æ¿åŸºç¡€è¯­æ³•

```yaml
# templates/default.tmpl
{{ define "slack.default.title" }}
[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }}
{{ end }}

{{ define "slack.default.text" }}
{{ range .Alerts }}
*Alert:* {{ .Labels.alertname }} - {{ .Labels.severity }}
*Summary:* {{ .Annotations.summary }}
*Description:* {{ .Annotations.description }}
{{ if .Labels.instance }}*Instance:* {{ .Labels.instance }}{{ end }}
{{ if .Labels.namespace }}*Namespace:* {{ .Labels.namespace }}{{ end }}
*Started:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
{{ if .EndsAt }}*Ended:* {{ .EndsAt.Format "2006-01-02 15:04:05" }}{{ end }}
{{ end }}
{{ end }}

{{ define "email.default.html" }}
<!DOCTYPE html>
<html>
<head>
<style>
  body { font-family: Arial, sans-serif; }
  .alert { border: 1px solid #ddd; margin: 10px; padding: 10px; }
  .firing { background-color: #ffebee; }
  .resolved { background-color: #e8f5e9; }
  .critical { border-left: 5px solid #f44336; }
  .warning { border-left: 5px solid #ff9800; }
</style>
</head>
<body>
<h2>AlertManager Notification</h2>
<p><b>Status:</b> {{ .Status | toUpper }}</p>
<p><b>Group:</b> {{ .GroupLabels.SortedPairs.Values | join ", " }}</p>

{{ range .Alerts }}
<div class="alert {{ .Status }} {{ .Labels.severity }}">
  <h3>{{ .Labels.alertname }}</h3>
  <p><b>Severity:</b> <span style="color: {{ if eq .Labels.severity "critical" }}red{{ else if eq .Labels.severity "warning" }}orange{{ else }}blue{{ end }}">{{ .Labels.severity }}</span></p>
  <p><b>Summary:</b> {{ .Annotations.summary }}</p>
  <p><b>Description:</b> {{ .Annotations.description }}</p>
  {{ if .Labels.instance }}<p><b>Instance:</b> {{ .Labels.instance }}</p>{{ end }}
  {{ if .Labels.namespace }}<p><b>Namespace:</b> {{ .Labels.namespace }}</p>{{ end }}
  <p><b>Started At:</b> {{ .StartsAt.Format "2006-01-02 15:04:05 MST" }}</p>
  {{ if .EndsAt }}<p><b>Resolved At:</b> {{ .EndsAt.Format "2006-01-02 15:04:05 MST" }}</p>{{ end }}
  <p><a href="{{ .GeneratorURL }}">View in Prometheus</a></p>
</div>
{{ end }}

</body>
</html>
{{ end }}
```

#### æ¨¡æ¿å˜é‡

```yaml
# å¯ç”¨å˜é‡
{{ .Status }}                 # "firing" æˆ– "resolved"
{{ .GroupLabels }}            # åˆ†ç»„æ ‡ç­¾
{{ .CommonLabels }}           # æ‰€æœ‰å‘Šè­¦çš„å…¬å…±æ ‡ç­¾
{{ .CommonAnnotations }}      # æ‰€æœ‰å‘Šè­¦çš„å…¬å…±æ³¨é‡Š
{{ .ExternalURL }}            # AlertManagerå¤–éƒ¨URL
{{ .Receiver }}               # æ¥æ”¶å™¨åç§°

# å‘Šè­¦åˆ—è¡¨
{{ .Alerts }}                 # æ‰€æœ‰å‘Šè­¦
{{ .Alerts.Firing }}          # è§¦å‘ä¸­çš„å‘Šè­¦
{{ .Alerts.Resolved }}        # å·²æ¢å¤çš„å‘Šè­¦

# å•ä¸ªå‘Šè­¦
{{ .Labels.alertname }}       # å‘Šè­¦åç§°
{{ .Labels.severity }}        # ä¸¥é‡çº§åˆ«
{{ .Annotations.summary }}    # æ‘˜è¦
{{ .Annotations.description }}# æè¿°
{{ .StartsAt }}               # å¼€å§‹æ—¶é—´
{{ .EndsAt }}                 # ç»“æŸæ—¶é—´
{{ .GeneratorURL }}           # PrometheusæŸ¥è¯¢é“¾æ¥
```

#### æ¨¡æ¿å‡½æ•°

```yaml
# å­—ç¬¦ä¸²å‡½æ•°
{{ .Status | toUpper }}       # è½¬å¤§å†™ â†’ "FIRING"
{{ .Status | toLower }}       # è½¬å°å†™ â†’ "firing"
{{ .Status | title }}         # é¦–å­—æ¯å¤§å†™ â†’ "Firing"

# æ—¶é—´æ ¼å¼åŒ–
{{ .StartsAt.Format "2006-01-02 15:04:05" }}

# åˆ—è¡¨å‡½æ•°
{{ .Alerts | len }}           # å‘Šè­¦æ•°é‡
{{ .Alerts.Firing | len }}    # è§¦å‘ä¸­çš„æ•°é‡

# æ¡ä»¶åˆ¤æ–­
{{ if eq .Status "firing" }}
  å‘Šè­¦è§¦å‘
{{ else }}
  å‘Šè­¦æ¢å¤
{{ end }}

# å¾ªç¯
{{ range .Alerts }}
  {{ .Labels.alertname }}
{{ end }}

# é”®å€¼å¯¹æ’åº
{{ .GroupLabels.SortedPairs.Values | join ", " }}
```

#### ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿

```yaml
# alertmanager.yml
global:
  ...

templates:
- '/etc/alertmanager/templates/*.tmpl'

receivers:
- name: 'slack-custom'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/XXX'
    channel: '#alerts'
    title: '{{ template "slack.default.title" . }}'
    text: '{{ template "slack.default.text" . }}'

- name: 'email-custom'
  email_configs:
  - to: 'ops@example.com'
    html: '{{ template "email.default.html" . }}'
```

**æŒ‚è½½æ¨¡æ¿åˆ°AlertManager Pod**ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-templates
  namespace: monitoring
data:
  default.tmpl: |
    {{ define "slack.default.title" }}
    ...
    {{ end }}
---
# åœ¨StatefulSetä¸­æŒ‚è½½
spec:
  template:
    spec:
      containers:
      - name: alertmanager
        volumeMounts:
        - name: templates
          mountPath: /etc/alertmanager/templates
      volumes:
      - name: templates
        configMap:
          name: alertmanager-templates
```

---

**ğŸ“Š 9.4èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Prometheuså‘Šè­¦è§„åˆ™å’ŒAlertManagerå‘Šè­¦ç®¡ç†ï¼š

âœ… **å‘Šè­¦è§„åˆ™ç¼–å†™**ï¼š
- å‘Šè­¦è§„åˆ™åŸºç¡€ç»“æ„ (alert/expr/for/labels/annotations)
- èµ„æºç›‘æ§å‘Šè­¦ (CPU/å†…å­˜/ç£ç›˜/èŠ‚ç‚¹)
- Kubernetesé›†ç¾¤å‘Šè­¦ (Pod/Deployment/PVC)
- åº”ç”¨æ€§èƒ½å‘Šè­¦ (REDæ–¹æ³•:é”™è¯¯ç‡/å»¶è¿Ÿ/QPS)
- å‘Šè­¦ä¸¥é‡çº§åˆ«å®šä¹‰

âœ… **AlertManageræ¶æ„**ï¼š
- 6æ­¥å¤„ç†æµç¨‹ (å»é‡/åˆ†ç»„/æŠ‘åˆ¶/é™é»˜/è·¯ç”±/é€šçŸ¥)
- éƒ¨ç½²æ–¹æ³• (Helm/æ‰‹åŠ¨/é«˜å¯ç”¨3å‰¯æœ¬)
- å‘Šè­¦è·¯ç”±æ ‘é…ç½®
- æ—¶é—´å‚æ•°è°ƒä¼˜

âœ… **æŠ‘åˆ¶ä¸é™é»˜**ï¼š
- æŠ‘åˆ¶è§„åˆ™ (é¿å…å‘Šè­¦é£æš´)
- é™é»˜è§„åˆ™ (ç»´æŠ¤çª—å£æœŸ)
- API/CLIæ“ä½œ

âœ… **å¤šæ¸ é“é€šçŸ¥**ï¼š
- Emailé€šçŸ¥ (HTMLæ¨¡æ¿)
- Slacké€šçŸ¥ (å½©è‰²æ¶ˆæ¯)
- é’‰é’‰é€šçŸ¥ (Webhooké€‚é…å™¨)
- ä¼ä¸šå¾®ä¿¡é€šçŸ¥
- PagerDutyé›†æˆ (On-CallæœåŠ¡)
- Webhooké€šç”¨é›†æˆ

âœ… **å‘Šè­¦æ¨¡æ¿**ï¼š
- Goæ¨¡æ¿è¯­æ³•
- æ¨¡æ¿å˜é‡ä¸å‡½æ•°
- è‡ªå®šä¹‰Slack/Emailæ¨¡æ¿

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ æ—¥å¿—ç®¡ç†ä¸EFKæ ˆï¼ŒåŒ…æ‹¬æ—¥å¿—æ”¶é›†æ¶æ„è®¾è®¡ã€Fluentd/Fluent Bitéƒ¨ç½²ã€Elasticsearché›†ç¾¤æ­å»ºã€Kibanaæ—¥å¿—æŸ¥è¯¢ä¸åˆ†æï¼Œä»¥åŠLokiè½»é‡çº§æ—¥å¿—æ–¹æ¡ˆã€‚

---

## 9.5 æ—¥å¿—ç®¡ç†ä¸EFKæ ˆ

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†Metricsç›‘æ§å’Œå‘Šè­¦ã€‚ä½†å½“å‘Šè­¦è§¦å‘æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æŸ¥çœ‹è¯¦ç»†çš„æ—¥å¿—æ¥å®šä½é—®é¢˜æ ¹å› ã€‚æ—¥å¿—æ˜¯å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±ä¹‹ä¸€ï¼Œå®ƒæä¾›äº†ç³»ç»Ÿè¡Œä¸ºçš„å®Œæ•´ä¸Šä¸‹æ–‡ã€‚

**ä¸ºä»€ä¹ˆéœ€è¦é›†ä¸­å¼æ—¥å¿—ç®¡ç†ï¼Ÿ**

åœ¨Kubernetesç¯å¢ƒä¸­ï¼Œæ—¥å¿—ç®¡ç†é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

| æŒ‘æˆ˜ | ä¼ ç»Ÿæ–¹å¼ | é›†ä¸­å¼æ—¥å¿— |
|------|---------|-----------|
| **Podé‡å¯** | æ—¥å¿—ä¸¢å¤± | æŒä¹…åŒ–å­˜å‚¨ |
| **å¤šå‰¯æœ¬** | éœ€è¦é€ä¸ªPodæŸ¥çœ‹ | ç»Ÿä¸€æŸ¥è¯¢ |
| **åˆ†å¸ƒå¼** | æ—¥å¿—åˆ†æ•£åœ¨å¤šä¸ªèŠ‚ç‚¹ | é›†ä¸­æ”¶é›† |
| **æœç´¢** | grepé€Ÿåº¦æ…¢ | å…¨æ–‡ç´¢å¼•ï¼Œç§’çº§æœç´¢ |
| **å…³è”** | éš¾ä»¥å…³è”å¤šä¸ªæœåŠ¡æ—¥å¿— | TraceIDå…³è” |
| **ä¿ç•™** | ç£ç›˜ç©ºé—´æœ‰é™ | å¯é…ç½®ä¿ç•™ç­–ç•¥ |

**EFK vs Lokiå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | EFK (Elasticsearch + Fluentd + Kibana) | Loki + Promtail + Grafana |
|------|----------------------------------------|---------------------------|
| **ç´¢å¼•æ–¹å¼** | å…¨æ–‡ç´¢å¼• (æ¯ä¸ªå­—æ®µ) | ä»…ç´¢å¼•æ ‡ç­¾ |
| **å­˜å‚¨æˆæœ¬** | é«˜ (10-50xåŸå§‹æ—¥å¿—) | ä½ (1-2xåŸå§‹æ—¥å¿—) |
| **æŸ¥è¯¢é€Ÿåº¦** | å¿« (å…¨æ–‡æœç´¢) | ä¸­ç­‰ (æ ‡ç­¾è¿‡æ»¤åæ‰«æ) |
| **èµ„æºå ç”¨** | é«˜ (ESé›†ç¾¤éœ€è¦å¤§é‡å†…å­˜) | ä½ (å•æœºå¯è¿è¡Œ) |
| **å­¦ä¹ æ›²çº¿** | é™¡å³­ (ESå¤æ‚) | å¹³ç¼“ (ç±»ä¼¼PromQL) |
| **é€‚ç”¨åœºæ™¯** | å¤§è§„æ¨¡/å¤æ‚æŸ¥è¯¢/åˆè§„å®¡è®¡ | ä¸­å°è§„æ¨¡/æˆæœ¬æ•æ„Ÿ |

### 9.5.1 æ—¥å¿—æ”¶é›†æ¶æ„è®¾è®¡

#### å®¹å™¨æ—¥å¿—ç”Ÿå‘½å‘¨æœŸ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å®¹å™¨æ—¥å¿—æµè½¬è·¯å¾„                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. åº”ç”¨è¾“å‡ºæ—¥å¿—
   â†“
   stdout/stderr
   â†“
2. å®¹å™¨è¿è¡Œæ—¶æ•è·
   â†“
   /var/log/pods/<namespace>_<pod>_<uid>/<container>/0.log
   â†“
   JSONæ ¼å¼: {"log":"...", "stream":"stdout", "time":"..."}
   â†“
3. kubeletæ—¥å¿—è½®è½¬
   â†“
   å•æ–‡ä»¶ä¸Šé™: 10MB (é»˜è®¤)
   ä¿ç•™æ–‡ä»¶æ•°: 5 (é»˜è®¤)
   â†“
4. æ—¥å¿—æ”¶é›†å™¨ (DaemonSet)
   â†“
   Fluentd/Fluent Bit/Filebeat
   â†“
5. æ—¥å¿—å­˜å‚¨
   â†“
   Elasticsearch / Loki / S3
   â†“
6. æ—¥å¿—æŸ¥è¯¢
   â†“
   Kibana / Grafana
```

#### æ—¥å¿—æ”¶é›†æ¶æ„æ¨¡å¼

**æ¨¡å¼1: Sidecaræ¨¡å¼ (ä¸æ¨è)**

```yaml
# æ¯ä¸ªPodéƒ½æœ‰ä¸€ä¸ªæ—¥å¿—æ”¶é›†Sidecar
apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  containers:
  - name: app
    image: my-app:v1.0
    volumeMounts:
    - name: logs
      mountPath: /var/log
  
  - name: log-collector  # Sidecarå®¹å™¨
    image: fluent/fluent-bit:2.0
    volumeMounts:
    - name: logs
      mountPath: /var/log
    - name: config
      mountPath: /fluent-bit/etc
  
  volumes:
  - name: logs
    emptyDir: {}
  - name: config
    configMap:
      name: fluent-bit-config
```

**ç¼ºç‚¹**ï¼š
- âŒ æ¯ä¸ªPodé¢å¤–æ¶ˆè€—èµ„æº (CPU/å†…å­˜)
- âŒ é…ç½®å¤æ‚ï¼Œéš¾ä»¥ç»Ÿä¸€ç®¡ç†
- âŒ æ‰©å±•æ€§å·® (1000ä¸ªPod = 1000ä¸ªSidecar)

**æ¨¡å¼2: DaemonSetæ¨¡å¼ (æ¨è)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Node 1                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Pod A   â”‚  â”‚  Pod B   â”‚  â”‚  Pod C   â”‚                  â”‚
â”‚  â”‚ (stdout) â”‚  â”‚ (stdout) â”‚  â”‚ (stdout) â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚       â”‚             â”‚             â”‚                         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                     â†“                                        â”‚
â”‚       /var/log/pods/<namespace>_<pod>_<uid>/<container>/    â”‚
â”‚                     â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Fluentd/Fluent Bit DaemonSet                â”‚           â”‚
â”‚  â”‚  - è¯»å–æ‰€æœ‰Podæ—¥å¿—                             â”‚           â”‚
â”‚  â”‚  - æ·»åŠ Kuberneteså…ƒæ•°æ®                       â”‚           â”‚
â”‚  â”‚  - è¿‡æ»¤/è½¬æ¢/è·¯ç”±                              â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Elasticsearch / Loki  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¼˜ç‚¹**ï¼š
- âœ… æ¯ä¸ªèŠ‚ç‚¹åªè¿è¡Œä¸€ä¸ªæ—¥å¿—æ”¶é›†å™¨
- âœ… ç»Ÿä¸€é…ç½®ç®¡ç†
- âœ… èµ„æºå ç”¨ä½
- âœ… æ˜“äºæ‰©å±•

**æ¨¡å¼3: Logging Operatoræ¨¡å¼ (ä¼ä¸šçº§)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Logging Operator (Banzai Cloud)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  CRD: Logging / Flow / Output                      â”‚     â”‚
â”‚  â”‚  - å£°æ˜å¼é…ç½®                                        â”‚     â”‚
â”‚  â”‚  - è‡ªåŠ¨ç”ŸæˆFluentd/Fluent Bité…ç½®                   â”‚     â”‚
â”‚  â”‚  - å¤šç§Ÿæˆ·éš”ç¦»                                        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ç¤ºä¾‹CRDï¼š

```yaml
apiVersion: logging.banzaicloud.io/v1beta1
kind: Logging
metadata:
  name: default-logging
spec:
  fluentd:
    replicas: 2
  fluentbit:
    image:
      tag: 2.0.0
---
apiVersion: logging.banzaicloud.io/v1beta1
kind: Flow
metadata:
  name: app-logs
  namespace: production
spec:
  match:
  - select:
      labels:
        app: my-app
  filters:
  - parser:
      parse:
        type: json
  localOutputRefs:
  - elasticsearch-output
---
apiVersion: logging.banzaicloud.io/v1beta1
kind: Output
metadata:
  name: elasticsearch-output
  namespace: production
spec:
  elasticsearch:
    host: elasticsearch.logging.svc.cluster.local
    port: 9200
    index_name: app-logs
```

#### æ—¥å¿—æ ¼å¼æ ‡å‡†åŒ–

**ç»“æ„åŒ–æ—¥å¿— vs éç»“æ„åŒ–æ—¥å¿—**ï¼š

```json
// âŒ éç»“æ„åŒ–æ—¥å¿— (éš¾ä»¥è§£æ)
"2024-01-20 10:30:15 INFO User john@example.com logged in from 192.168.1.100"

// âœ… ç»“æ„åŒ–æ—¥å¿— (JSONæ ¼å¼)
{
  "timestamp": "2024-01-20T10:30:15Z",
  "level": "INFO",
  "message": "User logged in",
  "user": {
    "email": "john@example.com",
    "id": "12345"
  },
  "source_ip": "192.168.1.100",
  "trace_id": "a1b2c3d4e5f6",  // å…³è”åˆ†å¸ƒå¼è¿½è¸ª
  "span_id": "7890abcd",
  "service": "auth-service",
  "namespace": "production",
  "pod": "auth-service-abc123"
}
```

**åº”ç”¨æ—¥å¿—æœ€ä½³å®è·µ**ï¼š

```go
// Goåº”ç”¨ç¤ºä¾‹ (ä½¿ç”¨zap)
package main

import (
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
)

func main() {
    // ç”Ÿäº§ç¯å¢ƒé…ç½®
    config := zap.NewProductionConfig()
    config.EncoderConfig.TimeKey = "timestamp"
    config.EncoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
    
    logger, _ := config.Build()
    defer logger.Sync()
    
    // ç»“æ„åŒ–æ—¥å¿—
    logger.Info("User logged in",
        zap.String("user_email", "john@example.com"),
        zap.String("user_id", "12345"),
        zap.String("source_ip", "192.168.1.100"),
        zap.String("trace_id", "a1b2c3d4e5f6"),
    )
    
    // è¾“å‡º:
    // {"level":"info","timestamp":"2024-01-20T10:30:15.123Z","msg":"User logged in","user_email":"john@example.com","user_id":"12345","source_ip":"192.168.1.100","trace_id":"a1b2c3d4e5f6"}
}
```

```python
# Pythonåº”ç”¨ç¤ºä¾‹ (ä½¿ç”¨structlog)
import structlog

structlog.configure(
    processors=[
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()

logger.info(
    "user_logged_in",
    user_email="john@example.com",
    user_id="12345",
    source_ip="192.168.1.100",
    trace_id="a1b2c3d4e5f6"
)
```

---

### 9.5.2 Fluentdéƒ¨ç½²ä¸é…ç½®

#### Fluentdæ¶æ„

Fluentdæ˜¯CNCFæ¯•ä¸šé¡¹ç›®ï¼Œé‡‡ç”¨æ’ä»¶åŒ–æ¶æ„ï¼Œæ”¯æŒ500+æ’ä»¶ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Fluentdæ¶æ„                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input Plugins (è¾“å…¥)
  â†“
  tail (æ–‡ä»¶)
  forward (ç½‘ç»œ)
  http (HTTP API)
  â†“
Filter Plugins (è¿‡æ»¤/è½¬æ¢)
  â†“
  parser (è§£æJSON/æ­£åˆ™)
  record_transformer (æ·»åŠ /ä¿®æ”¹å­—æ®µ)
  grep (è¿‡æ»¤)
  â†“
Output Plugins (è¾“å‡º)
  â†“
  elasticsearch
  kafka
  s3
  forward
```

#### éƒ¨ç½²Fluentd DaemonSet

```yaml
# fluentd-daemonset.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups: [""]
  resources:
  - namespaces
  - pods
  - pods/logs
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluentd
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: logging
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |
    # è¾“å…¥: å®¹å™¨æ—¥å¿—
    <source>
      @type tail
      @id in_tail_container_logs
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>
    
    # è¿‡æ»¤: æ·»åŠ Kuberneteså…ƒæ•°æ®
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url "#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
      verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
    </filter>
    
    # è¿‡æ»¤: è§£æJSONæ—¥å¿—
    <filter kubernetes.**>
      @type parser
      key_name log
      reserve_data true
      remove_key_name_field true
      <parse>
        @type json
      </parse>
    </filter>
    
    # è¿‡æ»¤: æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´çš„DEBUGæ—¥å¿—
    <filter kubernetes.**>
      @type grep
      <exclude>
        key $.kubernetes.namespace_name
        pattern /^(kube-system|kube-public|kube-node-lease)$/
      </exclude>
    </filter>
    
    # è¿‡æ»¤: æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
    <filter kubernetes.**>
      @type record_transformer
      enable_ruby true
      <record>
        cluster_name "#{ENV['CLUSTER_NAME'] || 'production'}"
        log_type "container"
        timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%LZ')}
      </record>
    </filter>
    
    # è¾“å‡º: Elasticsearch
    <match kubernetes.**>
      @type elasticsearch
      @id out_es
      @log_level info
      include_tag_key true
      host "#{ENV['FLUENT_ELASTICSEARCH_HOST'] || 'elasticsearch.logging.svc.cluster.local'}"
      port "#{ENV['FLUENT_ELASTICSEARCH_PORT'] || '9200'}"
      scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
      ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'false'}"
      
      # ç´¢å¼•é…ç½®
      logstash_format true
      logstash_prefix kubernetes
      logstash_dateformat %Y.%m.%d
      
      # æ€§èƒ½ä¼˜åŒ–
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.buffer
        flush_mode interval
        flush_interval 5s
        flush_at_shutdown true
        retry_type exponential_backoff
        retry_wait 10s
        retry_max_interval 300s
        retry_timeout 1h
        chunk_limit_size 2M
        queue_limit_length 32
        overflow_action block
      </buffer>
    </match>
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_SCHEME
          value: "http"
        - name: FLUENT_UID
          value: "0"
        - name: CLUSTER_NAME
          value: "production"
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 1000m
            memory: 512Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluentd-config
```

#### Fluent Bit (è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆ)

Fluent Bitæ˜¯Fluentdçš„è½»é‡çº§ç‰ˆæœ¬ï¼Œå†…å­˜å ç”¨ä»…ä¸ºFluentdçš„1/10ã€‚

**Fluentd vs Fluent Bitå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | Fluentd | Fluent Bit |
|------|---------|-----------|
| **å†…å­˜å ç”¨** | 40-60MB | 450KB |
| **æ’ä»¶æ•°é‡** | 500+ | 70+ |
| **è¯­è¨€** | Ruby + C | C |
| **é€‚ç”¨åœºæ™¯** | å¤æ‚è½¬æ¢/èšåˆ | è¾¹ç¼˜é‡‡é›†/è½¬å‘ |
| **æ¨èæ¶æ„** | ä¸­å¿ƒèšåˆå™¨ | è¾¹ç¼˜é‡‡é›†å™¨ |

**Fluent Bitéƒ¨ç½²**ï¼š

```yaml
# fluent-bit-daemonset.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         5
        Daemon        off
        Log_Level     info
        Parsers_File  parsers.conf
    
    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5
        Mem_Buf_Limit     5MB
        Skip_Long_Lines   On
    
    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix     kube.var.log.containers.
        Merge_Log           On
        Keep_Log            Off
        K8S-Logging.Parser  On
        K8S-Logging.Exclude On
    
    [OUTPUT]
        Name            es
        Match           *
        Host            elasticsearch.logging.svc.cluster.local
        Port            9200
        Logstash_Format On
        Logstash_Prefix kubernetes
        Retry_Limit     5
  
  parsers.conf: |
    [PARSER]
        Name   docker
        Format json
        Time_Key time
        Time_Format %Y-%m-%dT%H:%M:%S.%LZ
        Time_Keep On
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      app: fluent-bit
  template:
    metadata:
      labels:
        app: fluent-bit
    spec:
      serviceAccountName: fluentd  # å¤ç”¨Fluentdçš„ServiceAccount
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:2.0
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluent-bit/etc/
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 128Mi
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluent-bit-config
```

#### Fluentdé«˜çº§é…ç½®

**1. å¤šè¾“å‡ºè·¯ç”±**

```ruby
# æ ¹æ®å‘½åç©ºé—´è·¯ç”±åˆ°ä¸åŒçš„Elasticsearchç´¢å¼•
<match kubernetes.var.log.containers.**production**>
  @type elasticsearch
  host elasticsearch-prod.logging.svc.cluster.local
  port 9200
  logstash_prefix kubernetes-prod
</match>

<match kubernetes.var.log.containers.**staging**>
  @type elasticsearch
  host elasticsearch-staging.logging.svc.cluster.local
  port 9200
  logstash_prefix kubernetes-staging
</match>

# å…¶ä»–å‘½åç©ºé—´
<match kubernetes.**>
  @type elasticsearch
  host elasticsearch.logging.svc.cluster.local
  port 9200
  logstash_prefix kubernetes
</match>
```

**2. æ—¥å¿—é‡‡æ · (é™ä½æˆæœ¬)**

```ruby
# åªä¿ç•™10%çš„DEBUGæ—¥å¿—
<filter kubernetes.**>
  @type sampling
  interval 10
  sample_rate 1
  <filter>
    key level
    pattern DEBUG
  </filter>
</filter>
```

**3. æ•æ„Ÿä¿¡æ¯è„±æ•**

```ruby
<filter kubernetes.**>
  @type record_modifier
  <record>
    # è„±æ•ä¿¡ç”¨å¡å·
    message ${record["message"].gsub(/\d{4}-\d{4}-\d{4}-\d{4}/, "****-****-****-****")}
    # è„±æ•é‚®ç®±
    message ${record["message"].gsub(/[\w\.-]+@[\w\.-]+\.\w+/, "***@***.***")}
  </record>
</filter>
```

**4. æ—¥å¿—èšåˆ (å‡å°‘å†™å…¥)**

```ruby
<match kubernetes.**>
  @type elasticsearch
  <buffer>
    @type file
    path /var/log/fluentd-buffers/kubernetes.buffer
    flush_mode interval
    flush_interval 30s      # 30ç§’èšåˆä¸€æ¬¡
    chunk_limit_size 5M     # æ¯ä¸ªchunkæœ€å¤§5MB
    total_limit_size 1GB    # æ€»bufferå¤§å°1GB
  </buffer>
</match>
```

---

### 9.5.3 Elasticsearché›†ç¾¤æ­å»º

#### Elasticsearchæ¶æ„

Elasticsearchæ˜¯åˆ†å¸ƒå¼æœç´¢å’Œåˆ†æå¼•æ“ï¼Œé‡‡ç”¨ä¸»ä»æ¶æ„ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Elasticsearché›†ç¾¤æ¶æ„                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MasterèŠ‚ç‚¹ (ç®¡ç†é›†ç¾¤çŠ¶æ€)
  â”œâ”€â”€ åˆ›å»º/åˆ é™¤ç´¢å¼•
  â”œâ”€â”€ ç®¡ç†èŠ‚ç‚¹åŠ å…¥/ç¦»å¼€
  â””â”€â”€ åˆ†é…åˆ†ç‰‡

DataèŠ‚ç‚¹ (å­˜å‚¨æ•°æ®)
  â”œâ”€â”€ å­˜å‚¨æ–‡æ¡£
  â”œâ”€â”€ æ‰§è¡ŒæŸ¥è¯¢
  â””â”€â”€ èšåˆè®¡ç®—

CoordinatingèŠ‚ç‚¹ (åè°ƒæŸ¥è¯¢)
  â”œâ”€â”€ æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚
  â”œâ”€â”€ åˆ†å‘åˆ°DataèŠ‚ç‚¹
  â””â”€â”€ èšåˆç»“æœè¿”å›

IngestèŠ‚ç‚¹ (æ•°æ®é¢„å¤„ç†)
  â””â”€â”€ æ•°æ®è½¬æ¢/å¯ŒåŒ–
```

#### éƒ¨ç½²Elasticsearché›†ç¾¤

**1. ä½¿ç”¨Helméƒ¨ç½² (æ¨è)**

```bash
# æ·»åŠ Elastic Helmä»“åº“
helm repo add elastic https://helm.elastic.co
helm repo update

# éƒ¨ç½²Elasticsearch (3èŠ‚ç‚¹é›†ç¾¤)
helm install elasticsearch elastic/elasticsearch \
  --namespace logging \
  --set replicas=3 \
  --set minimumMasterNodes=2 \
  --set resources.requests.memory=2Gi \
  --set resources.limits.memory=4Gi \
  --set volumeClaimTemplate.resources.requests.storage=100Gi \
  --set persistence.enabled=true
```

**2. æ‰‹åŠ¨éƒ¨ç½²StatefulSet**

```yaml
# elasticsearch-statefulset.yaml
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    app: elasticsearch
spec:
  clusterIP: None  # Headless Service
  ports:
  - port: 9200
    name: http
  - port: 9300
    name: transport
  selector:
    app: elasticsearch
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      initContainers:
      # è®¾ç½®vm.max_map_count (ESè¦æ±‚)
      - name: increase-vm-max-map
        image: busybox:1.35
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
      
      # è®¾ç½®æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
      - name: increase-fd-ulimit
        image: busybox:1.35
        command: ["sh", "-c", "ulimit -n 65536"]
        securityContext:
          privileged: true
      
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        env:
        # é›†ç¾¤åç§°
        - name: cluster.name
          value: "kubernetes-logs"
        
        # èŠ‚ç‚¹åç§°
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        
        # å‘ç°é…ç½®
        - name: discovery.seed_hosts
          value: "elasticsearch-0.elasticsearch,elasticsearch-1.elasticsearch,elasticsearch-2.elasticsearch"
        - name: cluster.initial_master_nodes
          value: "elasticsearch-0,elasticsearch-1,elasticsearch-2"
        
        # èŠ‚ç‚¹è§’è‰²
        - name: node.roles
          value: "master,data,ingest"
        
        # å†…å­˜é…ç½® (å †å†…å­˜ = å®¹å™¨å†…å­˜çš„50%)
        - name: ES_JAVA_OPTS
          value: "-Xms2g -Xmx2g"
        
        # å®‰å…¨é…ç½® (ç”Ÿäº§ç¯å¢ƒåº”å¯ç”¨)
        - name: xpack.security.enabled
          value: "false"
        
        # ç½‘ç»œé…ç½®
        - name: network.host
          value: "0.0.0.0"
        
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
        
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        
        livenessProbe:
          httpGet:
            path: /_cluster/health?local=true
            port: 9200
          initialDelaySeconds: 90
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /_cluster/health?local=true
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 10
  
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: gp3
      resources:
        requests:
          storage: 100Gi
---
# å¯¹å¤–è®¿é—®çš„Service
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-external
  namespace: logging
spec:
  type: ClusterIP
  ports:
  - port: 9200
    targetPort: 9200
    name: http
  selector:
    app: elasticsearch
```

#### Elasticsearchç´¢å¼•ç®¡ç†

**1. ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç† (ILM)**

```json
// åˆ›å»ºILMç­–ç•¥
PUT _ilm/policy/kubernetes-logs-policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "forcemerge": {
            "max_num_segments": 1
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "freeze": {}
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}

// åº”ç”¨ILMç­–ç•¥åˆ°ç´¢å¼•æ¨¡æ¿
PUT _index_template/kubernetes-logs-template
{
  "index_patterns": ["kubernetes-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "index.lifecycle.name": "kubernetes-logs-policy",
      "index.lifecycle.rollover_alias": "kubernetes-logs"
    }
  }
}
```

**ILMé˜¶æ®µè¯´æ˜**ï¼š

| é˜¶æ®µ | æ—¶é—´ | æ“ä½œ | ç›®çš„ |
|------|------|------|------|
| **Hot** | 0-7å¤© | å†™å…¥æ–°æ•°æ® | é«˜æ€§èƒ½å†™å…¥ |
| **Warm** | 7-30å¤© | åˆå¹¶åˆ†ç‰‡/åªè¯» | èŠ‚çœå­˜å‚¨ |
| **Cold** | 30-90å¤© | å†»ç»“ç´¢å¼• | é™ä½å†…å­˜å ç”¨ |
| **Delete** | 90å¤©å | åˆ é™¤ç´¢å¼• | é‡Šæ”¾ç©ºé—´ |

**2. ç´¢å¼•æ¨¡æ¿**

```json
// åˆ›å»ºç´¢å¼•æ¨¡æ¿
PUT _index_template/kubernetes-logs
{
  "index_patterns": ["kubernetes-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "refresh_interval": "30s",
      "index.codec": "best_compression"
    },
    "mappings": {
      "properties": {
        "@timestamp": {
          "type": "date"
        },
        "kubernetes": {
          "properties": {
            "namespace_name": {
              "type": "keyword"
            },
            "pod_name": {
              "type": "keyword"
            },
            "container_name": {
              "type": "keyword"
            },
            "labels": {
              "type": "object"
            }
          }
        },
        "log": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "level": {
          "type": "keyword"
        },
        "message": {
          "type": "text"
        }
      }
    }
  }
}
```

**3. ç´¢å¼•ç»´æŠ¤**

```bash
# æŸ¥çœ‹æ‰€æœ‰ç´¢å¼•
curl -X GET "http://elasticsearch:9200/_cat/indices?v"

# æŸ¥çœ‹ç´¢å¼•å¤§å°
curl -X GET "http://elasticsearch:9200/_cat/indices?v&s=store.size:desc"

# åˆ é™¤æ—§ç´¢å¼• (90å¤©å‰)
curl -X DELETE "http://elasticsearch:9200/kubernetes-2023.10.*"

# å¼ºåˆ¶åˆå¹¶ç´¢å¼• (å‡å°‘æ®µæ•°)
curl -X POST "http://elasticsearch:9200/kubernetes-2024.01.01/_forcemerge?max_num_segments=1"

# å…³é—­ç´¢å¼• (é‡Šæ”¾å†…å­˜)
curl -X POST "http://elasticsearch:9200/kubernetes-2023.12.*/_close"
```

#### Elasticsearchæ€§èƒ½ä¼˜åŒ–

**1. ç¡¬ä»¶é…ç½®å»ºè®®**

```yaml
# ç”Ÿäº§ç¯å¢ƒé…ç½®
CPU: 8æ ¸èµ·æ­¥ (16æ ¸æ¨è)
å†…å­˜: 32GBèµ·æ­¥ (64GBæ¨è)
  - JVMå †å†…å­˜: ç‰©ç†å†…å­˜çš„50% (æœ€å¤§31GB)
  - å‰©ä½™50%ç”¨äºæ–‡ä»¶ç³»ç»Ÿç¼“å­˜
ç£ç›˜: SSD (NVMeæœ€ä½³)
  - IOPS: 10000+ (æ—¥å¿—å†™å…¥å¯†é›†)
ç½‘ç»œ: 10Gbps (é›†ç¾¤é—´é€šä¿¡)
```

**2. JVMè°ƒä¼˜**

```yaml
# elasticsearch.yml
ES_JAVA_OPTS: "-Xms16g -Xmx16g"  # å †å†…å­˜å›ºå®š16GB

# JVMå‚æ•°
-XX:+UseG1GC                      # ä½¿ç”¨G1åƒåœ¾å›æ”¶å™¨
-XX:MaxGCPauseMillis=200          # æœ€å¤§GCæš‚åœæ—¶é—´
-XX:+HeapDumpOnOutOfMemoryError   # OOMæ—¶ç”Ÿæˆå †è½¬å‚¨
-XX:HeapDumpPath=/var/log/elasticsearch
```

**3. ç´¢å¼•ä¼˜åŒ–**

```json
// æ‰¹é‡å†™å…¥ä¼˜åŒ–
PUT kubernetes-2024.01.20/_settings
{
  "index": {
    "refresh_interval": "30s",      // é™ä½åˆ·æ–°é¢‘ç‡ (é»˜è®¤1s)
    "number_of_replicas": 0,        // å†™å…¥æ—¶ç¦ç”¨å‰¯æœ¬
    "translog.durability": "async", // å¼‚æ­¥translog
    "translog.sync_interval": "30s"
  }
}

// å†™å…¥å®Œæˆåæ¢å¤
PUT kubernetes-2024.01.20/_settings
{
  "index": {
    "refresh_interval": "1s",
    "number_of_replicas": 1,
    "translog.durability": "request"
  }
}
```

**4. æŸ¥è¯¢ä¼˜åŒ–**

```json
// ä½¿ç”¨è¿‡æ»¤å™¨ (å¯ç¼“å­˜)
GET kubernetes-*/_search
{
  "query": {
    "bool": {
      "filter": [
        {"term": {"kubernetes.namespace_name": "production"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  }
}

// é™åˆ¶è¿”å›å­—æ®µ
GET kubernetes-*/_search
{
  "_source": ["@timestamp", "log", "kubernetes.pod_name"],
  "query": {...}
}

// ä½¿ç”¨åˆ†é¡µ (é¿å…æ·±åº¦åˆ†é¡µ)
GET kubernetes-*/_search
{
  "size": 100,
  "from": 0,  // ä¸è¦è¶…è¿‡10000
  "query": {...}
}
```

---

### 9.5.4 Kibanaæ—¥å¿—æŸ¥è¯¢ä¸åˆ†æ

#### éƒ¨ç½²Kibana

```yaml
# kibana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.11.0
        ports:
        - containerPort: 5601
          name: http
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch:9200"
        - name: SERVER_NAME
          value: "kibana"
        - name: SERVER_HOST
          value: "0.0.0.0"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 60
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: logging
spec:
  type: ClusterIP
  ports:
  - port: 5601
    targetPort: 5601
  selector:
    app: kibana
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kibana
  namespace: logging
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  rules:
  - host: kibana.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: kibana
            port:
              number: 5601
  tls:
  - hosts:
    - kibana.example.com
    secretName: kibana-tls
```

#### KibanaæŸ¥è¯¢è¯­æ³• (KQL)

**1. åŸºç¡€æŸ¥è¯¢**

```
# ç²¾ç¡®åŒ¹é…
kubernetes.namespace_name: "production"

# é€šé…ç¬¦
kubernetes.pod_name: nginx-*

# çŸ­è¯­åŒ¹é…
log: "user logged in"

# æ­£åˆ™è¡¨è¾¾å¼
log: /error|exception|fail/

# èŒƒå›´æŸ¥è¯¢
response_time: [200 TO 500]
@timestamp: [now-1h TO now]

# å­˜åœ¨æ€§æŸ¥è¯¢
_exists_: trace_id
NOT _exists_: error
```

**2. å¸ƒå°”æŸ¥è¯¢**

```
# AND
kubernetes.namespace_name: "production" AND level: "ERROR"

# OR
level: "ERROR" OR level: "FATAL"

# NOT
kubernetes.namespace_name: "production" NOT level: "DEBUG"

# ç»„åˆ
(level: "ERROR" OR level: "WARN") AND kubernetes.namespace_name: "production"
```

**3. å­—æ®µæŸ¥è¯¢**

```
# æ•°å€¼æ¯”è¾ƒ
response_time > 1000
status_code >= 500

# å­—ç¬¦ä¸²åŒ¹é…
user.email: john@example.com
kubernetes.labels.app: "nginx"

# åµŒå¥—å­—æ®µ
kubernetes.labels.app: "nginx" AND kubernetes.labels.version: "1.0"
```

#### Kibanaå®ç”¨åŠŸèƒ½

**1. åˆ›å»ºIndex Pattern**

```
1. è®¿é—® Kibana â†’ Management â†’ Stack Management â†’ Index Patterns
2. ç‚¹å‡» "Create index pattern"
3. è¾“å…¥: kubernetes-*
4. é€‰æ‹©æ—¶é—´å­—æ®µ: @timestamp
5. ç‚¹å‡» "Create index pattern"
```

**2. Discoveræ—¥å¿—æŸ¥è¯¢**

```
1. è®¿é—® Kibana â†’ Discover
2. é€‰æ‹©Index Pattern: kubernetes-*
3. è®¾ç½®æ—¶é—´èŒƒå›´: Last 1 hour
4. è¾“å…¥æŸ¥è¯¢:
   kubernetes.namespace_name: "production" AND level: "ERROR"
5. æ·»åŠ å­—æ®µåˆ°è¡¨æ ¼:
   - @timestamp
   - kubernetes.pod_name
   - level
   - message
6. ä¿å­˜æŸ¥è¯¢: "Production Errors"
```

**3. åˆ›å»ºå¯è§†åŒ–**

```yaml
# ç¤ºä¾‹1: æ—¥å¿—çº§åˆ«åˆ†å¸ƒ (é¥¼å›¾)
Visualization Type: Pie
Metrics: Count
Buckets: Split slices
  - Aggregation: Terms
  - Field: level.keyword
  - Size: 10

# ç¤ºä¾‹2: æ¯åˆ†é’Ÿæ—¥å¿—é‡ (æŠ˜çº¿å›¾)
Visualization Type: Line
Metrics: Count
Buckets: X-Axis
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: 1 minute

# ç¤ºä¾‹3: Top 10 é”™è¯¯Pod (è¡¨æ ¼)
Visualization Type: Data Table
Metrics: Count
Buckets: Split rows
  - Aggregation: Terms
  - Field: kubernetes.pod_name.keyword
  - Size: 10
  - Order: Descending
Filters: level: "ERROR"
```

**4. åˆ›å»ºDashboard**

```
1. Kibana â†’ Dashboard â†’ Create dashboard
2. æ·»åŠ å¯è§†åŒ–:
   - æ—¥å¿—çº§åˆ«åˆ†å¸ƒ (é¥¼å›¾)
   - æ¯åˆ†é’Ÿæ—¥å¿—é‡ (æŠ˜çº¿å›¾)
   - Top 10 é”™è¯¯Pod (è¡¨æ ¼)
   - å‘½åç©ºé—´æ—¥å¿—åˆ†å¸ƒ (æŸ±çŠ¶å›¾)
3. è°ƒæ•´å¸ƒå±€
4. ä¿å­˜Dashboard: "Kubernetes Logs Overview"
5. è®¾ç½®è‡ªåŠ¨åˆ·æ–°: 30ç§’
```

#### Kibanaé«˜çº§æŸ¥è¯¢

**1. èšåˆæŸ¥è¯¢**

```json
// ç»Ÿè®¡æ¯ä¸ªå‘½åç©ºé—´çš„é”™è¯¯æ•°
GET kubernetes-*/_search
{
  "size": 0,
  "query": {
    "bool": {
      "filter": [
        {"term": {"level": "ERROR"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  },
  "aggs": {
    "by_namespace": {
      "terms": {
        "field": "kubernetes.namespace_name.keyword",
        "size": 10
      }
    }
  }
}
```

**2. æ—¶é—´åºåˆ—èšåˆ**

```json
// æ¯5åˆ†é’Ÿçš„æ—¥å¿—é‡
GET kubernetes-*/_search
{
  "size": 0,
  "aggs": {
    "logs_over_time": {
      "date_histogram": {
        "field": "@timestamp",
        "fixed_interval": "5m"
      }
    }
  }
}
```

**3. å¤šçº§èšåˆ**

```json
// æ¯ä¸ªå‘½åç©ºé—´çš„æ¯ä¸ªPodçš„é”™è¯¯æ•°
GET kubernetes-*/_search
{
  "size": 0,
  "query": {
    "term": {"level": "ERROR"}
  },
  "aggs": {
    "by_namespace": {
      "terms": {
        "field": "kubernetes.namespace_name.keyword"
      },
      "aggs": {
        "by_pod": {
          "terms": {
            "field": "kubernetes.pod_name.keyword",
            "size": 5
          }
        }
      }
    }
  }
}
```

---

### 9.5.5 Lokiè½»é‡çº§æ—¥å¿—æ–¹æ¡ˆ

#### Lokiæ¶æ„

Lokiæ˜¯Grafana Labså¼€å‘çš„è½»é‡çº§æ—¥å¿—èšåˆç³»ç»Ÿï¼Œçµæ„Ÿæ¥è‡ªPrometheusã€‚

**Loki vs Elasticsearchæ ¸å¿ƒåŒºåˆ«**ï¼š

```
Elasticsearch:
  ç´¢å¼•: å…¨æ–‡ç´¢å¼• (æ¯ä¸ªå­—æ®µ)
  å­˜å‚¨: 10-50xåŸå§‹æ—¥å¿—å¤§å°
  æŸ¥è¯¢: å…¨æ–‡æœç´¢ï¼Œé€Ÿåº¦å¿«
  æˆæœ¬: é«˜ (éœ€è¦å¤§é‡å†…å­˜å’Œå­˜å‚¨)

Loki:
  ç´¢å¼•: ä»…ç´¢å¼•æ ‡ç­¾ (ç±»ä¼¼Prometheus)
  å­˜å‚¨: 1-2xåŸå§‹æ—¥å¿—å¤§å°
  æŸ¥è¯¢: æ ‡ç­¾è¿‡æ»¤ + æ—¥å¿—æ‰«æ
  æˆæœ¬: ä½ (å•æœºå¯è¿è¡Œ)
```

**Lokiæ¶æ„å›¾**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Lokiæ¶æ„                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Promtail (æ—¥å¿—é‡‡é›†å™¨)
  â†“
  è¯»å–å®¹å™¨æ—¥å¿—
  æ·»åŠ æ ‡ç­¾ (namespace/pod/container)
  â†“
Loki (æ—¥å¿—å­˜å‚¨)
  â”œâ”€â”€ Distributor (æ¥æ”¶æ—¥å¿—)
  â”œâ”€â”€ Ingester (å†™å…¥å†…å­˜/ç£ç›˜)
  â”œâ”€â”€ Querier (æŸ¥è¯¢æ—¥å¿—)
  â””â”€â”€ Compactor (å‹ç¼©åˆå¹¶)
  â†“
Object Storage (S3/GCS/MinIO)
  â†“
Grafana (æ—¥å¿—æŸ¥è¯¢)
```

#### éƒ¨ç½²Loki

**1. ä½¿ç”¨Helméƒ¨ç½² (æ¨è)**

```bash
# æ·»åŠ Grafana Helmä»“åº“
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# éƒ¨ç½²Loki Stack (Loki + Promtail + Grafana)
helm install loki grafana/loki-stack \
  --namespace logging \
  --set loki.persistence.enabled=true \
  --set loki.persistence.size=100Gi \
  --set promtail.enabled=true \
  --set grafana.enabled=true
```

**2. æ‰‹åŠ¨éƒ¨ç½²Loki**

```yaml
# loki-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: logging
data:
  loki.yaml: |
    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
    
    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
    
    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /loki/chunks
    
    compactor:
      working_directory: /loki/boltdb-shipper-compactor
      shared_store: filesystem
    
    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h  # 7å¤©
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20
    
    chunk_store_config:
      max_look_back_period: 0s
    
    table_manager:
      retention_deletes_enabled: true
      retention_period: 168h  # 7å¤©
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: logging
spec:
  serviceName: loki
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.0
        args:
        - -config.file=/etc/loki/loki.yaml
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9096
          name: grpc
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: data
          mountPath: /loki
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
      volumes:
      - name: config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: logging
spec:
  type: ClusterIP
  ports:
  - port: 3100
    targetPort: 3100
    name: http
  selector:
    app: loki
```

**3. éƒ¨ç½²Promtail (æ—¥å¿—é‡‡é›†å™¨)**

```yaml
# promtail-daemonset.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0
    
    positions:
      filename: /tmp/positions.yaml
    
    clients:
      - url: http://loki:3100/loki/api/v1/push
    
    scrape_configs:
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      
      pipeline_stages:
      - cri: {}  # è§£æCRIæ—¥å¿—æ ¼å¼
      
      relabel_configs:
      # åªæŠ“å–æœ‰æ—¥å¿—çš„Pod
      - source_labels: [__meta_kubernetes_pod_container_name]
        action: drop
        regex: ''
      
      # æ·»åŠ å‘½åç©ºé—´æ ‡ç­¾
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      
      # æ·»åŠ Podåç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      
      # æ·»åŠ å®¹å™¨åç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container
      
      # æ·»åŠ åº”ç”¨æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
      
      # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
      - source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]
        target_label: __path__
        separator: /
        replacement: /var/log/pods/*$1/*.log
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: logging
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      containers:
      - name: promtail
        image: grafana/promtail:2.9.0
        args:
        - -config.file=/etc/promtail/promtail.yaml
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: logging
```

#### LogQLæŸ¥è¯¢è¯­è¨€

LogQLæ˜¯Lokiçš„æŸ¥è¯¢è¯­è¨€ï¼Œè¯­æ³•ç±»ä¼¼PromQLã€‚

**1. æ—¥å¿—æµé€‰æ‹©å™¨**

```logql
# åŸºç¡€æŸ¥è¯¢ (æ ‡ç­¾è¿‡æ»¤)
{namespace="production"}

# å¤šæ ‡ç­¾è¿‡æ»¤
{namespace="production", app="nginx"}

# æ­£åˆ™åŒ¹é…
{namespace=~"prod.*", app!="debug"}

# ç»„åˆæŸ¥è¯¢
{namespace="production"} |= "error"  # åŒ…å«"error"
{namespace="production"} != "debug"  # ä¸åŒ…å«"debug"
{namespace="production"} |~ "error|exception"  # æ­£åˆ™åŒ¹é…
```

**2. æ—¥å¿—ç®¡é“æ“ä½œ**

```logql
# è¡Œè¿‡æ»¤
{namespace="production"} |= "error"  # åŒ…å«
{namespace="production"} != "debug"  # ä¸åŒ…å«
{namespace="production"} |~ "error|exception"  # æ­£åˆ™åŒ…å«
{namespace="production"} !~ "debug|trace"  # æ­£åˆ™ä¸åŒ…å«

# JSONè§£æ
{namespace="production"} | json | level="ERROR"

# æ­£åˆ™è§£æ
{namespace="production"} | regexp "(?P<level>\\w+) (?P<message>.*)"

# æ ‡ç­¾è¿‡æ»¤
{namespace="production"} | json | level="ERROR" | line_format "{{.message}}"
```

**3. èšåˆæŸ¥è¯¢**

```logql
# ç»Ÿè®¡æ—¥å¿—è¡Œæ•°
count_over_time({namespace="production"}[5m])

# æ¯ç§’æ—¥å¿—é€Ÿç‡
rate({namespace="production"}[5m])

# å­—èŠ‚é€Ÿç‡
bytes_rate({namespace="production"}[5m])

# æŒ‰æ ‡ç­¾èšåˆ
sum by (namespace) (rate({job="kubernetes-pods"}[5m]))

# Top K
topk(10, sum by (pod) (rate({namespace="production"}[5m])))
```

**4. å®ç”¨æŸ¥è¯¢ç¤ºä¾‹**

```logql
# æŸ¥è¯¢ç”Ÿäº§ç¯å¢ƒçš„é”™è¯¯æ—¥å¿—
{namespace="production"} |= "ERROR"

# æŸ¥è¯¢ç‰¹å®šPodçš„æ—¥å¿—
{namespace="production", pod=~"nginx-.*"}

# æŸ¥è¯¢JSONæ—¥å¿—ä¸­çš„é”™è¯¯
{namespace="production"} | json | level="ERROR"

# ç»Ÿè®¡æ¯åˆ†é’Ÿé”™è¯¯æ•°
sum(count_over_time({namespace="production"} |= "ERROR" [1m]))

# æŸ¥è¯¢æ…¢æŸ¥è¯¢ (å“åº”æ—¶é—´>1ç§’)
{namespace="production"} | json | response_time > 1000

# æŸ¥è¯¢ç‰¹å®šTraceIDçš„æ—¥å¿—
{namespace="production"} |= "trace_id=abc123"

# ç»Ÿè®¡Top 10é”™è¯¯Pod
topk(10, 
  sum by (pod) (
    count_over_time({namespace="production"} |= "ERROR" [1h])
  )
)
```

#### åœ¨Grafanaä¸­ä½¿ç”¨Loki

**1. æ·»åŠ Lokiæ•°æ®æº**

```
1. Grafana â†’ Configuration â†’ Data Sources
2. Add data source â†’ Loki
3. URL: http://loki:3100
4. Save & Test
```

**2. åˆ›å»ºæ—¥å¿—é¢æ¿**

```yaml
# Panelé…ç½®
Visualization: Logs
Data source: Loki
Query: {namespace="production"} |= "ERROR"
Options:
  - Show time: true
  - Show labels: true
  - Wrap lines: true
  - Deduplication: none
```

**3. åˆ›å»ºæ—¥å¿—Dashboard**

```yaml
# Dashboardå¸ƒå±€
Row 1: æ—¥å¿—ç»Ÿè®¡
  - Panel 1: æ¯åˆ†é’Ÿæ—¥å¿—é‡ (Graph)
    Query: sum(rate({namespace="production"}[1m]))
  
  - Panel 2: æ—¥å¿—çº§åˆ«åˆ†å¸ƒ (Pie)
    Query: sum by (level) (count_over_time({namespace="production"} | json [1h]))

Row 2: æ—¥å¿—æµ
  - Panel 3: å®æ—¶æ—¥å¿— (Logs)
    Query: {namespace="production"}
  
  - Panel 4: é”™è¯¯æ—¥å¿— (Logs)
    Query: {namespace="production"} |= "ERROR"
```

**4. æ—¥å¿—ä¸Metricså…³è”**

```yaml
# åœ¨Grafanaä¸­å…³è”æ—¥å¿—å’ŒæŒ‡æ ‡
Panel: Time series (Prometheus)
Query: rate(http_requests_total[5m])

Data links:
  - Title: View Logs
    URL: /explore?left={"datasource":"Loki","queries":[{"expr":"{namespace=\"${namespace}\",pod=\"${pod}\"}"}]}
```

#### Lokiæ€§èƒ½ä¼˜åŒ–

**1. æ ‡ç­¾åŸºæ•°æ§åˆ¶**

```yaml
# âŒ é”™è¯¯: é«˜åŸºæ•°æ ‡ç­¾
{user_id="12345"}  # ç™¾ä¸‡çº§ç”¨æˆ·
{request_id="uuid"}  # æ¯ä¸ªè¯·æ±‚å”¯ä¸€

# âœ… æ­£ç¡®: ä½åŸºæ•°æ ‡ç­¾
{namespace="production"}  # æ•°åä¸ªå‘½åç©ºé—´
{app="nginx"}  # æ•°ç™¾ä¸ªåº”ç”¨
{level="ERROR"}  # 5-6ä¸ªçº§åˆ«
```

**2. æŸ¥è¯¢ä¼˜åŒ–**

```logql
# âŒ æ…¢æŸ¥è¯¢ (æ‰«ææ‰€æœ‰æ—¥å¿—)
{namespace="production"} |~ "user.*logged in"

# âœ… å¿«æŸ¥è¯¢ (å…ˆç”¨æ ‡ç­¾è¿‡æ»¤)
{namespace="production", app="auth"} |~ "user.*logged in"

# âŒ æ…¢æŸ¥è¯¢ (å¤§æ—¶é—´èŒƒå›´)
{namespace="production"} [7d]

# âœ… å¿«æŸ¥è¯¢ (å°æ—¶é—´èŒƒå›´)
{namespace="production"} [1h]
```

**3. å­˜å‚¨ä¼˜åŒ–**

```yaml
# loki.yaml
limits_config:
  # é™åˆ¶æ¯ä¸ªæµçš„é€Ÿç‡
  ingestion_rate_mb: 10
  ingestion_burst_size_mb: 20
  
  # é™åˆ¶æŸ¥è¯¢èŒƒå›´
  max_query_length: 721h  # 30å¤©
  max_query_lookback: 30d
  
  # é™åˆ¶å¹¶å‘æŸ¥è¯¢
  max_concurrent_tail_requests: 10
  max_streams_per_user: 10000

# å‹ç¼©é…ç½®
chunk_store_config:
  chunk_cache_config:
    enable_fifocache: true
    fifocache:
      max_size_bytes: 1GB
```

---

**ğŸ“Š 9.5èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†æ—¥å¿—ç®¡ç†ä¸EFK/Lokiæ–¹æ¡ˆï¼š

âœ… **æ—¥å¿—æ”¶é›†æ¶æ„**ï¼š
- å®¹å™¨æ—¥å¿—ç”Ÿå‘½å‘¨æœŸ
- 3ç§æ”¶é›†æ¨¡å¼ (Sidecar/DaemonSet/Operator)
- ç»“æ„åŒ–æ—¥å¿—æœ€ä½³å®è·µ

âœ… **Fluentd/Fluent Bit**ï¼š
- Fluentdæ¶æ„ä¸æ’ä»¶ç³»ç»Ÿ
- DaemonSetéƒ¨ç½²é…ç½®
- Fluent Bitè½»é‡çº§æ–¹æ¡ˆ
- é«˜çº§é…ç½® (å¤šè¾“å‡º/é‡‡æ ·/è„±æ•/èšåˆ)

âœ… **Elasticsearché›†ç¾¤**ï¼š
- ESæ¶æ„ (Master/Data/Coordinating/Ingest)
- StatefulSetéƒ¨ç½²
- ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç† (ILM)
- æ€§èƒ½ä¼˜åŒ– (ç¡¬ä»¶/JVM/ç´¢å¼•/æŸ¥è¯¢)

âœ… **KibanaæŸ¥è¯¢åˆ†æ**ï¼š
- KQLæŸ¥è¯¢è¯­æ³•
- Index Patternåˆ›å»º
- Discoveræ—¥å¿—æŸ¥è¯¢
- å¯è§†åŒ–ä¸Dashboard

âœ… **Lokiè½»é‡çº§æ–¹æ¡ˆ**ï¼š
- Loki vs Elasticsearchå¯¹æ¯”
- Loki + Promtailéƒ¨ç½²
- LogQLæŸ¥è¯¢è¯­è¨€
- Grafanaé›†æˆ
- æ€§èƒ½ä¼˜åŒ–

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ åˆ†å¸ƒå¼è¿½è¸ªä¸Jaegerï¼ŒåŒ…æ‹¬OpenTelemetryæ ‡å‡†ã€Jaegeræ¶æ„ä¸éƒ¨ç½²ã€åº”ç”¨åŸ‹ç‚¹ä¸SDKé›†æˆã€è°ƒç”¨é“¾è·¯åˆ†æå®æˆ˜ï¼Œä»¥åŠæ€§èƒ½ç“¶é¢ˆå®šä½ã€‚

---

## 9.6 åˆ†å¸ƒå¼è¿½è¸ªä¸Jaeger

åœ¨å¾®æœåŠ¡æ¶æ„ä¸­ï¼Œä¸€ä¸ªç”¨æˆ·è¯·æ±‚å¯èƒ½ä¼šç»è¿‡æ•°åä¸ªæœåŠ¡çš„å¤„ç†ï¼Œå¦‚ä½•å¿«é€Ÿå®šä½æ€§èƒ½ç“¶é¢ˆå’Œæ•…éšœç‚¹ï¼Ÿåˆ†å¸ƒå¼è¿½è¸ªï¼ˆDistributed Tracingï¼‰é€šè¿‡è®°å½•è¯·æ±‚åœ¨å„ä¸ªæœåŠ¡é—´çš„è°ƒç”¨é“¾è·¯ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£ç³»ç»Ÿè¡Œä¸ºã€ä¼˜åŒ–æ€§èƒ½ã€æ’æŸ¥é—®é¢˜ã€‚æœ¬èŠ‚å°†æ·±å…¥è®²è§£åˆ†å¸ƒå¼è¿½è¸ªçš„æ ¸å¿ƒåŸç†ã€OpenTelemetryæ ‡å‡†ã€Jaegerçš„æ¶æ„ä¸éƒ¨ç½²ï¼Œä»¥åŠå¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­é›†æˆè¿½è¸ªåŠŸèƒ½ã€‚

### 9.6.1 åˆ†å¸ƒå¼è¿½è¸ªåŸºç¡€ç†è®º

#### ä¸ºä»€ä¹ˆéœ€è¦åˆ†å¸ƒå¼è¿½è¸ªï¼Ÿ

**å•ä½“åº”ç”¨ vs å¾®æœåŠ¡**ï¼š

```
# å•ä½“åº”ç”¨ï¼ˆè°ƒç”¨æ ˆæ¸…æ™°ï¼‰
User Request
  â†“
Web Server
  â†“
Business Logic
  â†“
Database
  â†“
Response

# å¾®æœåŠ¡ï¼ˆè°ƒç”¨é“¾å¤æ‚ï¼‰
User Request
  â†“
API Gateway â†’ Auth Service â†’ User Service â†’ Order Service
                                â†“              â†“
                           Cache Service   Inventory Service
                                              â†“
                                         Payment Service
                                              â†“
                                         Notification Service
```

**å¾®æœåŠ¡æ¶æ„çš„æŒ‘æˆ˜**ï¼š
- âŒ **è°ƒç”¨é“¾è·¯ä¸é€æ˜**ï¼šè¯·æ±‚ç»è¿‡å¤šä¸ªæœåŠ¡ï¼Œéš¾ä»¥è¿½è¸ªå®Œæ•´è·¯å¾„
- âŒ **æ€§èƒ½ç“¶é¢ˆéš¾å®šä½**ï¼šä¸çŸ¥é“å“ªä¸ªæœåŠ¡æ‹–æ…¢äº†æ•´ä½“å“åº”
- âŒ **æ•…éšœæ’æŸ¥å›°éš¾**ï¼šé”™è¯¯å¯èƒ½å‘ç”Ÿåœ¨ä»»ä½•ä¸€ä¸ªç¯èŠ‚
- âŒ **ä¾èµ–å…³ç³»å¤æ‚**ï¼šæœåŠ¡é—´ä¾èµ–å…³ç³»ä¸æ¸…æ™°

**åˆ†å¸ƒå¼è¿½è¸ªçš„ä»·å€¼**ï¼š
- âœ… **å¯è§†åŒ–è°ƒç”¨é“¾è·¯**ï¼šæ¸…æ™°å±•ç¤ºè¯·æ±‚çš„å®Œæ•´è·¯å¾„
- âœ… **æ€§èƒ½åˆ†æ**ï¼šç²¾ç¡®æµ‹é‡æ¯ä¸ªæœåŠ¡çš„è€—æ—¶
- âœ… **æ•…éšœå®šä½**ï¼šå¿«é€Ÿæ‰¾åˆ°å‡ºé”™çš„æœåŠ¡å’Œæ¥å£
- âœ… **ä¾èµ–åˆ†æ**ï¼šè‡ªåŠ¨ç”ŸæˆæœåŠ¡ä¾èµ–æ‹“æ‰‘å›¾

#### æ ¸å¿ƒæ¦‚å¿µï¼šTraceã€Spanã€Context

**Traceï¼ˆè¿½è¸ªï¼‰**ï¼š
- ä¸€ä¸ªå®Œæ•´çš„è¯·æ±‚é“¾è·¯ï¼Œç”±å¤šä¸ªSpanç»„æˆ
- æ¯ä¸ªTraceæœ‰å”¯ä¸€çš„Trace ID

**Spanï¼ˆè·¨åº¦ï¼‰**ï¼š
- ä¸€æ¬¡æœåŠ¡è°ƒç”¨æˆ–æ“ä½œï¼Œæ˜¯è¿½è¸ªçš„åŸºæœ¬å•å…ƒ
- æ¯ä¸ªSpanåŒ…å«ï¼š
  - Span IDï¼šå”¯ä¸€æ ‡è¯†
  - Parent Span IDï¼šçˆ¶Spançš„IDï¼ˆæ ¹Spanæ²¡æœ‰çˆ¶IDï¼‰
  - Operation Nameï¼šæ“ä½œåç§°ï¼ˆå¦‚ `GET /api/users`ï¼‰
  - Start Time & Durationï¼šå¼€å§‹æ—¶é—´å’ŒæŒç»­æ—¶é—´
  - Tagsï¼šé”®å€¼å¯¹æ ‡ç­¾ï¼ˆå¦‚ `http.method=GET`ï¼‰
  - Logsï¼šæ—¶é—´æˆ³æ—¥å¿—äº‹ä»¶

**Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰**ï¼š
- åœ¨æœåŠ¡é—´ä¼ é€’çš„è¿½è¸ªä¿¡æ¯ï¼ˆTrace IDã€Span IDï¼‰
- é€šè¿‡HTTP Headerã€gRPC Metadataç­‰æ–¹å¼ä¼ æ’­

**ç¤ºä¾‹ï¼šç”µå•†ä¸‹å•è¯·æ±‚çš„Trace**ï¼š

```
Trace ID: a1b2c3d4e5f6g7h8

Span 1 (Root Span)
â”œâ”€ Operation: POST /api/orders
â”œâ”€ Service: api-gateway
â”œâ”€ Duration: 850ms
â”œâ”€ Tags: http.method=POST, http.status_code=200
â”‚
â”œâ”€ Span 2 (Child Span)
â”‚  â”œâ”€ Operation: GET /api/users/123
â”‚  â”œâ”€ Service: user-service
â”‚  â”œâ”€ Duration: 50ms
â”‚  â””â”€ Parent: Span 1
â”‚
â”œâ”€ Span 3 (Child Span)
â”‚  â”œâ”€ Operation: POST /api/inventory/check
â”‚  â”œâ”€ Service: inventory-service
â”‚  â”œâ”€ Duration: 120ms
â”‚  â””â”€ Parent: Span 1
â”‚
â”œâ”€ Span 4 (Child Span)
â”‚  â”œâ”€ Operation: POST /api/payment/charge
â”‚  â”œâ”€ Service: payment-service
â”‚  â”œâ”€ Duration: 600ms  â† æ€§èƒ½ç“¶é¢ˆï¼
â”‚  â””â”€ Parent: Span 1
â”‚     â”‚
â”‚     â””â”€ Span 5 (Grandchild Span)
â”‚        â”œâ”€ Operation: POST /external/stripe/charge
â”‚        â”œâ”€ Service: payment-service
â”‚        â”œâ”€ Duration: 580ms
â”‚        â””â”€ Parent: Span 4
â”‚
â””â”€ Span 6 (Child Span)
   â”œâ”€ Operation: POST /api/notifications/send
   â”œâ”€ Service: notification-service
   â”œâ”€ Duration: 30ms
   â””â”€ Parent: Span 1
```

ä»è¿™ä¸ªTraceå¯ä»¥çœ‹å‡ºï¼š
- æ€»è€—æ—¶850msï¼Œå…¶ä¸­Payment Serviceå ç”¨600msï¼ˆ70%ï¼‰
- Payment Serviceè°ƒç”¨å¤–éƒ¨Stripe APIè€—æ—¶580msï¼Œæ˜¯ä¸»è¦ç“¶é¢ˆ
- ä¼˜åŒ–æ–¹å‘ï¼šè€ƒè™‘å¼‚æ­¥å¤„ç†æ”¯ä»˜ã€å¢åŠ è¶…æ—¶æ§åˆ¶

#### é‡‡æ ·ç­–ç•¥ï¼ˆSamplingï¼‰

**ä¸ºä»€ä¹ˆéœ€è¦é‡‡æ ·ï¼Ÿ**
- é«˜æµé‡ç³»ç»Ÿæ¯ç§’å¯èƒ½äº§ç”Ÿæ•°ç™¾ä¸‡ä¸ªSpan
- å­˜å‚¨å’Œåˆ†ææ‰€æœ‰Traceæˆæœ¬é«˜æ˜‚
- é‡‡æ ·å¯ä»¥åœ¨ä¿è¯å¯è§‚æµ‹æ€§çš„åŒæ—¶é™ä½å¼€é”€

**å¸¸è§é‡‡æ ·ç­–ç•¥**ï¼š

1. **æ’å®šé‡‡æ ·ï¼ˆConstant Samplingï¼‰**ï¼š
```yaml
# é‡‡æ ·ç‡10%ï¼ˆæ¯10ä¸ªè¯·æ±‚é‡‡æ ·1ä¸ªï¼‰
sampler:
  type: probabilistic
  param: 0.1
```

2. **é€Ÿç‡é™åˆ¶é‡‡æ ·ï¼ˆRate Limiting Samplingï¼‰**ï¼š
```yaml
# æ¯ç§’æœ€å¤šé‡‡æ ·100ä¸ªTrace
sampler:
  type: ratelimiting
  param: 100
```

3. **è‡ªé€‚åº”é‡‡æ ·ï¼ˆAdaptive Samplingï¼‰**ï¼š
```go
// æ ¹æ®æœåŠ¡è´Ÿè½½åŠ¨æ€è°ƒæ•´é‡‡æ ·ç‡
if requestRate > 10000 {
    samplingRate = 0.01  // 1%
} else if requestRate > 1000 {
    samplingRate = 0.1   // 10%
} else {
    samplingRate = 1.0   // 100%
}
```

4. **å°¾éƒ¨é‡‡æ ·ï¼ˆTail-based Samplingï¼‰**ï¼š
```yaml
# ä¼˜å…ˆé‡‡æ ·æ…¢è¯·æ±‚å’Œé”™è¯¯è¯·æ±‚
policies:
  - name: error-traces
    type: status_code
    status_code:
      status_codes: [ERROR]
  - name: slow-traces
    type: latency
    latency:
      threshold_ms: 1000
```

**é‡‡æ ·å†³ç­–ä¼ æ’­**ï¼š
```
Service A (é‡‡æ ·å†³ç­–: YES)
  â†“ (ä¼ æ’­é‡‡æ ·æ ‡å¿—)
Service B (ç»§æ‰¿é‡‡æ ·å†³ç­–: YES)
  â†“ (ä¼ æ’­é‡‡æ ·æ ‡å¿—)
Service C (ç»§æ‰¿é‡‡æ ·å†³ç­–: YES)
```

#### è¿½è¸ªæ•°æ®æ¨¡å‹

**OpenTracingæ ‡å‡†æ•°æ®æ¨¡å‹**ï¼š

```json
{
  "traceID": "a1b2c3d4e5f6g7h8",
  "spans": [
    {
      "spanID": "span-001",
      "parentSpanID": null,
      "operationName": "POST /api/orders",
      "startTime": 1705824000000000,
      "duration": 850000,
      "tags": {
        "http.method": "POST",
        "http.url": "/api/orders",
        "http.status_code": 200,
        "service.name": "api-gateway",
        "span.kind": "server"
      },
      "logs": [
        {
          "timestamp": 1705824000100000,
          "fields": {
            "event": "order_validation_start"
          }
        },
        {
          "timestamp": 1705824000150000,
          "fields": {
            "event": "order_validation_success"
          }
        }
      ],
      "references": []
    },
    {
      "spanID": "span-004",
      "parentSpanID": "span-001",
      "operationName": "POST /api/payment/charge",
      "startTime": 1705824000200000,
      "duration": 600000,
      "tags": {
        "http.method": "POST",
        "http.status_code": 200,
        "service.name": "payment-service",
        "payment.amount": 99.99,
        "payment.currency": "USD"
      },
      "logs": [
        {
          "timestamp": 1705824000250000,
          "fields": {
            "event": "stripe_api_call_start"
          }
        },
        {
          "timestamp": 1705824000830000,
          "fields": {
            "event": "stripe_api_call_success",
            "stripe.charge_id": "ch_1234567890"
          }
        }
      ],
      "references": [
        {
          "refType": "CHILD_OF",
          "traceID": "a1b2c3d4e5f6g7h8",
          "spanID": "span-001"
        }
      ]
    }
  ]
}
```

**å…³é”®å­—æ®µè¯´æ˜**ï¼š
- `traceID`ï¼šå…¨å±€å”¯ä¸€çš„è¿½è¸ªIDï¼ˆé€šå¸¸æ˜¯128ä½æˆ–64ä½ï¼‰
- `spanID`ï¼šSpançš„å”¯ä¸€ID
- `parentSpanID`ï¼šçˆ¶Spançš„IDï¼ˆæ ¹Spanä¸ºnullï¼‰
- `operationName`ï¼šæ“ä½œåç§°ï¼ˆå»ºè®®ä½¿ç”¨ `HTTPæ–¹æ³• + è·¯å¾„` æ ¼å¼ï¼‰
- `startTime`ï¼šå¼€å§‹æ—¶é—´ï¼ˆå¾®ç§’çº§æ—¶é—´æˆ³ï¼‰
- `duration`ï¼šæŒç»­æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
- `tags`ï¼šç»“æ„åŒ–æ ‡ç­¾ï¼ˆç”¨äºè¿‡æ»¤å’Œèšåˆï¼‰
- `logs`ï¼šæ—¶é—´åºåˆ—æ—¥å¿—äº‹ä»¶
- `references`ï¼šSpané—´çš„å…³ç³»ï¼ˆCHILD_OFã€FOLLOWS_FROMï¼‰

#### ä¸Šä¸‹æ–‡ä¼ æ’­ï¼ˆContext Propagationï¼‰

**HTTP Headerä¼ æ’­**ï¼š

```http
# è¯·æ±‚å¤´ï¼ˆService A â†’ Service Bï¼‰
GET /api/users/123 HTTP/1.1
Host: user-service
uber-trace-id: a1b2c3d4e5f6g7h8:span-002:span-001:1
```

**uber-trace-idæ ¼å¼**ï¼š
```
{trace-id}:{span-id}:{parent-span-id}:{flags}
```

**W3C Trace Contextæ ‡å‡†**ï¼ˆæ¨èï¼‰ï¼š

```http
# traceparent header
traceparent: 00-a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6-q7r8s9t0u1v2w3x4-01

# æ ¼å¼ï¼šversion-trace-id-parent-id-trace-flags
# version: 00ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰
# trace-id: 32ä½åå…­è¿›åˆ¶ï¼ˆ128ä½ï¼‰
# parent-id: 16ä½åå…­è¿›åˆ¶ï¼ˆ64ä½ï¼‰
# trace-flags: 01ï¼ˆé‡‡æ ·æ ‡å¿—ï¼‰

# tracestate headerï¼ˆå¯é€‰ï¼Œç”¨äºä¼ é€’ä¾›åº”å•†ç‰¹å®šä¿¡æ¯ï¼‰
tracestate: jaeger=span-002,sampling.priority=1
```

**gRPC Metadataä¼ æ’­**ï¼š

```go
import (
    "google.golang.org/grpc/metadata"
    "go.opentelemetry.io/otel/propagation"
)

// å®¢æˆ·ç«¯ï¼šæ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡
func callUserService(ctx context.Context) {
    md := metadata.New(nil)
    propagator := propagation.TraceContext{}
    propagator.Inject(ctx, &metadataCarrier{md: &md})
    
    ctx = metadata.NewOutgoingContext(ctx, md)
    resp, err := userClient.GetUser(ctx, &pb.GetUserRequest{ID: "123"})
}

// æœåŠ¡ç«¯ï¼šæå–è¿½è¸ªä¸Šä¸‹æ–‡
func (s *UserServiceServer) GetUser(ctx context.Context, req *pb.GetUserRequest) {
    md, _ := metadata.FromIncomingContext(ctx)
    propagator := propagation.TraceContext{}
    ctx = propagator.Extract(ctx, &metadataCarrier{md: &md})
    
    // ä½¿ç”¨æå–çš„ä¸Šä¸‹æ–‡åˆ›å»ºå­Span
    span := tracer.Start(ctx, "GetUser")
    defer span.End()
}
```

**æ¶ˆæ¯é˜Ÿåˆ—ä¼ æ’­**ï¼ˆKafkaç¤ºä¾‹ï¼‰ï¼š

```go
import (
    "github.com/Shopify/sarama"
    "go.opentelemetry.io/otel/propagation"
)

// ç”Ÿäº§è€…ï¼šæ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡åˆ°æ¶ˆæ¯å¤´
func produceMessage(ctx context.Context, topic string, value []byte) {
    msg := &sarama.ProducerMessage{
        Topic: topic,
        Value: sarama.ByteEncoder(value),
    }
    
    // æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡
    propagator := propagation.TraceContext{}
    carrier := NewKafkaHeaderCarrier(msg)
    propagator.Inject(ctx, carrier)
    
    producer.SendMessage(msg)
}

// æ¶ˆè´¹è€…ï¼šæå–è¿½è¸ªä¸Šä¸‹æ–‡
func consumeMessage(msg *sarama.ConsumerMessage) {
    propagator := propagation.TraceContext{}
    carrier := NewKafkaHeaderCarrier(msg)
    ctx := propagator.Extract(context.Background(), carrier)
    
    // ä½¿ç”¨æå–çš„ä¸Šä¸‹æ–‡åˆ›å»ºSpan
    span := tracer.Start(ctx, "ProcessMessage")
    defer span.End()
}

// Kafka Header Carrierå®ç°
type KafkaHeaderCarrier struct {
    msg interface{}
}

func (c *KafkaHeaderCarrier) Get(key string) string {
    // ä»Kafkaæ¶ˆæ¯å¤´è¯»å–
}

func (c *KafkaHeaderCarrier) Set(key, value string) {
    // å†™å…¥Kafkaæ¶ˆæ¯å¤´
}
```

### 9.6.2 OpenTelemetryæ ‡å‡†

OpenTelemetryï¼ˆç®€ç§°OTelï¼‰æ˜¯CNCFçš„å¯è§‚æµ‹æ€§æ ‡å‡†ï¼Œç»Ÿä¸€äº†è¿½è¸ªã€æŒ‡æ ‡ã€æ—¥å¿—çš„æ•°æ®é‡‡é›†å’Œä¼ è¾“ã€‚å®ƒæ˜¯OpenTracingå’ŒOpenCensusé¡¹ç›®åˆå¹¶åçš„äº§ç‰©ï¼Œå·²æˆä¸ºåˆ†å¸ƒå¼è¿½è¸ªçš„äº‹å®æ ‡å‡†ã€‚

#### OpenTelemetryæ¶æ„

**æ ¸å¿ƒç»„ä»¶**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Code                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ OTel SDK     â”‚  â”‚ OTel SDK     â”‚  â”‚ OTel SDK     â”‚      â”‚
â”‚  â”‚ (Go)         â”‚  â”‚ (Java)       â”‚  â”‚ (Python)     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â”‚ OTLP Protocol    â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OpenTelemetry Collector                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Receivers â”‚â†’ â”‚Processorsâ”‚â†’ â”‚Exporters â”‚  â”‚Extensionsâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Jaeger  â”‚        â”‚Prometheusâ”‚       â”‚ Loki    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç»„ä»¶è¯´æ˜**ï¼š
- **OTel SDK**ï¼šåµŒå…¥åº”ç”¨ä»£ç ï¼Œè´Ÿè´£ç”Ÿæˆè¿½è¸ªæ•°æ®
- **OTel Collector**ï¼šç‹¬ç«‹è¿›ç¨‹ï¼Œè´Ÿè´£æ¥æ”¶ã€å¤„ç†ã€å¯¼å‡ºæ•°æ®
- **OTLP Protocol**ï¼šOpenTelemetryåè®®ï¼ˆgRPC/HTTPï¼‰

#### OpenTelemetry SDKé›†æˆ

**Goåº”ç”¨é›†æˆç¤ºä¾‹**ï¼š

```go
package main

import (
    "context"
    "log"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.17.0"
    "go.opentelemetry.io/otel/trace"
)

// åˆå§‹åŒ–OpenTelemetry
func initTracer() (*sdktrace.TracerProvider, error) {
    // 1. åˆ›å»ºOTLP Exporterï¼ˆè¿æ¥åˆ°OTel Collectorï¼‰
    exporter, err := otlptracegrpc.New(
        context.Background(),
        otlptracegrpc.WithEndpoint("otel-collector.observability.svc.cluster.local:4317"),
        otlptracegrpc.WithInsecure(),
    )
    if err != nil {
        return nil, err
    }

    // 2. åˆ›å»ºResourceï¼ˆæœåŠ¡æ ‡è¯†ä¿¡æ¯ï¼‰
    res, err := resource.New(
        context.Background(),
        resource.WithAttributes(
            semconv.ServiceNameKey.String("order-service"),
            semconv.ServiceVersionKey.String("1.0.0"),
            semconv.DeploymentEnvironmentKey.String("production"),
            attribute.String("service.namespace", "ecommerce"),
        ),
    )
    if err != nil {
        return nil, err
    }

    // 3. åˆ›å»ºTracerProvider
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),  // æ‰¹é‡å‘é€
        sdktrace.WithResource(res),
        sdktrace.WithSampler(sdktrace.ParentBased(
            sdktrace.TraceIDRatioBased(0.1),  // 10%é‡‡æ ·ç‡
        )),
    )

    // 4. è®¾ç½®å…¨å±€TracerProvider
    otel.SetTracerProvider(tp)

    return tp, nil
}

func main() {
    // åˆå§‹åŒ–Tracer
    tp, err := initTracer()
    if err != nil {
        log.Fatal(err)
    }
    defer func() {
        if err := tp.Shutdown(context.Background()); err != nil {
            log.Printf("Error shutting down tracer provider: %v", err)
        }
    }()

    // åˆ›å»ºTracer
    tracer := otel.Tracer("order-service")

    // æ¨¡æ‹Ÿä¸šåŠ¡é€»è¾‘
    ctx := context.Background()
    processOrder(ctx, tracer, "order-12345")
}

// ä¸šåŠ¡å‡½æ•°ï¼šå¤„ç†è®¢å•
func processOrder(ctx context.Context, tracer trace.Tracer, orderID string) {
    // åˆ›å»ºRoot Span
    ctx, span := tracer.Start(ctx, "ProcessOrder",
        trace.WithSpanKind(trace.SpanKindServer),
        trace.WithAttributes(
            attribute.String("order.id", orderID),
        ),
    )
    defer span.End()

    // æ·»åŠ äº‹ä»¶
    span.AddEvent("Order validation started")

    // è°ƒç”¨å­å‡½æ•°ï¼ˆè‡ªåŠ¨åˆ›å»ºChild Spanï¼‰
    validateOrder(ctx, tracer, orderID)
    checkInventory(ctx, tracer, orderID)
    chargePayment(ctx, tracer, orderID)

    // è®¾ç½®SpançŠ¶æ€
    span.SetAttributes(attribute.String("order.status", "completed"))
    span.AddEvent("Order processing completed")
}

// å­å‡½æ•°ï¼šéªŒè¯è®¢å•
func validateOrder(ctx context.Context, tracer trace.Tracer, orderID string) {
    ctx, span := tracer.Start(ctx, "ValidateOrder")
    defer span.End()

    // æ¨¡æ‹ŸéªŒè¯é€»è¾‘
    time.Sleep(50 * time.Millisecond)

    span.SetAttributes(
        attribute.Bool("validation.passed", true),
    )
}

// å­å‡½æ•°ï¼šæ£€æŸ¥åº“å­˜
func checkInventory(ctx context.Context, tracer trace.Tracer, orderID string) {
    ctx, span := tracer.Start(ctx, "CheckInventory")
    defer span.End()

    // æ¨¡æ‹ŸHTTPè°ƒç”¨
    span.SetAttributes(
        attribute.String("http.method", "GET"),
        attribute.String("http.url", "http://inventory-service/api/check"),
        attribute.Int("http.status_code", 200),
    )

    time.Sleep(120 * time.Millisecond)
}

// å­å‡½æ•°ï¼šæ”¯ä»˜æ‰£æ¬¾
func chargePayment(ctx context.Context, tracer trace.Tracer, orderID string) {
    ctx, span := tracer.Start(ctx, "ChargePayment")
    defer span.End()

    // æ¨¡æ‹Ÿæ”¯ä»˜è°ƒç”¨
    span.SetAttributes(
        attribute.String("payment.provider", "stripe"),
        attribute.Float64("payment.amount", 99.99),
        attribute.String("payment.currency", "USD"),
    )

    time.Sleep(600 * time.Millisecond)

    // è®°å½•æ”¯ä»˜æˆåŠŸäº‹ä»¶
    span.AddEvent("Payment charged successfully",
        trace.WithAttributes(
            attribute.String("charge.id", "ch_1234567890"),
        ),
    )
}
```

**Javaåº”ç”¨é›†æˆç¤ºä¾‹ï¼ˆSpring Bootï¼‰**ï¼š

```java
// pom.xmlä¾èµ–
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-api</artifactId>
    <version>1.32.0</version>
</dependency>
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-sdk</artifactId>
    <version>1.32.0</version>
</dependency>
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-exporter-otlp</artifactId>
    <version>1.32.0</version>
</dependency>

// OpenTelemetryConfig.java
@Configuration
public class OpenTelemetryConfig {

    @Bean
    public OpenTelemetry openTelemetry() {
        // OTLP Exporter
        OtlpGrpcSpanExporter spanExporter = OtlpGrpcSpanExporter.builder()
            .setEndpoint("http://otel-collector.observability.svc.cluster.local:4317")
            .build();

        // Resource
        Resource resource = Resource.getDefault()
            .merge(Resource.create(Attributes.of(
                ResourceAttributes.SERVICE_NAME, "user-service",
                ResourceAttributes.SERVICE_VERSION, "1.0.0"
            )));

        // TracerProvider
        SdkTracerProvider tracerProvider = SdkTracerProvider.builder()
            .addSpanProcessor(BatchSpanProcessor.builder(spanExporter).build())
            .setResource(resource)
            .setSampler(Sampler.traceIdRatioBased(0.1))  // 10%é‡‡æ ·
            .build();

        return OpenTelemetrySdk.builder()
            .setTracerProvider(tracerProvider)
            .setPropagators(ContextPropagators.create(W3CTraceContextPropagator.getInstance()))
            .buildAndRegisterGlobal();
    }

    @Bean
    public Tracer tracer(OpenTelemetry openTelemetry) {
        return openTelemetry.getTracer("user-service");
    }
}

// UserController.java
@RestController
@RequestMapping("/api/users")
public class UserController {

    @Autowired
    private Tracer tracer;

    @Autowired
    private UserService userService;

    @GetMapping("/{id}")
    public ResponseEntity<User> getUser(@PathVariable String id) {
        // åˆ›å»ºSpan
        Span span = tracer.spanBuilder("GET /api/users/{id}")
            .setSpanKind(SpanKind.SERVER)
            .setAttribute("http.method", "GET")
            .setAttribute("http.route", "/api/users/{id}")
            .setAttribute("user.id", id)
            .startSpan();

        try (Scope scope = span.makeCurrent()) {
            User user = userService.findById(id);
            span.setAttribute("http.status_code", 200);
            return ResponseEntity.ok(user);
        } catch (Exception e) {
            span.recordException(e);
            span.setStatus(StatusCode.ERROR, e.getMessage());
            throw e;
        } finally {
            span.end();
        }
    }
}

// UserService.java
@Service
public class UserService {

    @Autowired
    private Tracer tracer;

    @Autowired
    private RestTemplate restTemplate;

    public User findById(String id) {
        Span span = tracer.spanBuilder("UserService.findById")
            .startSpan();

        try (Scope scope = span.makeCurrent()) {
            // æ•°æ®åº“æŸ¥è¯¢
            span.addEvent("Database query started");
            User user = userRepository.findById(id);
            span.addEvent("Database query completed");

            // è°ƒç”¨å¤–éƒ¨æœåŠ¡
            enrichUserData(user);

            return user;
        } finally {
            span.end();
        }
    }

    private void enrichUserData(User user) {
        Span span = tracer.spanBuilder("EnrichUserData")
            .setAttribute("http.method", "GET")
            .setAttribute("http.url", "http://profile-service/api/profiles/" + user.getId())
            .startSpan();

        try (Scope scope = span.makeCurrent()) {
            Profile profile = restTemplate.getForObject(
                "http://profile-service/api/profiles/" + user.getId(),
                Profile.class
            );
            user.setProfile(profile);
            span.setAttribute("http.status_code", 200);
        } finally {
            span.end();
        }
    }
}
```


**Pythonåº”ç”¨é›†æˆç¤ºä¾‹ï¼ˆFlaskï¼‰**ï¼š

```python
# requirements.txt
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
opentelemetry-exporter-otlp==1.21.0
opentelemetry-instrumentation-flask==0.42b0
opentelemetry-instrumentation-requests==0.42b0

# app.py
from flask import Flask
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.semconv.resource import ResourceAttributes
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor

# åˆå§‹åŒ–OpenTelemetry
def init_tracer():
    # Resource
    resource = Resource(attributes={
        ResourceAttributes.SERVICE_NAME: "inventory-service",
        ResourceAttributes.SERVICE_VERSION: "1.0.0",
    })

    # OTLP Exporter
    otlp_exporter = OTLPSpanExporter(
        endpoint="otel-collector.observability.svc.cluster.local:4317",
        insecure=True
    )

    # TracerProvider
    provider = TracerProvider(resource=resource)
    processor = BatchSpanProcessor(otlp_exporter)
    provider.add_span_processor(processor)
    trace.set_tracer_provider(provider)

    return trace.get_tracer(__name__)

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
tracer = init_tracer()

# è‡ªåŠ¨åŸ‹ç‚¹ï¼ˆè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰Flaskè·¯ç”±å’Œrequestsè°ƒç”¨ï¼‰
FlaskInstrumentor().instrument_app(app)
RequestsInstrumentor().instrument()

@app.route('/api/inventory/check', methods=['POST'])
def check_inventory():
    # è·å–å½“å‰Span
    current_span = trace.get_current_span()
    current_span.set_attribute("inventory.item_count", 5)

    # æ‰‹åŠ¨åˆ›å»ºå­Span
    with tracer.start_as_current_span("CheckDatabase") as span:
        span.set_attribute("db.system", "postgresql")
        span.set_attribute("db.statement", "SELECT * FROM inventory WHERE product_id = ?")
        
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        import time
        time.sleep(0.05)
        
        span.add_event("Database query completed", {
            "rows.returned": 1
        })

    return {"available": True, "quantity": 100}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

#### OpenTelemetry Collectoréƒ¨ç½²

**Collectoré…ç½®æ–‡ä»¶**ï¼š

```yaml
# otel-collector-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: observability
data:
  otel-collector-config.yaml: |
    # Receivers: æ¥æ”¶è¿½è¸ªæ•°æ®
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      # JaegeråŸç”Ÿåè®®ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268

    # Processors: å¤„ç†è¿½è¸ªæ•°æ®
    processors:
      # æ‰¹é‡å¤„ç†ï¼ˆæé«˜æ€§èƒ½ï¼‰
      batch:
        timeout: 10s
        send_batch_size: 1024
      
      # å†…å­˜é™åˆ¶ï¼ˆé˜²æ­¢OOMï¼‰
      memory_limiter:
        check_interval: 1s
        limit_mib: 512
        spike_limit_mib: 128
      
      # èµ„æºæ£€æµ‹ï¼ˆè‡ªåŠ¨æ·»åŠ K8så…ƒæ•°æ®ï¼‰
      resource:
        attributes:
          - key: cluster.name
            value: production-cluster
            action: insert
      
      # é‡‡æ ·ï¼ˆå°¾éƒ¨é‡‡æ ·ï¼‰
      tail_sampling:
        decision_wait: 10s
        num_traces: 100
        expected_new_traces_per_sec: 10
        policies:
          # é‡‡æ ·æ‰€æœ‰é”™è¯¯Trace
          - name: error-traces
            type: status_code
            status_code:
              status_codes: [ERROR]
          
          # é‡‡æ ·æ…¢è¯·æ±‚ï¼ˆ>1ç§’ï¼‰
          - name: slow-traces
            type: latency
            latency:
              threshold_ms: 1000
          
          # å…¶ä»–è¯·æ±‚10%é‡‡æ ·
          - name: probabilistic-policy
            type: probabilistic
            probabilistic:
              sampling_percentage: 10

      # Spanå±æ€§å¤„ç†
      attributes:
        actions:
          # åˆ é™¤æ•æ„Ÿä¿¡æ¯
          - key: http.request.header.authorization
            action: delete
          - key: http.request.header.cookie
            action: delete
          
          # é‡å‘½åå±æ€§
          - key: http.url
            action: update
            from_attribute: http.target

    # Exporters: å¯¼å‡ºè¿½è¸ªæ•°æ®
    exporters:
      # å¯¼å‡ºåˆ°Jaeger
      jaeger:
        endpoint: jaeger-collector.observability.svc.cluster.local:14250
        tls:
          insecure: true
      
      # å¯¼å‡ºåˆ°Prometheusï¼ˆæŒ‡æ ‡ï¼‰
      prometheus:
        endpoint: 0.0.0.0:8889
      
      # å¯¼å‡ºåˆ°æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
      logging:
        loglevel: debug
      
      # å¯¼å‡ºåˆ°å¤šä¸ªåç«¯
      otlp/jaeger:
        endpoint: jaeger-collector.observability.svc.cluster.local:4317
        tls:
          insecure: true

    # Extensions: æ‰©å±•åŠŸèƒ½
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      pprof:
        endpoint: 0.0.0.0:1777
      zpages:
        endpoint: 0.0.0.0:55679

    # Service: æœåŠ¡é…ç½®
    service:
      extensions: [health_check, pprof, zpages]
      pipelines:
        # è¿½è¸ªæ•°æ®ç®¡é“
        traces:
          receivers: [otlp, jaeger]
          processors: [memory_limiter, resource, batch, tail_sampling, attributes]
          exporters: [jaeger, logging]
        
        # æŒ‡æ ‡æ•°æ®ç®¡é“
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [prometheus]
```

**Collector Deployment**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: observability
spec:
  replicas: 3
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.91.0
        args:
          - --config=/conf/otel-collector-config.yaml
        ports:
        - containerPort: 4317  # OTLP gRPC
          name: otlp-grpc
        - containerPort: 4318  # OTLP HTTP
          name: otlp-http
        - containerPort: 14250 # Jaeger gRPC
          name: jaeger-grpc
        - containerPort: 14268 # Jaeger HTTP
          name: jaeger-http
        - containerPort: 8889  # Prometheus metrics
          name: prometheus
        - containerPort: 13133 # Health check
          name: health
        volumeMounts:
        - name: config
          mountPath: /conf
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: observability
spec:
  selector:
    app: otel-collector
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  - name: jaeger-grpc
    port: 14250
    targetPort: 14250
  - name: jaeger-http
    port: 14268
    targetPort: 14268
  - name: prometheus
    port: 8889
    targetPort: 8889
  type: ClusterIP
```

**è‡ªåŠ¨åŸ‹ç‚¹ï¼ˆAuto-Instrumentationï¼‰**ï¼š

OpenTelemetryæ”¯æŒé€šè¿‡Operatorè‡ªåŠ¨æ³¨å…¥è¿½è¸ªä»£ç ï¼Œæ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç ã€‚

```yaml
# å®‰è£…OpenTelemetry Operator
kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml

# åˆ›å»ºInstrumentationèµ„æº
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: auto-instrumentation
  namespace: default
spec:
  exporter:
    endpoint: http://otel-collector.observability.svc.cluster.local:4318
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "0.1"  # 10%é‡‡æ ·ç‡
  
  # Javaè‡ªåŠ¨åŸ‹ç‚¹
  java:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java:latest
  
  # Pythonè‡ªåŠ¨åŸ‹ç‚¹
  python:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-python:latest
  
  # Node.jsè‡ªåŠ¨åŸ‹ç‚¹
  nodejs:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-nodejs:latest

---
# åœ¨Deploymentä¸­å¯ç”¨è‡ªåŠ¨åŸ‹ç‚¹ï¼ˆé€šè¿‡annotationï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
spec:
  template:
    metadata:
      annotations:
        # å¯ç”¨Javaè‡ªåŠ¨åŸ‹ç‚¹
        instrumentation.opentelemetry.io/inject-java: "true"
    spec:
      containers:
      - name: order-service
        image: myregistry/order-service:1.0.0
        env:
        - name: OTEL_SERVICE_NAME
          value: "order-service"
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.namespace=ecommerce,deployment.environment=production"
```

### 9.6.3 Jaegeræ¶æ„ä¸éƒ¨ç½²

Jaegeræ˜¯Uberå¼€æºçš„åˆ†å¸ƒå¼è¿½è¸ªç³»ç»Ÿï¼Œç°å·²æˆä¸ºCNCFæ¯•ä¸šé¡¹ç›®ã€‚å®ƒæä¾›äº†å®Œæ•´çš„è¿½è¸ªæ•°æ®æ”¶é›†ã€å­˜å‚¨ã€æŸ¥è¯¢å’Œå¯è§†åŒ–åŠŸèƒ½ã€‚

#### Jaegeræ¶æ„

**æ ¸å¿ƒç»„ä»¶**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Services                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Service Aâ”‚  â”‚ Service Bâ”‚  â”‚ Service Câ”‚  â”‚ Service Dâ”‚   â”‚
â”‚  â”‚ (Jaeger  â”‚  â”‚ (Jaeger  â”‚  â”‚ (Jaeger  â”‚  â”‚ (Jaeger  â”‚   â”‚
â”‚  â”‚  Client) â”‚  â”‚  Client) â”‚  â”‚  Client) â”‚  â”‚  Client) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â”‚ UDP/HTTP    â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Jaeger Agent (DaemonSet)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Agent    â”‚  â”‚ Agent    â”‚  â”‚ Agent    â”‚  â”‚ Agent    â”‚   â”‚
â”‚  â”‚ (Node 1) â”‚  â”‚ (Node 2) â”‚  â”‚ (Node 3) â”‚  â”‚ (Node 4) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â”‚ gRPC        â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Jaeger Collector (Deployment)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  - æ¥æ”¶Spanæ•°æ®                                       â”‚   â”‚
â”‚  â”‚  - æ•°æ®éªŒè¯ä¸å¤„ç†                                     â”‚   â”‚
â”‚  â”‚  - å†™å…¥å­˜å‚¨åç«¯                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Storage Backend                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Elasticsearchâ”‚  â”‚  Cassandra   â”‚  â”‚   Kafka      â”‚      â”‚
â”‚  â”‚  (æ¨è)      â”‚  â”‚  (å¤§è§„æ¨¡)    â”‚  â”‚  (ç¼“å†²)      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–²
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Jaeger Query (Deployment)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  - æŸ¥è¯¢Traceæ•°æ®                                      â”‚   â”‚
â”‚  â”‚  - æä¾›REST API                                       â”‚   â”‚
â”‚  â”‚  - æœåŠ¡ä¾èµ–åˆ†æ                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Jaeger UI (Webç•Œé¢)                       â”‚
â”‚  - Traceæœç´¢ä¸æŸ¥çœ‹                                           â”‚
â”‚  - æœåŠ¡ä¾èµ–æ‹“æ‰‘å›¾                                            â”‚
â”‚  - æ€§èƒ½åˆ†æ                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç»„ä»¶èŒè´£**ï¼š

1. **Jaeger Clientï¼ˆå®¢æˆ·ç«¯åº“ï¼‰**ï¼š
   - åµŒå…¥åº”ç”¨ä»£ç ï¼Œç”ŸæˆSpan
   - æ”¯æŒå¤šç§è¯­è¨€ï¼ˆGoã€Javaã€Pythonã€Node.jsç­‰ï¼‰
   - å·²è¢«OpenTelemetry SDKå–ä»£ï¼ˆæ¨èä½¿ç”¨OTelï¼‰

2. **Jaeger Agentï¼ˆä»£ç†ï¼‰**ï¼š
   - ä»¥DaemonSetæ–¹å¼éƒ¨ç½²åœ¨æ¯ä¸ªèŠ‚ç‚¹
   - ç›‘å¬UDP/HTTPç«¯å£ï¼Œæ¥æ”¶æœ¬åœ°åº”ç”¨çš„Span
   - æ‰¹é‡è½¬å‘Spanåˆ°Collectorï¼ˆå‡å°‘ç½‘ç»œå¼€é”€ï¼‰
   - å¯é€‰ç»„ä»¶ï¼ˆå¯ç›´æ¥å‘é€åˆ°Collectorï¼‰

3. **Jaeger Collectorï¼ˆæ”¶é›†å™¨ï¼‰**ï¼š
   - æ¥æ”¶Spanæ•°æ®ï¼ˆæ¥è‡ªAgentæˆ–ç›´æ¥æ¥è‡ªåº”ç”¨ï¼‰
   - æ•°æ®éªŒè¯ã€å¤„ç†ã€é‡‡æ ·
   - å†™å…¥å­˜å‚¨åç«¯ï¼ˆElasticsearchã€Cassandraã€Kafkaï¼‰
   - æ”¯æŒæ°´å¹³æ‰©å±•

4. **Storage Backendï¼ˆå­˜å‚¨åç«¯ï¼‰**ï¼š
   - **Elasticsearch**ï¼šæ¨èï¼Œæ”¯æŒå…¨æ–‡æœç´¢ï¼Œæ˜“äºè¿ç»´
   - **Cassandra**ï¼šé€‚åˆè¶…å¤§è§„æ¨¡ï¼ˆæ¯å¤©æ•°åäº¿Spanï¼‰
   - **Kafka**ï¼šä½œä¸ºç¼“å†²å±‚ï¼Œè§£è€¦Collectorå’Œå­˜å‚¨
   - **Memory**ï¼šä»…ç”¨äºå¼€å‘æµ‹è¯•

5. **Jaeger Queryï¼ˆæŸ¥è¯¢æœåŠ¡ï¼‰**ï¼š
   - ä»å­˜å‚¨åç«¯æŸ¥è¯¢Traceæ•°æ®
   - æä¾›REST APIä¾›UIè°ƒç”¨
   - ç”ŸæˆæœåŠ¡ä¾èµ–æ‹“æ‰‘å›¾

6. **Jaeger UIï¼ˆWebç•Œé¢ï¼‰**ï¼š
   - å¯è§†åŒ–Traceæ•°æ®
   - æœç´¢ã€è¿‡æ»¤ã€åˆ†æTrace
   - å±•ç¤ºæœåŠ¡ä¾èµ–å…³ç³»

#### Jaeger All-in-Oneéƒ¨ç½²ï¼ˆå¼€å‘æµ‹è¯•ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå¼€å‘ã€æµ‹è¯•ç¯å¢ƒï¼Œå•èŠ‚ç‚¹éƒ¨ç½²ï¼Œæ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:1.52
        env:
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: ":9411"
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        ports:
        - containerPort: 5775   # Jaeger Agent (UDP)
          protocol: UDP
        - containerPort: 6831   # Jaeger Agent (UDP)
          protocol: UDP
        - containerPort: 6832   # Jaeger Agent (UDP)
          protocol: UDP
        - containerPort: 5778   # Jaeger Agent (HTTP)
        - containerPort: 16686  # Jaeger UI
        - containerPort: 14250  # Jaeger Collector (gRPC)
        - containerPort: 14268  # Jaeger Collector (HTTP)
        - containerPort: 14269  # Jaeger Collector (Admin)
        - containerPort: 9411   # Zipkin compatible endpoint
        - containerPort: 4317   # OTLP gRPC
        - containerPort: 4318   # OTLP HTTP
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
---
apiVersion: v1
kind: Service
metadata:
  name: jaeger
  namespace: observability
spec:
  selector:
    app: jaeger
  ports:
  - name: jaeger-agent-udp-5775
    port: 5775
    targetPort: 5775
    protocol: UDP
  - name: jaeger-agent-udp-6831
    port: 6831
    targetPort: 6831
    protocol: UDP
  - name: jaeger-agent-udp-6832
    port: 6832
    targetPort: 6832
    protocol: UDP
  - name: jaeger-agent-http
    port: 5778
    targetPort: 5778
  - name: jaeger-ui
    port: 16686
    targetPort: 16686
  - name: jaeger-collector-grpc
    port: 14250
    targetPort: 14250
  - name: jaeger-collector-http
    port: 14268
    targetPort: 14268
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  type: ClusterIP
---
# Ingressï¼ˆæš´éœ²Jaeger UIï¼‰
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: jaeger-ui
  namespace: observability
spec:
  rules:
  - host: jaeger.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: jaeger
            port:
              number: 16686
```

**è®¿é—®Jaeger UI**ï¼š
```bash
# ç«¯å£è½¬å‘
kubectl port-forward -n observability svc/jaeger 16686:16686

# æµè§ˆå™¨è®¿é—®
open http://localhost:16686
```


#### Jaegerç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆElasticsearchåç«¯ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šç”Ÿäº§ç¯å¢ƒï¼Œé«˜å¯ç”¨ï¼Œæ•°æ®æŒä¹…åŒ–ï¼Œæ”¯æŒå¤§è§„æ¨¡è¿½è¸ªæ•°æ®ã€‚

**1. éƒ¨ç½²Elasticsearché›†ç¾¤**ï¼ˆå‚è€ƒ9.5.3èŠ‚ï¼‰

**2. éƒ¨ç½²Jaeger Collector**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger-collector
  namespace: observability
spec:
  replicas: 3
  selector:
    matchLabels:
      app: jaeger-collector
  template:
    metadata:
      labels:
        app: jaeger-collector
    spec:
      containers:
      - name: jaeger-collector
        image: jaegertracing/jaeger-collector:1.52
        env:
        # Elasticsearché…ç½®
        - name: SPAN_STORAGE_TYPE
          value: elasticsearch
        - name: ES_SERVER_URLS
          value: http://elasticsearch.observability.svc.cluster.local:9200
        - name: ES_INDEX_PREFIX
          value: jaeger
        - name: ES_NUM_SHARDS
          value: "3"
        - name: ES_NUM_REPLICAS
          value: "1"
        
        # Collectoré…ç½®
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: ":9411"
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        - name: COLLECTOR_QUEUE_SIZE
          value: "2000"
        - name: COLLECTOR_NUM_WORKERS
          value: "50"
        
        # é‡‡æ ·é…ç½®
        - name: SAMPLING_STRATEGIES_FILE
          value: /etc/jaeger/sampling-strategies.json
        
        ports:
        - containerPort: 14250  # gRPC
          name: grpc
        - containerPort: 14268  # HTTP
          name: http
        - containerPort: 14269  # Admin/Health
          name: admin
        - containerPort: 9411   # Zipkin
          name: zipkin
        - containerPort: 4317   # OTLP gRPC
          name: otlp-grpc
        - containerPort: 4318   # OTLP HTTP
          name: otlp-http
        
        volumeMounts:
        - name: sampling-config
          mountPath: /etc/jaeger
        
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        
        livenessProbe:
          httpGet:
            path: /
            port: 14269
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /
            port: 14269
          initialDelaySeconds: 10
          periodSeconds: 5
      
      volumes:
      - name: sampling-config
        configMap:
          name: jaeger-sampling-config
---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-collector
  namespace: observability
spec:
  selector:
    app: jaeger-collector
  ports:
  - name: grpc
    port: 14250
    targetPort: 14250
  - name: http
    port: 14268
    targetPort: 14268
  - name: zipkin
    port: 9411
    targetPort: 9411
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  type: ClusterIP
---
# é‡‡æ ·ç­–ç•¥é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-sampling-config
  namespace: observability
data:
  sampling-strategies.json: |
    {
      "default_strategy": {
        "type": "probabilistic",
        "param": 0.1
      },
      "service_strategies": [
        {
          "service": "order-service",
          "type": "probabilistic",
          "param": 0.5
        },
        {
          "service": "payment-service",
          "type": "probabilistic",
          "param": 1.0
        },
        {
          "service": "notification-service",
          "type": "probabilistic",
          "param": 0.01
        }
      ]
    }
```

**3. éƒ¨ç½²Jaeger Query**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger-query
  namespace: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: jaeger-query
  template:
    metadata:
      labels:
        app: jaeger-query
    spec:
      containers:
      - name: jaeger-query
        image: jaegertracing/jaeger-query:1.52
        env:
        # Elasticsearché…ç½®
        - name: SPAN_STORAGE_TYPE
          value: elasticsearch
        - name: ES_SERVER_URLS
          value: http://elasticsearch.observability.svc.cluster.local:9200
        - name: ES_INDEX_PREFIX
          value: jaeger
        
        # Queryé…ç½®
        - name: QUERY_BASE_PATH
          value: /
        - name: QUERY_MAX_CLOCK_SKEW_ADJUSTMENT
          value: 0s
        
        ports:
        - containerPort: 16686  # UI
          name: ui
        - containerPort: 16687  # Admin/Health
          name: admin
        
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
        
        livenessProbe:
          httpGet:
            path: /
            port: 16687
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /
            port: 16687
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-query
  namespace: observability
spec:
  selector:
    app: jaeger-query
  ports:
  - name: ui
    port: 16686
    targetPort: 16686
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: jaeger-query
  namespace: observability
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: jaeger.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: jaeger-query
            port:
              number: 16686
```

**4. éƒ¨ç½²Jaeger Agentï¼ˆå¯é€‰ï¼‰**ï¼š

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: jaeger-agent
  namespace: observability
spec:
  selector:
    matchLabels:
      app: jaeger-agent
  template:
    metadata:
      labels:
        app: jaeger-agent
    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: jaeger-agent
        image: jaegertracing/jaeger-agent:1.52
        env:
        - name: REPORTER_GRPC_HOST_PORT
          value: jaeger-collector.observability.svc.cluster.local:14250
        - name: REPORTER_TYPE
          value: grpc
        
        ports:
        - containerPort: 5775
          protocol: UDP
          hostPort: 5775
        - containerPort: 6831
          protocol: UDP
          hostPort: 6831
        - containerPort: 6832
          protocol: UDP
          hostPort: 6832
        - containerPort: 5778
          protocol: TCP
          hostPort: 5778
        
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 128Mi
```

**5. Elasticsearchç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼š

```bash
# åˆ›å»ºILMç­–ç•¥ï¼ˆè‡ªåŠ¨åˆ é™¤æ—§æ•°æ®ï¼‰
curl -X PUT "http://elasticsearch.observability.svc.cluster.local:9200/_ilm/policy/jaeger-ilm-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          }
        }
      },
      "delete": {
        "min_age": "7d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}'

# åº”ç”¨ILMç­–ç•¥åˆ°Jaegerç´¢å¼•
curl -X PUT "http://elasticsearch.observability.svc.cluster.local:9200/jaeger-*/_settings" -H 'Content-Type: application/json' -d'
{
  "index.lifecycle.name": "jaeger-ilm-policy"
}'
```

### 9.6.4 åº”ç”¨åŸ‹ç‚¹ä¸SDKé›†æˆ

#### æ‰‹åŠ¨åŸ‹ç‚¹æœ€ä½³å®è·µ

**1. Spanå‘½åè§„èŒƒ**ï¼š

```go
// âŒ ä¸å¥½çš„å‘½åï¼ˆå¤ªæ³›åŒ–ï¼‰
span := tracer.Start(ctx, "process")
span := tracer.Start(ctx, "handle")

// âœ… å¥½çš„å‘½åï¼ˆæ¸…æ™°æè¿°æ“ä½œï¼‰
span := tracer.Start(ctx, "ProcessOrder")
span := tracer.Start(ctx, "GET /api/users/{id}")
span := tracer.Start(ctx, "mysql.query.users")
span := tracer.Start(ctx, "redis.get.user:123")
```

**å‘½åè§„èŒƒ**ï¼š
- HTTPè¯·æ±‚ï¼š`HTTPæ–¹æ³• + è·¯å¾„æ¨¡æ¿`ï¼ˆå¦‚ `GET /api/orders/{id}`ï¼‰
- æ•°æ®åº“æ“ä½œï¼š`dbç±»å‹.æ“ä½œ.è¡¨å`ï¼ˆå¦‚ `mysql.select.orders`ï¼‰
- ç¼“å­˜æ“ä½œï¼š`cacheç±»å‹.æ“ä½œ.keyæ¨¡å¼`ï¼ˆå¦‚ `redis.get.user:*`ï¼‰
- æ¶ˆæ¯é˜Ÿåˆ—ï¼š`mqç±»å‹.æ“ä½œ.topic`ï¼ˆå¦‚ `kafka.produce.order-events`ï¼‰
- å‡½æ•°è°ƒç”¨ï¼š`ç±»å.æ–¹æ³•å`ï¼ˆå¦‚ `OrderService.CreateOrder`ï¼‰

**2. Spanå±æ€§ï¼ˆTagsï¼‰æœ€ä½³å®è·µ**ï¼š

```go
import "go.opentelemetry.io/otel/semconv/v1.17.0"

// âœ… ä½¿ç”¨è¯­ä¹‰åŒ–çº¦å®šï¼ˆSemantic Conventionsï¼‰
span.SetAttributes(
    // HTTPå±æ€§
    semconv.HTTPMethodKey.String("POST"),
    semconv.HTTPURLKey.String("https://api.example.com/orders"),
    semconv.HTTPStatusCodeKey.Int(200),
    semconv.HTTPRequestContentLengthKey.Int(1024),
    
    // æ•°æ®åº“å±æ€§
    semconv.DBSystemKey.String("mysql"),
    semconv.DBStatementKey.String("SELECT * FROM orders WHERE id = ?"),
    semconv.DBNameKey.String("ecommerce"),
    semconv.DBOperationKey.String("SELECT"),
    
    // æ¶ˆæ¯é˜Ÿåˆ—å±æ€§
    semconv.MessagingSystemKey.String("kafka"),
    semconv.MessagingDestinationKey.String("order-events"),
    semconv.MessagingOperationKey.String("publish"),
    
    // ä¸šåŠ¡å±æ€§
    attribute.String("order.id", "order-12345"),
    attribute.Float64("order.amount", 99.99),
    attribute.String("user.id", "user-67890"),
)
```

**3. Spanäº‹ä»¶ï¼ˆEventsï¼‰æœ€ä½³å®è·µ**ï¼š

```go
// è®°å½•å…³é”®ä¸šåŠ¡äº‹ä»¶
span.AddEvent("Order validation started")
span.AddEvent("Inventory checked", trace.WithAttributes(
    attribute.Int("inventory.available", 100),
))
span.AddEvent("Payment processed", trace.WithAttributes(
    attribute.String("payment.transaction_id", "txn-123"),
    attribute.Float64("payment.amount", 99.99),
))
span.AddEvent("Order created successfully")

// è®°å½•å¼‚å¸¸
if err != nil {
    span.RecordError(err, trace.WithAttributes(
        attribute.String("error.type", "ValidationError"),
    ))
    span.SetStatus(codes.Error, err.Error())
}
```

**4. Spanç±»å‹ï¼ˆSpan Kindï¼‰**ï¼š

```go
// SERVER: å¤„ç†RPC/HTTPè¯·æ±‚çš„æœåŠ¡ç«¯
span := tracer.Start(ctx, "GET /api/orders",
    trace.WithSpanKind(trace.SpanKindServer),
)

// CLIENT: å‘èµ·RPC/HTTPè¯·æ±‚çš„å®¢æˆ·ç«¯
span := tracer.Start(ctx, "Call UserService",
    trace.WithSpanKind(trace.SpanKindClient),
)

// PRODUCER: æ¶ˆæ¯ç”Ÿäº§è€…
span := tracer.Start(ctx, "Publish OrderCreated Event",
    trace.WithSpanKind(trace.SpanKindProducer),
)

// CONSUMER: æ¶ˆæ¯æ¶ˆè´¹è€…
span := tracer.Start(ctx, "Consume OrderCreated Event",
    trace.WithSpanKind(trace.SpanKindConsumer),
)

// INTERNAL: å†…éƒ¨æ“ä½œï¼ˆé»˜è®¤ï¼‰
span := tracer.Start(ctx, "ValidateOrder",
    trace.WithSpanKind(trace.SpanKindInternal),
)
```

#### ä¸­é—´ä»¶è‡ªåŠ¨åŸ‹ç‚¹

**HTTPä¸­é—´ä»¶ï¼ˆGo Ginæ¡†æ¶ï¼‰**ï¼š

```go
import (
    "github.com/gin-gonic/gin"
    "go.opentelemetry.io/contrib/instrumentation/github.com/gin-gonic/gin/otelgin"
    "go.opentelemetry.io/otel"
)

func main() {
    r := gin.Default()
    
    // ä½¿ç”¨OpenTelemetryä¸­é—´ä»¶ï¼ˆè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰HTTPè¯·æ±‚ï¼‰
    r.Use(otelgin.Middleware("order-service"))
    
    r.GET("/api/orders/:id", getOrder)
    r.POST("/api/orders", createOrder)
    
    r.Run(":8080")
}

func getOrder(c *gin.Context) {
    // ä»Contextè·å–å½“å‰Span
    span := trace.SpanFromContext(c.Request.Context())
    
    // æ·»åŠ è‡ªå®šä¹‰å±æ€§
    orderID := c.Param("id")
    span.SetAttributes(attribute.String("order.id", orderID))
    
    // ä¸šåŠ¡é€»è¾‘...
    order := fetchOrderFromDB(c.Request.Context(), orderID)
    
    c.JSON(200, order)
}
```

**gRPCæ‹¦æˆªå™¨ï¼ˆGoï¼‰**ï¼š

```go
import (
    "google.golang.org/grpc"
    "go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc"
)

// gRPCæœåŠ¡ç«¯
func main() {
    server := grpc.NewServer(
        grpc.UnaryInterceptor(otelgrpc.UnaryServerInterceptor()),
        grpc.StreamInterceptor(otelgrpc.StreamServerInterceptor()),
    )
    
    pb.RegisterOrderServiceServer(server, &orderServiceServer{})
    server.Serve(lis)
}

// gRPCå®¢æˆ·ç«¯
func newUserServiceClient() pb.UserServiceClient {
    conn, _ := grpc.Dial(
        "user-service:50051",
        grpc.WithUnaryInterceptor(otelgrpc.UnaryClientInterceptor()),
        grpc.WithStreamInterceptor(otelgrpc.StreamClientInterceptor()),
    )
    return pb.NewUserServiceClient(conn)
}
```

**æ•°æ®åº“è‡ªåŠ¨åŸ‹ç‚¹ï¼ˆGo GORMï¼‰**ï¼š

```go
import (
    "gorm.io/driver/mysql"
    "gorm.io/gorm"
    "go.opentelemetry.io/contrib/instrumentation/gorm.io/gorm/otelgorm"
)

func initDB() *gorm.DB {
    db, _ := gorm.Open(mysql.Open(dsn), &gorm.Config{})
    
    // æ³¨å†ŒOpenTelemetryæ’ä»¶ï¼ˆè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰SQLæŸ¥è¯¢ï¼‰
    if err := db.Use(otelgorm.NewPlugin()); err != nil {
        panic(err)
    }
    
    return db
}

// ä½¿ç”¨æ—¶è‡ªåŠ¨åˆ›å»ºSpan
func getUser(ctx context.Context, userID string) (*User, error) {
    var user User
    // è‡ªåŠ¨åˆ›å»ºSpan: "gorm.query"
    err := db.WithContext(ctx).Where("id = ?", userID).First(&user).Error
    return &user, err
}
```

**Redisè‡ªåŠ¨åŸ‹ç‚¹ï¼ˆGo go-redisï¼‰**ï¼š

```go
import (
    "github.com/go-redis/redis/v8"
    "go.opentelemetry.io/contrib/instrumentation/github.com/go-redis/redis/v8/otelredis"
)

func initRedis() *redis.Client {
    rdb := redis.NewClient(&redis.Options{
        Addr: "redis:6379",
    })
    
    // æ·»åŠ OpenTelemetry Hookï¼ˆè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰Rediså‘½ä»¤ï¼‰
    rdb.AddHook(otelredis.NewTracingHook())
    
    return rdb
}

// ä½¿ç”¨æ—¶è‡ªåŠ¨åˆ›å»ºSpan
func getCache(ctx context.Context, key string) (string, error) {
    // è‡ªåŠ¨åˆ›å»ºSpan: "redis.get"
    return rdb.Get(ctx, key).Result()
}
```

#### è·¨è¯­è¨€è¿½è¸ªç¤ºä¾‹

**åœºæ™¯**ï¼šGoæœåŠ¡ â†’ JavaæœåŠ¡ â†’ PythonæœåŠ¡

**GoæœåŠ¡ï¼ˆAPI Gatewayï¼‰**ï¼š

```go
func handleRequest(c *gin.Context) {
    ctx := c.Request.Context()
    
    // åˆ›å»ºRoot Span
    ctx, span := tracer.Start(ctx, "API Gateway: Process Request",
        trace.WithSpanKind(trace.SpanKindServer),
    )
    defer span.End()
    
    // è°ƒç”¨JavaæœåŠ¡
    userResp := callUserService(ctx, userID)
    
    // è°ƒç”¨PythonæœåŠ¡
    inventoryResp := callInventoryService(ctx, productID)
    
    c.JSON(200, gin.H{
        "user": userResp,
        "inventory": inventoryResp,
    })
}

func callUserService(ctx context.Context, userID string) map[string]interface{} {
    // åˆ›å»ºHTTPè¯·æ±‚
    req, _ := http.NewRequestWithContext(ctx, "GET", 
        "http://user-service:8080/api/users/"+userID, nil)
    
    // æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡åˆ°HTTP Header
    otel.GetTextMapPropagator().Inject(ctx, propagation.HeaderCarrier(req.Header))
    
    // å‘é€è¯·æ±‚
    resp, _ := http.DefaultClient.Do(req)
    defer resp.Body.Close()
    
    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    return result
}
```

**JavaæœåŠ¡ï¼ˆUser Serviceï¼‰**ï¼š

```java
@RestController
@RequestMapping("/api/users")
public class UserController {

    @Autowired
    private Tracer tracer;

    @Autowired
    private RestTemplate restTemplate;

    @GetMapping("/{id}")
    public ResponseEntity<User> getUser(@PathVariable String id, 
                                        @RequestHeader HttpHeaders headers) {
        // æå–è¿½è¸ªä¸Šä¸‹æ–‡
        Context extractedContext = otel.getPropagators().getTextMapPropagator()
            .extract(Context.current(), headers, new HttpHeadersGetter());
        
        // åˆ›å»ºChild Span
        Span span = tracer.spanBuilder("UserService: Get User")
            .setParent(extractedContext)
            .setSpanKind(SpanKind.SERVER)
            .startSpan();
        
        try (Scope scope = span.makeCurrent()) {
            // æŸ¥è¯¢æ•°æ®åº“
            User user = userRepository.findById(id);
            
            // è°ƒç”¨PythonæœåŠ¡è·å–ç”¨æˆ·åå¥½
            String preferencesUrl = "http://preference-service:5000/api/preferences/" + id;
            Preferences prefs = restTemplate.getForObject(preferencesUrl, Preferences.class);
            user.setPreferences(prefs);
            
            return ResponseEntity.ok(user);
        } finally {
            span.end();
        }
    }
}
```

**PythonæœåŠ¡ï¼ˆPreference Serviceï¼‰**ï¼š

```python
from flask import Flask, request
from opentelemetry import trace
from opentelemetry.propagate import extract

app = Flask(__name__)
tracer = trace.get_tracer(__name__)

@app.route('/api/preferences/<user_id>')
def get_preferences(user_id):
    # æå–è¿½è¸ªä¸Šä¸‹æ–‡
    ctx = extract(request.headers)
    
    # åˆ›å»ºChild Span
    with tracer.start_as_current_span(
        "PreferenceService: Get Preferences",
        context=ctx,
        kind=trace.SpanKind.SERVER
    ) as span:
        span.set_attribute("user.id", user_id)
        
        # æŸ¥è¯¢æ•°æ®åº“
        preferences = db.query(f"SELECT * FROM preferences WHERE user_id = '{user_id}'")
        
        span.add_event("Preferences fetched", {
            "preferences.count": len(preferences)
        })
        
        return {"user_id": user_id, "preferences": preferences}
```

**å®Œæ•´è°ƒç”¨é“¾**ï¼š

```
Trace ID: a1b2c3d4e5f6g7h8

Span 1: API Gateway: Process Request (Go)
â”œâ”€ Duration: 850ms
â”œâ”€ Service: api-gateway
â”‚
â”œâ”€ Span 2: UserService: Get User (Java)
â”‚  â”œâ”€ Duration: 600ms
â”‚  â”œâ”€ Service: user-service
â”‚  â”œâ”€ Parent: Span 1
â”‚  â”‚
â”‚  â””â”€ Span 3: PreferenceService: Get Preferences (Python)
â”‚     â”œâ”€ Duration: 200ms
â”‚     â”œâ”€ Service: preference-service
â”‚     â””â”€ Parent: Span 2
â”‚
â””â”€ Span 4: InventoryService: Check Stock (Python)
   â”œâ”€ Duration: 150ms
   â”œâ”€ Service: inventory-service
   â””â”€ Parent: Span 1
```


### 9.6.5 è°ƒç”¨é“¾è·¯åˆ†æå®æˆ˜

#### Jaeger UIä½¿ç”¨æŒ‡å—

**1. Traceæœç´¢**ï¼š

è®¿é—®Jaeger UIï¼ˆhttp://jaeger.example.comï¼‰ï¼Œä¸»ç•Œé¢æä¾›å¼ºå¤§çš„æœç´¢åŠŸèƒ½ï¼š

```
æœç´¢æ¡ä»¶ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service: [order-service â–¼]                                  â”‚
â”‚ Operation: [All â–¼] æˆ– [POST /api/orders]                    â”‚
â”‚ Tags: [http.status_code=500] [error=true]                   â”‚
â”‚ Lookback: [Last Hour â–¼] æˆ– [Custom Time Range]              â”‚
â”‚ Min Duration: [1s]  Max Duration: [10s]                     â”‚
â”‚ Limit Results: [20 â–¼]                                        â”‚
â”‚                                                              â”‚
â”‚ [Find Traces]                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å¸¸ç”¨æœç´¢åœºæ™¯**ï¼š

```bash
# æŸ¥æ‰¾é”™è¯¯è¯·æ±‚
Tags: error=true

# æŸ¥æ‰¾æ…¢è¯·æ±‚ï¼ˆ>1ç§’ï¼‰
Min Duration: 1s

# æŸ¥æ‰¾ç‰¹å®šç”¨æˆ·çš„è¯·æ±‚
Tags: user.id=user-12345

# æŸ¥æ‰¾ç‰¹å®šè®¢å•çš„å®Œæ•´é“¾è·¯
Tags: order.id=order-67890

# æŸ¥æ‰¾HTTP 500é”™è¯¯
Tags: http.status_code=500

# æŸ¥æ‰¾æ•°æ®åº“æ…¢æŸ¥è¯¢
Operation: mysql.query.orders
Min Duration: 500ms

# ç»„åˆæŸ¥è¯¢ï¼ˆæ…¢ä¸”å‡ºé”™çš„æ”¯ä»˜è¯·æ±‚ï¼‰
Service: payment-service
Tags: error=true
Min Duration: 2s
```

**2. Traceè¯¦æƒ…é¡µ**ï¼š

ç‚¹å‡»ä»»æ„Traceï¼Œè¿›å…¥è¯¦æƒ…é¡µï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trace Timeline (Gantt Chart)                                â”‚
â”‚                                                              â”‚
â”‚ order-service: POST /api/orders [850ms] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
â”‚   â”œâ”€ user-service: GET /api/users/123 [50ms] â–ˆâ–ˆ            â”‚
â”‚   â”œâ”€ inventory-service: POST /check [120ms] â–ˆâ–ˆâ–ˆâ–ˆ           â”‚
â”‚   â”œâ”€ payment-service: POST /charge [600ms] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚
â”‚   â”‚   â””â”€ stripe-api: POST /charges [580ms] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚
â”‚   â””â”€ notification-service: POST /send [30ms] â–ˆ             â”‚
â”‚                                                              â”‚
â”‚ 0ms        200ms       400ms       600ms       800ms        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Spanè¯¦æƒ…ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Span: payment-service: POST /charge                          â”‚
â”‚ Duration: 600ms (70% of trace)                               â”‚
â”‚ Start Time: 2024-01-20 10:30:15.200                          â”‚
â”‚                                                              â”‚
â”‚ Tags:                                                        â”‚
â”‚   http.method: POST                                          â”‚
â”‚   http.url: /api/payment/charge                              â”‚
â”‚   http.status_code: 200                                      â”‚
â”‚   payment.amount: 99.99                                      â”‚
â”‚   payment.currency: USD                                      â”‚
â”‚   payment.provider: stripe                                   â”‚
â”‚                                                              â”‚
â”‚ Logs:                                                        â”‚
â”‚   [10:30:15.250] stripe_api_call_start                       â”‚
â”‚   [10:30:15.830] stripe_api_call_success                     â”‚
â”‚                  charge_id: ch_1234567890                    â”‚
â”‚                                                              â”‚
â”‚ Process:                                                     â”‚
â”‚   service.name: payment-service                              â”‚
â”‚   service.version: 1.0.0                                     â”‚
â”‚   host.name: payment-pod-abc123                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3. æœåŠ¡ä¾èµ–æ‹“æ‰‘å›¾ï¼ˆSystem Architectureï¼‰**ï¼š

ç‚¹å‡»é¡¶éƒ¨èœå• "System Architecture"ï¼ŒæŸ¥çœ‹æœåŠ¡ä¾èµ–å…³ç³»ï¼š

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ api-gateway â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  user-   â”‚    â”‚inventory-â”‚    â”‚ payment- â”‚
    â”‚ service  â”‚    â”‚ service  â”‚    â”‚ service  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ stripe-  â”‚
                                    â”‚   api    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

èŠ‚ç‚¹ä¿¡æ¯ï¼š
- åœ†åœˆå¤§å°ï¼šè¯·æ±‚é‡
- è¿çº¿ç²—ç»†ï¼šè°ƒç”¨é¢‘ç‡
- é¢œè‰²ï¼šé”™è¯¯ç‡ï¼ˆç»¿è‰²=æ­£å¸¸ï¼Œçº¢è‰²=é«˜é”™è¯¯ç‡ï¼‰
```

**4. æ€§èƒ½å¯¹æ¯”ï¼ˆCompare Tracesï¼‰**ï¼š

é€‰æ‹©å¤šä¸ªTraceè¿›è¡Œå¯¹æ¯”ï¼Œæ‰¾å‡ºæ€§èƒ½å·®å¼‚ï¼š

```
Trace 1 (Fast - 200ms):
order-service [200ms]
  â”œâ”€ user-service [30ms]
  â”œâ”€ inventory-service [50ms]
  â”œâ”€ payment-service [100ms]  â† æ­£å¸¸
  â””â”€ notification-service [20ms]

Trace 2 (Slow - 850ms):
order-service [850ms]
  â”œâ”€ user-service [50ms]
  â”œâ”€ inventory-service [120ms]
  â”œâ”€ payment-service [600ms]  â† ç“¶é¢ˆï¼
  â””â”€ notification-service [30ms]

å·®å¼‚åˆ†æï¼š
- payment-serviceè€—æ—¶ä»100mså¢åŠ åˆ°600msï¼ˆ6å€ï¼‰
- åŸå› ï¼šè°ƒç”¨å¤–éƒ¨Stripe APIè¶…æ—¶
- ä¼˜åŒ–å»ºè®®ï¼šå¢åŠ è¶…æ—¶æ§åˆ¶ã€å¼‚æ­¥å¤„ç†ã€é‡è¯•æœºåˆ¶
```

#### æ€§èƒ½ç“¶é¢ˆå®šä½æ¡ˆä¾‹

**æ¡ˆä¾‹1ï¼šæ•°æ®åº“N+1æŸ¥è¯¢é—®é¢˜**

**é—®é¢˜ç°è±¡**ï¼š
```
Trace: GET /api/orders (æ€»è€—æ—¶: 5.2ç§’)
â”œâ”€ OrderService.getOrders [5.1s]
â”‚  â”œâ”€ mysql.query: SELECT * FROM orders [50ms]
â”‚  â”œâ”€ mysql.query: SELECT * FROM users WHERE id=1 [10ms]
â”‚  â”œâ”€ mysql.query: SELECT * FROM users WHERE id=2 [10ms]
â”‚  â”œâ”€ mysql.query: SELECT * FROM users WHERE id=3 [10ms]
â”‚  â”œâ”€ ... (é‡å¤100æ¬¡)
â”‚  â””â”€ mysql.query: SELECT * FROM users WHERE id=100 [10ms]
```

**é—®é¢˜åˆ†æ**ï¼š
- æŸ¥è¯¢100ä¸ªè®¢å•åï¼Œé€ä¸ªæŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯ï¼ˆN+1é—®é¢˜ï¼‰
- æ€»è€—æ—¶ = 50msï¼ˆè®¢å•æŸ¥è¯¢ï¼‰+ 100 Ã— 10msï¼ˆç”¨æˆ·æŸ¥è¯¢ï¼‰= 1050ms

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

```go
// âŒ åŸä»£ç ï¼ˆN+1æŸ¥è¯¢ï¼‰
func getOrders(ctx context.Context) ([]Order, error) {
    ctx, span := tracer.Start(ctx, "OrderService.getOrders")
    defer span.End()
    
    // æŸ¥è¯¢æ‰€æœ‰è®¢å•
    orders, _ := db.WithContext(ctx).Find(&orders).Error
    
    // é€ä¸ªæŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯
    for i := range orders {
        var user User
        db.WithContext(ctx).Where("id = ?", orders[i].UserID).First(&user)
        orders[i].User = user
    }
    
    return orders, nil
}

// âœ… ä¼˜åŒ–åï¼ˆæ‰¹é‡æŸ¥è¯¢ï¼‰
func getOrders(ctx context.Context) ([]Order, error) {
    ctx, span := tracer.Start(ctx, "OrderService.getOrders")
    defer span.End()
    
    // æŸ¥è¯¢æ‰€æœ‰è®¢å•
    orders, _ := db.WithContext(ctx).Find(&orders).Error
    
    // æå–æ‰€æœ‰ç”¨æˆ·ID
    userIDs := make([]int, len(orders))
    for i, order := range orders {
        userIDs[i] = order.UserID
    }
    
    // æ‰¹é‡æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯
    var users []User
    db.WithContext(ctx).Where("id IN ?", userIDs).Find(&users)
    
    // æ„å»ºç”¨æˆ·æ˜ å°„
    userMap := make(map[int]User)
    for _, user := range users {
        userMap[user.ID] = user
    }
    
    // å…³è”ç”¨æˆ·ä¿¡æ¯
    for i := range orders {
        orders[i].User = userMap[orders[i].UserID]
    }
    
    return orders, nil
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
```
Trace: GET /api/orders (æ€»è€—æ—¶: 80ms)
â”œâ”€ OrderService.getOrders [70ms]
â”‚  â”œâ”€ mysql.query: SELECT * FROM orders [50ms]
â”‚  â””â”€ mysql.query: SELECT * FROM users WHERE id IN (...) [20ms]

æ€§èƒ½æå‡ï¼š5.2ç§’ â†’ 80msï¼ˆ65å€æå‡ï¼‰
```

**æ¡ˆä¾‹2ï¼šç¼“å­˜ç©¿é€é—®é¢˜**

**é—®é¢˜ç°è±¡**ï¼š
```
Trace: GET /api/products/999 (æ€»è€—æ—¶: 2.5ç§’)
â”œâ”€ ProductService.getProduct [2.4s]
â”‚  â”œâ”€ redis.get: product:999 [5ms] â†’ MISS
â”‚  â”œâ”€ mysql.query: SELECT * FROM products WHERE id=999 [2.3s]
â”‚  â””â”€ redis.set: product:999 [10ms]

å¤§é‡ç›¸ä¼¼Traceï¼ˆåŒä¸€ä¸ªä¸å­˜åœ¨çš„äº§å“IDï¼‰ï¼š
- æ¯æ¬¡éƒ½æŸ¥è¯¢æ•°æ®åº“ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
- æ•°æ®åº“æŸ¥è¯¢æ…¢ï¼ˆå…¨è¡¨æ‰«æï¼‰
- æ²¡æœ‰ç¼“å­˜ç©ºç»“æœ
```

**é—®é¢˜åˆ†æ**ï¼š
- æ¶æ„è¯·æ±‚æŸ¥è¯¢ä¸å­˜åœ¨çš„äº§å“ID
- ç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ¯æ¬¡éƒ½ç©¿é€åˆ°æ•°æ®åº“
- æ•°æ®åº“å‹åŠ›æ¿€å¢ï¼Œå“åº”å˜æ…¢

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

```go
// âŒ åŸä»£ç ï¼ˆç¼“å­˜ç©¿é€ï¼‰
func getProduct(ctx context.Context, productID string) (*Product, error) {
    ctx, span := tracer.Start(ctx, "ProductService.getProduct")
    defer span.End()
    
    // æŸ¥è¯¢ç¼“å­˜
    cacheKey := "product:" + productID
    cached, err := redis.Get(ctx, cacheKey).Result()
    if err == nil {
        var product Product
        json.Unmarshal([]byte(cached), &product)
        return &product, nil
    }
    
    // æŸ¥è¯¢æ•°æ®åº“
    var product Product
    err = db.WithContext(ctx).Where("id = ?", productID).First(&product).Error
    if err != nil {
        return nil, err  // ä¸å­˜åœ¨çš„äº§å“ï¼Œä¸ç¼“å­˜
    }
    
    // å†™å…¥ç¼“å­˜
    data, _ := json.Marshal(product)
    redis.Set(ctx, cacheKey, data, 1*time.Hour)
    
    return &product, nil
}

// âœ… ä¼˜åŒ–åï¼ˆç¼“å­˜ç©ºç»“æœ + å¸ƒéš†è¿‡æ»¤å™¨ï¼‰
var productBloomFilter *bloom.BloomFilter

func init() {
    // åˆå§‹åŒ–å¸ƒéš†è¿‡æ»¤å™¨ï¼ˆé¢„åŠ è½½æ‰€æœ‰å­˜åœ¨çš„äº§å“IDï¼‰
    productBloomFilter = bloom.NewWithEstimates(1000000, 0.01)
    
    var productIDs []string
    db.Model(&Product{}).Pluck("id", &productIDs)
    for _, id := range productIDs {
        productBloomFilter.AddString(id)
    }
}

func getProduct(ctx context.Context, productID string) (*Product, error) {
    ctx, span := tracer.Start(ctx, "ProductService.getProduct")
    defer span.End()
    
    // å¸ƒéš†è¿‡æ»¤å™¨å¿«é€Ÿåˆ¤æ–­ï¼ˆä¸å­˜åœ¨åˆ™ç›´æ¥è¿”å›ï¼‰
    if !productBloomFilter.TestString(productID) {
        span.SetAttributes(attribute.Bool("bloom_filter.hit", true))
        return nil, ErrProductNotFound
    }
    
    // æŸ¥è¯¢ç¼“å­˜
    cacheKey := "product:" + productID
    cached, err := redis.Get(ctx, cacheKey).Result()
    if err == nil {
        if cached == "NULL" {
            // ç¼“å­˜çš„ç©ºç»“æœ
            return nil, ErrProductNotFound
        }
        var product Product
        json.Unmarshal([]byte(cached), &product)
        return &product, nil
    }
    
    // æŸ¥è¯¢æ•°æ®åº“
    var product Product
    err = db.WithContext(ctx).Where("id = ?", productID).First(&product).Error
    if err != nil {
        // ç¼“å­˜ç©ºç»“æœï¼ˆ5åˆ†é’Ÿï¼‰
        redis.Set(ctx, cacheKey, "NULL", 5*time.Minute)
        return nil, ErrProductNotFound
    }
    
    // å†™å…¥ç¼“å­˜
    data, _ := json.Marshal(product)
    redis.Set(ctx, cacheKey, data, 1*time.Hour)
    
    return &product, nil
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
```
Trace: GET /api/products/999 (æ€»è€—æ—¶: 2ms)
â”œâ”€ ProductService.getProduct [1ms]
â”‚  â””â”€ bloom_filter.test [1ms] â†’ NOT_EXIST

æ€§èƒ½æå‡ï¼š2.5ç§’ â†’ 2msï¼ˆ1250å€æå‡ï¼‰
æ•°æ®åº“æŸ¥è¯¢ï¼š100% â†’ 0%ï¼ˆå®Œå…¨é¿å…ï¼‰
```

**æ¡ˆä¾‹3ï¼šå¹¶å‘è°ƒç”¨ä¼˜åŒ–**

**é—®é¢˜ç°è±¡**ï¼š
```
Trace: POST /api/orders (æ€»è€—æ—¶: 1.2ç§’)
â”œâ”€ OrderService.createOrder [1.15s]
â”‚  â”œâ”€ UserService.getUser [300ms]        â† ä¸²è¡Œ
â”‚  â”œâ”€ InventoryService.checkStock [400ms] â† ä¸²è¡Œ
â”‚  â”œâ”€ PricingService.calculatePrice [200ms] â† ä¸²è¡Œ
â”‚  â””â”€ PaymentService.charge [250ms]
```

**é—®é¢˜åˆ†æ**ï¼š
- å‰ä¸‰ä¸ªæœåŠ¡è°ƒç”¨æ˜¯ç‹¬ç«‹çš„ï¼Œå¯ä»¥å¹¶å‘æ‰§è¡Œ
- ä¸²è¡Œæ‰§è¡Œå¯¼è‡´æ€»è€—æ—¶ = 300 + 400 + 200 = 900ms
- å¹¶å‘æ‰§è¡Œåæ€»è€—æ—¶ = max(300, 400, 200) = 400ms

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

```go
// âŒ åŸä»£ç ï¼ˆä¸²è¡Œè°ƒç”¨ï¼‰
func createOrder(ctx context.Context, req *CreateOrderRequest) (*Order, error) {
    ctx, span := tracer.Start(ctx, "OrderService.createOrder")
    defer span.End()
    
    // ä¸²è¡Œè°ƒç”¨
    user, _ := userService.GetUser(ctx, req.UserID)
    stock, _ := inventoryService.CheckStock(ctx, req.ProductID)
    price, _ := pricingService.CalculatePrice(ctx, req.ProductID, req.Quantity)
    
    // æ”¯ä»˜
    payment, _ := paymentService.Charge(ctx, user.ID, price)
    
    // åˆ›å»ºè®¢å•
    order := &Order{...}
    db.Create(order)
    
    return order, nil
}

// âœ… ä¼˜åŒ–åï¼ˆå¹¶å‘è°ƒç”¨ï¼‰
func createOrder(ctx context.Context, req *CreateOrderRequest) (*Order, error) {
    ctx, span := tracer.Start(ctx, "OrderService.createOrder")
    defer span.End()
    
    // å¹¶å‘è°ƒç”¨ï¼ˆä½¿ç”¨errgroupï¼‰
    var (
        user  *User
        stock *Stock
        price float64
    )
    
    g, ctx := errgroup.WithContext(ctx)
    
    g.Go(func() error {
        var err error
        user, err = userService.GetUser(ctx, req.UserID)
        return err
    })
    
    g.Go(func() error {
        var err error
        stock, err = inventoryService.CheckStock(ctx, req.ProductID)
        return err
    })
    
    g.Go(func() error {
        var err error
        price, err = pricingService.CalculatePrice(ctx, req.ProductID, req.Quantity)
        return err
    })
    
    // ç­‰å¾…æ‰€æœ‰å¹¶å‘è°ƒç”¨å®Œæˆ
    if err := g.Wait(); err != nil {
        return nil, err
    }
    
    // æ”¯ä»˜ï¼ˆä¾èµ–å‰é¢çš„ç»“æœï¼‰
    payment, _ := paymentService.Charge(ctx, user.ID, price)
    
    // åˆ›å»ºè®¢å•
    order := &Order{...}
    db.Create(order)
    
    return order, nil
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
```
Trace: POST /api/orders (æ€»è€—æ—¶: 700ms)
â”œâ”€ OrderService.createOrder [650ms]
â”‚  â”œâ”€ UserService.getUser [300ms]        â”
â”‚  â”œâ”€ InventoryService.checkStock [400ms] â”œâ”€ å¹¶å‘æ‰§è¡Œ
â”‚  â”œâ”€ PricingService.calculatePrice [200ms] â”˜
â”‚  â””â”€ PaymentService.charge [250ms]

æ€§èƒ½æå‡ï¼š1.2ç§’ â†’ 700msï¼ˆ42%æå‡ï¼‰
```

#### è¿½è¸ªæ•°æ®åˆ†æä¸å‘Šè­¦

**1. åŸºäºTraceçš„å‘Šè­¦è§„åˆ™**ï¼š

```yaml
# Prometheuså‘Šè­¦è§„åˆ™ï¼ˆåŸºäºJaegerå¯¼å‡ºçš„æŒ‡æ ‡ï¼‰
groups:
- name: tracing-alerts
  rules:
  # æ…¢è¯·æ±‚å‘Šè­¦
  - alert: SlowTraces
    expr: |
      histogram_quantile(0.99, 
        sum(rate(jaeger_tracer_finished_spans_bucket[5m])) by (le, service_name)
      ) > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Service {{ $labels.service_name }} has slow traces"
      description: "P99 latency is {{ $value }}s (threshold: 2s)"
  
  # é”™è¯¯ç‡å‘Šè­¦
  - alert: HighErrorRate
    expr: |
      sum(rate(jaeger_tracer_finished_spans{error="true"}[5m])) by (service_name)
      /
      sum(rate(jaeger_tracer_finished_spans[5m])) by (service_name)
      > 0.05
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Service {{ $labels.service_name }} has high error rate"
      description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
  
  # æœåŠ¡ä¾èµ–å¼‚å¸¸
  - alert: ServiceDependencyFailure
    expr: |
      sum(rate(jaeger_tracer_finished_spans{
        span_kind="client",
        error="true"
      }[5m])) by (service_name, peer_service)
      > 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Service {{ $labels.service_name }} â†’ {{ $labels.peer_service }} dependency failing"
      description: "{{ $value }} errors/sec in downstream calls"
```

**2. Traceæ•°æ®å¯¼å‡ºåˆ°Elasticsearchè¿›è¡Œåˆ†æ**ï¼š

```bash
# KibanaæŸ¥è¯¢ï¼šç»Ÿè®¡å„æœåŠ¡çš„P99å»¶è¿Ÿ
GET jaeger-span-*/_search
{
  "size": 0,
  "query": {
    "bool": {
      "filter": [
        {"term": {"process.serviceName": "order-service"}},
        {"range": {"startTime": {"gte": "now-1h"}}}
      ]
    }
  },
  "aggs": {
    "latency_percentiles": {
      "percentiles": {
        "field": "duration",
        "percents": [50, 90, 95, 99]
      }
    }
  }
}

# ç»Ÿè®¡é”™è¯¯Spançš„Top 10æ“ä½œ
GET jaeger-span-*/_search
{
  "size": 0,
  "query": {
    "bool": {
      "filter": [
        {"term": {"tags.error": "true"}},
        {"range": {"startTime": {"gte": "now-1h"}}}
      ]
    }
  },
  "aggs": {
    "top_error_operations": {
      "terms": {
        "field": "operationName.keyword",
        "size": 10
      }
    }
  }
}

# åˆ†ææœåŠ¡é—´è°ƒç”¨å…³ç³»
GET jaeger-span-*/_search
{
  "size": 0,
  "query": {
    "range": {"startTime": {"gte": "now-1h"}}
  },
  "aggs": {
    "service_dependencies": {
      "composite": {
        "sources": [
          {"caller": {"terms": {"field": "process.serviceName.keyword"}}},
          {"callee": {"terms": {"field": "tags.peer.service.keyword"}}}
        ]
      }
    }
  }
}
```

**3. è‡ªå®šä¹‰Traceåˆ†æè„šæœ¬**ï¼š

```python
# trace_analyzer.py - åˆ†æTraceæ•°æ®ï¼Œæ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆ
import requests
import json
from collections import defaultdict

JAEGER_QUERY_URL = "http://jaeger-query.observability.svc.cluster.local:16686"

def analyze_slow_traces(service_name, min_duration_ms=1000, limit=100):
    """åˆ†ææ…¢Traceï¼Œæ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆ"""
    
    # æŸ¥è¯¢æ…¢Trace
    params = {
        "service": service_name,
        "minDuration": f"{min_duration_ms}ms",
        "limit": limit
    }
    resp = requests.get(f"{JAEGER_QUERY_URL}/api/traces", params=params)
    traces = resp.json()["data"]
    
    # ç»Ÿè®¡å„æ“ä½œçš„è€—æ—¶
    operation_stats = defaultdict(lambda: {"count": 0, "total_duration": 0, "max_duration": 0})
    
    for trace in traces:
        for span in trace["spans"]:
            op_name = span["operationName"]
            duration = span["duration"] / 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            stats = operation_stats[op_name]
            stats["count"] += 1
            stats["total_duration"] += duration
            stats["max_duration"] = max(stats["max_duration"], duration)
    
    # è®¡ç®—å¹³å‡è€—æ—¶å¹¶æ’åº
    results = []
    for op_name, stats in operation_stats.items():
        avg_duration = stats["total_duration"] / stats["count"]
        results.append({
            "operation": op_name,
            "count": stats["count"],
            "avg_duration_ms": round(avg_duration, 2),
            "max_duration_ms": round(stats["max_duration"], 2)
        })
    
    results.sort(key=lambda x: x["avg_duration_ms"], reverse=True)
    
    # è¾“å‡ºæŠ¥å‘Š
    print(f"\n=== Slow Trace Analysis for {service_name} ===")
    print(f"Analyzed {len(traces)} traces with duration > {min_duration_ms}ms\n")
    print(f"{'Operation':<50} {'Count':<10} {'Avg (ms)':<12} {'Max (ms)':<12}")
    print("-" * 84)
    
    for result in results[:20]:  # Top 20
        print(f"{result['operation']:<50} {result['count']:<10} "
              f"{result['avg_duration_ms']:<12} {result['max_duration_ms']:<12}")

if __name__ == "__main__":
    analyze_slow_traces("order-service", min_duration_ms=1000, limit=100)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
=== Slow Trace Analysis for order-service ===
Analyzed 87 traces with duration > 1000ms

Operation                                          Count      Avg (ms)     Max (ms)    
------------------------------------------------------------------------------------
payment-service: POST /charge                      87         1850.23      3200.45     
mysql.query.orders                                 87         450.12       890.34      
inventory-service: POST /check                     87         280.56       520.78      
user-service: GET /api/users/{id}                  87         120.34       250.12      
redis.get.user:*                                   87         15.67        45.23       
```

### 9.6.6 æœ¬èŠ‚æ€»ç»“

æœ¬èŠ‚æ·±å…¥è®²è§£äº†åˆ†å¸ƒå¼è¿½è¸ªä¸Jaegerçš„æ ¸å¿ƒåŸç†å’Œå®æˆ˜åº”ç”¨ï¼š

âœ… **åˆ†å¸ƒå¼è¿½è¸ªåŸºç¡€**ï¼š
- å¾®æœåŠ¡æ¶æ„çš„å¯è§‚æµ‹æ€§æŒ‘æˆ˜
- Traceã€Spanã€Contextæ ¸å¿ƒæ¦‚å¿µ
- é‡‡æ ·ç­–ç•¥ï¼ˆæ’å®š/é€Ÿç‡é™åˆ¶/è‡ªé€‚åº”/å°¾éƒ¨é‡‡æ ·ï¼‰
- è¿½è¸ªæ•°æ®æ¨¡å‹ä¸ä¸Šä¸‹æ–‡ä¼ æ’­

âœ… **OpenTelemetryæ ‡å‡†**ï¼š
- OTelæ¶æ„ï¼ˆSDK + Collector + OTLPåè®®ï¼‰
- å¤šè¯­è¨€SDKé›†æˆï¼ˆGo/Java/Pythonï¼‰
- OTel Collectoréƒ¨ç½²ä¸é…ç½®
- è‡ªåŠ¨åŸ‹ç‚¹ï¼ˆAuto-Instrumentationï¼‰

âœ… **Jaegeræ¶æ„ä¸éƒ¨ç½²**ï¼š
- Jaegerç»„ä»¶ï¼ˆClient/Agent/Collector/Query/UIï¼‰
- All-in-Oneå¼€å‘éƒ¨ç½²
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆElasticsearchåç«¯ï¼‰
- ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†

âœ… **åº”ç”¨åŸ‹ç‚¹ä¸SDKé›†æˆ**ï¼š
- æ‰‹åŠ¨åŸ‹ç‚¹æœ€ä½³å®è·µï¼ˆå‘½å/å±æ€§/äº‹ä»¶/ç±»å‹ï¼‰
- ä¸­é—´ä»¶è‡ªåŠ¨åŸ‹ç‚¹ï¼ˆHTTP/gRPC/æ•°æ®åº“/ç¼“å­˜ï¼‰
- è·¨è¯­è¨€è¿½è¸ªï¼ˆGo â†’ Java â†’ Pythonï¼‰

âœ… **è°ƒç”¨é“¾è·¯åˆ†æå®æˆ˜**ï¼š
- Jaeger UIä½¿ç”¨ï¼ˆæœç´¢/è¯¦æƒ…/æ‹“æ‰‘å›¾/å¯¹æ¯”ï¼‰
- æ€§èƒ½ç“¶é¢ˆå®šä½ï¼ˆN+1æŸ¥è¯¢/ç¼“å­˜ç©¿é€/å¹¶å‘ä¼˜åŒ–ï¼‰
- è¿½è¸ªæ•°æ®åˆ†æä¸å‘Šè­¦

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ APMåº”ç”¨æ€§èƒ½ç›‘æ§ï¼ŒåŒ…æ‹¬åº”ç”¨æŒ‡æ ‡é‡‡é›†ã€æ€§èƒ½å‰–æï¼ˆProfilingï¼‰ã€é”™è¯¯è¿½è¸ªã€ç”¨æˆ·ä½“éªŒç›‘æ§ï¼Œä»¥åŠå¦‚ä½•æ„å»ºå®Œæ•´çš„å¯è§‚æµ‹æ€§å¹³å°ã€‚

---


## 9.7 APMåº”ç”¨æ€§èƒ½ç›‘æ§

åº”ç”¨æ€§èƒ½ç›‘æ§ï¼ˆApplication Performance Monitoringï¼ŒAPMï¼‰æ˜¯å¯è§‚æµ‹æ€§çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒä¸“æ³¨äºåº”ç”¨å±‚é¢çš„æ€§èƒ½æŒ‡æ ‡ã€é”™è¯¯è¿½è¸ªã€ç”¨æˆ·ä½“éªŒç›‘æ§ã€‚å‰é¢æˆ‘ä»¬å­¦ä¹ äº†æŒ‡æ ‡ç›‘æ§ï¼ˆPrometheusï¼‰ã€æ—¥å¿—ç®¡ç†ï¼ˆEFKï¼‰ã€åˆ†å¸ƒå¼è¿½è¸ªï¼ˆJaegerï¼‰ï¼Œæœ¬èŠ‚å°†æ•´åˆè¿™äº›æŠ€æœ¯ï¼Œæ„å»ºå®Œæ•´çš„APMè§£å†³æ–¹æ¡ˆã€‚

### 9.7.1 APMåŸºç¡€ä¸æ ¸å¿ƒæŒ‡æ ‡

#### ä»€ä¹ˆæ˜¯APMï¼Ÿ

**APMçš„æ ¸å¿ƒç›®æ ‡**ï¼š
- ğŸ“Š **æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶ç›‘æ§åº”ç”¨å“åº”æ—¶é—´ã€ååé‡ã€èµ„æºä½¿ç”¨
- ğŸ› **é”™è¯¯è¿½è¸ª**ï¼šæ•è·å¼‚å¸¸ã€é”™è¯¯å †æ ˆã€ä¸Šä¸‹æ–‡ä¿¡æ¯
- ğŸ‘¤ **ç”¨æˆ·ä½“éªŒ**ï¼šç›‘æ§çœŸå®ç”¨æˆ·çš„è®¿é—®ä½“éªŒï¼ˆRUMï¼‰
- ğŸ” **æ ¹å› åˆ†æ**ï¼šå¿«é€Ÿå®šä½æ€§èƒ½ç“¶é¢ˆå’Œæ•…éšœæ ¹æº
- ğŸ“ˆ **è¶‹åŠ¿åˆ†æ**ï¼šé•¿æœŸæ€§èƒ½è¶‹åŠ¿ã€å®¹é‡è§„åˆ’

**APM vs ä¼ ç»Ÿç›‘æ§**ï¼š

```
ä¼ ç»Ÿç›‘æ§ï¼ˆåŸºç¡€è®¾æ–½å±‚ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CPUä½¿ç”¨ç‡: 60%                                               â”‚
â”‚ å†…å­˜ä½¿ç”¨ç‡: 75%                                              â”‚
â”‚ ç£ç›˜IO: 200 IOPS                                             â”‚
â”‚ ç½‘ç»œæµé‡: 100 Mbps                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
âŒ é—®é¢˜ï¼šæ— æ³•å›ç­”"ä¸ºä»€ä¹ˆç”¨æˆ·åé¦ˆæ…¢ï¼Ÿ"

APMç›‘æ§ï¼ˆåº”ç”¨å±‚ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ APIå“åº”æ—¶é—´: P99 = 2.5sï¼ˆæ…¢ï¼ï¼‰                              â”‚
â”‚ é”™è¯¯ç‡: 5%ï¼ˆé«˜ï¼ï¼‰                                           â”‚
â”‚ æ…¢æŸ¥è¯¢: SELECT * FROM orders WHERE ... (1.8s)                â”‚
â”‚ å¤–éƒ¨è°ƒç”¨: Stripe APIè¶…æ—¶ (3æ¬¡/åˆ†é’Ÿ)                          â”‚
â”‚ ç”¨æˆ·å½±å“: 1000ä¸ªç”¨æˆ·å—å½±å“                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
âœ… æ¸…æ™°å®šä½ï¼šStripe APIè¶…æ—¶å¯¼è‡´æ”¯ä»˜æ¥å£æ…¢
```

#### APMæ ¸å¿ƒæŒ‡æ ‡ä½“ç³»

**1. é»„é‡‘ä¿¡å·ï¼ˆGolden Signalsï¼‰**ï¼š

Google SREæå‡ºçš„å››å¤§æ ¸å¿ƒæŒ‡æ ‡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Latencyï¼ˆå»¶è¿Ÿï¼‰                                           â”‚
â”‚    - è¯·æ±‚å“åº”æ—¶é—´                                            â”‚
â”‚    - P50/P90/P95/P99åˆ†ä½æ•°                                   â”‚
â”‚    - åŒºåˆ†æˆåŠŸè¯·æ±‚å’Œå¤±è´¥è¯·æ±‚çš„å»¶è¿Ÿ                            â”‚
â”‚                                                              â”‚
â”‚ 2. Trafficï¼ˆæµé‡ï¼‰                                           â”‚
â”‚    - æ¯ç§’è¯·æ±‚æ•°ï¼ˆRPSï¼‰                                       â”‚
â”‚    - æ¯ç§’äº‹åŠ¡æ•°ï¼ˆTPSï¼‰                                       â”‚
â”‚    - å¸¦å®½ä½¿ç”¨é‡                                              â”‚
â”‚                                                              â”‚
â”‚ 3. Errorsï¼ˆé”™è¯¯ï¼‰                                            â”‚
â”‚    - é”™è¯¯ç‡ï¼ˆ4xx/5xxï¼‰                                       â”‚
â”‚    - å¼‚å¸¸æ•°é‡                                                â”‚
â”‚    - å¤±è´¥çš„è¯·æ±‚æ¯”ä¾‹                                          â”‚
â”‚                                                              â”‚
â”‚ 4. Saturationï¼ˆé¥±å’Œåº¦ï¼‰                                      â”‚
â”‚    - èµ„æºåˆ©ç”¨ç‡ï¼ˆCPU/å†…å­˜/ç£ç›˜/ç½‘ç»œï¼‰                        â”‚
â”‚    - é˜Ÿåˆ—é•¿åº¦                                                â”‚
â”‚    - çº¿ç¨‹æ± ä½¿ç”¨ç‡                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**2. REDæ–¹æ³•ï¼ˆé¢å‘è¯·æ±‚çš„æœåŠ¡ï¼‰**ï¼š

```
R - Rateï¼ˆé€Ÿç‡ï¼‰
    - æ¯ç§’è¯·æ±‚æ•°
    - æŒ‡æ ‡ï¼šhttp_requests_total

E - Errorsï¼ˆé”™è¯¯ï¼‰
    - å¤±è´¥è¯·æ±‚æ•°
    - æŒ‡æ ‡ï¼šhttp_requests_total{status=~"5.."}

D - Durationï¼ˆæŒç»­æ—¶é—´ï¼‰
    - è¯·æ±‚è€—æ—¶åˆ†å¸ƒ
    - æŒ‡æ ‡ï¼šhttp_request_duration_seconds
```

**PrometheusæŸ¥è¯¢ç¤ºä¾‹**ï¼š

```promql
# Rate: æ¯ç§’è¯·æ±‚æ•°
rate(http_requests_total[5m])

# Errors: é”™è¯¯ç‡
sum(rate(http_requests_total{status=~"5.."}[5m]))
/
sum(rate(http_requests_total[5m]))

# Duration: P99å»¶è¿Ÿ
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

**3. USEæ–¹æ³•ï¼ˆé¢å‘èµ„æºï¼‰**ï¼š

```
U - Utilizationï¼ˆåˆ©ç”¨ç‡ï¼‰
    - èµ„æºä½¿ç”¨ç™¾åˆ†æ¯”
    - CPU/å†…å­˜/ç£ç›˜/ç½‘ç»œåˆ©ç”¨ç‡

S - Saturationï¼ˆé¥±å’Œåº¦ï¼‰
    - èµ„æºæ’é˜Ÿæƒ…å†µ
    - ç­‰å¾…é˜Ÿåˆ—é•¿åº¦ã€çº¿ç¨‹æ± æ»¡è½½

E - Errorsï¼ˆé”™è¯¯ï¼‰
    - èµ„æºé”™è¯¯æ•°
    - ç£ç›˜é”™è¯¯ã€ç½‘ç»œä¸¢åŒ…
```

**4. åº”ç”¨çº§å…³é”®æŒ‡æ ‡**ï¼š

```yaml
# ä¸šåŠ¡æŒ‡æ ‡
business_metrics:
  - è®¢å•åˆ›å»ºæ•°ï¼ˆorders_created_totalï¼‰
  - æ”¯ä»˜æˆåŠŸç‡ï¼ˆpayment_success_rateï¼‰
  - ç”¨æˆ·æ³¨å†Œæ•°ï¼ˆuser_registrations_totalï¼‰
  - è´­ç‰©è½¦è½¬åŒ–ç‡ï¼ˆcart_conversion_rateï¼‰

# æ€§èƒ½æŒ‡æ ‡
performance_metrics:
  - APIå“åº”æ—¶é—´ï¼ˆapi_response_time_secondsï¼‰
  - æ•°æ®åº“æŸ¥è¯¢æ—¶é—´ï¼ˆdb_query_duration_secondsï¼‰
  - ç¼“å­˜å‘½ä¸­ç‡ï¼ˆcache_hit_rateï¼‰
  - å¤–éƒ¨APIè°ƒç”¨æ—¶é—´ï¼ˆexternal_api_duration_secondsï¼‰

# èµ„æºæŒ‡æ ‡
resource_metrics:
  - åº”ç”¨å†…å­˜ä½¿ç”¨ï¼ˆapp_memory_usage_bytesï¼‰
  - GCæš‚åœæ—¶é—´ï¼ˆgc_pause_duration_secondsï¼‰
  - çº¿ç¨‹æ•°ï¼ˆapp_threads_totalï¼‰
  - è¿æ¥æ± ä½¿ç”¨ç‡ï¼ˆconnection_pool_usage_ratioï¼‰

# é”™è¯¯æŒ‡æ ‡
error_metrics:
  - å¼‚å¸¸æ•°é‡ï¼ˆexceptions_totalï¼‰
  - é”™è¯¯æ—¥å¿—æ•°ï¼ˆerror_logs_totalï¼‰
  - è¶…æ—¶æ•°é‡ï¼ˆtimeouts_totalï¼‰
  - é‡è¯•æ¬¡æ•°ï¼ˆretries_totalï¼‰
```

#### APMæ•°æ®é‡‡é›†æ¶æ„

**å®Œæ•´çš„APMæ•°æ®æµ**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Service A  â”‚  â”‚   Service B  â”‚  â”‚   Service C  â”‚      â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚      â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚  â”‚ â”‚APM Agent â”‚ â”‚  â”‚ â”‚APM Agent â”‚ â”‚  â”‚ â”‚APM Agent â”‚ â”‚      â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â”‚ Metrics          â”‚ Traces           â”‚ Logs
          â”‚ Traces           â”‚ Metrics          â”‚ Errors
          â”‚ Errors           â”‚ Errors           â”‚ Profiles
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Collection Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Prometheus   â”‚  â”‚ OTel         â”‚  â”‚ Fluentd      â”‚      â”‚
â”‚  â”‚ (Metrics)    â”‚  â”‚ Collector    â”‚  â”‚ (Logs)       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Storage Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Prometheus   â”‚  â”‚ Jaeger       â”‚  â”‚Elasticsearch â”‚      â”‚
â”‚  â”‚ (TSDB)       â”‚  â”‚ (Traces)     â”‚  â”‚ (Logs)       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Visualization Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              APM Dashboard (Grafana)                  â”‚   â”‚
â”‚  â”‚  - æ€§èƒ½æ¦‚è§ˆ                                           â”‚   â”‚
â”‚  â”‚  - é”™è¯¯è¿½è¸ª                                           â”‚   â”‚
â”‚  â”‚  - è°ƒç”¨é“¾è·¯                                           â”‚   â”‚
â”‚  â”‚  - èµ„æºä½¿ç”¨                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### åº”ç”¨æŒ‡æ ‡é‡‡é›†å®ç°

**Goåº”ç”¨æŒ‡æ ‡é‡‡é›†ï¼ˆä½¿ç”¨Prometheuså®¢æˆ·ç«¯ï¼‰**ï¼š

```go
package main

import (
    "net/http"
    "time"

    "github.com/gin-gonic/gin"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    // HTTPè¯·æ±‚æ€»æ•°
    httpRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    // HTTPè¯·æ±‚è€—æ—¶
    httpRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},
        },
        []string{"method", "endpoint"},
    )

    // å½“å‰å¤„ç†ä¸­çš„è¯·æ±‚æ•°
    httpRequestsInFlight = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "http_requests_in_flight",
            Help: "Current number of HTTP requests being processed",
        },
    )

    // æ•°æ®åº“æŸ¥è¯¢è€—æ—¶
    dbQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1},
        },
        []string{"query_type", "table"},
    )

    // ç¼“å­˜å‘½ä¸­ç‡
    cacheHits = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_hits_total",
            Help: "Total number of cache hits",
        },
        []string{"cache_name"},
    )

    cacheMisses = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_misses_total",
            Help: "Total number of cache misses",
        },
        []string{"cache_name"},
    )

    // ä¸šåŠ¡æŒ‡æ ‡ï¼šè®¢å•åˆ›å»ºæ•°
    ordersCreated = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "orders_created_total",
            Help: "Total number of orders created",
        },
        []string{"status"},
    )

    // ä¸šåŠ¡æŒ‡æ ‡ï¼šæ”¯ä»˜é‡‘é¢
    paymentAmount = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "payment_amount_dollars",
            Help:    "Payment amount in dollars",
            Buckets: []float64{1, 5, 10, 25, 50, 100, 250, 500, 1000},
        },
        []string{"currency"},
    )
)

// Prometheusä¸­é—´ä»¶
func PrometheusMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()
        
        // å¢åŠ å¤„ç†ä¸­çš„è¯·æ±‚æ•°
        httpRequestsInFlight.Inc()
        defer httpRequestsInFlight.Dec()

        // å¤„ç†è¯·æ±‚
        c.Next()

        // è®°å½•æŒ‡æ ‡
        duration := time.Since(start).Seconds()
        status := c.Writer.Status()
        
        httpRequestsTotal.WithLabelValues(
            c.Request.Method,
            c.FullPath(),
            http.StatusText(status),
        ).Inc()

        httpRequestDuration.WithLabelValues(
            c.Request.Method,
            c.FullPath(),
        ).Observe(duration)
    }
}

// æ•°æ®åº“æŸ¥è¯¢åŒ…è£…å‡½æ•°
func QueryDB(queryType, table string, fn func() error) error {
    start := time.Now()
    err := fn()
    duration := time.Since(start).Seconds()
    
    dbQueryDuration.WithLabelValues(queryType, table).Observe(duration)
    return err
}

// ç¼“å­˜æŸ¥è¯¢åŒ…è£…å‡½æ•°
func GetFromCache(cacheName, key string, fn func() (interface{}, error)) (interface{}, error) {
    // å°è¯•ä»ç¼“å­˜è·å–
    value, err := redis.Get(key).Result()
    if err == nil {
        cacheHits.WithLabelValues(cacheName).Inc()
        return value, nil
    }
    
    // ç¼“å­˜æœªå‘½ä¸­
    cacheMisses.WithLabelValues(cacheName).Inc()
    
    // ä»æ•°æ®åº“è·å–
    return fn()
}

func main() {
    r := gin.Default()
    
    // æ³¨å†ŒPrometheusä¸­é—´ä»¶
    r.Use(PrometheusMiddleware())
    
    // æš´éœ²PrometheusæŒ‡æ ‡ç«¯ç‚¹
    r.GET("/metrics", gin.WrapH(promhttp.Handler()))
    
    // ä¸šåŠ¡æ¥å£
    r.POST("/api/orders", createOrder)
    r.GET("/api/orders/:id", getOrder)
    
    r.Run(":8080")
}

func createOrder(c *gin.Context) {
    var req CreateOrderRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }
    
    // åˆ›å»ºè®¢å•ï¼ˆè®°å½•æ•°æ®åº“æŸ¥è¯¢æ—¶é—´ï¼‰
    var order Order
    err := QueryDB("INSERT", "orders", func() error {
        return db.Create(&order).Error
    })
    
    if err != nil {
        c.JSON(500, gin.H{"error": err.Error()})
        ordersCreated.WithLabelValues("failed").Inc()
        return
    }
    
    // è®°å½•ä¸šåŠ¡æŒ‡æ ‡
    ordersCreated.WithLabelValues("success").Inc()
    paymentAmount.WithLabelValues(req.Currency).Observe(req.Amount)
    
    c.JSON(200, order)
}

func getOrder(c *gin.Context) {
    orderID := c.Param("id")
    
    // ä»ç¼“å­˜è·å–ï¼ˆè®°å½•ç¼“å­˜å‘½ä¸­ç‡ï¼‰
    order, err := GetFromCache("orders", "order:"+orderID, func() (interface{}, error) {
        var order Order
        err := QueryDB("SELECT", "orders", func() error {
            return db.Where("id = ?", orderID).First(&order).Error
        })
        return order, err
    })
    
    if err != nil {
        c.JSON(404, gin.H{"error": "Order not found"})
        return
    }
    
    c.JSON(200, order)
}
```

**Javaåº”ç”¨æŒ‡æ ‡é‡‡é›†ï¼ˆä½¿ç”¨Micrometerï¼‰**ï¼š

```java
// pom.xmlä¾èµ–
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
    <version>1.12.0</version>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

// application.ymlé…ç½®
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
      environment: ${spring.profiles.active}

// MetricsConfig.java
@Configuration
public class MetricsConfig {

    @Bean
    public MeterRegistryCustomizer<MeterRegistry> metricsCommonTags() {
        return registry -> registry.config().commonTags(
            "application", "order-service",
            "environment", "production"
        );
    }

    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
}

// OrderController.java
@RestController
@RequestMapping("/api/orders")
public class OrderController {

    @Autowired
    private MeterRegistry meterRegistry;

    @Autowired
    private OrderService orderService;

    // è‡ªåŠ¨è®°å½•è¯·æ±‚è€—æ—¶ï¼ˆé€šè¿‡@Timedæ³¨è§£ï¼‰
    @PostMapping
    @Timed(value = "orders.create", description = "Time taken to create order")
    public ResponseEntity<Order> createOrder(@RequestBody CreateOrderRequest request) {
        // è®°å½•ä¸šåŠ¡æŒ‡æ ‡
        Counter.builder("orders.created")
            .tag("status", "success")
            .register(meterRegistry)
            .increment();

        // è®°å½•æ”¯ä»˜é‡‘é¢
        DistributionSummary.builder("payment.amount")
            .tag("currency", request.getCurrency())
            .baseUnit("dollars")
            .register(meterRegistry)
            .record(request.getAmount());

        Order order = orderService.createOrder(request);
        return ResponseEntity.ok(order);
    }

    @GetMapping("/{id}")
    @Timed(value = "orders.get", description = "Time taken to get order")
    public ResponseEntity<Order> getOrder(@PathVariable String id) {
        // è®°å½•ç¼“å­˜å‘½ä¸­ç‡
        Timer.Sample sample = Timer.start(meterRegistry);
        
        Order order = orderService.getOrder(id);
        
        sample.stop(Timer.builder("cache.access")
            .tag("cache_name", "orders")
            .tag("result", order.isFromCache() ? "hit" : "miss")
            .register(meterRegistry));

        return ResponseEntity.ok(order);
    }
}

// OrderService.java
@Service
public class OrderService {

    @Autowired
    private MeterRegistry meterRegistry;

    @Autowired
    private OrderRepository orderRepository;

    public Order createOrder(CreateOrderRequest request) {
        // è®°å½•æ•°æ®åº“æŸ¥è¯¢æ—¶é—´
        return Timer.builder("db.query")
            .tag("query_type", "INSERT")
            .tag("table", "orders")
            .register(meterRegistry)
            .record(() -> {
                Order order = new Order();
                // ... è®¾ç½®è®¢å•å±æ€§
                return orderRepository.save(order);
            });
    }

    public Order getOrder(String id) {
        // å°è¯•ä»ç¼“å­˜è·å–
        Order cachedOrder = cacheService.get("order:" + id);
        if (cachedOrder != null) {
            meterRegistry.counter("cache.hits", "cache_name", "orders").increment();
            cachedOrder.setFromCache(true);
            return cachedOrder;
        }

        // ç¼“å­˜æœªå‘½ä¸­
        meterRegistry.counter("cache.misses", "cache_name", "orders").increment();

        // ä»æ•°æ®åº“æŸ¥è¯¢
        Order order = Timer.builder("db.query")
            .tag("query_type", "SELECT")
            .tag("table", "orders")
            .register(meterRegistry)
            .record(() -> orderRepository.findById(id).orElseThrow());

        // å†™å…¥ç¼“å­˜
        cacheService.set("order:" + id, order);
        order.setFromCache(false);
        return order;
    }
}
```


**Pythonåº”ç”¨æŒ‡æ ‡é‡‡é›†ï¼ˆä½¿ç”¨prometheus_clientï¼‰**ï¼š

```python
# requirements.txt
prometheus-client==0.19.0
flask==3.0.0

# app.py
from flask import Flask, request, jsonify
from prometheus_client import Counter, Histogram, Gauge, Summary, generate_latest
import time

app = Flask(__name__)

# å®šä¹‰æŒ‡æ ‡
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint'],
    buckets=[.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10]
)

http_requests_in_flight = Gauge(
    'http_requests_in_flight',
    'Current number of HTTP requests being processed'
)

db_query_duration_seconds = Histogram(
    'db_query_duration_seconds',
    'Database query duration in seconds',
    ['query_type', 'table'],
    buckets=[.001, .005, .01, .025, .05, .1, .25, .5, 1]
)

cache_hits_total = Counter(
    'cache_hits_total',
    'Total cache hits',
    ['cache_name']
)

cache_misses_total = Counter(
    'cache_misses_total',
    'Total cache misses',
    ['cache_name']
)

orders_created_total = Counter(
    'orders_created_total',
    'Total orders created',
    ['status']
)

# Prometheusä¸­é—´ä»¶
@app.before_request
def before_request():
    request.start_time = time.time()
    http_requests_in_flight.inc()

@app.after_request
def after_request(response):
    http_requests_in_flight.dec()
    
    duration = time.time() - request.start_time
    
    http_requests_total.labels(
        method=request.method,
        endpoint=request.endpoint or 'unknown',
        status=response.status_code
    ).inc()
    
    http_request_duration_seconds.labels(
        method=request.method,
        endpoint=request.endpoint or 'unknown'
    ).observe(duration)
    
    return response

# æš´éœ²PrometheusæŒ‡æ ‡ç«¯ç‚¹
@app.route('/metrics')
def metrics():
    return generate_latest()

# ä¸šåŠ¡æ¥å£
@app.route('/api/orders', methods=['POST'])
def create_order():
    data = request.get_json()
    
    # è®°å½•æ•°æ®åº“æŸ¥è¯¢æ—¶é—´
    start = time.time()
    order = db.create_order(data)
    db_query_duration_seconds.labels(
        query_type='INSERT',
        table='orders'
    ).observe(time.time() - start)
    
    # è®°å½•ä¸šåŠ¡æŒ‡æ ‡
    orders_created_total.labels(status='success').inc()
    
    return jsonify(order), 201

@app.route('/api/orders/<order_id>')
def get_order(order_id):
    # å°è¯•ä»ç¼“å­˜è·å–
    cached_order = cache.get(f'order:{order_id}')
    if cached_order:
        cache_hits_total.labels(cache_name='orders').inc()
        return jsonify(cached_order)
    
    # ç¼“å­˜æœªå‘½ä¸­
    cache_misses_total.labels(cache_name='orders').inc()
    
    # ä»æ•°æ®åº“æŸ¥è¯¢
    start = time.time()
    order = db.get_order(order_id)
    db_query_duration_seconds.labels(
        query_type='SELECT',
        table='orders'
    ).observe(time.time() - start)
    
    # å†™å…¥ç¼“å­˜
    cache.set(f'order:{order_id}', order)
    
    return jsonify(order)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### 9.7.2 æ€§èƒ½å‰–æï¼ˆProfilingï¼‰

æ€§èƒ½å‰–æï¼ˆProfilingï¼‰æ˜¯æ·±å…¥åˆ†æåº”ç”¨æ€§èƒ½çš„å…³é”®æŠ€æœ¯ï¼Œå®ƒå¯ä»¥ç²¾ç¡®å®šä½CPUã€å†…å­˜ã€IOç­‰èµ„æºçš„ä½¿ç”¨æƒ…å†µï¼Œæ‰¾å‡ºæ€§èƒ½çƒ­ç‚¹ã€‚

#### ä»€ä¹ˆæ˜¯Profilingï¼Ÿ

**Profilingç±»å‹**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CPU Profilingï¼ˆCPUå‰–æï¼‰                                     â”‚
â”‚ - å“ªäº›å‡½æ•°å ç”¨CPUæ—¶é—´æœ€å¤šï¼Ÿ                                  â”‚
â”‚ - è°ƒç”¨æ ˆåˆ†æ                                                 â”‚
â”‚ - ç«ç„°å›¾ï¼ˆFlame Graphï¼‰                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Memory Profilingï¼ˆå†…å­˜å‰–æï¼‰                                 â”‚
â”‚ - å“ªäº›å¯¹è±¡å ç”¨å†…å­˜æœ€å¤šï¼Ÿ                                     â”‚
â”‚ - å†…å­˜æ³„æ¼æ£€æµ‹                                               â”‚
â”‚ - å †å†…å­˜åˆ†é…åˆ†æ                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Goroutine Profilingï¼ˆåç¨‹å‰–æï¼ŒGoç‰¹æœ‰ï¼‰                      â”‚
â”‚ - å½“å‰æœ‰å¤šå°‘Goroutineï¼Ÿ                                      â”‚
â”‚ - Goroutineæ³„æ¼æ£€æµ‹                                          â”‚
â”‚ - é˜»å¡åˆ†æ                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block Profilingï¼ˆé˜»å¡å‰–æï¼‰                                  â”‚
â”‚ - å“ªäº›æ“ä½œå¯¼è‡´é˜»å¡ï¼Ÿ                                         â”‚
â”‚ - é”ç«äº‰åˆ†æ                                                 â”‚
â”‚ - IOç­‰å¾…åˆ†æ                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mutex Profilingï¼ˆäº’æ–¥é”å‰–æï¼‰                                â”‚
â”‚ - é”ç«äº‰çƒ­ç‚¹                                                 â”‚
â”‚ - é”æŒæœ‰æ—¶é—´                                                 â”‚
â”‚ - æ­»é”æ£€æµ‹                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Goåº”ç”¨Profiling

**1. å†…ç½®pprofå·¥å…·**ï¼š

```go
package main

import (
    "net/http"
    _ "net/http/pprof"  // å¯¼å…¥pprofåŒ…ï¼ˆè‡ªåŠ¨æ³¨å†Œ/debug/pprofè·¯ç”±ï¼‰
    
    "github.com/gin-gonic/gin"
)

func main() {
    r := gin.Default()
    
    // ä¸šåŠ¡è·¯ç”±
    r.GET("/api/orders", getOrders)
    
    // å¯åŠ¨pprofæœåŠ¡ï¼ˆç‹¬ç«‹ç«¯å£ï¼Œé¿å…æš´éœ²åˆ°å…¬ç½‘ï¼‰
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()
    
    r.Run(":8080")
}
```

**è®¿é—®pprofç«¯ç‚¹**ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„profile
curl http://localhost:6060/debug/pprof/

# CPU Profilingï¼ˆé‡‡æ ·30ç§’ï¼‰
curl http://localhost:6060/debug/pprof/profile?seconds=30 > cpu.prof

# Memory Profilingï¼ˆå †å†…å­˜ï¼‰
curl http://localhost:6060/debug/pprof/heap > heap.prof

# Goroutine Profiling
curl http://localhost:6060/debug/pprof/goroutine > goroutine.prof

# Block Profilingï¼ˆé˜»å¡åˆ†æï¼‰
curl http://localhost:6060/debug/pprof/block > block.prof

# Mutex Profilingï¼ˆé”ç«äº‰ï¼‰
curl http://localhost:6060/debug/pprof/mutex > mutex.prof

# Allocs Profilingï¼ˆå†…å­˜åˆ†é…ï¼‰
curl http://localhost:6060/debug/pprof/allocs > allocs.prof
```

**2. ä½¿ç”¨go tool pprofåˆ†æ**ï¼š

```bash
# äº¤äº’å¼åˆ†æCPU profile
go tool pprof cpu.prof

# pprofäº¤äº’å‘½ä»¤
(pprof) top10          # æ˜¾ç¤ºCPUå ç”¨Top 10å‡½æ•°
(pprof) list funcName  # æ˜¾ç¤ºå‡½æ•°æºç åŠCPUå ç”¨
(pprof) web            # ç”Ÿæˆè°ƒç”¨å›¾ï¼ˆéœ€è¦graphvizï¼‰
(pprof) pdf            # ç”ŸæˆPDFæŠ¥å‘Š
(pprof) png            # ç”ŸæˆPNGå›¾ç‰‡

# ç›´æ¥ç”Ÿæˆç«ç„°å›¾
go tool pprof -http=:8081 cpu.prof
# æµè§ˆå™¨è®¿é—® http://localhost:8081
```

**CPU Profileç¤ºä¾‹è¾“å‡º**ï¼š

```
(pprof) top10
Showing nodes accounting for 8.50s, 85.00% of 10.00s total
Dropped 50 nodes (cum <= 0.05s)
Showing top 10 nodes out of 100

      flat  flat%   sum%        cum   cum%
     2.50s 25.00% 25.00%      2.50s 25.00%  runtime.mallocgc
     1.80s 18.00% 43.00%      1.80s 18.00%  encoding/json.Marshal
     1.20s 12.00% 55.00%      3.00s 30.00%  main.processOrder
     0.90s  9.00% 64.00%      0.90s  9.00%  database/sql.(*DB).Query
     0.70s  7.00% 71.00%      0.70s  7.00%  crypto/sha256.block
     0.50s  5.00% 76.00%      0.50s  5.00%  runtime.scanobject
     0.40s  4.00% 80.00%      0.40s  4.00%  syscall.Syscall
     0.30s  3.00% 83.00%      0.30s  3.00%  runtime.gcDrain
     0.10s  1.00% 84.00%      0.10s  1.00%  runtime.memmove
     0.10s  1.00% 85.00%      0.10s  1.00%  runtime.heapBitsSetType

# flat: å‡½æ•°è‡ªèº«æ‰§è¡Œæ—¶é—´
# cum: å‡½æ•°åŠå…¶è°ƒç”¨çš„æ‰€æœ‰å‡½æ•°çš„æ€»æ—¶é—´
```

**3. ç«ç„°å›¾ï¼ˆFlame Graphï¼‰**ï¼š

ç«ç„°å›¾æ˜¯å¯è§†åŒ–CPU profileçš„æœ€ä½³æ–¹å¼ï¼š

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         main.main (10s)             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      main.processOrder (3s)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â”‚ json.Marshal   â”‚          â”‚ db.Query (0.9s)  â”‚          â”‚ redis.Get      â”‚
â”‚    (1.8s)      â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   (0.3s)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Xè½´ï¼šå‡½æ•°å ç”¨çš„CPUæ—¶é—´ï¼ˆå®½åº¦è¶Šå®½ï¼Œå ç”¨è¶Šå¤šï¼‰
# Yè½´ï¼šè°ƒç”¨æ ˆæ·±åº¦ï¼ˆä»ä¸‹åˆ°ä¸Šï¼‰
# é¢œè‰²ï¼šéšæœºï¼ˆä¾¿äºåŒºåˆ†ä¸åŒå‡½æ•°ï¼‰
```

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

```go
// âŒ æ€§èƒ½é—®é¢˜ï¼šé¢‘ç¹çš„JSONåºåˆ—åŒ–
func getOrders(c *gin.Context) {
    var orders []Order
    db.Find(&orders)
    
    // æ¯æ¬¡è¯·æ±‚éƒ½åºåˆ—åŒ–ï¼ˆCPUå ç”¨é«˜ï¼‰
    for i := range orders {
        orders[i].UserJSON, _ = json.Marshal(orders[i].User)
    }
    
    c.JSON(200, orders)
}

// âœ… ä¼˜åŒ–ï¼šç¼“å­˜åºåˆ—åŒ–ç»“æœ
var orderCache = cache.New(5*time.Minute, 10*time.Minute)

func getOrders(c *gin.Context) {
    // å°è¯•ä»ç¼“å­˜è·å–
    if cached, found := orderCache.Get("orders"); found {
        c.JSON(200, cached)
        return
    }
    
    var orders []Order
    db.Find(&orders)
    
    // åªåºåˆ—åŒ–ä¸€æ¬¡
    for i := range orders {
        orders[i].UserJSON, _ = json.Marshal(orders[i].User)
    }
    
    // ç¼“å­˜ç»“æœ
    orderCache.Set("orders", orders, cache.DefaultExpiration)
    
    c.JSON(200, orders)
}

// æ€§èƒ½æå‡ï¼šCPUå ç”¨ä»25% â†’ 5%ï¼ˆ5å€æå‡ï¼‰
```

**4. å†…å­˜æ³„æ¼æ£€æµ‹**ï¼š

```bash
# é‡‡é›†ä¸¤æ¬¡å †å†…å­˜å¿«ç…§ï¼ˆé—´éš”5åˆ†é’Ÿï¼‰
curl http://localhost:6060/debug/pprof/heap > heap1.prof
# ... ç­‰å¾…5åˆ†é’Ÿ ...
curl http://localhost:6060/debug/pprof/heap > heap2.prof

# å¯¹æ¯”ä¸¤æ¬¡å¿«ç…§ï¼Œæ‰¾å‡ºå¢é•¿çš„å¯¹è±¡
go tool pprof -base heap1.prof heap2.prof

(pprof) top10
Showing nodes accounting for 512.50MB, 100% of 512.50MB total
      flat  flat%   sum%        cum   cum%
  256.00MB 50.00% 50.00%   256.00MB 50.00%  main.(*Cache).Set
  128.00MB 25.00% 75.00%   128.00MB 25.00%  encoding/json.Unmarshal
   64.00MB 12.50% 87.50%    64.00MB 12.50%  net/http.(*conn).serve
   32.00MB  6.25% 93.75%    32.00MB  6.25%  database/sql.(*Rows).Scan
   16.00MB  3.12% 96.87%    16.00MB  3.12%  runtime.mallocgc

# å‘ç°ï¼šCache.Setå ç”¨256MBï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼
```

**å†…å­˜æ³„æ¼ä¿®å¤ç¤ºä¾‹**ï¼š

```go
// âŒ å†…å­˜æ³„æ¼ï¼šç¼“å­˜æ— è¿‡æœŸæ—¶é—´
type Cache struct {
    data map[string]interface{}
    mu   sync.RWMutex
}

func (c *Cache) Set(key string, value interface{}) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = value  // æ°¸ä¸åˆ é™¤ï¼Œå†…å­˜æŒç»­å¢é•¿
}

// âœ… ä¿®å¤ï¼šæ·»åŠ è¿‡æœŸæ—¶é—´å’Œå®šæœŸæ¸…ç†
type CacheItem struct {
    Value      interface{}
    ExpireTime time.Time
}

type Cache struct {
    data map[string]*CacheItem
    mu   sync.RWMutex
}

func (c *Cache) Set(key string, value interface{}, ttl time.Duration) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = &CacheItem{
        Value:      value,
        ExpireTime: time.Now().Add(ttl),
    }
}

func (c *Cache) cleanup() {
    ticker := time.NewTicker(1 * time.Minute)
    defer ticker.Stop()
    
    for range ticker.C {
        c.mu.Lock()
        now := time.Now()
        for key, item := range c.data {
            if now.After(item.ExpireTime) {
                delete(c.data, key)  // åˆ é™¤è¿‡æœŸé¡¹
            }
        }
        c.mu.Unlock()
    }
}
```

#### Javaåº”ç”¨Profiling

**1. JVMå†…ç½®å·¥å…·**ï¼š

```bash
# jstackï¼šçº¿ç¨‹å †æ ˆåˆ†æ
jstack <pid> > thread_dump.txt

# jmapï¼šå †å†…å­˜åˆ†æ
jmap -heap <pid>                    # æŸ¥çœ‹å †å†…å­˜é…ç½®
jmap -histo <pid>                   # æŸ¥çœ‹å¯¹è±¡ç»Ÿè®¡
jmap -dump:format=b,file=heap.bin <pid>  # å¯¼å‡ºå †è½¬å‚¨

# jstatï¼šGCç»Ÿè®¡
jstat -gc <pid> 1000 10             # æ¯ç§’è¾“å‡ºGCç»Ÿè®¡ï¼Œå…±10æ¬¡
jstat -gcutil <pid> 1000            # æŒç»­è¾“å‡ºGCåˆ©ç”¨ç‡

# jcmdï¼šç»¼åˆè¯Šæ–­å·¥å…·
jcmd <pid> VM.flags                 # æŸ¥çœ‹JVMå‚æ•°
jcmd <pid> GC.heap_info             # æŸ¥çœ‹å †ä¿¡æ¯
jcmd <pid> Thread.print             # æ‰“å°çº¿ç¨‹æ ˆ
jcmd <pid> VM.native_memory summary # æŸ¥çœ‹æœ¬åœ°å†…å­˜
```

**2. ä½¿ç”¨async-profilerï¼ˆæ¨èï¼‰**ï¼š

async-profileræ˜¯ä½å¼€é”€çš„Javaæ€§èƒ½åˆ†æå·¥å…·ï¼Œæ”¯æŒCPUã€å†…å­˜ã€é”åˆ†æã€‚

```bash
# ä¸‹è½½async-profiler
wget https://github.com/async-profiler/async-profiler/releases/download/v2.9/async-profiler-2.9-linux-x64.tar.gz
tar -xzf async-profiler-2.9-linux-x64.tar.gz

# CPU Profilingï¼ˆé‡‡æ ·60ç§’ï¼Œç”Ÿæˆç«ç„°å›¾ï¼‰
./profiler.sh -d 60 -f cpu-flamegraph.html <pid>

# å†…å­˜åˆ†é…Profiling
./profiler.sh -d 60 -e alloc -f alloc-flamegraph.html <pid>

# é”ç«äº‰Profiling
./profiler.sh -d 60 -e lock -f lock-flamegraph.html <pid>
```

**3. Spring Boot Actuatoré›†æˆ**ï¼š

```yaml
# application.yml
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,heapdump,threaddump
  endpoint:
    heapdump:
      enabled: true
    threaddump:
      enabled: true
```

```bash
# ä¸‹è½½å †è½¬å‚¨
curl http://localhost:8080/actuator/heapdump -o heap.hprof

# ä½¿ç”¨MATï¼ˆMemory Analyzer Toolï¼‰åˆ†æ
# ä¸‹è½½ï¼šhttps://www.eclipse.org/mat/

# ä¸‹è½½çº¿ç¨‹è½¬å‚¨
curl http://localhost:8080/actuator/threaddump > threads.json
```

#### Pythonåº”ç”¨Profiling

**1. cProfileï¼ˆå†…ç½®ï¼‰**ï¼š

```python
import cProfile
import pstats
from flask import Flask

app = Flask(__name__)

@app.route('/api/orders')
def get_orders():
    # ä¸šåŠ¡é€»è¾‘
    orders = db.query_orders()
    return jsonify(orders)

if __name__ == '__main__':
    # å¯åŠ¨profiling
    profiler = cProfile.Profile()
    profiler.enable()
    
    app.run(host='0.0.0.0', port=5000)
    
    profiler.disable()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # æ˜¾ç¤ºTop 20
```

**2. py-spyï¼ˆæ¨èï¼‰**ï¼š

py-spyæ˜¯ä½å¼€é”€çš„Pythonæ€§èƒ½åˆ†æå·¥å…·ï¼Œæ— éœ€ä¿®æ”¹ä»£ç ã€‚

```bash
# å®‰è£…py-spy
pip install py-spy

# CPU Profilingï¼ˆé‡‡æ ·60ç§’ï¼Œç”Ÿæˆç«ç„°å›¾ï¼‰
py-spy record -o flamegraph.svg --duration 60 --pid <pid>

# å®æ—¶æŸ¥çœ‹Topå‡½æ•°
py-spy top --pid <pid>

# å¯¼å‡ºprofileæ•°æ®
py-spy record -o profile.speedscope --format speedscope --pid <pid>
```

**3. memory_profilerï¼ˆå†…å­˜åˆ†æï¼‰**ï¼š

```python
# å®‰è£…
pip install memory-profiler

# ä½¿ç”¨è£…é¥°å™¨åˆ†æå‡½æ•°å†…å­˜
from memory_profiler import profile

@profile
def process_orders():
    orders = []
    for i in range(10000):
        order = {
            'id': i,
            'items': [{'name': f'item-{j}', 'price': j} for j in range(100)]
        }
        orders.append(order)
    return orders

# è¿è¡Œå¹¶æŸ¥çœ‹å†…å­˜ä½¿ç”¨
python -m memory_profiler app.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     3   38.5 MiB     38.5 MiB           1   @profile
     4                                         def process_orders():
     5   38.5 MiB      0.0 MiB           1       orders = []
     6  156.2 MiB      0.0 MiB       10001       for i in range(10000):
     7  156.2 MiB      0.1 MiB       10000           order = {
     8  156.2 MiB      0.0 MiB       10000               'id': i,
     9  156.2 MiB    117.7 MiB       10000               'items': [...]
    10                                                 }
    11  156.2 MiB      0.0 MiB       10000           orders.append(order)
    12  156.2 MiB      0.0 MiB           1       return orders
```

#### æŒç»­æ€§èƒ½å‰–æï¼ˆContinuous Profilingï¼‰

**Pyroscopeï¼šå¼€æºæŒç»­æ€§èƒ½å‰–æå¹³å°**

Pyroscopeå¯ä»¥æŒç»­é‡‡é›†åº”ç”¨çš„æ€§èƒ½æ•°æ®ï¼Œæ— éœ€æ‰‹åŠ¨è§¦å‘ã€‚

**1. éƒ¨ç½²Pyroscope Server**ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pyroscope
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pyroscope
  template:
    metadata:
      labels:
        app: pyroscope
    spec:
      containers:
      - name: pyroscope
        image: pyroscope/pyroscope:latest
        ports:
        - containerPort: 4040
        volumeMounts:
        - name: data
          mountPath: /var/lib/pyroscope
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: pyroscope-data
---
apiVersion: v1
kind: Service
metadata:
  name: pyroscope
  namespace: observability
spec:
  selector:
    app: pyroscope
  ports:
  - port: 4040
    targetPort: 4040
  type: ClusterIP
```

**2. Goåº”ç”¨é›†æˆPyroscope**ï¼š

```go
package main

import (
    "github.com/pyroscope-io/client/pyroscope"
    "github.com/gin-gonic/gin"
)

func main() {
    // åˆå§‹åŒ–Pyroscope
    pyroscope.Start(pyroscope.Config{
        ApplicationName: "order-service",
        ServerAddress:   "http://pyroscope.observability.svc.cluster.local:4040",
        Logger:          pyroscope.StandardLogger,
        
        // é‡‡é›†æ‰€æœ‰ç±»å‹çš„profile
        ProfileTypes: []pyroscope.ProfileType{
            pyroscope.ProfileCPU,
            pyroscope.ProfileAllocObjects,
            pyroscope.ProfileAllocSpace,
            pyroscope.ProfileInuseObjects,
            pyroscope.ProfileInuseSpace,
        },
        
        // æ·»åŠ æ ‡ç­¾
        Tags: map[string]string{
            "environment": "production",
            "region":      "us-west-2",
        },
    })

    r := gin.Default()
    r.GET("/api/orders", getOrders)
    r.Run(":8080")
}
```

**3. Javaåº”ç”¨é›†æˆPyroscope**ï¼š

```java
// pom.xml
<dependency>
    <groupId>io.pyroscope</groupId>
    <artifactId>agent</artifactId>
    <version>0.13.0</version>
</dependency>

// Application.java
import io.pyroscope.javaagent.PyroscopeAgent;
import io.pyroscope.javaagent.config.Config;

@SpringBootApplication
public class Application {
    public static void main(String[] args) {
        // åˆå§‹åŒ–Pyroscope
        PyroscopeAgent.start(
            new Config.Builder()
                .setApplicationName("user-service")
                .setProfilingEvent(EventType.ITIMER)
                .setServerAddress("http://pyroscope.observability.svc.cluster.local:4040")
                .build()
        );
        
        SpringApplication.run(Application.class, args);
    }
}
```

**4. Pyroscope UIä½¿ç”¨**ï¼š

è®¿é—®Pyroscope UIï¼ˆhttp://pyroscope.example.comï¼‰ï¼Œå¯ä»¥ï¼š
- æŸ¥çœ‹å®æ—¶ç«ç„°å›¾
- å¯¹æ¯”ä¸åŒæ—¶é—´æ®µçš„æ€§èƒ½
- æŒ‰æ ‡ç­¾è¿‡æ»¤ï¼ˆç¯å¢ƒã€ç‰ˆæœ¬ã€åŒºåŸŸï¼‰
- å¯¼å‡ºprofileæ•°æ®


### 9.7.3 é”™è¯¯è¿½è¸ªä¸å¼‚å¸¸ç›‘æ§

é”™è¯¯è¿½è¸ªæ˜¯APMçš„å…³é”®åŠŸèƒ½ï¼Œå®ƒå¸®åŠ©æˆ‘ä»¬å¿«é€Ÿå‘ç°ã€å®šä½å’Œä¿®å¤åº”ç”¨é”™è¯¯ã€‚

#### Sentryï¼šå¼€æºé”™è¯¯è¿½è¸ªå¹³å°

Sentryæ˜¯ä¸šç•Œé¢†å…ˆçš„é”™è¯¯è¿½è¸ªå¹³å°ï¼Œæ”¯æŒå¤šç§è¯­è¨€å’Œæ¡†æ¶ã€‚

**1. éƒ¨ç½²Sentryï¼ˆä½¿ç”¨Helmï¼‰**ï¼š

```bash
# æ·»åŠ Sentry Helmä»“åº“
helm repo add sentry https://sentry-kubernetes.github.io/charts
helm repo update

# åˆ›å»ºnamespace
kubectl create namespace sentry

# å®‰è£…Sentry
helm install sentry sentry/sentry \
  --namespace sentry \
  --set user.email=admin@example.com \
  --set user.password=admin123 \
  --set ingress.enabled=true \
  --set ingress.hostname=sentry.example.com \
  --set postgresql.enabled=true \
  --set redis.enabled=true \
  --set kafka.enabled=true

# ç­‰å¾…æ‰€æœ‰Podå°±ç»ª
kubectl wait --for=condition=ready pod -l app=sentry -n sentry --timeout=600s

# è·å–Sentry URL
echo "Sentry URL: http://sentry.example.com"
```

**2. Goåº”ç”¨é›†æˆSentry**ï¼š

```go
package main

import (
    "fmt"
    "time"

    "github.com/getsentry/sentry-go"
    sentrygin "github.com/getsentry/sentry-go/gin"
    "github.com/gin-gonic/gin"
)

func main() {
    // åˆå§‹åŒ–Sentry
    err := sentry.Init(sentry.ClientOptions{
        Dsn: "https://examplePublicKey@sentry.example.com/0",
        Environment: "production",
        Release: "order-service@1.0.0",
        
        // é‡‡æ ·ç‡ï¼ˆ1.0 = 100%ï¼‰
        SampleRate: 1.0,
        
        // è¿½è¸ªé‡‡æ ·ç‡
        TracesSampleRate: 0.1,
        
        // æ€§èƒ½ç›‘æ§
        EnableTracing: true,
        
        // é™„åŠ ä¸Šä¸‹æ–‡
        BeforeSend: func(event *sentry.Event, hint *sentry.EventHint) *sentry.Event {
            // è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
            if event.Request != nil {
                event.Request.Cookies = ""
                event.Request.Headers = filterHeaders(event.Request.Headers)
            }
            return event
        },
    })
    if err != nil {
        panic(err)
    }
    defer sentry.Flush(2 * time.Second)

    r := gin.Default()
    
    // ä½¿ç”¨Sentryä¸­é—´ä»¶
    r.Use(sentrygin.New(sentrygin.Options{
        Repanic: true,
        WaitForDelivery: false,
    }))

    r.GET("/api/orders/:id", getOrder)
    r.POST("/api/orders", createOrder)
    
    r.Run(":8080")
}

func getOrder(c *gin.Context) {
    orderID := c.Param("id")
    
    // è®¾ç½®Sentryä¸Šä¸‹æ–‡
    if hub := sentrygin.GetHubFromContext(c); hub != nil {
        hub.Scope().SetTag("order_id", orderID)
        hub.Scope().SetUser(sentry.User{
            ID:       c.GetHeader("X-User-ID"),
            Email:    c.GetHeader("X-User-Email"),
            Username: c.GetHeader("X-User-Name"),
        })
    }
    
    // ä¸šåŠ¡é€»è¾‘
    order, err := orderService.GetOrder(orderID)
    if err != nil {
        // æ‰‹åŠ¨æ•è·é”™è¯¯
        sentry.CaptureException(err)
        c.JSON(500, gin.H{"error": err.Error()})
        return
    }
    
    c.JSON(200, order)
}

func createOrder(c *gin.Context) {
    var req CreateOrderRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        // æ•è·éªŒè¯é”™è¯¯
        sentry.CaptureException(err)
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }
    
    // åˆ›å»ºSentryäº‹åŠ¡ï¼ˆç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
    span := sentry.StartSpan(c.Request.Context(), "order.create")
    defer span.Finish()
    
    // å­æ“ä½œ
    validateSpan := span.StartChild("order.validate")
    if err := validateOrder(&req); err != nil {
        validateSpan.Status = sentry.SpanStatusInvalidArgument
        validateSpan.Finish()
        
        sentry.CaptureException(err)
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }
    validateSpan.Status = sentry.SpanStatusOK
    validateSpan.Finish()
    
    // æ•°æ®åº“æ“ä½œ
    dbSpan := span.StartChild("db.insert.orders")
    order, err := orderService.CreateOrder(&req)
    dbSpan.Finish()
    
    if err != nil {
        // æ•è·æ•°æ®åº“é”™è¯¯ï¼Œé™„åŠ é¢å¤–ä¿¡æ¯
        sentry.WithScope(func(scope *sentry.Scope) {
            scope.SetContext("order_data", map[string]interface{}{
                "user_id":    req.UserID,
                "product_id": req.ProductID,
                "quantity":   req.Quantity,
            })
            scope.SetLevel(sentry.LevelError)
            sentry.CaptureException(err)
        })
        
        c.JSON(500, gin.H{"error": "Failed to create order"})
        return
    }
    
    c.JSON(201, order)
}

// è‡ªå®šä¹‰é”™è¯¯ç±»å‹
type OrderValidationError struct {
    Field   string
    Message string
}

func (e *OrderValidationError) Error() string {
    return fmt.Sprintf("Validation error on field %s: %s", e.Field, e.Message)
}

func validateOrder(req *CreateOrderRequest) error {
    if req.Quantity <= 0 {
        return &OrderValidationError{
            Field:   "quantity",
            Message: "Quantity must be greater than 0",
        }
    }
    return nil
}

// è¿‡æ»¤æ•æ„ŸHTTPå¤´
func filterHeaders(headers map[string]string) map[string]string {
    filtered := make(map[string]string)
    for k, v := range headers {
        if k == "Authorization" || k == "Cookie" {
            filtered[k] = "[Filtered]"
        } else {
            filtered[k] = v
        }
    }
    return filtered
}
```

**3. Javaåº”ç”¨é›†æˆSentry**ï¼š

```java
// pom.xml
<dependency>
    <groupId>io.sentry</groupId>
    <artifactId>sentry-spring-boot-starter</artifactId>
    <version>6.34.0</version>
</dependency>

// application.yml
sentry:
  dsn: https://examplePublicKey@sentry.example.com/0
  environment: production
  release: user-service@1.0.0
  traces-sample-rate: 0.1
  send-default-pii: false  # ä¸å‘é€ä¸ªäººèº«ä»½ä¿¡æ¯

// SentryConfig.java
@Configuration
public class SentryConfig {

    @Bean
    public SentryOptions.BeforeSendCallback beforeSendCallback() {
        return (event, hint) -> {
            // è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
            if (event.getRequest() != null) {
                event.getRequest().setCookies(null);
                Map<String, String> headers = event.getRequest().getHeaders();
                if (headers != null) {
                    headers.remove("Authorization");
                    headers.remove("Cookie");
                }
            }
            return event;
        };
    }
}

// UserController.java
@RestController
@RequestMapping("/api/users")
public class UserController {

    @Autowired
    private UserService userService;

    @GetMapping("/{id}")
    public ResponseEntity<User> getUser(@PathVariable String id) {
        try {
            // è®¾ç½®Sentryä¸Šä¸‹æ–‡
            Sentry.configureScope(scope -> {
                scope.setTag("user_id", id);
                scope.setUser(new io.sentry.protocol.User() {{
                    setId(id);
                }});
            });

            User user = userService.findById(id);
            return ResponseEntity.ok(user);
            
        } catch (UserNotFoundException e) {
            // æ•è·ä¸šåŠ¡å¼‚å¸¸
            Sentry.captureException(e);
            return ResponseEntity.notFound().build();
            
        } catch (Exception e) {
            // æ•è·æœªçŸ¥å¼‚å¸¸
            Sentry.captureException(e);
            return ResponseEntity.status(500).build();
        }
    }

    @PostMapping
    public ResponseEntity<User> createUser(@RequestBody CreateUserRequest request) {
        // åˆ›å»ºSentryäº‹åŠ¡
        ITransaction transaction = Sentry.startTransaction("user.create", "http");
        
        try {
            // éªŒè¯
            ISpan validateSpan = transaction.startChild("user.validate");
            validateUser(request);
            validateSpan.finish();

            // æ•°æ®åº“æ“ä½œ
            ISpan dbSpan = transaction.startChild("db.insert.users");
            User user = userService.createUser(request);
            dbSpan.finish();

            transaction.setStatus(SpanStatus.OK);
            return ResponseEntity.ok(user);
            
        } catch (ValidationException e) {
            transaction.setStatus(SpanStatus.INVALID_ARGUMENT);
            Sentry.captureException(e);
            return ResponseEntity.badRequest().build();
            
        } catch (Exception e) {
            transaction.setStatus(SpanStatus.INTERNAL_ERROR);
            Sentry.captureException(e);
            return ResponseEntity.status(500).build();
            
        } finally {
            transaction.finish();
        }
    }
}

// å…¨å±€å¼‚å¸¸å¤„ç†å™¨
@ControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(Exception.class)
    public ResponseEntity<ErrorResponse> handleException(Exception e) {
        // è‡ªåŠ¨æ•è·æ‰€æœ‰æœªå¤„ç†çš„å¼‚å¸¸
        Sentry.captureException(e);
        
        return ResponseEntity.status(500).body(
            new ErrorResponse("Internal server error")
        );
    }
}
```

**4. Pythonåº”ç”¨é›†æˆSentry**ï¼š

```python
# requirements.txt
sentry-sdk[flask]==1.39.0

# app.py
import sentry_sdk
from sentry_sdk.integrations.flask import FlaskIntegration
from sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration
from flask import Flask, request, jsonify

# åˆå§‹åŒ–Sentry
sentry_sdk.init(
    dsn="https://examplePublicKey@sentry.example.com/0",
    environment="production",
    release="inventory-service@1.0.0",
    
    # é›†æˆ
    integrations=[
        FlaskIntegration(),
        SqlalchemyIntegration(),
    ],
    
    # é‡‡æ ·ç‡
    traces_sample_rate=0.1,
    
    # è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
    before_send=lambda event, hint: filter_sensitive_data(event),
)

app = Flask(__name__)

@app.route('/api/inventory/<product_id>')
def get_inventory(product_id):
    # è®¾ç½®Sentryä¸Šä¸‹æ–‡
    with sentry_sdk.configure_scope() as scope:
        scope.set_tag("product_id", product_id)
        scope.set_user({
            "id": request.headers.get("X-User-ID"),
            "email": request.headers.get("X-User-Email"),
        })
    
    try:
        inventory = db.query_inventory(product_id)
        return jsonify(inventory)
    except InventoryNotFoundError as e:
        # æ•è·ä¸šåŠ¡å¼‚å¸¸
        sentry_sdk.capture_exception(e)
        return jsonify({"error": "Inventory not found"}), 404
    except Exception as e:
        # æ•è·æœªçŸ¥å¼‚å¸¸
        sentry_sdk.capture_exception(e)
        return jsonify({"error": "Internal server error"}), 500

@app.route('/api/inventory', methods=['POST'])
def update_inventory():
    data = request.get_json()
    
    # åˆ›å»ºSentryäº‹åŠ¡
    with sentry_sdk.start_transaction(op="inventory.update", name="POST /api/inventory"):
        # éªŒè¯
        with sentry_sdk.start_span(op="inventory.validate"):
            if not validate_inventory_data(data):
                raise ValidationError("Invalid inventory data")
        
        # æ•°æ®åº“æ“ä½œ
        with sentry_sdk.start_span(op="db.update.inventory"):
            result = db.update_inventory(data)
        
        return jsonify(result), 200

def filter_sensitive_data(event):
    """è¿‡æ»¤æ•æ„Ÿä¿¡æ¯"""
    if event.get('request'):
        # ç§»é™¤æ•æ„ŸHTTPå¤´
        if 'headers' in event['request']:
            event['request']['headers'].pop('Authorization', None)
            event['request']['headers'].pop('Cookie', None)
        
        # ç§»é™¤æ•æ„ŸæŸ¥è¯¢å‚æ•°
        if 'query_string' in event['request']:
            event['request']['query_string'] = '[Filtered]'
    
    return event

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**5. Sentryå‘Šè­¦é…ç½®**ï¼š

åœ¨Sentry UIä¸­é…ç½®å‘Šè­¦è§„åˆ™ï¼š

```yaml
# å‘Šè­¦è§„åˆ™ç¤ºä¾‹
alerts:
  # é”™è¯¯ç‡å‘Šè­¦
  - name: High Error Rate
    conditions:
      - type: event_frequency
        value: 100
        interval: 1m
    actions:
      - type: slack
        channel: "#alerts"
      - type: email
        recipients: ["team@example.com"]
  
  # æ–°é”™è¯¯å‘Šè­¦
  - name: New Error Type
    conditions:
      - type: first_seen_event
    actions:
      - type: slack
        channel: "#alerts"
  
  # æ€§èƒ½é€€åŒ–å‘Šè­¦
  - name: Performance Degradation
    conditions:
      - type: transaction_duration
        percentile: 95
        threshold: 2000  # 2ç§’
        comparison: greater
    actions:
      - type: pagerduty
        service: "order-service"
```

#### é”™è¯¯åˆ†ç±»ä¸ä¼˜å…ˆçº§

**é”™è¯¯ä¸¥é‡æ€§åˆ†çº§**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CRITICALï¼ˆä¸¥é‡ï¼‰                                             â”‚
â”‚ - å½±å“æ ¸å¿ƒä¸šåŠ¡æµç¨‹ï¼ˆæ”¯ä»˜å¤±è´¥ã€è®¢å•ä¸¢å¤±ï¼‰                     â”‚
â”‚ - æ•°æ®æŸåæˆ–ä¸¢å¤±                                             â”‚
â”‚ - å®‰å…¨æ¼æ´                                                   â”‚
â”‚ - å¤„ç†ï¼šç«‹å³ä¿®å¤ï¼Œå‘é€PagerDutyå‘Šè­¦                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ERRORï¼ˆé”™è¯¯ï¼‰                                                â”‚
â”‚ - åŠŸèƒ½ä¸å¯ç”¨ï¼ˆAPIè¿”å›500ï¼‰                                   â”‚
â”‚ - å¤–éƒ¨æœåŠ¡è°ƒç”¨å¤±è´¥                                           â”‚
â”‚ - æ•°æ®åº“è¿æ¥å¤±è´¥                                             â”‚
â”‚ - å¤„ç†ï¼š24å°æ—¶å†…ä¿®å¤ï¼Œå‘é€Slackå‘Šè­¦                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WARNINGï¼ˆè­¦å‘Šï¼‰                                              â”‚
â”‚ - æ€§èƒ½ä¸‹é™ï¼ˆå“åº”æ—¶é—´>2ç§’ï¼‰                                   â”‚
â”‚ - èµ„æºä½¿ç”¨ç‡é«˜ï¼ˆCPU>80%ï¼‰                                    â”‚
â”‚ - é‡è¯•æˆåŠŸçš„å¤±è´¥                                             â”‚
â”‚ - å¤„ç†ï¼š1å‘¨å†…ä¿®å¤ï¼Œè®°å½•æ—¥å¿—                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INFOï¼ˆä¿¡æ¯ï¼‰                                                 â”‚
â”‚ - é¢„æœŸçš„ä¸šåŠ¡å¼‚å¸¸ï¼ˆç”¨æˆ·æœªæ‰¾åˆ°ï¼‰                               â”‚
â”‚ - éªŒè¯å¤±è´¥ï¼ˆå‚æ•°é”™è¯¯ï¼‰                                       â”‚
â”‚ - å¤„ç†ï¼šä¸éœ€è¦ç«‹å³å¤„ç†ï¼Œç”¨äºåˆ†æ                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é”™è¯¯åˆ†ç»„ç­–ç•¥**ï¼š

```go
// è‡ªå®šä¹‰é”™è¯¯åˆ†ç»„ï¼ˆé€šè¿‡Fingerprintï¼‰
func captureErrorWithFingerprint(err error, fingerprint []string) {
    sentry.WithScope(func(scope *sentry.Scope) {
        // è®¾ç½®Fingerprintï¼Œç›¸åŒFingerprintçš„é”™è¯¯ä¼šè¢«åˆ†ç»„
        scope.SetFingerprint(fingerprint)
        sentry.CaptureException(err)
    })
}

// ç¤ºä¾‹ï¼šæŒ‰é”™è¯¯ç±»å‹å’Œæ•°æ®åº“è¡¨åˆ†ç»„
func handleDBError(err error, table string) {
    fingerprint := []string{
        "database-error",
        table,
        err.Error(),
    }
    captureErrorWithFingerprint(err, fingerprint)
}

// ç¤ºä¾‹ï¼šæŒ‰å¤–éƒ¨APIå’Œé”™è¯¯ç åˆ†ç»„
func handleAPIError(err error, apiName string, statusCode int) {
    fingerprint := []string{
        "external-api-error",
        apiName,
        fmt.Sprintf("status-%d", statusCode),
    }
    captureErrorWithFingerprint(err, fingerprint)
}
```

### 9.7.4 ç”¨æˆ·ä½“éªŒç›‘æ§ï¼ˆRUMï¼‰

çœŸå®ç”¨æˆ·ç›‘æ§ï¼ˆReal User Monitoringï¼ŒRUMï¼‰å…³æ³¨çœŸå®ç”¨æˆ·çš„è®¿é—®ä½“éªŒï¼ŒåŒ…æ‹¬é¡µé¢åŠ è½½æ—¶é—´ã€äº¤äº’å“åº”ã€é”™è¯¯ç‡ç­‰ã€‚

#### å‰ç«¯æ€§èƒ½æŒ‡æ ‡

**æ ¸å¿ƒWebæŒ‡æ ‡ï¼ˆCore Web Vitalsï¼‰**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LCPï¼ˆLargest Contentful Paintï¼‰- æœ€å¤§å†…å®¹ç»˜åˆ¶               â”‚
â”‚ - è¡¡é‡åŠ è½½æ€§èƒ½                                               â”‚
â”‚ - ç›®æ ‡ï¼š< 2.5ç§’                                              â”‚
â”‚ - ä¼˜åŒ–ï¼šä¼˜åŒ–å›¾ç‰‡ã€ä½¿ç”¨CDNã€æœåŠ¡ç«¯æ¸²æŸ“                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FIDï¼ˆFirst Input Delayï¼‰- é¦–æ¬¡è¾“å…¥å»¶è¿Ÿ                      â”‚
â”‚ - è¡¡é‡äº¤äº’æ€§                                                 â”‚
â”‚ - ç›®æ ‡ï¼š< 100æ¯«ç§’                                            â”‚
â”‚ - ä¼˜åŒ–ï¼šå‡å°‘JavaScriptæ‰§è¡Œæ—¶é—´ã€ä»£ç åˆ†å‰²                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLSï¼ˆCumulative Layout Shiftï¼‰- ç´¯ç§¯å¸ƒå±€åç§»                â”‚
â”‚ - è¡¡é‡è§†è§‰ç¨³å®šæ€§                                             â”‚
â”‚ - ç›®æ ‡ï¼š< 0.1                                                â”‚
â”‚ - ä¼˜åŒ–ï¼šä¸ºå›¾ç‰‡/è§†é¢‘è®¾ç½®å°ºå¯¸ã€é¿å…åŠ¨æ€æ’å…¥å†…å®¹                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…¶ä»–å…³é”®æŒ‡æ ‡**ï¼š

```javascript
// TTFBï¼ˆTime to First Byteï¼‰- é¦–å­—èŠ‚æ—¶é—´
// FCPï¼ˆFirst Contentful Paintï¼‰- é¦–æ¬¡å†…å®¹ç»˜åˆ¶
// TTIï¼ˆTime to Interactiveï¼‰- å¯äº¤äº’æ—¶é—´
// TBTï¼ˆTotal Blocking Timeï¼‰- æ€»é˜»å¡æ—¶é—´
```

#### å‰ç«¯ç›‘æ§å®ç°

**1. ä½¿ç”¨Web Vitalsåº“**ï¼š

```html
<!DOCTYPE html>
<html>
<head>
    <title>Order Page</title>
</head>
<body>
    <h1>My Orders</h1>
    <div id="orders"></div>

    <script type="module">
        import {onCLS, onFID, onLCP, onFCP, onTTFB} from 'https://unpkg.com/web-vitals@3?module';

        // å‘é€æŒ‡æ ‡åˆ°åç«¯
        function sendToAnalytics(metric) {
            const body = JSON.stringify({
                name: metric.name,
                value: metric.value,
                rating: metric.rating,
                delta: metric.delta,
                id: metric.id,
                navigationType: metric.navigationType,
                url: window.location.href,
                userAgent: navigator.userAgent,
            });

            // ä½¿ç”¨sendBeaconç¡®ä¿æ•°æ®å‘é€ï¼ˆå³ä½¿é¡µé¢å…³é—­ï¼‰
            if (navigator.sendBeacon) {
                navigator.sendBeacon('/api/analytics/web-vitals', body);
            } else {
                fetch('/api/analytics/web-vitals', {
                    method: 'POST',
                    body: body,
                    headers: {'Content-Type': 'application/json'},
                    keepalive: true,
                });
            }
        }

        // ç›‘å¬æ‰€æœ‰Core Web Vitals
        onCLS(sendToAnalytics);
        onFID(sendToAnalytics);
        onLCP(sendToAnalytics);
        onFCP(sendToAnalytics);
        onTTFB(sendToAnalytics);
    </script>
</body>
</html>
```

**2. åç«¯æ¥æ”¶Web Vitalsæ•°æ®**ï¼š

```go
package main

import (
    "github.com/gin-gonic/gin"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // Web VitalsæŒ‡æ ‡
    webVitalsLCP = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "web_vitals_lcp_seconds",
            Help:    "Largest Contentful Paint in seconds",
            Buckets: []float64{0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 10},
        },
        []string{"page", "rating"},
    )

    webVitalsFID = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "web_vitals_fid_seconds",
            Help:    "First Input Delay in seconds",
            Buckets: []float64{0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 1},
        },
        []string{"page", "rating"},
    )

    webVitalsCLS = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "web_vitals_cls_score",
            Help:    "Cumulative Layout Shift score",
            Buckets: []float64{0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 1},
        },
        []string{"page", "rating"},
    )
)

type WebVitalsMetric struct {
    Name            string  `json:"name"`
    Value           float64 `json:"value"`
    Rating          string  `json:"rating"`
    Delta           float64 `json:"delta"`
    ID              string  `json:"id"`
    NavigationType  string  `json:"navigationType"`
    URL             string  `json:"url"`
    UserAgent       string  `json:"userAgent"`
}

func handleWebVitals(c *gin.Context) {
    var metric WebVitalsMetric
    if err := c.ShouldBindJSON(&metric); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }

    // æå–é¡µé¢è·¯å¾„
    page := extractPagePath(metric.URL)

    // è®°å½•æŒ‡æ ‡
    switch metric.Name {
    case "LCP":
        webVitalsLCP.WithLabelValues(page, metric.Rating).Observe(metric.Value / 1000)
    case "FID":
        webVitalsFID.WithLabelValues(page, metric.Rating).Observe(metric.Value / 1000)
    case "CLS":
        webVitalsCLS.WithLabelValues(page, metric.Rating).Observe(metric.Value)
    }

    c.JSON(200, gin.H{"status": "ok"})
}

func main() {
    r := gin.Default()
    r.POST("/api/analytics/web-vitals", handleWebVitals)
    r.Run(":8080")
}
```

**3. Grafanaå¯è§†åŒ–Web Vitals**ï¼š

```promql
# LCP P75ï¼ˆ75%çš„ç”¨æˆ·ä½“éªŒï¼‰
histogram_quantile(0.75, 
  sum(rate(web_vitals_lcp_seconds_bucket[5m])) by (le, page)
)

# FID P95
histogram_quantile(0.95, 
  sum(rate(web_vitals_fid_seconds_bucket[5m])) by (le, page)
)

# CLSå¹³å‡å€¼
avg(rate(web_vitals_cls_score_sum[5m])) by (page)
/
avg(rate(web_vitals_cls_score_count[5m])) by (page)

# å„é¡µé¢çš„"Good"è¯„çº§å æ¯”
sum(rate(web_vitals_lcp_seconds_count{rating="good"}[5m])) by (page)
/
sum(rate(web_vitals_lcp_seconds_count[5m])) by (page)
```


#### å‰ç«¯é”™è¯¯ç›‘æ§

**1. å…¨å±€é”™è¯¯æ•è·**ï¼š

```javascript
// æ•è·JavaScripté”™è¯¯
window.addEventListener('error', function(event) {
    const errorData = {
        type: 'javascript_error',
        message: event.message,
        filename: event.filename,
        lineno: event.lineno,
        colno: event.colno,
        stack: event.error ? event.error.stack : null,
        url: window.location.href,
        userAgent: navigator.userAgent,
        timestamp: new Date().toISOString(),
    };

    // å‘é€åˆ°åç«¯
    fetch('/api/analytics/errors', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify(errorData),
        keepalive: true,
    });
});

// æ•è·Promiseæœªå¤„ç†çš„rejection
window.addEventListener('unhandledrejection', function(event) {
    const errorData = {
        type: 'unhandled_rejection',
        message: event.reason ? event.reason.message : 'Unknown error',
        stack: event.reason ? event.reason.stack : null,
        url: window.location.href,
        userAgent: navigator.userAgent,
        timestamp: new Date().toISOString(),
    };

    fetch('/api/analytics/errors', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify(errorData),
        keepalive: true,
    });
});

// æ•è·èµ„æºåŠ è½½é”™è¯¯
window.addEventListener('error', function(event) {
    if (event.target !== window) {
        const errorData = {
            type: 'resource_error',
            message: `Failed to load resource: ${event.target.src || event.target.href}`,
            resource: event.target.tagName,
            url: window.location.href,
            timestamp: new Date().toISOString(),
        };

        fetch('/api/analytics/errors', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(errorData),
            keepalive: true,
        });
    }
}, true);
```

**2. APIè°ƒç”¨ç›‘æ§**ï¼š

```javascript
// å°è£…fetchï¼Œè‡ªåŠ¨ç›‘æ§APIè°ƒç”¨
const originalFetch = window.fetch;
window.fetch = function(...args) {
    const startTime = performance.now();
    const url = args[0];
    const options = args[1] || {};

    return originalFetch.apply(this, args)
        .then(response => {
            const duration = performance.now() - startTime;

            // è®°å½•APIè°ƒç”¨æŒ‡æ ‡
            const apiMetric = {
                type: 'api_call',
                url: url,
                method: options.method || 'GET',
                status: response.status,
                duration: duration,
                timestamp: new Date().toISOString(),
            };

            navigator.sendBeacon('/api/analytics/api-calls', JSON.stringify(apiMetric));

            // å¦‚æœæ˜¯é”™è¯¯å“åº”ï¼Œè®°å½•é”™è¯¯
            if (!response.ok) {
                const errorData = {
                    type: 'api_error',
                    url: url,
                    method: options.method || 'GET',
                    status: response.status,
                    statusText: response.statusText,
                    timestamp: new Date().toISOString(),
                };

                navigator.sendBeacon('/api/analytics/errors', JSON.stringify(errorData));
            }

            return response;
        })
        .catch(error => {
            const duration = performance.now() - startTime;

            // è®°å½•ç½‘ç»œé”™è¯¯
            const errorData = {
                type: 'network_error',
                url: url,
                method: options.method || 'GET',
                message: error.message,
                duration: duration,
                timestamp: new Date().toISOString(),
            };

            navigator.sendBeacon('/api/analytics/errors', JSON.stringify(errorData));

            throw error;
        });
};
```

### 9.7.5 å¯è§‚æµ‹æ€§å¹³å°æ„å»º

æ•´åˆå‰é¢å­¦ä¹ çš„æ‰€æœ‰æŠ€æœ¯ï¼Œæ„å»ºå®Œæ•´çš„å¯è§‚æµ‹æ€§å¹³å°ã€‚

#### ç»Ÿä¸€å¯è§‚æµ‹æ€§æ¶æ„

**å®Œæ•´æ¶æ„å›¾**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Frontend  â”‚  â”‚Service A â”‚  â”‚Service B â”‚  â”‚Service C â”‚   â”‚
â”‚  â”‚(Browser) â”‚  â”‚  (Go)    â”‚  â”‚ (Java)   â”‚  â”‚ (Python) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â”‚ RUM         â”‚ Metrics     â”‚ Traces      â”‚ Logs
        â”‚ Errors      â”‚ Traces      â”‚ Metrics     â”‚ Errors
        â”‚             â”‚ Logs        â”‚ Logs        â”‚ Profiles
        â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Collection Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Analytics â”‚  â”‚Prometheusâ”‚  â”‚   OTel   â”‚  â”‚ Fluentd  â”‚   â”‚
â”‚  â”‚ Service  â”‚  â”‚  (Pull)  â”‚  â”‚Collector â”‚  â”‚ (Push)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Storage Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚PostgreSQLâ”‚  â”‚Prometheusâ”‚  â”‚  Jaeger  â”‚  â”‚  Elastic â”‚   â”‚
â”‚  â”‚  (RUM)   â”‚  â”‚ (Metrics)â”‚  â”‚ (Traces) â”‚  â”‚  (Logs)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Visualization & Analysis                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  Grafana Dashboard                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚  Metrics   â”‚  â”‚   Traces   â”‚  â”‚    Logs    â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  (Prom)    â”‚  â”‚  (Jaeger)  â”‚  â”‚   (ES)     â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚    RUM     â”‚  â”‚   Errors   â”‚  â”‚  Profiles  â”‚     â”‚   â”‚
â”‚  â”‚  â”‚   (SQL)    â”‚  â”‚  (Sentry)  â”‚  â”‚ (Pyroscope)â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 Alerting & Incident                   â”‚   â”‚
â”‚  â”‚  - AlertManager (Prometheus)                          â”‚   â”‚
â”‚  â”‚  - Sentry Alerts (Errors)                             â”‚   â”‚
â”‚  â”‚  - PagerDuty Integration                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ç»Ÿä¸€Grafana Dashboard

**åˆ›å»ºç»¼åˆAPM Dashboard**ï¼š

```yaml
# grafana-dashboard-apm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-apm
  namespace: observability
  labels:
    grafana_dashboard: "1"
data:
  apm-dashboard.json: |
    {
      "dashboard": {
        "title": "APM - Application Performance Monitoring",
        "tags": ["apm", "performance"],
        "timezone": "browser",
        "panels": [
          {
            "title": "Golden Signals",
            "type": "row",
            "panels": [
              {
                "title": "Request Rate (RPS)",
                "targets": [
                  {
                    "expr": "sum(rate(http_requests_total[5m])) by (service)",
                    "legendFormat": "{{service}}"
                  }
                ]
              },
              {
                "title": "Error Rate",
                "targets": [
                  {
                    "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service)",
                    "legendFormat": "{{service}}"
                  }
                ]
              },
              {
                "title": "P99 Latency",
                "targets": [
                  {
                    "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))",
                    "legendFormat": "{{service}}"
                  }
                ]
              },
              {
                "title": "Saturation (CPU)",
                "targets": [
                  {
                    "expr": "avg(rate(container_cpu_usage_seconds_total[5m])) by (pod)",
                    "legendFormat": "{{pod}}"
                  }
                ]
              }
            ]
          },
          {
            "title": "Business Metrics",
            "type": "row",
            "panels": [
              {
                "title": "Orders Created",
                "targets": [
                  {
                    "expr": "sum(rate(orders_created_total[5m])) by (status)",
                    "legendFormat": "{{status}}"
                  }
                ]
              },
              {
                "title": "Payment Success Rate",
                "targets": [
                  {
                    "expr": "sum(rate(orders_created_total{status=\"success\"}[5m])) / sum(rate(orders_created_total[5m]))",
                    "legendFormat": "Success Rate"
                  }
                ]
              }
            ]
          },
          {
            "title": "Database Performance",
            "type": "row",
            "panels": [
              {
                "title": "DB Query Duration (P95)",
                "targets": [
                  {
                    "expr": "histogram_quantile(0.95, sum(rate(db_query_duration_seconds_bucket[5m])) by (le, query_type, table))",
                    "legendFormat": "{{query_type}} - {{table}}"
                  }
                ]
              },
              {
                "title": "Cache Hit Rate",
                "targets": [
                  {
                    "expr": "sum(rate(cache_hits_total[5m])) by (cache_name) / (sum(rate(cache_hits_total[5m])) by (cache_name) + sum(rate(cache_misses_total[5m])) by (cache_name))",
                    "legendFormat": "{{cache_name}}"
                  }
                ]
              }
            ]
          },
          {
            "title": "Traces (Jaeger)",
            "type": "row",
            "panels": [
              {
                "title": "Trace Heatmap",
                "type": "heatmap",
                "dataFormat": "tsbuckets",
                "targets": [
                  {
                    "expr": "sum(rate(jaeger_tracer_finished_spans_bucket[5m])) by (le)",
                    "format": "heatmap"
                  }
                ]
              },
              {
                "title": "Service Dependencies",
                "type": "nodeGraph",
                "dataSource": "Jaeger"
              }
            ]
          },
          {
            "title": "Errors (Sentry)",
            "type": "row",
            "panels": [
              {
                "title": "Error Count by Service",
                "type": "table",
                "dataSource": "PostgreSQL",
                "targets": [
                  {
                    "rawSql": "SELECT service, COUNT(*) as error_count FROM sentry_errors WHERE timestamp > NOW() - INTERVAL '1 hour' GROUP BY service ORDER BY error_count DESC"
                  }
                ]
              }
            ]
          },
          {
            "title": "Real User Monitoring",
            "type": "row",
            "panels": [
              {
                "title": "Core Web Vitals - LCP",
                "targets": [
                  {
                    "expr": "histogram_quantile(0.75, sum(rate(web_vitals_lcp_seconds_bucket[5m])) by (le, page))",
                    "legendFormat": "{{page}} (P75)"
                  }
                ]
              },
              {
                "title": "Frontend Errors",
                "type": "table",
                "dataSource": "PostgreSQL",
                "targets": [
                  {
                    "rawSql": "SELECT type, COUNT(*) as count FROM frontend_errors WHERE timestamp > NOW() - INTERVAL '1 hour' GROUP BY type ORDER BY count DESC"
                  }
                ]
              }
            ]
          }
        ]
      }
    }
```

#### å…³è”åˆ†æï¼šMetrics + Traces + Logs

**1. Exemplarsï¼ˆç¤ºä¾‹ï¼‰**ï¼š

Prometheusæ”¯æŒExemplarsï¼Œå¯ä»¥å°†æŒ‡æ ‡ä¸Traceå…³è”ã€‚

```go
package main

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "go.opentelemetry.io/otel/trace"
)

var (
    httpRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )
)

func handleRequest(c *gin.Context) {
    start := time.Now()
    
    // å¤„ç†è¯·æ±‚
    c.Next()
    
    duration := time.Since(start).Seconds()
    
    // è·å–å½“å‰Trace ID
    spanContext := trace.SpanContextFromContext(c.Request.Context())
    traceID := spanContext.TraceID().String()
    
    // è®°å½•æŒ‡æ ‡ï¼Œé™„åŠ Trace IDä½œä¸ºExemplar
    observer := httpRequestDuration.WithLabelValues(
        c.Request.Method,
        c.FullPath(),
    )
    
    // ä½¿ç”¨ObserveWithExemplarå…³è”Trace
    if exemplar, ok := observer.(prometheus.ExemplarObserver); ok {
        exemplar.ObserveWithExemplar(
            duration,
            prometheus.Labels{"traceID": traceID},
        )
    } else {
        observer.Observe(duration)
    }
}
```

**Grafanaä¸­æŸ¥çœ‹Exemplars**ï¼š

åœ¨Grafanaçš„PrometheusæŸ¥è¯¢ä¸­ï¼Œå¯ä»¥ç›´æ¥ç‚¹å‡»Exemplarè·³è½¬åˆ°å¯¹åº”çš„Traceã€‚

```promql
# æŸ¥è¯¢P99å»¶è¿Ÿï¼Œæ˜¾ç¤ºExemplars
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

**2. Trace IDæ³¨å…¥æ—¥å¿—**ï¼š

```go
import (
    "go.uber.org/zap"
    "go.opentelemetry.io/otel/trace"
)

func logWithTraceID(ctx context.Context, logger *zap.Logger, msg string) {
    spanContext := trace.SpanContextFromContext(ctx)
    traceID := spanContext.TraceID().String()
    spanID := spanContext.SpanID().String()
    
    logger.Info(msg,
        zap.String("trace_id", traceID),
        zap.String("span_id", spanID),
    )
}

// ä½¿ç”¨ç¤ºä¾‹
func processOrder(ctx context.Context, orderID string) {
    logWithTraceID(ctx, logger, "Processing order started")
    
    // ä¸šåŠ¡é€»è¾‘...
    
    logWithTraceID(ctx, logger, "Processing order completed")
}
```

**åœ¨Grafanaä¸­å…³è”æŸ¥è¯¢**ï¼š

```
1. åœ¨Prometheusä¸­å‘ç°æ…¢è¯·æ±‚
2. ç‚¹å‡»Exemplarè·³è½¬åˆ°JaegeræŸ¥çœ‹Trace
3. ä»Traceä¸­è·å–Trace ID
4. åœ¨Elasticsearchä¸­æœç´¢è¯¥Trace IDçš„æ‰€æœ‰æ—¥å¿—
```

**Grafana ExploreæŸ¥è¯¢ç¤ºä¾‹**ï¼š

```
# LokiæŸ¥è¯¢ï¼ˆé€šè¿‡Trace IDè¿‡æ»¤æ—¥å¿—ï¼‰
{namespace="production"} |= "trace_id=a1b2c3d4e5f6g7h8"
```

#### å‘Šè­¦å…³è”ä¸äº‹ä»¶ç®¡ç†

**1. å¤šç»´åº¦å‘Šè­¦è§„åˆ™**ï¼š

```yaml
# prometheus-rules.yaml
groups:
- name: apm-alerts
  rules:
  # ç»¼åˆå‘Šè­¦ï¼šé«˜é”™è¯¯ç‡ + æ…¢å“åº”
  - alert: ServiceDegraded
    expr: |
      (
        sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
        /
        sum(rate(http_requests_total[5m])) by (service)
        > 0.05
      )
      and
      (
        histogram_quantile(0.99, 
          sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
        ) > 2
      )
    for: 5m
    labels:
      severity: critical
      component: application
    annotations:
      summary: "Service {{ $labels.service }} is degraded"
      description: "Error rate: {{ $value | humanizePercentage }}, P99 latency > 2s"
      runbook_url: "https://wiki.example.com/runbooks/service-degraded"
      dashboard_url: "https://grafana.example.com/d/apm/service={{ $labels.service }}"
      jaeger_url: "https://jaeger.example.com/search?service={{ $labels.service }}&lookback=1h"

  # ä¸šåŠ¡å‘Šè­¦ï¼šè®¢å•åˆ›å»ºå¤±è´¥ç‡é«˜
  - alert: HighOrderFailureRate
    expr: |
      sum(rate(orders_created_total{status="failed"}[5m]))
      /
      sum(rate(orders_created_total[5m]))
      > 0.1
    for: 5m
    labels:
      severity: critical
      component: business
    annotations:
      summary: "High order failure rate"
      description: "{{ $value | humanizePercentage }} of orders are failing"

  # æ•°æ®åº“å‘Šè­¦ï¼šæ…¢æŸ¥è¯¢
  - alert: SlowDatabaseQueries
    expr: |
      histogram_quantile(0.95, 
        sum(rate(db_query_duration_seconds_bucket[5m])) by (le, table)
      ) > 1
    for: 10m
    labels:
      severity: warning
      component: database
    annotations:
      summary: "Slow queries on table {{ $labels.table }}"
      description: "P95 query duration: {{ $value }}s"

  # å‰ç«¯å‘Šè­¦ï¼šLCPé€€åŒ–
  - alert: PoorUserExperience
    expr: |
      histogram_quantile(0.75, 
        sum(rate(web_vitals_lcp_seconds_bucket[5m])) by (le, page)
      ) > 2.5
    for: 15m
    labels:
      severity: warning
      component: frontend
    annotations:
      summary: "Poor user experience on {{ $labels.page }}"
      description: "LCP P75: {{ $value }}s (threshold: 2.5s)"
```

**2. AlertManagerè·¯ç”±é…ç½®**ï¼š

```yaml
# alertmanager-config.yaml
route:
  receiver: 'default'
  group_by: ['alertname', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  
  routes:
  # ä¸¥é‡å‘Šè­¦ â†’ PagerDuty
  - match:
      severity: critical
    receiver: 'pagerduty'
    continue: true
  
  # åº”ç”¨å‘Šè­¦ â†’ Slack #alerts
  - match:
      component: application
    receiver: 'slack-alerts'
  
  # ä¸šåŠ¡å‘Šè­¦ â†’ Slack #business
  - match:
      component: business
    receiver: 'slack-business'
  
  # å‰ç«¯å‘Šè­¦ â†’ Slack #frontend
  - match:
      component: frontend
    receiver: 'slack-frontend'

receivers:
- name: 'default'
  email_configs:
  - to: 'team@example.com'

- name: 'pagerduty'
  pagerduty_configs:
  - service_key: '<pagerduty-service-key>'
    description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
    details:
      firing: '{{ .Alerts.Firing | len }}'
      resolved: '{{ .Alerts.Resolved | len }}'
      dashboard: '{{ .CommonAnnotations.dashboard_url }}'
      jaeger: '{{ .CommonAnnotations.jaeger_url }}'

- name: 'slack-alerts'
  slack_configs:
  - api_url: '<slack-webhook-url>'
    channel: '#alerts'
    title: '{{ .GroupLabels.alertname }}'
    text: |
      {{ range .Alerts }}
      *Summary:* {{ .Annotations.summary }}
      *Description:* {{ .Annotations.description }}
      *Dashboard:* {{ .Annotations.dashboard_url }}
      *Jaeger:* {{ .Annotations.jaeger_url }}
      {{ end }}
```

### 9.7.6 æœ¬èŠ‚æ€»ç»“

æœ¬èŠ‚æ·±å…¥è®²è§£äº†APMåº”ç”¨æ€§èƒ½ç›‘æ§çš„å®Œæ•´ä½“ç³»ï¼š

âœ… **APMåŸºç¡€ä¸æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- é»„é‡‘ä¿¡å·ï¼ˆLatency/Traffic/Errors/Saturationï¼‰
- REDæ–¹æ³•ï¼ˆRate/Errors/Durationï¼‰
- USEæ–¹æ³•ï¼ˆUtilization/Saturation/Errorsï¼‰
- åº”ç”¨çº§å…³é”®æŒ‡æ ‡ï¼ˆä¸šåŠ¡/æ€§èƒ½/èµ„æº/é”™è¯¯ï¼‰
- å¤šè¯­è¨€æŒ‡æ ‡é‡‡é›†å®ç°ï¼ˆGo/Java/Pythonï¼‰

âœ… **æ€§èƒ½å‰–æï¼ˆProfilingï¼‰**ï¼š
- CPU/å†…å­˜/Goroutine/é˜»å¡/é”å‰–æ
- Go pprofå·¥å…·ä¸ç«ç„°å›¾
- Java async-profilerä¸MAT
- Python py-spyä¸memory_profiler
- æŒç»­æ€§èƒ½å‰–æï¼ˆPyroscopeï¼‰

âœ… **é”™è¯¯è¿½è¸ªä¸å¼‚å¸¸ç›‘æ§**ï¼š
- Sentryéƒ¨ç½²ä¸é›†æˆï¼ˆGo/Java/Pythonï¼‰
- é”™è¯¯ä¸Šä¸‹æ–‡ä¸å †æ ˆè¿½è¸ª
- é”™è¯¯åˆ†ç±»ä¸ä¼˜å…ˆçº§
- é”™è¯¯åˆ†ç»„ç­–ç•¥
- å‘Šè­¦é…ç½®ä¸é€šçŸ¥

âœ… **ç”¨æˆ·ä½“éªŒç›‘æ§ï¼ˆRUMï¼‰**ï¼š
- Core Web Vitalsï¼ˆLCP/FID/CLSï¼‰
- å‰ç«¯æ€§èƒ½æŒ‡æ ‡é‡‡é›†
- Web Vitalsåç«¯æ¥æ”¶ä¸å­˜å‚¨
- å‰ç«¯é”™è¯¯ç›‘æ§
- APIè°ƒç”¨ç›‘æ§

âœ… **å¯è§‚æµ‹æ€§å¹³å°æ„å»º**ï¼š
- ç»Ÿä¸€å¯è§‚æµ‹æ€§æ¶æ„
- Grafanaç»¼åˆAPM Dashboard
- Metrics + Traces + Logså…³è”åˆ†æ
- Exemplarsä¸Trace IDæ³¨å…¥
- å¤šç»´åº¦å‘Šè­¦ä¸äº‹ä»¶ç®¡ç†

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ ç¬¬9ç« çš„æœ€åä¸€èŠ‚â€”â€”å¯è§‚æµ‹æ€§æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬ç›‘æ§ç­–ç•¥ã€å‘Šè­¦è®¾è®¡ã€æ•…éšœæ’æŸ¥æµç¨‹ã€æ€§èƒ½ä¼˜åŒ–æ–¹æ³•è®ºï¼Œä»¥åŠå¦‚ä½•æ„å»ºé«˜æ•ˆçš„SREå›¢é˜Ÿã€‚

---

## 9.8 å¯è§‚æµ‹æ€§æœ€ä½³å®è·µ

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†Prometheusç›‘æ§ã€æ—¥å¿—ç®¡ç†ã€åˆ†å¸ƒå¼è¿½è¸ªå’ŒAPMç­‰æŠ€æœ¯ã€‚æœ¬èŠ‚å°†è¿™äº›æŠ€æœ¯æ•´åˆèµ·æ¥ï¼Œæ¢è®¨å¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ„å»ºå®Œæ•´çš„å¯è§‚æµ‹æ€§ä½“ç³»ï¼ŒåŒ…æ‹¬ç›‘æ§ç­–ç•¥è®¾è®¡ã€å‘Šè­¦ä¼˜åŒ–ã€æ•…éšœæ’æŸ¥æµç¨‹ã€æ€§èƒ½ä¼˜åŒ–æ–¹æ³•è®ºï¼Œä»¥åŠSREå›¢é˜Ÿå»ºè®¾ã€‚

### 9.8.1 ç›‘æ§ç­–ç•¥ä¸æŒ‡æ ‡è®¾è®¡

#### 1. ç›‘æ§é‡‘å­—å¡”æ¨¡å‹

å¯è§‚æµ‹æ€§æ•°æ®æŒ‰ç…§ä»·å€¼å’Œæˆæœ¬å¯ä»¥åˆ†ä¸ºå››å±‚ï¼š

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Business KPI  â”‚  ä¸šåŠ¡æŒ‡æ ‡ï¼ˆæœ€é«˜ä»·å€¼ï¼‰
           â”‚   è®¢å•é‡ã€GMV   â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           â”‚  Service Level  â”‚  æœåŠ¡æ°´å¹³æŒ‡æ ‡
           â”‚  SLI/SLO/SLA    â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           â”‚  Application    â”‚  åº”ç”¨æŒ‡æ ‡
           â”‚  RED/USE/Logs   â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           â”‚  Infrastructure â”‚  åŸºç¡€è®¾æ–½æŒ‡æ ‡ï¼ˆæœ€ä½æˆæœ¬ï¼‰
           â”‚  CPU/Mem/Disk   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å„å±‚ç›‘æ§é‡ç‚¹**ï¼š

| å±‚çº§ | å…³æ³¨ç‚¹ | ç¤ºä¾‹æŒ‡æ ‡ | å‘Šè­¦ä¼˜å…ˆçº§ |
|------|--------|----------|-----------|
| ä¸šåŠ¡æŒ‡æ ‡ | ç”¨æˆ·ä½“éªŒã€æ”¶å…¥å½±å“ | è®¢å•æˆåŠŸç‡ã€æ”¯ä»˜æˆåŠŸç‡ã€GMV | P0ï¼ˆç«‹å³å“åº”ï¼‰ |
| æœåŠ¡æ°´å¹³ | SLOè¾¾æˆæƒ…å†µ | Error Budgetæ¶ˆè€—ç‡ã€å¯ç”¨æ€§ | P1ï¼ˆ15åˆ†é’Ÿå†…ï¼‰ |
| åº”ç”¨æŒ‡æ ‡ | æœåŠ¡å¥åº·åº¦ | è¯·æ±‚å»¶è¿Ÿã€é”™è¯¯ç‡ã€ååé‡ | P2ï¼ˆ1å°æ—¶å†…ï¼‰ |
| åŸºç¡€è®¾æ–½ | èµ„æºä½¿ç”¨æƒ…å†µ | CPUä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ç‡ | P3ï¼ˆå·¥ä½œæ—¶é—´ï¼‰ |

#### 2. SLI/SLO/SLAè®¾è®¡

**SLIï¼ˆService Level Indicatorï¼‰** - æœåŠ¡æ°´å¹³æŒ‡æ ‡ï¼š

```yaml
# SLIå®šä¹‰ç¤ºä¾‹
apiVersion: v1
kind: ConfigMap
metadata:
  name: sli-definitions
  namespace: monitoring
data:
  sli.yaml: |
    # å¯ç”¨æ€§SLI
    availability:
      name: "APIå¯ç”¨æ€§"
      description: "HTTP 5xxé”™è¯¯ç‡"
      query: |
        sum(rate(http_requests_total{code=~"5.."}[5m]))
        /
        sum(rate(http_requests_total[5m]))
      
    # å»¶è¿ŸSLI
    latency:
      name: "APIå»¶è¿Ÿ"
      description: "P95å»¶è¿Ÿå°äº500ms"
      query: |
        histogram_quantile(0.95,
          sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
        )
    
    # ååé‡SLI
    throughput:
      name: "APIååé‡"
      description: "æ¯ç§’è¯·æ±‚æ•°"
      query: |
        sum(rate(http_requests_total[5m]))
```

**SLOï¼ˆService Level Objectiveï¼‰** - æœåŠ¡æ°´å¹³ç›®æ ‡ï¼š

```yaml
# SLOå®šä¹‰ç¤ºä¾‹
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: slo-rules
  namespace: monitoring
spec:
  groups:
  - name: slo.rules
    interval: 30s
    rules:
    # å¯ç”¨æ€§SLOï¼š99.9%ï¼ˆæœˆåº¦ï¼‰
    - record: slo:availability:ratio_rate5m
      expr: |
        1 - (
          sum(rate(http_requests_total{code=~"5.."}[5m]))
          /
          sum(rate(http_requests_total[5m]))
        )
    
    # å»¶è¿ŸSLOï¼š95%è¯·æ±‚ < 500ms
    - record: slo:latency:ratio_rate5m
      expr: |
        (
          sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))
          /
          sum(rate(http_request_duration_seconds_count[5m]))
        )
    
    # Error Budgetè®¡ç®—ï¼ˆ30å¤©çª—å£ï¼‰
    - record: slo:error_budget:remaining
      expr: |
        1 - (
          (1 - slo:availability:ratio_rate5m)
          /
          (1 - 0.999)  # ç›®æ ‡SLO
        )
```

**SLAï¼ˆService Level Agreementï¼‰** - æœåŠ¡æ°´å¹³åè®®ï¼š

```markdown
# æœåŠ¡æ°´å¹³åè®®ç¤ºä¾‹

## æ ¸å¿ƒAPIæœåŠ¡SLA

### 1. å¯ç”¨æ€§æ‰¿è¯º
- **æœˆåº¦å¯ç”¨æ€§**ï¼š99.9%ï¼ˆå…è®¸43.2åˆ†é’Ÿåœæœºï¼‰
- **è®¡ç®—æ–¹å¼**ï¼š(æ€»æ—¶é—´ - æ•…éšœæ—¶é—´) / æ€»æ—¶é—´
- **æ’é™¤é¡¹**ï¼šè®¡åˆ’ç»´æŠ¤ã€å®¢æˆ·ä¾§é—®é¢˜ã€ä¸å¯æŠ—åŠ›

### 2. æ€§èƒ½æ‰¿è¯º
- **P95å»¶è¿Ÿ**ï¼š< 500ms
- **P99å»¶è¿Ÿ**ï¼š< 1000ms
- **æµ‹é‡å‘¨æœŸ**ï¼š5åˆ†é’Ÿæ»šåŠ¨çª—å£

### 3. èµ”å¿æ¡æ¬¾
| æœˆåº¦å¯ç”¨æ€§ | æœåŠ¡ç§¯åˆ† |
|-----------|---------|
| < 99.9%   | 10%     |
| < 99.0%   | 25%     |
| < 95.0%   | 100%    |

### 4. æ”¯æŒå“åº”æ—¶é—´
| ä¼˜å…ˆçº§ | é¦–æ¬¡å“åº” | è§£å†³æ—¶é—´ |
|-------|---------|---------|
| P0    | 15åˆ†é’Ÿ  | 4å°æ—¶   |
| P1    | 1å°æ—¶   | 1å·¥ä½œæ—¥ |
| P2    | 4å°æ—¶   | 3å·¥ä½œæ—¥ |
| P3    | 1å·¥ä½œæ—¥ | 1å‘¨     |
```

#### 3. æŒ‡æ ‡å‘½åè§„èŒƒ

éµå¾ªPrometheusæœ€ä½³å®è·µçš„å‘½åè§„èŒƒï¼š

```yaml
# æŒ‡æ ‡å‘½åè§„èŒƒ
naming_conventions:
  # åŸºæœ¬æ ¼å¼ï¼š<namespace>_<subsystem>_<name>_<unit>
  
  # âœ… å¥½çš„å‘½å
  good_examples:
    - http_requests_total              # Counterï¼šæ€»è¯·æ±‚æ•°
    - http_request_duration_seconds    # Histogramï¼šè¯·æ±‚å»¶è¿Ÿ
    - http_requests_in_flight          # Gaugeï¼šè¿›è¡Œä¸­çš„è¯·æ±‚
    - process_cpu_seconds_total        # Counterï¼šCPUä½¿ç”¨æ—¶é—´
    - node_memory_bytes                # Gaugeï¼šå†…å­˜å­—èŠ‚æ•°
  
  # âŒ ä¸å¥½çš„å‘½å
  bad_examples:
    - httpRequests                     # ä½¿ç”¨é©¼å³°å‘½å
    - http_request_duration_ms         # ä¸ä½¿ç”¨æ ‡å‡†å•ä½ï¼ˆåº”è¯¥ç”¨secondsï¼‰
    - requests                         # ç¼ºå°‘namespace
    - http_errors                      # ç¼ºå°‘_totalåç¼€ï¼ˆCounterï¼‰
    - memory_usage_percent             # ç™¾åˆ†æ¯”åº”è¯¥ç”¨ratioï¼ˆ0-1ï¼‰

# å•ä½è§„èŒƒ
units:
  time: seconds                        # æ—¶é—´ç»Ÿä¸€ç”¨ç§’
  size: bytes                          # å¤§å°ç»Ÿä¸€ç”¨å­—èŠ‚
  ratio: ratio                         # æ¯”ç‡ç”¨0-1ä¹‹é—´çš„å€¼
  percentage: ratio                    # ç™¾åˆ†æ¯”è½¬æ¢ä¸ºratio

# Labelå‘½åè§„èŒƒ
label_conventions:
  good:
    - method="GET"                     # HTTPæ–¹æ³•
    - status="200"                     # HTTPçŠ¶æ€ç 
    - job="api-server"                 # ä»»åŠ¡åç§°
    - instance="10.0.1.5:8080"        # å®ä¾‹åœ°å€
  
  bad:
    - Method="GET"                     # é¦–å­—æ¯å¤§å†™
    - http_status="200"                # å†—ä½™å‰ç¼€
    - user_id="12345"                  # é«˜åŸºæ•°æ ‡ç­¾ï¼ˆä¼šå¯¼è‡´æŒ‡æ ‡çˆ†ç‚¸ï¼‰
```

**Goåº”ç”¨æŒ‡æ ‡é‡‡é›†ç¤ºä¾‹**ï¼š

```go
package metrics

import (
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	// HTTPè¯·æ±‚æ€»æ•°ï¼ˆCounterï¼‰
	HttpRequestsTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Total number of HTTP requests",
		},
		[]string{"method", "path", "status"},
	)

	// HTTPè¯·æ±‚å»¶è¿Ÿï¼ˆHistogramï¼‰
	HttpRequestDuration = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "http_request_duration_seconds",
			Help:    "HTTP request latency in seconds",
			Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},
		},
		[]string{"method", "path"},
	)

	// è¿›è¡Œä¸­çš„HTTPè¯·æ±‚ï¼ˆGaugeï¼‰
	HttpRequestsInFlight = promauto.NewGauge(
		prometheus.GaugeOpts{
			Name: "http_requests_in_flight",
			Help: "Current number of HTTP requests being processed",
		},
	)

	// æ•°æ®åº“è¿æ¥æ± ï¼ˆGaugeï¼‰
	DbConnectionsInUse = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "db_connections_in_use",
			Help: "Number of database connections currently in use",
		},
		[]string{"database"},
	)

	// ç¼“å­˜å‘½ä¸­ç‡ï¼ˆCounterï¼Œéœ€è¦è®¡ç®—ratioï¼‰
	CacheHitsTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "cache_hits_total",
			Help: "Total number of cache hits",
		},
		[]string{"cache_name"},
	)

	CacheMissesTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "cache_misses_total",
			Help: "Total number of cache misses",
		},
		[]string{"cache_name"},
	)

	// ä¸šåŠ¡æŒ‡æ ‡ï¼šè®¢å•æ•°ï¼ˆCounterï¼‰
	OrdersTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "orders_total",
			Help: "Total number of orders",
		},
		[]string{"status", "payment_method"},
	)

	// ä¸šåŠ¡æŒ‡æ ‡ï¼šè®¢å•é‡‘é¢ï¼ˆHistogramï¼‰
	OrderAmount = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "order_amount_yuan",
			Help:    "Order amount in yuan",
			Buckets: []float64{10, 50, 100, 200, 500, 1000, 2000, 5000, 10000},
		},
		[]string{"payment_method"},
	)
)

// ä¸­é—´ä»¶ç¤ºä¾‹
func MetricsMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// å¢åŠ è¿›è¡Œä¸­çš„è¯·æ±‚æ•°
		HttpRequestsInFlight.Inc()
		defer HttpRequestsInFlight.Dec()

		// è®°å½•å¼€å§‹æ—¶é—´
		start := time.Now()

		// åŒ…è£…ResponseWriterä»¥æ•è·çŠ¶æ€ç 
		ww := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}

		// æ‰§è¡Œä¸‹ä¸€ä¸ªå¤„ç†å™¨
		next.ServeHTTP(ww, r)

		// è®°å½•æŒ‡æ ‡
		duration := time.Since(start).Seconds()
		HttpRequestDuration.WithLabelValues(r.Method, r.URL.Path).Observe(duration)
		HttpRequestsTotal.WithLabelValues(
			r.Method,
			r.URL.Path,
			strconv.Itoa(ww.statusCode),
		).Inc()
	})
}

type responseWriter struct {
	http.ResponseWriter
	statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
	rw.statusCode = code
	rw.ResponseWriter.WriteHeader(code)
}
```

#### 4. é«˜åŸºæ•°é—®é¢˜å¤„ç†

**é—®é¢˜åœºæ™¯**ï¼š

```go
// âŒ é”™è¯¯ç¤ºä¾‹ï¼šä½¿ç”¨ç”¨æˆ·IDä½œä¸ºæ ‡ç­¾
UserRequestsTotal := promauto.NewCounterVec(
	prometheus.CounterOpts{
		Name: "user_requests_total",
	},
	[]string{"user_id"},  // å¦‚æœæœ‰100ä¸‡ç”¨æˆ·ï¼Œä¼šäº§ç”Ÿ100ä¸‡ä¸ªæ—¶é—´åºåˆ—ï¼
)

// âŒ é”™è¯¯ç¤ºä¾‹ï¼šä½¿ç”¨å®Œæ•´URLè·¯å¾„
HttpRequestsTotal := promauto.NewCounterVec(
	prometheus.CounterOpts{
		Name: "http_requests_total",
	},
	[]string{"url"},  // /api/users/1, /api/users/2, ... ä¼šå¯¼è‡´æŒ‡æ ‡çˆ†ç‚¸
)
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```go
// âœ… æ­£ç¡®ç¤ºä¾‹1ï¼šä½¿ç”¨è·¯ç”±æ¨¡æ¿è€Œéå…·ä½“è·¯å¾„
HttpRequestsTotal := promauto.NewCounterVec(
	prometheus.CounterOpts{
		Name: "http_requests_total",
	},
	[]string{"method", "route"},  // route="/api/users/:id"
)

// âœ… æ­£ç¡®ç¤ºä¾‹2ï¼šä½¿ç”¨ç”¨æˆ·åˆ†ç»„è€Œéå…·ä½“ç”¨æˆ·
UserRequestsTotal := promauto.NewCounterVec(
	prometheus.CounterOpts{
		Name: "user_requests_total",
	},
	[]string{"user_tier"},  // user_tier="free|premium|enterprise"
)

// âœ… æ­£ç¡®ç¤ºä¾‹3ï¼šä½¿ç”¨Exemplarsè®°å½•é«˜åŸºæ•°ä¿¡æ¯
HttpRequestDuration := promauto.NewHistogramVec(
	prometheus.HistogramOpts{
		Name: "http_request_duration_seconds",
		// åœ¨Histogramä¸­ä½¿ç”¨Exemplarsè®°å½•trace_id
	},
	[]string{"method", "route", "status"},
)

// è®°å½•æŒ‡æ ‡æ—¶é™„åŠ Exemplar
func RecordRequestWithExemplar(method, route, status string, duration float64, traceID string) {
	HttpRequestDuration.WithLabelValues(method, route, status).(prometheus.ExemplarObserver).
		ObserveWithExemplar(duration, prometheus.Labels{"trace_id": traceID})
}
```

**åŸºæ•°ç›‘æ§**ï¼š

```yaml
# Prometheusè§„åˆ™ï¼šç›‘æ§é«˜åŸºæ•°æŒ‡æ ‡
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cardinality-alerts
spec:
  groups:
  - name: cardinality
    rules:
    # ç›‘æ§æ¯ä¸ªæŒ‡æ ‡çš„æ—¶é—´åºåˆ—æ•°é‡
    - alert: HighCardinalityMetric
      expr: |
        count by (__name__) ({__name__=~".+"})
        > 10000
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "æŒ‡æ ‡ {{ $labels.__name__ }} åŸºæ•°è¿‡é«˜"
        description: "{{ $labels.__name__ }} æœ‰ {{ $value }} ä¸ªæ—¶é—´åºåˆ—"
    
    # ç›‘æ§æ€»æ—¶é—´åºåˆ—æ•°
    - alert: TotalSeriesHigh
      expr: |
        prometheus_tsdb_symbol_table_size_bytes > 1e9  # 1GB
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "Prometheusæ—¶é—´åºåˆ—æ€»æ•°è¿‡é«˜"
        description: "å½“å‰ç¬¦å·è¡¨å¤§å°ï¼š{{ $value | humanize }}B"
```


### 9.8.2 å‘Šè­¦è®¾è®¡ä¸é™å™ª

#### 1. å‘Šè­¦è®¾è®¡åŸåˆ™

**Google SREå‘Šè­¦å“²å­¦**ï¼š

```markdown
# å‘Šè­¦è®¾è®¡çš„å››ä¸ªé»„é‡‘é—®é¢˜

1. **è¿™ä¸ªå‘Šè­¦æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥ï¼Ÿ**
   - âœ… æ˜¯ï¼šä¿ç•™å‘Šè­¦
   - âŒ å¦ï¼šè½¬ä¸ºDashboardæˆ–è‡ªåŠ¨ä¿®å¤

2. **è¿™ä¸ªå‘Šè­¦æ˜¯å¦ç´§æ€¥ï¼Ÿ**
   - âœ… æ˜¯ï¼šç«‹å³é€šçŸ¥ï¼ˆç”µè¯/çŸ­ä¿¡ï¼‰
   - âŒ å¦ï¼šå»¶è¿Ÿé€šçŸ¥ï¼ˆé‚®ä»¶/å·¥å•ï¼‰

3. **è¿™ä¸ªå‘Šè­¦æ˜¯å¦å¯æ“ä½œï¼Ÿ**
   - âœ… æ˜¯ï¼šæä¾›æ˜ç¡®çš„å¤„ç†æ­¥éª¤
   - âŒ å¦ï¼šæ”¹è¿›å‘Šè­¦å†…å®¹æˆ–åˆ é™¤

4. **è¿™ä¸ªå‘Šè­¦æ˜¯å¦ä¼šäº§ç”Ÿå™ªéŸ³ï¼Ÿ**
   - âœ… æ˜¯ï¼šè°ƒæ•´é˜ˆå€¼æˆ–å¢åŠ æŠ‘åˆ¶è§„åˆ™
   - âŒ å¦ï¼šä¿æŒç°çŠ¶
```

**å‘Šè­¦åˆ†çº§æ ‡å‡†**ï¼š

```yaml
# å‘Šè­¦åˆ†çº§å®šä¹‰
alert_levels:
  P0_Critical:
    description: "æœåŠ¡å®Œå…¨ä¸å¯ç”¨ï¼Œå½±å“æ‰€æœ‰ç”¨æˆ·"
    examples:
      - "æ ¸å¿ƒAPIå®Œå…¨å®•æœº"
      - "æ•°æ®åº“ä¸»åº“ä¸å¯è®¿é—®"
      - "æ”¯ä»˜ç³»ç»Ÿæ•…éšœ"
    response_time: "ç«‹å³å“åº”ï¼ˆ5åˆ†é’Ÿå†…ï¼‰"
    notification: "ç”µè¯ + çŸ­ä¿¡ + IM"
    escalation: "15åˆ†é’Ÿæ— å“åº”å‡çº§åˆ°æ€»ç›‘"
  
  P1_High:
    description: "æœåŠ¡éƒ¨åˆ†ä¸å¯ç”¨æˆ–ä¸¥é‡é™çº§"
    examples:
      - "Error Budgetæ¶ˆè€—ç‡ > 10x"
      - "P99å»¶è¿Ÿ > 5ç§’"
      - "é”™è¯¯ç‡ > 5%"
    response_time: "15åˆ†é’Ÿå†…å“åº”"
    notification: "çŸ­ä¿¡ + IM"
    escalation: "30åˆ†é’Ÿæ— å“åº”å‡çº§åˆ°ä¸»ç®¡"
  
  P2_Medium:
    description: "æœåŠ¡è½»å¾®é™çº§ï¼Œç”¨æˆ·ä½“éªŒå—å½±å“"
    examples:
      - "Error Budgetæ¶ˆè€—ç‡ > 2x"
      - "P95å»¶è¿Ÿ > 1ç§’"
      - "é”™è¯¯ç‡ > 1%"
    response_time: "1å°æ—¶å†…å“åº”"
    notification: "IM + é‚®ä»¶"
    escalation: "å·¥ä½œæ—¶é—´å¤„ç†"
  
  P3_Low:
    description: "æ½œåœ¨é—®é¢˜ï¼Œä¸å½±å“ç”¨æˆ·"
    examples:
      - "ç£ç›˜ä½¿ç”¨ç‡ > 80%"
      - "è¯ä¹¦30å¤©åè¿‡æœŸ"
      - "å¤‡ä»½ä»»åŠ¡å¤±è´¥"
    response_time: "å·¥ä½œæ—¶é—´å¤„ç†"
    notification: "é‚®ä»¶ + å·¥å•"
    escalation: "æ— éœ€å‡çº§"
```

#### 2. å‘Šè­¦è§„åˆ™æœ€ä½³å®è·µ

**åŸºäºSLOçš„å‘Šè­¦**ï¼š

```yaml
# å¤šçª—å£å¤šç‡ƒçƒ§ç‡å‘Šè­¦ï¼ˆMulti-Window Multi-Burn-Rateï¼‰
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: slo-alerts
spec:
  groups:
  - name: slo.alerts
    rules:
    # å¿«é€Ÿç‡ƒçƒ§ï¼ˆ1å°æ—¶çª—å£ï¼Œ14.4xç‡ƒçƒ§ç‡ï¼‰
    - alert: ErrorBudgetBurnRateFast
      expr: |
        (
          (1 - slo:availability:ratio_rate1h) > (14.4 * (1 - 0.999))
          and
          (1 - slo:availability:ratio_rate5m) > (14.4 * (1 - 0.999))
        )
      for: 2m
      labels:
        severity: critical
        priority: P0
      annotations:
        summary: "Error Budgetå¿«é€Ÿç‡ƒçƒ§ï¼ˆ1å°æ—¶å†…è€—å°½ï¼‰"
        description: |
          å½“å‰é”™è¯¯ç‡ï¼š{{ $value | humanizePercentage }}
          å¦‚æœæŒç»­ï¼ŒError Budgetå°†åœ¨1å°æ—¶å†…è€—å°½
          Runbook: https://wiki.example.com/runbooks/error-budget-burn
    
    # ä¸­é€Ÿç‡ƒçƒ§ï¼ˆ6å°æ—¶çª—å£ï¼Œ6xç‡ƒçƒ§ç‡ï¼‰
    - alert: ErrorBudgetBurnRateMedium
      expr: |
        (
          (1 - slo:availability:ratio_rate6h) > (6 * (1 - 0.999))
          and
          (1 - slo:availability:ratio_rate30m) > (6 * (1 - 0.999))
        )
      for: 15m
      labels:
        severity: warning
        priority: P1
      annotations:
        summary: "Error Budgetä¸­é€Ÿç‡ƒçƒ§ï¼ˆ6å°æ—¶å†…è€—å°½ï¼‰"
        description: |
          å½“å‰é”™è¯¯ç‡ï¼š{{ $value | humanizePercentage }}
          å¦‚æœæŒç»­ï¼ŒError Budgetå°†åœ¨6å°æ—¶å†…è€—å°½
    
    # æ…¢é€Ÿç‡ƒçƒ§ï¼ˆ3å¤©çª—å£ï¼Œ1xç‡ƒçƒ§ç‡ï¼‰
    - alert: ErrorBudgetBurnRateSlow
      expr: |
        (
          (1 - slo:availability:ratio_rate3d) > (1 * (1 - 0.999))
          and
          (1 - slo:availability:ratio_rate6h) > (1 * (1 - 0.999))
        )
      for: 1h
      labels:
        severity: info
        priority: P2
      annotations:
        summary: "Error Budgetæ…¢é€Ÿç‡ƒçƒ§ï¼ˆæŒ‰å½“å‰é€Ÿç‡æœˆåº•è€—å°½ï¼‰"
        description: |
          å½“å‰é”™è¯¯ç‡ï¼š{{ $value | humanizePercentage }}
          å»ºè®®ä¼˜åŒ–æœåŠ¡è´¨é‡
```

**ç—‡çŠ¶å‹å‘Šè­¦ vs åŸå› å‹å‘Šè­¦**ï¼š

```yaml
# âœ… ç—‡çŠ¶å‹å‘Šè­¦ï¼ˆæ¨èï¼‰ï¼šå…³æ³¨ç”¨æˆ·ä½“éªŒ
symptom_based_alerts:
  - alert: HighErrorRate
    expr: |
      sum(rate(http_requests_total{code=~"5.."}[5m]))
      /
      sum(rate(http_requests_total[5m]))
      > 0.01
    annotations:
      summary: "ç”¨æˆ·æ­£åœ¨é‡åˆ°å¤§é‡5xxé”™è¯¯"
  
  - alert: HighLatency
    expr: |
      histogram_quantile(0.95,
        sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
      ) > 1
    annotations:
      summary: "ç”¨æˆ·æ­£åœ¨ç»å†é«˜å»¶è¿Ÿ"

# âŒ åŸå› å‹å‘Šè­¦ï¼ˆä¸æ¨èï¼‰ï¼šå…³æ³¨åº•å±‚èµ„æº
cause_based_alerts:
  - alert: HighCPU
    expr: node_cpu_usage > 0.8
    annotations:
      summary: "CPUä½¿ç”¨ç‡é«˜"
      # é—®é¢˜ï¼šCPUé«˜ä¸ä¸€å®šå½±å“ç”¨æˆ·ï¼Œå¯èƒ½æ˜¯æ­£å¸¸çš„æ‰¹å¤„ç†ä»»åŠ¡
  
  - alert: HighMemory
    expr: node_memory_usage > 0.9
    annotations:
      summary: "å†…å­˜ä½¿ç”¨ç‡é«˜"
      # é—®é¢˜ï¼šLinuxä¼šä½¿ç”¨å¤§é‡å†…å­˜ä½œä¸ºç¼“å­˜ï¼Œè¿™æ˜¯æ­£å¸¸çš„
```

**å‘Šè­¦æŠ‘åˆ¶ï¼ˆInhibitionï¼‰**ï¼š

```yaml
# Alertmanageré…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
data:
  alertmanager.yml: |
    # æŠ‘åˆ¶è§„åˆ™ï¼šå½“é«˜ä¼˜å…ˆçº§å‘Šè­¦è§¦å‘æ—¶ï¼ŒæŠ‘åˆ¶ä½ä¼˜å…ˆçº§å‘Šè­¦
    inhibit_rules:
    # è§„åˆ™1ï¼šæœåŠ¡å®Œå…¨å®•æœºæ—¶ï¼ŒæŠ‘åˆ¶é«˜å»¶è¿Ÿå‘Šè­¦
    - source_match:
        alertname: ServiceDown
        severity: critical
      target_match:
        severity: warning
      target_match_re:
        alertname: High.*  # æŠ‘åˆ¶æ‰€æœ‰Highå¼€å¤´çš„å‘Šè­¦
      equal:
        - service
        - namespace
    
    # è§„åˆ™2ï¼šæ•´ä¸ªèŠ‚ç‚¹å®•æœºæ—¶ï¼ŒæŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰Podå‘Šè­¦
    - source_match:
        alertname: NodeDown
      target_match_re:
        alertname: Pod.*
      equal:
        - instance
    
    # è§„åˆ™3ï¼šæ•°æ®åº“ä¸»åº“æ•…éšœæ—¶ï¼ŒæŠ‘åˆ¶ä»åº“å»¶è¿Ÿå‘Šè­¦
    - source_match:
        alertname: DatabasePrimaryDown
        severity: critical
      target_match:
        alertname: DatabaseReplicationLag
      equal:
        - cluster
```

#### 3. å‘Šè­¦é™å™ªæŠ€æœ¯

**æŠ€æœ¯1ï¼šåŠ¨æ€é˜ˆå€¼**

```yaml
# ä½¿ç”¨Prometheusçš„predict_linearé¢„æµ‹è¶‹åŠ¿
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: dynamic-threshold-alerts
spec:
  groups:
  - name: dynamic
    rules:
    # ç£ç›˜ç©ºé—´é¢„æµ‹å‘Šè­¦
    - alert: DiskWillFillIn4Hours
      expr: |
        predict_linear(
          node_filesystem_avail_bytes{mountpoint="/"}[1h],
          4 * 3600
        ) < 0
      for: 10m
      annotations:
        summary: "ç£ç›˜å°†åœ¨4å°æ—¶å†…å¡«æ»¡"
        description: |
          å½“å‰å¯ç”¨ç©ºé—´ï¼š{{ $value | humanize }}B
          é¢„æµ‹4å°æ—¶åå°†è€—å°½
    
    # åŸºäºå†å²æ•°æ®çš„å¼‚å¸¸æ£€æµ‹
    - alert: RequestRateAnomaly
      expr: |
        abs(
          rate(http_requests_total[5m])
          -
          avg_over_time(rate(http_requests_total[5m])[1d:5m])
        )
        /
        stddev_over_time(rate(http_requests_total[5m])[1d:5m])
        > 3  # 3å€æ ‡å‡†å·®
      for: 10m
      annotations:
        summary: "è¯·æ±‚é€Ÿç‡å¼‚å¸¸ï¼ˆåç¦»å†å²å‡å€¼3Ïƒï¼‰"
```

**æŠ€æœ¯2ï¼šå‘Šè­¦èšåˆ**

```yaml
# Alertmanagerè·¯ç”±é…ç½®
route:
  receiver: default
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s        # ç­‰å¾…30ç§’æ”¶é›†åŒç»„å‘Šè­¦
  group_interval: 5m     # æ¯5åˆ†é’Ÿå‘é€ä¸€æ¬¡èšåˆå‘Šè­¦
  repeat_interval: 4h    # 4å°æ—¶åé‡å¤å‘é€æœªæ¢å¤çš„å‘Šè­¦
  
  routes:
  # P0å‘Šè­¦ï¼šç«‹å³å‘é€ï¼Œä¸èšåˆ
  - match:
      priority: P0
    receiver: pagerduty
    group_wait: 0s
    group_interval: 1m
    repeat_interval: 5m
  
  # P1å‘Šè­¦ï¼šèšåˆåå‘é€
  - match:
      priority: P1
    receiver: slack-critical
    group_wait: 1m
    group_interval: 5m
    repeat_interval: 1h
  
  # P2/P3å‘Šè­¦ï¼šå¤§é‡èšåˆ
  - match_re:
      priority: P2|P3
    receiver: slack-warning
    group_wait: 5m
    group_interval: 30m
    repeat_interval: 12h
```

**æŠ€æœ¯3ï¼šé™é»˜ï¼ˆSilencesï¼‰**

```bash
# ä½¿ç”¨amtoolåˆ›å»ºé™é»˜
# åœºæ™¯1ï¼šè®¡åˆ’ç»´æŠ¤
amtool silence add \
  alertname=".*" \
  service="payment-api" \
  --start="2024-01-20T02:00:00+08:00" \
  --end="2024-01-20T04:00:00+08:00" \
  --comment="è®¡åˆ’ç»´æŠ¤ï¼šæ•°æ®åº“å‡çº§" \
  --author="ops@example.com"

# åœºæ™¯2ï¼šå·²çŸ¥é—®é¢˜
amtool silence add \
  alertname="HighLatency" \
  cluster="prod-us-west" \
  --duration=24h \
  --comment="å·²çŸ¥é—®é¢˜ï¼šç­‰å¾…ä¾›åº”å•†ä¿®å¤ç½‘ç»œ" \
  --author="sre@example.com"

# æŸ¥çœ‹æ‰€æœ‰é™é»˜
amtool silence query

# åˆ é™¤é™é»˜
amtool silence expire <silence-id>
```

**æŠ€æœ¯4ï¼šå‘Šè­¦ä¾èµ–å›¾**

```yaml
# ä½¿ç”¨Prometheusçš„alert_relabel_configså»ºç«‹ä¾èµ–å…³ç³»
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: main
spec:
  alertmanagerConfiguration:
    name: alertmanager-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
data:
  config.yml: |
    # å‘Šè­¦ä¾èµ–å…³ç³»
    route:
      routes:
      # æ•°æ®åº“å‘Šè­¦è·¯ç”±
      - match:
          component: database
        receiver: dba-team
        continue: true  # ç»§ç»­åŒ¹é…åç»­è·¯ç”±
      
      # åº”ç”¨å‘Šè­¦è·¯ç”±ï¼ˆä¾èµ–æ•°æ®åº“ï¼‰
      - match:
          component: application
        receiver: dev-team
        # å¦‚æœæ•°æ®åº“å‘Šè­¦å·²è§¦å‘ï¼ŒæŠ‘åˆ¶åº”ç”¨å‘Šè­¦
        inhibit_rules:
        - source_match:
            component: database
            severity: critical
          target_match:
            component: application
```

#### 4. å‘Šè­¦é€šçŸ¥æ¸ é“

**å¤šæ¸ é“é€šçŸ¥é…ç½®**ï¼š

```yaml
# Alertmanager receiversé…ç½®
receivers:
# 1. PagerDutyï¼ˆP0å‘Šè­¦ï¼‰
- name: pagerduty
  pagerduty_configs:
  - service_key: <pagerduty-integration-key>
    description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
    details:
      firing: '{{ .Alerts.Firing | len }}'
      resolved: '{{ .Alerts.Resolved | len }}'
      details: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

# 2. Slackï¼ˆP1/P2å‘Šè­¦ï¼‰
- name: slack-critical
  slack_configs:
  - api_url: <slack-webhook-url>
    channel: '#alerts-critical'
    title: '{{ .GroupLabels.alertname }}'
    text: |
      {{ range .Alerts }}
      *Alert:* {{ .Labels.alertname }}
      *Severity:* {{ .Labels.severity }}
      *Summary:* {{ .Annotations.summary }}
      *Description:* {{ .Annotations.description }}
      *Runbook:* {{ .Annotations.runbook_url }}
      {{ end }}
    actions:
    - type: button
      text: 'Runbook'
      url: '{{ (index .Alerts 0).Annotations.runbook_url }}'
    - type: button
      text: 'Silence 1h'
      url: '{{ .ExternalURL }}/#/silences/new?filter={alertname="{{.GroupLabels.alertname}}"}'

# 3. ä¼ä¸šå¾®ä¿¡
- name: wechat
  wechat_configs:
  - corp_id: <corp-id>
    agent_id: <agent-id>
    api_secret: <api-secret>
    to_user: '@all'
    message: |
      ã€å‘Šè­¦é€šçŸ¥ã€‘
      å‘Šè­¦åç§°ï¼š{{ .GroupLabels.alertname }}
      ä¸¥é‡ç¨‹åº¦ï¼š{{ .CommonLabels.severity }}
      å‘Šè­¦æ‘˜è¦ï¼š{{ .CommonAnnotations.summary }}
      è¯¦ç»†ä¿¡æ¯ï¼š{{ .CommonAnnotations.description }}
      è§¦å‘æ—¶é—´ï¼š{{ .CommonAnnotations.startsAt }}

# 4. é‚®ä»¶ï¼ˆP3å‘Šè­¦ï¼‰
- name: email
  email_configs:
  - to: 'ops-team@example.com'
    from: 'alertmanager@example.com'
    smarthost: 'smtp.example.com:587'
    auth_username: 'alertmanager@example.com'
    auth_password: '<password>'
    headers:
      Subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
    html: |
      <h2>{{ .GroupLabels.alertname }}</h2>
      <table>
        <tr><th>Severity</th><td>{{ .CommonLabels.severity }}</td></tr>
        <tr><th>Summary</th><td>{{ .CommonAnnotations.summary }}</td></tr>
        <tr><th>Description</th><td>{{ .CommonAnnotations.description }}</td></tr>
      </table>
      <h3>Firing Alerts ({{ .Alerts.Firing | len }})</h3>
      <ul>
      {{ range .Alerts.Firing }}
        <li>{{ .Labels.instance }}: {{ .Annotations.description }}</li>
      {{ end }}
      </ul>

# 5. Webhookï¼ˆè‡ªå®šä¹‰é›†æˆï¼‰
- name: webhook
  webhook_configs:
  - url: 'http://alertmanager-webhook-adapter:8080/alerts'
    send_resolved: true
    http_config:
      bearer_token: '<token>'
```

**å‘Šè­¦é€šçŸ¥æ¨¡æ¿**ï¼š

```go
// Goå®ç°çš„Webhookæ¥æ”¶å™¨
package main

import (
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"time"
)

type AlertmanagerWebhook struct {
	Version           string            `json:"version"`
	GroupKey          string            `json:"groupKey"`
	Status            string            `json:"status"`
	Receiver          string            `json:"receiver"`
	GroupLabels       map[string]string `json:"groupLabels"`
	CommonLabels      map[string]string `json:"commonLabels"`
	CommonAnnotations map[string]string `json:"commonAnnotations"`
	ExternalURL       string            `json:"externalURL"`
	Alerts            []Alert           `json:"alerts"`
}

type Alert struct {
	Status       string            `json:"status"`
	Labels       map[string]string `json:"labels"`
	Annotations  map[string]string `json:"annotations"`
	StartsAt     time.Time         `json:"startsAt"`
	EndsAt       time.Time         `json:"endsAt"`
	GeneratorURL string            `json:"generatorURL"`
	Fingerprint  string            `json:"fingerprint"`
}

func handleWebhook(w http.ResponseWriter, r *http.Request) {
	var webhook AlertmanagerWebhook
	if err := json.NewDecoder(r.Body).Decode(&webhook); err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	// æ ¹æ®ä¼˜å…ˆçº§è·¯ç”±åˆ°ä¸åŒçš„å¤„ç†é€»è¾‘
	priority := webhook.CommonLabels["priority"]
	switch priority {
	case "P0":
		handleP0Alert(webhook)
	case "P1":
		handleP1Alert(webhook)
	default:
		handleLowPriorityAlert(webhook)
	}

	w.WriteHeader(http.StatusOK)
}

func handleP0Alert(webhook AlertmanagerWebhook) {
	// P0å‘Šè­¦ï¼šåˆ›å»ºPagerDutyäº‹ä»¶ + å‘é€çŸ­ä¿¡ + æ‹¨æ‰“ç”µè¯
	log.Printf("[P0] Critical alert: %s", webhook.GroupLabels["alertname"])
	
	// 1. åˆ›å»ºäº‹ä»¶å·¥å•
	createIncident(webhook)
	
	// 2. å‘é€çŸ­ä¿¡é€šçŸ¥
	sendSMS(webhook)
	
	// 3. å¦‚æœ5åˆ†é’Ÿå†…æœªç¡®è®¤ï¼Œæ‹¨æ‰“ç”µè¯
	go func() {
		time.Sleep(5 * time.Minute)
		if !isAcknowledged(webhook.GroupKey) {
			makePhoneCall(webhook)
		}
	}()
}

func handleP1Alert(webhook AlertmanagerWebhook) {
	// P1å‘Šè­¦ï¼šå‘é€Slackæ¶ˆæ¯ + åˆ›å»ºå·¥å•
	log.Printf("[P1] High priority alert: %s", webhook.GroupLabels["alertname"])
	sendSlackMessage(webhook)
	createTicket(webhook)
}

func handleLowPriorityAlert(webhook AlertmanagerWebhook) {
	// P2/P3å‘Šè­¦ï¼šä»…è®°å½•æ—¥å¿—å’Œå‘é€é‚®ä»¶
	log.Printf("[P2/P3] Low priority alert: %s", webhook.GroupLabels["alertname"])
	sendEmail(webhook)
}

func main() {
	http.HandleFunc("/alerts", handleWebhook)
	log.Println("Webhook server listening on :8080")
	log.Fatal(http.ListenAndServe(":8080", nil))
}
```

