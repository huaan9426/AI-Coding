# ç¬¬9ç«  ç›‘æ§ä¸å¯è§‚æµ‹æ€§

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Kubernetesçš„æ ¸å¿ƒç»„ä»¶ã€å·¥ä½œè´Ÿè½½ç®¡ç†ã€æœåŠ¡å‘ç°ã€é…ç½®ç®¡ç†ã€èµ„æºè°ƒåº¦å’Œå­˜å‚¨ç®¡ç†ã€‚è¿™äº›çŸ¥è¯†è®©æˆ‘ä»¬èƒ½å¤ŸæˆåŠŸéƒ¨ç½²å’Œè¿è¡Œå®¹å™¨åŒ–åº”ç”¨ã€‚ä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä»…ä»…è®©åº”ç”¨è¿è¡Œèµ·æ¥æ˜¯è¿œè¿œä¸å¤Ÿçš„ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å›ç­”ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

**è¿ç»´ä¸‰å¤§çµé­‚æ‹·é—®**ï¼š
1. **ç³»ç»Ÿç°åœ¨æ€ä¹ˆæ ·ï¼Ÿ** - å®æ—¶ç›‘æ§ï¼ˆMetricsï¼‰
2. **å‡ºé—®é¢˜äº†æ€ä¹ˆåŠï¼Ÿ** - æ—¥å¿—è¿½è¸ªï¼ˆLoggingï¼‰
3. **ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ** - é“¾è·¯è¿½è¸ªï¼ˆTracingï¼‰

è€ƒè™‘ä»¥ä¸‹ç”Ÿäº§åœºæ™¯ï¼š

ğŸ“Š **ç›‘æ§åœºæ™¯**ï¼š
- Podå†…å­˜ä½¿ç”¨ç‡çªç„¶ä»30%é£™å‡åˆ°95%ï¼Œä½†æ²¡æœ‰å‘Šè­¦
- èŠ‚ç‚¹CPUæŒç»­é«˜è´Ÿè½½ï¼Œä½†ä¸çŸ¥é“æ˜¯å“ªä¸ªPodå¯¼è‡´çš„
- PVCå­˜å‚¨å®¹é‡å³å°†è€—å°½ï¼Œæ²¡æœ‰æå‰é¢„è­¦
- API Serverè¯·æ±‚å»¶è¿Ÿå¢åŠ 3å€ï¼Œç”¨æˆ·å¼€å§‹æŠ•è¯‰

ğŸ” **æ—¥å¿—åœºæ™¯**ï¼š
- ç”¨æˆ·æŠ¥å‘Šæ”¯ä»˜å¤±è´¥ï¼Œä½†ä¸çŸ¥é“é”™è¯¯å‘ç”Ÿåœ¨å“ªä¸ªå¾®æœåŠ¡
- åº”ç”¨å´©æºƒé‡å¯ï¼Œä½†æ—¥å¿—éšå®¹å™¨æ¶ˆå¤±æ— æ³•æ’æŸ¥
- å¤šä¸ªPodåˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹ï¼Œæ—¥å¿—åˆ†æ•£æ— æ³•ç»Ÿä¸€æŸ¥è¯¢
- æ—¥å¿—é‡å·¨å¤§ï¼ˆTBçº§ï¼‰ï¼Œæœç´¢é€Ÿåº¦æ…¢ä¸”æˆæœ¬é«˜

ğŸ”— **è¿½è¸ªåœºæ™¯**ï¼š
- ä¸€ä¸ªAPIè¯·æ±‚ç»è¿‡10ä¸ªå¾®æœåŠ¡ï¼Œæ€»è€—æ—¶5ç§’ï¼Œç“¶é¢ˆåœ¨å“ªï¼Ÿ
- è®¢å•å¤„ç†å¤±è´¥ï¼Œä½†ä¸çŸ¥é“æ˜¯åº“å­˜æœåŠ¡è¿˜æ˜¯æ”¯ä»˜æœåŠ¡çš„é—®é¢˜
- åˆ†å¸ƒå¼äº‹åŠ¡è·¨è¶Šå¤šä¸ªæœåŠ¡ï¼Œæ— æ³•å®šä½å¤±è´¥åŸå› 

è¿™å°±æ˜¯**å¯è§‚æµ‹æ€§ (Observability)** è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚å¯è§‚æµ‹æ€§æ˜¯ç°ä»£äº‘åŸç”Ÿåº”ç”¨çš„åŸºçŸ³ï¼Œå®ƒè®©æˆ‘ä»¬èƒ½å¤Ÿï¼š
- **ä¸»åŠ¨å‘ç°é—®é¢˜** - åœ¨ç”¨æˆ·æŠ•è¯‰å‰å°±å‘ç°å¼‚å¸¸
- **å¿«é€Ÿå®šä½æ ¹å› ** - åˆ†é’Ÿçº§è€Œéå°æ—¶çº§æ•…éšœæ’æŸ¥
- **ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½** - åŸºäºæ•°æ®é©±åŠ¨çš„æ€§èƒ½è°ƒä¼˜
- **å®¹é‡è§„åˆ’å†³ç­–** - å‡†ç¡®é¢„æµ‹èµ„æºéœ€æ±‚ï¼Œé™ä½æˆæœ¬

## å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±

Kubernetesç”Ÿæ€æä¾›äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§è§£å†³æ–¹æ¡ˆï¼Œéµå¾ªä¸šç•Œå…¬è®¤çš„"ä¸‰å¤§æ”¯æŸ±"ç†å¿µï¼š

### 1ï¸âƒ£ Metrics (æŒ‡æ ‡ç›‘æ§)

**å®šä¹‰**ï¼šèšåˆçš„æ•°å€¼å‹æ—¶åºæ•°æ®ï¼Œç”¨äºé‡åŒ–ç³»ç»ŸçŠ¶æ€

**å…¸å‹æŒ‡æ ‡**ï¼š
- **åŸºç¡€è®¾æ–½å±‚**ï¼šCPUä½¿ç”¨ç‡ã€å†…å­˜å ç”¨ã€ç£ç›˜IOPSã€ç½‘ç»œå¸¦å®½
- **å®¹å™¨å±‚**ï¼šPodé‡å¯æ¬¡æ•°ã€å®¹å™¨OOMæ¬¡æ•°ã€é•œåƒæ‹‰å–æ—¶é•¿
- **åº”ç”¨å±‚**ï¼šHTTPè¯·æ±‚QPSã€APIå»¶è¿ŸP99ã€é”™è¯¯ç‡ã€ä¸šåŠ¡æŒ‡æ ‡ï¼ˆè®¢å•é‡ï¼‰

**æŠ€æœ¯æ ˆ**ï¼šPrometheus + Grafana

### 2ï¸âƒ£ Logging (æ—¥å¿—è¿½è¸ª)

**å®šä¹‰**ï¼šç¦»æ•£çš„äº‹ä»¶è®°å½•ï¼Œç”¨äºæè¿°ç³»ç»Ÿè¡Œä¸º

**æ—¥å¿—ç±»å‹**ï¼š
- **åº”ç”¨æ—¥å¿—**ï¼šä¸šåŠ¡é€»è¾‘è¾“å‡ºï¼ˆè®¢å•åˆ›å»ºã€ç”¨æˆ·ç™»å½•ï¼‰
- **å®¡è®¡æ—¥å¿—**ï¼šå®‰å…¨åˆè§„è®°å½•ï¼ˆAPIè°ƒç”¨ã€æƒé™å˜æ›´ï¼‰
- **ç³»ç»Ÿæ—¥å¿—**ï¼šç»„ä»¶è¿è¡Œæ—¥å¿—ï¼ˆkubeletã€kube-proxyï¼‰

**æŠ€æœ¯æ ˆ**ï¼šEFK (Elasticsearch + Fluentd + Kibana) æˆ– Loki + Promtail

### 3ï¸âƒ£ Tracing (é“¾è·¯è¿½è¸ª)

**å®šä¹‰**ï¼šåˆ†å¸ƒå¼è¯·æ±‚çš„å®Œæ•´è°ƒç”¨é“¾è·¯ï¼Œç”¨äºåˆ†ææœåŠ¡ä¾èµ–

**è¿½è¸ªå†…å®¹**ï¼š
- è¯·æ±‚ä»ç½‘å…³åˆ°æ•°æ®åº“çš„å®Œæ•´è·¯å¾„
- æ¯ä¸ªå¾®æœåŠ¡çš„å¤„ç†è€—æ—¶å’Œä¾èµ–å…³ç³»
- è·¨æœåŠ¡è°ƒç”¨çš„ä¸Šä¸‹æ–‡ä¼ é€’

**æŠ€æœ¯æ ˆ**ï¼šJaeger / Zipkin / Tempo

## æœ¬ç« å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†æŒæ¡ï¼š

âœ… **Metricsç›‘æ§ä½“ç³»**: ç†è§£Prometheusæ¶æ„ï¼ŒæŒæ¡PromQLæŸ¥è¯¢è¯­è¨€ï¼Œé…ç½®Grafanaä»ªè¡¨ç›˜
âœ… **æŒ‡æ ‡é‡‡é›†å®æˆ˜**: éƒ¨ç½²Metrics Serverã€Node Exporterã€kube-state-metrics
âœ… **å‘Šè­¦è§„åˆ™é…ç½®**: ä½¿ç”¨AlertManagerå®ç°å¤šæ¸ é“å‘Šè­¦ï¼ˆé‚®ä»¶/Slack/é’‰é’‰/ä¼ä¸šå¾®ä¿¡ï¼‰
âœ… **æ—¥å¿—æ”¶é›†æ¶æ„**: éƒ¨ç½²EFKæ ˆï¼Œå®ç°å®¹å™¨æ—¥å¿—çš„é›†ä¸­æ”¶é›†ã€ç´¢å¼•å’ŒæŸ¥è¯¢
âœ… **æ—¥å¿—æŸ¥è¯¢åˆ†æ**: æŒæ¡Kibana/LokiæŸ¥è¯¢è¯­æ³•ï¼Œå¿«é€Ÿå®šä½é—®é¢˜æ—¥å¿—
âœ… **åˆ†å¸ƒå¼è¿½è¸ª**: éƒ¨ç½²Jaegerï¼Œå®ç°å¾®æœåŠ¡è°ƒç”¨é“¾è·¯çš„å¯è§†åŒ–åˆ†æ
âœ… **æ€§èƒ½åˆ†æå·¥å…·**: ä½¿ç”¨kubectl topã€PrometheusæŸ¥è¯¢ã€ç«ç„°å›¾åˆ†ææ€§èƒ½ç“¶é¢ˆ
âœ… **ç”Ÿäº§æœ€ä½³å®è·µ**: ç›‘æ§æŒ‡æ ‡ä½“ç³»è®¾è®¡ã€å‘Šè­¦ç­–ç•¥åˆ¶å®šã€æˆæœ¬ä¼˜åŒ–

## æœ¬ç« å†…å®¹æ¦‚è§ˆ

```
ç¬¬9ç« : ç›‘æ§ä¸å¯è§‚æµ‹æ€§
â”œâ”€â”€ 9.1 ç›‘æ§åŸºç¡€ä¸æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ å¯è§‚æµ‹æ€§æ ¸å¿ƒæ¦‚å¿µ
â”‚   â”œâ”€â”€ Kubernetesç›‘æ§æ¶æ„
â”‚   â”œâ”€â”€ Metrics APIä¸èµ„æºæŒ‡æ ‡
â”‚   â””â”€â”€ ç›‘æ§æ•°æ®é‡‡é›†è·¯å¾„
â”‚
â”œâ”€â”€ 9.2 Prometheusæ ¸å¿ƒåŸç†ä¸å®æˆ˜
â”‚   â”œâ”€â”€ Prometheusæ¶æ„ä¸æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ æœåŠ¡å‘ç°ä¸ç›®æ ‡æŠ“å–
â”‚   â”œâ”€â”€ PromQLæŸ¥è¯¢è¯­è¨€è¯¦è§£
â”‚   â”œâ”€â”€ Recording Rulesæ€§èƒ½ä¼˜åŒ–
â”‚   â””â”€â”€ æ•°æ®æŒä¹…åŒ–ä¸é«˜å¯ç”¨
â”‚
â”œâ”€â”€ 9.3 Grafanaå¯è§†åŒ–ä¸ä»ªè¡¨ç›˜
â”‚   â”œâ”€â”€ Grafanaéƒ¨ç½²ä¸é…ç½®
â”‚   â”œâ”€â”€ æ•°æ®æºé›†æˆï¼ˆPrometheus/Loki/Jaegerï¼‰
â”‚   â”œâ”€â”€ ä»ªè¡¨ç›˜è®¾è®¡æœ€ä½³å®è·µ
â”‚   â”œâ”€â”€ å˜é‡ä¸æ¨¡æ¿åº”ç”¨
â”‚   â””â”€â”€ ä¼ä¸šçº§ä»ªè¡¨ç›˜ç¤ºä¾‹
â”‚
â”œâ”€â”€ 9.4 å‘Šè­¦è§„åˆ™ä¸AlertManager
â”‚   â”œâ”€â”€ AlertManageræ¶æ„ä¸é…ç½®
â”‚   â”œâ”€â”€ å‘Šè­¦è§„åˆ™ç¼–å†™ï¼ˆCPU/å†…å­˜/ç£ç›˜/Podï¼‰
â”‚   â”œâ”€â”€ å‘Šè­¦è·¯ç”±ä¸åˆ†ç»„
â”‚   â”œâ”€â”€ æŠ‘åˆ¶ä¸é™é»˜ç­–ç•¥
â”‚   â””â”€â”€ å¤šæ¸ é“é€šçŸ¥é›†æˆï¼ˆé’‰é’‰/ä¼ä¸šå¾®ä¿¡/PagerDutyï¼‰
â”‚
â”œâ”€â”€ 9.5 æ—¥å¿—ç®¡ç†ä¸EFKæ ˆ
â”‚   â”œâ”€â”€ æ—¥å¿—æ”¶é›†æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ Fluentd/Fluent Bitéƒ¨ç½²
â”‚   â”œâ”€â”€ Elasticsearché›†ç¾¤æ­å»º
â”‚   â”œâ”€â”€ Kibanaæ—¥å¿—æŸ¥è¯¢ä¸åˆ†æ
â”‚   â””â”€â”€ Lokiè½»é‡çº§æ—¥å¿—æ–¹æ¡ˆ
â”‚
â”œâ”€â”€ 9.6 åˆ†å¸ƒå¼è¿½è¸ªä¸Jaeger
â”‚   â”œâ”€â”€ OpenTelemetryæ ‡å‡†
â”‚   â”œâ”€â”€ Jaegeræ¶æ„ä¸éƒ¨ç½²
â”‚   â”œâ”€â”€ åº”ç”¨åŸ‹ç‚¹ä¸SDKé›†æˆ
â”‚   â”œâ”€â”€ è°ƒç”¨é“¾è·¯åˆ†æå®æˆ˜
â”‚   â””â”€â”€ æ€§èƒ½ç“¶é¢ˆå®šä½
â”‚
â”œâ”€â”€ 9.7 Kubernetesäº‹ä»¶ç›‘æ§
â”‚   â”œâ”€â”€ Eventsèµ„æºè¯¦è§£
â”‚   â”œâ”€â”€ kube-eventeréƒ¨ç½²
â”‚   â”œâ”€â”€ äº‹ä»¶æŒä¹…åŒ–å­˜å‚¨
â”‚   â””â”€â”€ å…³é”®äº‹ä»¶å‘Šè­¦
â”‚
â””â”€â”€ 9.8 ç›‘æ§æœ€ä½³å®è·µä¸ç”Ÿäº§æ¡ˆä¾‹
    â”œâ”€â”€ ç›‘æ§æŒ‡æ ‡ä½“ç³»è®¾è®¡ï¼ˆUSE/REDæ–¹æ³•ï¼‰
    â”œâ”€â”€ é»„é‡‘æŒ‡æ ‡ä¸SLI/SLO/SLA
    â”œâ”€â”€ æˆæœ¬ä¼˜åŒ–ï¼ˆæ•°æ®ä¿ç•™ç­–ç•¥/é‡‡æ ·ç‡ï¼‰
    â”œâ”€â”€ ç”Ÿäº§æ•…éšœæ¡ˆä¾‹ï¼ˆOOM/ç£ç›˜æ»¡/é›ªå´©ï¼‰
    â””â”€â”€ ä¼ä¸šçº§ç›‘æ§å¹³å°æ¶æ„
```

## å­¦ä¹ è·¯å¾„å»ºè®®

**åˆå­¦è€…è·¯å¾„**ï¼ˆæŒæ¡åŸºç¡€ç›‘æ§ï¼‰ï¼š
1. å…ˆå­¦ä¹  9.1 ç›‘æ§åŸºç¡€ï¼Œç†è§£æ ¸å¿ƒæ¦‚å¿µ
2. éƒ¨ç½² Metrics Serverï¼Œä½¿ç”¨ `kubectl top` æŸ¥çœ‹èµ„æº
3. å­¦ä¹  9.2 Prometheus åŸºç¡€ï¼Œéƒ¨ç½²å•æœºç‰ˆ
4. é…ç½® 9.3 Grafana ä»ªè¡¨ç›˜ï¼Œå¯è§†åŒ–é›†ç¾¤çŠ¶æ€
5. å®è·µ 9.4 ç®€å•å‘Šè­¦è§„åˆ™ï¼ˆCPU/å†…å­˜é˜ˆå€¼ï¼‰

**è¿›é˜¶è·¯å¾„**ï¼ˆæ„å»ºå®Œæ•´å¯è§‚æµ‹æ€§ï¼‰ï¼š
1. æ·±å…¥å­¦ä¹  9.2 PromQLï¼Œç¼–å†™å¤æ‚æŸ¥è¯¢
2. éƒ¨ç½² 9.5 EFK æ ˆï¼Œå®ç°æ—¥å¿—é›†ä¸­ç®¡ç†
3. é…ç½® 9.4 é«˜çº§å‘Šè­¦ï¼ˆåŸºäºå˜åŒ–ç‡/è¶‹åŠ¿é¢„æµ‹ï¼‰
4. å­¦ä¹  9.6 Jaegerï¼Œåˆ†æå¾®æœåŠ¡è°ƒç”¨é“¾
5. æŒæ¡ 9.8 æœ€ä½³å®è·µï¼Œè®¾è®¡ä¼ä¸šçº§ç›‘æ§ä½“ç³»

**ç”Ÿäº§ç¯å¢ƒå‡†å¤‡**ï¼š
- Prometheusé›†ç¾¤é«˜å¯ç”¨ï¼ˆå¤šå‰¯æœ¬+Thanosï¼‰
- æ—¥å¿—å­˜å‚¨æˆæœ¬ä¼˜åŒ–ï¼ˆå†·çƒ­åˆ†ç¦»+ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰
- å‘Šè­¦é™å™ªç­–ç•¥ï¼ˆæŠ‘åˆ¶è§„åˆ™+åˆ†çº§é€šçŸ¥ï¼‰
- ç›‘æ§æ•°æ®å®‰å…¨ï¼ˆRBAC+åŠ å¯†ä¼ è¾“ï¼‰

---

## æŠ€æœ¯æ ˆæ€»è§ˆ

æœ¬ç« æ¶‰åŠçš„æ ¸å¿ƒæŠ€æœ¯æ ˆï¼š

| ç±»åˆ« | å¼€æºæ–¹æ¡ˆ | å•†ä¸šæ–¹æ¡ˆ | äº‘åŸç”Ÿæ–¹æ¡ˆ |
|------|---------|---------|-----------|
| **Metrics** | Prometheus + Grafana | Datadog, New Relic | AWS CloudWatch, GCP Monitoring |
| **Logging** | EFK (Elasticsearch + Fluentd + Kibana) | Splunk, Sumo Logic | AWS CloudWatch Logs, GCP Logging |
| **Tracing** | Jaeger, Zipkin | Datadog APM, Dynatrace | AWS X-Ray, GCP Trace |
| **é›†æˆæ–¹æ¡ˆ** | Loki + Tempo + Grafana (LGTMæ ˆ) | Elastic Observability | - |

**æœ¬ç« é€‰æ‹©å¼€æºæ–¹æ¡ˆçš„åŸå› **ï¼š
- âœ… é›¶æˆæœ¬ï¼Œé€‚åˆå­¦ä¹ å’Œä¸­å°ä¼ä¸š
- âœ… ç¤¾åŒºæ´»è·ƒï¼Œæ–‡æ¡£ä¸°å¯Œ
- âœ… äº‘å‚å•†å…¼å®¹ï¼ˆå¯æ— ç¼è¿ç§»åˆ°æ‰˜ç®¡æœåŠ¡ï¼‰
- âœ… ä¼ä¸šçº§ç”Ÿäº§éªŒè¯ï¼ˆNetflixã€Uberã€Shopifyç­‰ä½¿ç”¨ï¼‰

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿ** è®©æˆ‘ä»¬ä»ç›‘æ§åŸºç¡€å¼€å§‹ï¼Œé€æ­¥æ„å»ºå®Œæ•´çš„Kuberneteså¯è§‚æµ‹æ€§å¹³å°ï¼

---


## 9.1 ç›‘æ§åŸºç¡€ä¸æ¶æ„è®¾è®¡

### 9.1.1 å¯è§‚æµ‹æ€§æ ¸å¿ƒæ¦‚å¿µ

#### ä»€ä¹ˆæ˜¯å¯è§‚æµ‹æ€§ï¼Ÿ

**å¯è§‚æµ‹æ€§ (Observability)** ä¸ç­‰äºç›‘æ§ (Monitoring)ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ›´å¹¿æ³›çš„æ¦‚å¿µï¼š

```
ç›‘æ§ (Monitoring)ï¼š
  - å·²çŸ¥é—®é¢˜çš„æ£€æµ‹ï¼ˆæˆ‘çŸ¥é“å¯èƒ½ä¼šå‡ºç°CPUè¿‡é«˜ï¼Œæ‰€ä»¥è®¾ç½®å‘Šè­¦ï¼‰
  - é¢„å®šä¹‰æŒ‡æ ‡çš„æ”¶é›†ï¼ˆå›ºå®šçš„Dashboardï¼‰
  - è¢«åŠ¨å“åº”ï¼ˆæ”¶åˆ°å‘Šè­¦åæ’æŸ¥ï¼‰

å¯è§‚æµ‹æ€§ (Observability)ï¼š
  - æœªçŸ¥é—®é¢˜çš„æ¢ç´¢ï¼ˆç³»ç»Ÿå‡ºç°ä»æœªè§è¿‡çš„å¼‚å¸¸ï¼Œèƒ½å¿«é€Ÿå®šä½ï¼‰
  - ä»»æ„ç»´åº¦çš„æŸ¥è¯¢ï¼ˆå¯ä»¥è‡ªç”±ç»„åˆå„ç§æ¡ä»¶æŸ¥è¯¢ï¼‰
  - ä¸»åŠ¨æ´å¯Ÿï¼ˆé€šè¿‡æ•°æ®å‘ç°æ½œåœ¨é—®é¢˜ï¼‰
```

**æ ¸å¿ƒåŒºåˆ«ç¤ºä¾‹**ï¼š

å‡è®¾ç”Ÿäº§ç¯å¢ƒå‡ºç°"ç”¨æˆ·æ”¯ä»˜æˆåŠŸç‡ä»99.5%é™åˆ°95%"ï¼š

```
ä¼ ç»Ÿç›‘æ§æ€è·¯ï¼š
1. æŸ¥çœ‹é¢„è®¾çš„Dashboard â†’ æ²¡æœ‰"æ”¯ä»˜æˆåŠŸç‡"è¿™ä¸ªæŒ‡æ ‡
2. ç™»å½•å„ä¸ªPodæŸ¥çœ‹æ—¥å¿— â†’ è€—æ—¶ä¸”åˆ†æ•£
3. çŒœæµ‹å¯èƒ½çš„åŸå›  â†’ æ•°æ®åº“ï¼Ÿç½‘ç»œï¼Ÿä»£ç bugï¼Ÿ
4. é€ä¸ªæ’æŸ¥ â†’ å¯èƒ½éœ€è¦æ•°å°æ—¶

å¯è§‚æµ‹æ€§æ€è·¯ï¼š
1. Metrics: æŸ¥è¯¢æ”¯ä»˜APIçš„P99å»¶è¿Ÿ â†’ å‘ç°ä»200mså‡åˆ°2s
2. Tracing: è°ƒç”¨é“¾åˆ†æ â†’ å®šä½åˆ°"åº“å­˜æŸ¥è¯¢"æ­¥éª¤è€—æ—¶å¢åŠ 
3. Logging: æŸ¥çœ‹åº“å­˜æœåŠ¡æ—¥å¿— â†’ å‘ç°å¤§é‡"connection timeout"
4. æ ¹å› å®šä½ï¼šåº“å­˜æœåŠ¡æ•°æ®åº“è¿æ¥æ± è€—å°½ â†’ 5åˆ†é’Ÿå†…ä¿®å¤
```

#### å¯è§‚æµ‹æ€§çš„ä»·å€¼

**ä¸šåŠ¡ä»·å€¼**ï¼š

| ç»´åº¦ | ä¼ ç»Ÿæ–¹å¼ | å¯è§‚æµ‹æ€§æ–¹å¼ | ä»·å€¼æå‡ |
|------|---------|-------------|---------|
| **æ•…éšœå‘ç°** | ç”¨æˆ·æŠ•è¯‰åè¢«åŠ¨å‘ç° | æå‰5-30åˆ†é’Ÿä¸»åŠ¨å‘Šè­¦ | å‡å°‘ç”¨æˆ·å½±å“é¢80% |
| **æ•…éšœå®šä½** | å¹³å‡2-4å°æ—¶ (MTTR) | å¹³å‡5-15åˆ†é’Ÿ | MTTRé™ä½90% |
| **å®¹é‡è§„åˆ’** | åŸºäºç»éªŒçŒœæµ‹ | åŸºäºå†å²è¶‹åŠ¿é¢„æµ‹ | æˆæœ¬é™ä½30-50% |
| **æ€§èƒ½ä¼˜åŒ–** | æ„Ÿè§‰å“ªé‡Œæ…¢å°±ä¼˜åŒ–å“ªé‡Œ | æ•°æ®é©±åŠ¨ï¼Œç²¾å‡†å®šä½ç“¶é¢ˆ | ä¼˜åŒ–æ•ˆæœæå‡5-10å€ |

**çœŸå®æ¡ˆä¾‹**ï¼š

æŸç”µå•†å…¬å¸åœ¨å¼•å…¥å®Œæ•´å¯è§‚æµ‹æ€§ä½“ç³»åï¼š
- âœ… 99.9% SLAè¾¾æˆç‡ä»92%æå‡åˆ°99.7%
- âœ… å¹³å‡æ•…éšœæ¢å¤æ—¶é—´ä»3.5å°æ—¶é™è‡³12åˆ†é’Ÿ
- âœ… é€šè¿‡å®¹é‡ä¼˜åŒ–èŠ‚çœäº‘æˆæœ¬38%ï¼ˆå¹´çœ200ä¸‡ç¾å…ƒï¼‰
- âœ… æ€§èƒ½é—®é¢˜å®šä½æ—¶é—´ä»å¹³å‡2å¤©é™è‡³1å°æ—¶

#### å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±è¯¦è§£

##### 1. Metrics (æŒ‡æ ‡ç›‘æ§)

**æ•°æ®ç‰¹ç‚¹**ï¼š
- èšåˆçš„æ•°å€¼å‹æ•°æ®ï¼ˆå¦‚ï¼šå¹³å‡å€¼ã€P99ã€ç´¯åŠ å€¼ï¼‰
- æ—¶åºå­˜å‚¨ï¼ˆæ—¶é—´æˆ³ + æ ‡ç­¾ + æ•°å€¼ï¼‰
- ä½å­˜å‚¨æˆæœ¬ï¼ˆæ¯ä¸ªæŒ‡æ ‡çº¦1-2 bytes/sampleï¼‰

**å…¸å‹åº”ç”¨åœºæ™¯**ï¼š
```yaml
# åœºæ™¯1: èµ„æºç›‘æ§
node_cpu_usage{node="node1", cpu="0"} 45.2    # CPUä½¿ç”¨ç‡45.2%
container_memory_usage{pod="nginx-abc", namespace="prod"} 256000000  # å†…å­˜256MB

# åœºæ™¯2: åº”ç”¨æ€§èƒ½
http_requests_total{method="GET", path="/api/users", status="200"} 15840  # è¯·æ±‚æ€»æ•°
http_request_duration_seconds{quantile="0.99"} 0.235  # P99å»¶è¿Ÿ235ms

# åœºæ™¯3: ä¸šåŠ¡æŒ‡æ ‡
order_created_total{region="us-west", payment_method="credit_card"} 3580  # è®¢å•æ•°
payment_success_rate 0.995  # æ”¯ä»˜æˆåŠŸç‡99.5%
```

**ä¼˜åŠ¿**ï¼š
- âœ… æŸ¥è¯¢é€Ÿåº¦å¿«ï¼ˆæ¯«ç§’çº§ï¼‰
- âœ… å­˜å‚¨æˆæœ¬ä½ï¼ˆTBçº§æ•°æ®/æœˆä»…éœ€å‡ GBï¼‰
- âœ… é€‚åˆå®æ—¶å‘Šè­¦ï¼ˆç§’çº§æ£€æµ‹é˜ˆå€¼ï¼‰
- âœ… æ˜“äºå¯è§†åŒ–ï¼ˆæŠ˜çº¿å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ï¼‰

**å±€é™**ï¼š
- âŒ æ— æ³•æŸ¥çœ‹è¯¦ç»†äº‹ä»¶ï¼ˆåªçŸ¥é“é”™è¯¯ç‡å‡é«˜ï¼Œä¸çŸ¥é“å…·ä½“é”™è¯¯ä¿¡æ¯ï¼‰
- âŒ ä¸¢å¤±ä¸Šä¸‹æ–‡ï¼ˆä¸çŸ¥é“æ˜¯å“ªä¸ªç”¨æˆ·ã€å“ªä¸ªè®¢å•å‡ºé”™ï¼‰

##### 2. Logging (æ—¥å¿—è¿½è¸ª)

**æ•°æ®ç‰¹ç‚¹**ï¼š
- ç¦»æ•£çš„äº‹ä»¶è®°å½•ï¼ˆæ¯æ¡æ—¥å¿—æ˜¯ä¸€ä¸ªå®Œæ•´äº‹ä»¶ï¼‰
- åŒ…å«ä¸°å¯Œä¸Šä¸‹æ–‡ï¼ˆæ—¶é—´ã€çº§åˆ«ã€æ¶ˆæ¯ã€å †æ ˆç­‰ï¼‰
- å­˜å‚¨æˆæœ¬é«˜ï¼ˆæ¯GBæ—¥å¿—çº¦å ç”¨1-3GBå­˜å‚¨ï¼‰

**æ—¥å¿—çº§åˆ«**ï¼š
```python
# åº”ç”¨æ—¥å¿—ç¤ºä¾‹
DEBUG: [2024-01-20 10:30:15] User session cache hit: user_id=12345
INFO:  [2024-01-20 10:30:16] Order created: order_id=ORD-789, amount=99.99, user=12345
WARN:  [2024-01-20 10:30:17] Payment retry attempt 2/3: gateway_timeout
ERROR: [2024-01-20 10:30:18] Payment failed: order=ORD-789, error=ConnectionTimeout
FATAL: [2024-01-20 10:30:19] Database connection pool exhausted
```

**ç»“æ„åŒ–æ—¥å¿— vs éç»“æ„åŒ–æ—¥å¿—**ï¼š

```json
// éç»“æ„åŒ–æ—¥å¿— (éš¾ä»¥æŸ¥è¯¢)
"2024-01-20 10:30:16 User john@example.com created order ORD-789 with amount $99.99"

// ç»“æ„åŒ–æ—¥å¿— (æ˜“äºæŸ¥è¯¢å’Œåˆ†æ)
{
  "timestamp": "2024-01-20T10:30:16Z",
  "level": "INFO",
  "message": "Order created",
  "order_id": "ORD-789",
  "user_email": "john@example.com",
  "amount": 99.99,
  "currency": "USD",
  "trace_id": "a1b2c3d4e5f6"  // å…³è”Tracing
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… åŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆèƒ½çœ‹åˆ°è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€å †æ ˆè¿½è¸ªï¼‰
- âœ… æ”¯æŒå…¨æ–‡æœç´¢ï¼ˆå¿«é€Ÿæ‰¾åˆ°ç‰¹å®šé”™è¯¯æ¶ˆæ¯ï¼‰
- âœ… é€‚åˆé—®é¢˜æ’æŸ¥ï¼ˆç»“åˆæ—¶é—´æˆ³ç²¾å‡†å®šä½ï¼‰

**å±€é™**ï¼š
- âŒ å­˜å‚¨æˆæœ¬é«˜ï¼ˆæ—¥å¿—é‡å¤§çš„ç³»ç»Ÿæ¯æœˆæ•°TBï¼‰
- âŒ æŸ¥è¯¢é€Ÿåº¦æ…¢ï¼ˆå…¨æ–‡æœç´¢TBçº§æ•°æ®å¯èƒ½éœ€è¦æ•°ç§’åˆ°æ•°åˆ†é’Ÿï¼‰
- âŒ éš¾ä»¥èšåˆåˆ†æï¼ˆä¸é€‚åˆç»Ÿè®¡è¶‹åŠ¿ï¼‰

##### 3. Tracing (é“¾è·¯è¿½è¸ª)

**æ•°æ®ç‰¹ç‚¹**ï¼š
- åˆ†å¸ƒå¼è¯·æ±‚çš„å®Œæ•´è°ƒç”¨é“¾ï¼ˆä¸€æ¬¡ç”¨æˆ·è¯·æ±‚å¯èƒ½è·¨è¶Š10+æœåŠ¡ï¼‰
- åŒ…å«æ—¶åºå…³ç³»å’Œä¾èµ–ï¼ˆå“ªä¸ªæ­¥éª¤å…ˆæ‰§è¡Œï¼Œå“ªä¸ªæœåŠ¡è°ƒç”¨äº†å“ªä¸ªæœåŠ¡ï¼‰
- é‡‡æ ·å­˜å‚¨ï¼ˆé€šå¸¸åªä¿å­˜1-10%çš„è¯·æ±‚ï¼Œå¦åˆ™æ•°æ®é‡è¿‡å¤§ï¼‰

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š

```
Trace (è¿½è¸ª): ä¸€æ¬¡å®Œæ•´çš„è¯·æ±‚é“¾è·¯
  â””â”€â”€ Span (è·¨åº¦): é“¾è·¯ä¸­çš„ä¸€ä¸ªæ“ä½œæ­¥éª¤
      â”œâ”€â”€ Span ID: å½“å‰æ­¥éª¤çš„å”¯ä¸€æ ‡è¯†
      â”œâ”€â”€ Parent Span ID: çˆ¶çº§æ­¥éª¤çš„ID
      â”œâ”€â”€ Start Time: å¼€å§‹æ—¶é—´
      â”œâ”€â”€ Duration: æŒç»­æ—¶é•¿
      â””â”€â”€ Tags/Logs: é™„åŠ ä¿¡æ¯ï¼ˆHTTPçŠ¶æ€ç ã€é”™è¯¯ä¿¡æ¯ç­‰ï¼‰
```

**å®é™…æ¡ˆä¾‹**ï¼š

ä¸€æ¬¡"ç”¨æˆ·ä¸‹å•"è¯·æ±‚çš„å®Œæ•´Traceï¼š

```
[Trace ID: a1b2c3d4e5f6]
â”‚
â”œâ”€â”€ [Span 1] API Gateway (æ€»è€—æ—¶: 1250ms)
â”‚   â”‚
â”‚   â”œâ”€â”€ [Span 2] ç”¨æˆ·è®¤è¯æœåŠ¡ (100ms)
â”‚   â”‚   â””â”€â”€ [Span 3] RedisæŸ¥è¯¢ç¼“å­˜ (5ms)
â”‚   â”‚
â”‚   â”œâ”€â”€ [Span 4] è®¢å•æœåŠ¡ (1100ms)
â”‚   â”‚   â”œâ”€â”€ [Span 5] åº“å­˜æœåŠ¡ (800ms) â† ç“¶é¢ˆï¼
â”‚   â”‚   â”‚   â””â”€â”€ [Span 6] MySQLæŸ¥è¯¢åº“å­˜ (780ms) â† æ ¹å› ï¼šæ…¢æŸ¥è¯¢
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ [Span 7] ä¼˜æƒ åˆ¸æœåŠ¡ (50ms)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ [Span 8] æ”¯ä»˜æœåŠ¡ (200ms)
â”‚   â”‚       â””â”€â”€ [Span 9] ç¬¬ä¸‰æ–¹æ”¯ä»˜ç½‘å…³ (180ms)
â”‚   â”‚
â”‚   â””â”€â”€ [Span 10] æ—¥å¿—è®°å½• (50ms)
```

é€šè¿‡Tracingå¯ä»¥ä¸€çœ¼çœ‹å‡ºï¼š
- âœ… æ€»è€—æ—¶1250msï¼Œå…¶ä¸­åº“å­˜æœåŠ¡å 64%ï¼ˆ800msï¼‰
- âœ… åº“å­˜æœåŠ¡çš„ç“¶é¢ˆåœ¨MySQLæŸ¥è¯¢ï¼ˆ780msï¼‰
- âœ… ä¼˜åŒ–æ–¹å‘ï¼šä¼˜åŒ–åº“å­˜æŸ¥è¯¢SQLæˆ–å¢åŠ ç¼“å­˜

**ä¼˜åŠ¿**ï¼š
- âœ… å¯è§†åŒ–æœåŠ¡ä¾èµ–ï¼ˆè‡ªåŠ¨ç”ŸæˆæœåŠ¡æ‹“æ‰‘å›¾ï¼‰
- âœ… ç²¾å‡†å®šä½ç“¶é¢ˆï¼ˆæ¯ä¸ªæ­¥éª¤çš„è€—æ—¶ä¸€ç›®äº†ç„¶ï¼‰
- âœ… ç†è§£å¤æ‚è°ƒç”¨é“¾ï¼ˆå¾®æœåŠ¡æ¶æ„ä¸‹å°¤ä¸ºé‡è¦ï¼‰

**å±€é™**ï¼š
- âŒ éœ€è¦åº”ç”¨åŸ‹ç‚¹ï¼ˆä»£ç ä¾µå…¥ï¼Œå¢åŠ å¼€å‘æˆæœ¬ï¼‰
- âŒ é‡‡æ ·ç‡æƒè¡¡ï¼ˆ100%é‡‡æ ·å­˜å‚¨æˆæœ¬é«˜ï¼Œä½é‡‡æ ·ç‡å¯èƒ½æ¼æ‰å…³é”®è¯·æ±‚ï¼‰
- âŒ å­¦ä¹ æ›²çº¿ï¼ˆéœ€è¦ç†è§£åˆ†å¸ƒå¼è¿½è¸ªæ¦‚å¿µï¼‰

#### ä¸‰å¤§æ”¯æŸ±çš„ååŒä½¿ç”¨

**å…¸å‹æ•…éšœæ’æŸ¥æµç¨‹**ï¼š

```
æ­¥éª¤1: Metricså‘ç°å¼‚å¸¸
  â†’ Grafana Dashboardæ˜¾ç¤º"APIé”™è¯¯ç‡ä»0.1%å‡åˆ°5%"

æ­¥éª¤2: Metricså®šä½æ—¶é—´å’ŒèŒƒå›´
  â†’ PromQLæŸ¥è¯¢: rate(http_requests_total{status=~"5.."}[5m])
  â†’ å‘ç°æ˜¯"è®¢å•æœåŠ¡"åœ¨"10:30-10:45"é”™è¯¯ç‡å¼‚å¸¸

æ­¥éª¤3: Tracingå®šä½å…·ä½“æœåŠ¡
  â†’ JaegeræŸ¥è¯¢"è®¢å•æœåŠ¡"åœ¨è¯¥æ—¶é—´æ®µçš„Trace
  â†’ å‘ç°80%çš„æ…¢è¯·æ±‚éƒ½å¡åœ¨"åº“å­˜æŸ¥è¯¢"æ­¥éª¤

æ­¥éª¤4: LoggingæŸ¥çœ‹è¯¦ç»†é”™è¯¯
  â†’ Kibanaæœç´¢: service="inventory" AND level="ERROR" AND time:[10:30 TO 10:45]
  â†’ æ‰¾åˆ°é”™è¯¯æ—¥å¿—: "com.mysql.jdbc.exceptions.MySQLTimeoutException: Connection timeout"

æ­¥éª¤5: æ ¹å› åˆ†æ
  â†’ ç»“åˆMetrics: MySQLè¿æ¥æ•°ä»50çªå¢åˆ°200ï¼ˆè¿æ¥æ± ä¸Šé™ï¼‰
  â†’ ç»“åˆLogging: å‘ç°æŸä¸ªå®šæ—¶ä»»åŠ¡åœ¨10:30å¯åŠ¨ï¼Œæ‰§è¡Œäº†å¤§é‡æ…¢æŸ¥è¯¢
  â†’ è§£å†³æ–¹æ¡ˆ: ä¼˜åŒ–æ…¢æŸ¥è¯¢SQLï¼Œå¢åŠ è¿æ¥æ± å¤§å°

æ€»è€—æ—¶: 5-10åˆ†é’Ÿï¼ˆå¦‚æœåªç”¨Loggingå¯èƒ½éœ€è¦1-2å°æ—¶ï¼‰
```

**ååŒä»·å€¼æ€»ç»“**ï¼š

| é—®é¢˜ç±»å‹ | ä¸»è¦ä½¿ç”¨å·¥å…· | è¾…åŠ©å·¥å…· |
|---------|------------|---------|
| å‘ç°å¼‚å¸¸ | Metrics (Prometheuså‘Šè­¦) | - |
| å®šä½æœåŠ¡ | Tracing (Jaeger) | Metrics (ç¼©å°æ—¶é—´èŒƒå›´) |
| æŸ¥çœ‹è¯¦æƒ… | Logging (Kibana) | Tracing (è·å–Trace ID) |
| è¶‹åŠ¿åˆ†æ | Metrics (Grafana Dashboard) | - |
| å®¹é‡è§„åˆ’ | Metrics (å†å²æ•°æ®åˆ†æ) | Logging (é”™è¯¯æ—¥å¿—ç»Ÿè®¡) |

---

### 9.1.2 Kubernetesç›‘æ§æ¶æ„

#### Kubernetesç›‘æ§å±‚æ¬¡

Kubernetesçš„ç›‘æ§éœ€è¦è¦†ç›–å¤šä¸ªå±‚æ¬¡ï¼Œæ¯ä¸€å±‚éƒ½æœ‰ä¸åŒçš„å…³æ³¨ç‚¹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     åº”ç”¨å±‚ (Application)                      â”‚
â”‚  â— ä¸šåŠ¡æŒ‡æ ‡: è®¢å•é‡ã€æ”¯ä»˜æˆåŠŸç‡ã€ç”¨æˆ·æ´»è·ƒåº¦                     â”‚
â”‚  â— åº”ç”¨æ€§èƒ½: APIå»¶è¿Ÿã€é”™è¯¯ç‡ã€QPS                              â”‚
â”‚  â— è‡ªå®šä¹‰Metrics: /metricsç«¯ç‚¹æš´éœ²çš„ä¸šåŠ¡æŒ‡æ ‡                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   å®¹å™¨å±‚ (Container)                          â”‚
â”‚  â— å®¹å™¨èµ„æº: CPUã€å†…å­˜ã€ç½‘ç»œã€ç£ç›˜IO                            â”‚
â”‚  â— å®¹å™¨çŠ¶æ€: é‡å¯æ¬¡æ•°ã€OOMæ¬¡æ•°ã€é•œåƒæ‹‰å–æ—¶é•¿                     â”‚
â”‚  â— å®¹å™¨æ—¥å¿—: stdout/stderrè¾“å‡º                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Podå±‚ (Pod)                               â”‚
â”‚  â— PodçŠ¶æ€: Running/Pending/Failed/CrashLoopBackOff          â”‚
â”‚  â— Podäº‹ä»¶: è°ƒåº¦å¤±è´¥ã€å¥åº·æ£€æŸ¥å¤±è´¥ã€VolumeæŒ‚è½½å¤±è´¥               â”‚
â”‚  â— Podèµ„æº: requests/limitsè®¾ç½®ã€å®é™…ä½¿ç”¨é‡                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Kubernetesèµ„æºå±‚ (K8s Resources)                â”‚
â”‚  â— Deployment: å‰¯æœ¬æ•°ã€å¯ç”¨å‰¯æœ¬ã€æ›´æ–°çŠ¶æ€                       â”‚
â”‚  â— Service: Endpointæ•°é‡ã€æµé‡åˆ†å¸ƒ                            â”‚
â”‚  â— PVC/PV: å­˜å‚¨ä½¿ç”¨ç‡ã€IOPSã€ååé‡                           â”‚
â”‚  â— Node: èŠ‚ç‚¹çŠ¶æ€ã€å¯è°ƒåº¦èµ„æºã€æ±¡ç‚¹å’Œæ ‡ç­¾                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   èŠ‚ç‚¹å±‚ (Node)                              â”‚
â”‚  â— ç³»ç»Ÿèµ„æº: CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ                             â”‚
â”‚  â— ç³»ç»ŸæœåŠ¡: kubeletã€kube-proxyã€å®¹å™¨è¿è¡Œæ—¶                   â”‚
â”‚  â— ç³»ç»Ÿæ—¥å¿—: /var/log/messagesã€journalctl                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               æ§åˆ¶å¹³é¢å±‚ (Control Plane)                      â”‚
â”‚  â— API Server: è¯·æ±‚å»¶è¿Ÿã€é”™è¯¯ç‡ã€å®¡è®¡æ—¥å¿—                      â”‚
â”‚  â— etcd: æ•°æ®åº“å¤§å°ã€å†™å…¥å»¶è¿Ÿã€Leaderé€‰ä¸¾                      â”‚
â”‚  â— Scheduler: è°ƒåº¦å»¶è¿Ÿã€é˜Ÿåˆ—é•¿åº¦ã€å¤±è´¥æ¬¡æ•°                     â”‚
â”‚  â— Controller Manager: Reconcileå¾ªç¯è€—æ—¶ã€å·¥ä½œé˜Ÿåˆ—æ·±åº¦        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### KubernetesåŸç”Ÿç›‘æ§æ¶æ„

Kubernetesæä¾›äº†ä¸¤å¥—å®˜æ–¹ç›‘æ§APIï¼š

##### 1. Resource Metrics API (èµ„æºæŒ‡æ ‡)

**ç”¨é€”**ï¼šæä¾›Podå’ŒNodeçš„CPU/å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œç”¨äºHPAå’ŒVPA

**æ¶æ„**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubectl top  â”‚  (æŸ¥è¯¢CPU/å†…å­˜)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server (Metrics API)           â”‚
â”‚   /apis/metrics.k8s.io/v1beta1/      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metrics Server                     â”‚  (èšåˆå™¨)
â”‚   - ä»kubeletæŠ“å–æŒ‡æ ‡                 â”‚
â”‚   - å†…å­˜å­˜å‚¨(æœ€è¿‘15åˆ†é’Ÿ)               â”‚
â”‚   - ä¸æŒä¹…åŒ–                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   kubelet (æ¯ä¸ªNode)                 â”‚
â”‚   - cAdvisor: å®¹å™¨èµ„æºæ•°æ®            â”‚
â”‚   - /stats/summary API               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metrics Serverçš„å±€é™**ï¼š
- âŒ åªä¿å­˜æœ€è¿‘15åˆ†é’Ÿæ•°æ®ï¼ˆæ— æ³•æŸ¥çœ‹å†å²è¶‹åŠ¿ï¼‰
- âŒ åªæœ‰CPU/å†…å­˜ï¼ˆæ— æ³•æŸ¥çœ‹ç½‘ç»œã€ç£ç›˜IOï¼‰
- âŒ æ— æ³•è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆåªèƒ½çœ‹èµ„æºï¼Œçœ‹ä¸åˆ°ä¸šåŠ¡æŒ‡æ ‡ï¼‰
- âŒ ä¸æ”¯æŒå‘Šè­¦ï¼ˆéœ€è¦é…åˆå…¶ä»–å·¥å…·ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… HPAè‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆåŸºäºCPU/å†…å­˜ï¼‰
- âœ… å¿«é€ŸæŸ¥çœ‹å½“å‰èµ„æºä½¿ç”¨ï¼ˆkubectl topï¼‰
- âœ… è½»é‡çº§éƒ¨ç½²ï¼ˆå°å‹é›†ç¾¤ï¼‰

##### 2. Custom Metrics API (è‡ªå®šä¹‰æŒ‡æ ‡)

**ç”¨é€”**ï¼šæ”¯æŒä»»æ„è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆå¦‚ï¼šQPSã€é”™è¯¯ç‡ï¼‰ï¼Œç”¨äºé«˜çº§HPA

**æ¶æ„**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HPA Controller                     â”‚
â”‚   (æ ¹æ®è‡ªå®šä¹‰æŒ‡æ ‡æ‰©ç¼©å®¹)               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server                         â”‚
â”‚   /apis/custom.metrics.k8s.io/v1beta1â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prometheus Adapter                 â”‚  (é€‚é…å™¨)
â”‚   - å°†PrometheusæŒ‡æ ‡è½¬æ¢ä¸ºK8s API     â”‚
â”‚   - æ”¯æŒPromQLæŸ¥è¯¢                    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prometheus                         â”‚
â”‚   - æŠ“å–åº”ç”¨çš„/metricsç«¯ç‚¹            â”‚
â”‚   - å­˜å‚¨æ—¶åºæ•°æ®                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç¤ºä¾‹**ï¼šåŸºäºQPSè‡ªåŠ¨æ‰©ç¼©å®¹

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second  # è‡ªå®šä¹‰æŒ‡æ ‡
      target:
        type: AverageValue
        averageValue: "1000"  # æ¯ä¸ªPodå¤„ç†1000 QPSæ—¶æ‰©å®¹
```

#### å®Œæ•´çš„ç”Ÿäº§çº§ç›‘æ§æ¶æ„

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚      å¤–éƒ¨ç”¨æˆ·/è¿ç»´äººå‘˜                â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Grafana      â”‚  â”‚  Kibana    â”‚  â”‚  Jaeger UI     â”‚
            â”‚  (å¯è§†åŒ–)       â”‚  â”‚ (æ—¥å¿—æŸ¥è¯¢)  â”‚  â”‚  (é“¾è·¯è¿½è¸ª)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                 â”‚                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus  â”‚ â”‚ Elasticsearchâ”‚ â”‚ Jaeger Collectorâ”‚
â”‚ (Metrics)   â”‚ â”‚  (æ—¥å¿—å­˜å‚¨)   â”‚ â”‚  (Traceå­˜å‚¨)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚   Fluentd      â”‚  â”‚ Jaeger Agent â”‚
         â”‚  â”‚  (æ—¥å¿—æ”¶é›†)     â”‚  â”‚  (Traceé‡‡é›†) â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚         Kubernetes Cluster                 â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
    â”‚  â”‚ kube-state-metrics (K8sèµ„æºçŠ¶æ€)      â”‚â—„â”€â”˜ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Node Exporter (èŠ‚ç‚¹æŒ‡æ ‡)              â”‚â—„â”€â”€â”€â”¤
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Application Pods (åº”ç”¨æŒ‡æ ‡/æ—¥å¿—)      â”‚â—„â”€â”€â”€â”˜
    â”‚  â”‚  - /metrics (Prometheusæ ¼å¼)          â”‚
    â”‚  â”‚  - stdout/stderræ—¥å¿—                  â”‚
    â”‚  â”‚  - OpenTelemetry SDK (TracingåŸ‹ç‚¹)    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å„ç»„ä»¶èŒè´£**ï¼š

| ç»„ä»¶ | èŒè´£ | æ•°æ®é‡çº§ |
|------|------|---------|
| **Prometheus** | æŠ“å–å’Œå­˜å‚¨Metrics | ä¸­ç­‰ï¼ˆæ¯ç§’æ•°åƒæ ·æœ¬ï¼‰ |
| **kube-state-metrics** | æš´éœ²K8sèµ„æºçŠ¶æ€ä¸ºMetrics | ä½ï¼ˆèµ„æºå¯¹è±¡çº§åˆ«ï¼‰ |
| **Node Exporter** | æš´éœ²èŠ‚ç‚¹ç³»ç»ŸæŒ‡æ ‡ | ä¸­ç­‰ï¼ˆæ¯ä¸ªèŠ‚ç‚¹æ•°ç™¾æŒ‡æ ‡ï¼‰ |
| **Fluentd/Fluent Bit** | æ”¶é›†å®¹å™¨æ—¥å¿—å¹¶è½¬å‘åˆ°ES | é«˜ï¼ˆæ¯ç§’GBçº§åˆ«ï¼‰ |
| **Elasticsearch** | å­˜å‚¨å’Œç´¢å¼•æ—¥å¿— | æé«˜ï¼ˆTBçº§åˆ«ï¼‰ |
| **Kibana** | æ—¥å¿—æŸ¥è¯¢å’Œå¯è§†åŒ– | - |
| **Jaeger Agent** | æ¥æ”¶åº”ç”¨Traceæ•°æ®å¹¶è½¬å‘ | ä¸­ç­‰ï¼ˆé‡‡æ ·åï¼‰ |
| **Jaeger Collector** | èšåˆTraceå¹¶å†™å…¥å­˜å‚¨ | ä¸­ç­‰ |
| **Grafana** | ç»Ÿä¸€å¯è§†åŒ–å¹³å° | - |

---

### 9.1.3 Metrics APIä¸èµ„æºæŒ‡æ ‡

#### Metrics Serverè¯¦è§£

**Metrics Serveræ˜¯ä»€ä¹ˆï¼Ÿ**

Metrics Serveræ˜¯Kuberneteså®˜æ–¹æä¾›çš„è½»é‡çº§ã€çŸ­æœŸçš„èµ„æºæŒ‡æ ‡æ”¶é›†å™¨ã€‚å®ƒä»æ¯ä¸ªèŠ‚ç‚¹çš„kubeletæ”¶é›†CPUå’Œå†…å­˜ä½¿ç”¨æ•°æ®ï¼Œå¹¶é€šè¿‡Metrics APIæš´éœ²ç»™Kubernetesç»„ä»¶ï¼ˆå¦‚HPAã€VPAã€kubectl topï¼‰ã€‚

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š
- âœ… å®˜æ–¹ç»´æŠ¤ï¼Œç¨³å®šå¯é 
- âœ… éƒ¨ç½²ç®€å•ï¼ˆå•ä¸ªDeploymentï¼‰
- âœ… èµ„æºå ç”¨ä½ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ä»…éœ€10-20MBå†…å­˜ï¼‰
- âœ… ä¸kubectlé›†æˆï¼ˆkubectl topå‘½ä»¤ï¼‰
- âŒ åªä¿å­˜æœ€è¿‘æ•°æ®ï¼ˆä¸é€‚åˆå†å²åˆ†æï¼‰
- âŒ åŠŸèƒ½æœ‰é™ï¼ˆä»…CPU/å†…å­˜ï¼‰

**æ¶æ„å›¾**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kubernetes API Server                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Aggregation Layer (APIèšåˆå±‚)                       â”‚   â”‚
â”‚  â”‚  - /apis/metrics.k8s.io/v1beta1/nodes                â”‚   â”‚
â”‚  â”‚  - /apis/metrics.k8s.io/v1beta1/pods                 â”‚   â”‚
â”‚  â”‚  - /apis/metrics.k8s.io/v1beta1/namespaces/{ns}/pods â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Metrics Server           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ In-Memory Storage    â”‚  â”‚ (ä»…ä¿ç•™15åˆ†é’Ÿæ•°æ®)
        â”‚  â”‚ - CPU/Memory         â”‚  â”‚
        â”‚  â”‚ - 60ç§’åˆ·æ–°é—´éš”        â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ Kubelet Client       â”‚  â”‚ (æŠ“å–kubeletæ•°æ®)
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚kubelet â”‚   â”‚kubelet â”‚   â”‚kubelet â”‚
â”‚ Node1  â”‚   â”‚ Node2  â”‚   â”‚ Node3  â”‚
â”‚  â””â”€â”€â”  â”‚   â”‚  â””â”€â”€â”  â”‚   â”‚  â””â”€â”€â”  â”‚
â”‚ cAdvâ”‚  â”‚   â”‚ cAdvâ”‚  â”‚   â”‚ cAdvâ”‚  â”‚ (å®¹å™¨èµ„æºç›‘æ§)
â””â”€â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”€â”˜  â”‚
   Pod1     Pod2        Pod3
```

#### éƒ¨ç½²Metrics Server

**1. å¿«é€Ÿéƒ¨ç½²ï¼ˆå®˜æ–¹YAMLï¼‰**

```bash
# ä¸‹è½½å®˜æ–¹éƒ¨ç½²æ–‡ä»¶
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

**2. è‡ªå®šä¹‰éƒ¨ç½²ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰**

```yaml
# metrics-server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  replicas: 1  # ç”Ÿäº§ç¯å¢ƒå»ºè®®2ä¸ªå‰¯æœ¬ï¼ˆé«˜å¯ç”¨ï¼‰
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      containers:
      - name: metrics-server
        image: registry.k8s.io/metrics-server/metrics-server:v0.7.0
        imagePullPolicy: IfNotPresent
        args:
        - --cert-dir=/tmp
        - --secure-port=10250
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s  # æ•°æ®é‡‡é›†é—´éš”ï¼ˆé»˜è®¤60sï¼Œå¯è°ƒæ•´ä¸º15sæé«˜ç²¾åº¦ï¼‰
        # å¦‚æœkubeletä½¿ç”¨è‡ªç­¾åè¯ä¹¦ï¼Œéœ€è¦æ·»åŠ ä»¥ä¸‹å‚æ•°ï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰
        # - --kubelet-insecure-tls
        ports:
        - containerPort: 10250
          name: https
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /livez
            port: https
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /readyz
            port: https
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 10
          failureThreshold: 3
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
      volumes:
      - name: tmp-dir
        emptyDir: {}
      priorityClassName: system-cluster-critical
      nodeSelector:
        kubernetes.io/os: linux
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    k8s-app: metrics-server
  ports:
  - port: 443
    protocol: TCP
    targetPort: https
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:metrics-server
rules:
- apiGroups:
  - ""
  resources:
  - nodes/metrics
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:metrics-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:metrics-server
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:aggregated-metrics-reader
  labels:
    rbac.authorization.k8s.io/aggregate-to-view: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
rules:
- apiGroups:
  - metrics.k8s.io
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1beta1.metrics.k8s.io
spec:
  service:
    name: metrics-server
    namespace: kube-system
  group: metrics.k8s.io
  version: v1beta1
  insecureSkipTLSVerify: true
  groupPriorityMinimum: 100
  versionPriority: 100
```

**3. éƒ¨ç½²å¹¶éªŒè¯**

```bash
# éƒ¨ç½²
kubectl apply -f metrics-server-deployment.yaml

# æ£€æŸ¥PodçŠ¶æ€
kubectl get pod -n kube-system -l k8s-app=metrics-server

# è¾“å‡ºç¤ºä¾‹:
# NAME                              READY   STATUS    RESTARTS   AGE
# metrics-server-5f8d6b7c9d-7x4ml   1/1     Running   0          2m

# æ£€æŸ¥APIæ³¨å†Œ
kubectl get apiservice v1beta1.metrics.k8s.io

# è¾“å‡ºç¤ºä¾‹:
# NAME                     SERVICE                      AVAILABLE   AGE
# v1beta1.metrics.k8s.io   kube-system/metrics-server   True        2m

# æµ‹è¯•æŸ¥è¯¢ï¼ˆç­‰å¾…1-2åˆ†é’Ÿæ•°æ®é‡‡é›†å®Œæˆï¼‰
kubectl top nodes
kubectl top pods -A
```

**å¸¸è§é—®é¢˜æ’æŸ¥**ï¼š

```bash
# é—®é¢˜1: Metrics Server PodçŠ¶æ€ä¸ºCrashLoopBackOff
kubectl logs -n kube-system -l k8s-app=metrics-server

# å¸¸è§é”™è¯¯: "x509: cannot validate certificate for xxx because it doesn't contain any IP SANs"
# è§£å†³: æ·»åŠ  --kubelet-insecure-tls å‚æ•°ï¼ˆä»…é™æµ‹è¯•ç¯å¢ƒï¼‰

# é—®é¢˜2: kubectl top nodes æŠ¥é”™ "Error from server (ServiceUnavailable): the server is currently unable to handle the request"
# åŸå› : Metrics Serverè¿˜åœ¨é‡‡é›†æ•°æ®ï¼Œç­‰å¾…1-2åˆ†é’Ÿ

# é—®é¢˜3: æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
kubectl logs -n kube-system deploy/metrics-server --tail=100 -f
```

#### ä½¿ç”¨kubectl topæŸ¥çœ‹èµ„æº

**1. æŸ¥çœ‹èŠ‚ç‚¹èµ„æº**

```bash
# æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹çš„CPUå’Œå†…å­˜ä½¿ç”¨
kubectl top nodes

# è¾“å‡ºç¤ºä¾‹:
# NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
# node1      450m         22%    3500Mi          45%
# node2      320m         16%    2800Mi          36%
# node3      580m         29%    4200Mi          54%
```

**è§£è¯»**ï¼š
- `CPU(cores)`: ä½¿ç”¨çš„CPUæ ¸å¿ƒæ•°ï¼ˆ450m = 0.45æ ¸ï¼‰
- `CPU%`: å èŠ‚ç‚¹æ€»CPUçš„ç™¾åˆ†æ¯”ï¼ˆå‡è®¾èŠ‚ç‚¹æœ‰2æ ¸ï¼Œ450m/2000m = 22.5%ï¼‰
- `MEMORY(bytes)`: å†…å­˜ä½¿ç”¨é‡ï¼ˆ3500Mi â‰ˆ 3.5GBï¼‰
- `MEMORY%`: å èŠ‚ç‚¹æ€»å†…å­˜çš„ç™¾åˆ†æ¯”

**2. æŸ¥çœ‹Podèµ„æº**

```bash
# æŸ¥çœ‹æ‰€æœ‰å‘½åç©ºé—´çš„Pod
kubectl top pods -A

# æŸ¥çœ‹ç‰¹å®šå‘½åç©ºé—´
kubectl top pods -n production

# æŸ¥çœ‹ç‰¹å®šPodçš„å®¹å™¨çº§åˆ«èµ„æº
kubectl top pods nginx-deployment-abc123 --containers

# è¾“å‡ºç¤ºä¾‹:
# POD                          CONTAINER    CPU(cores)   MEMORY(bytes)
# nginx-deployment-abc123      nginx        10m          50Mi
# nginx-deployment-abc123      sidecar      2m           20Mi

# æ’åºï¼ˆæŒ‰CPUé™åºï¼‰
kubectl top pods -A --sort-by=cpu

# æ’åºï¼ˆæŒ‰å†…å­˜é™åºï¼‰
kubectl top pods -A --sort-by=memory
```

**3. ç»“åˆå…¶ä»–å‘½ä»¤åˆ†æ**

```bash
# æ‰¾å‡ºå†…å­˜ä½¿ç”¨TOP 10çš„Pod
kubectl top pods -A --sort-by=memory | head -11

# æ‰¾å‡ºCPUä½¿ç”¨è¶…è¿‡100mçš„Pod
kubectl top pods -A | awk '$2 > 100'

# å¯¹æ¯”requests/limitsé…ç½®
kubectl get pods nginx-abc -o json | jq '.spec.containers[].resources'
kubectl top pod nginx-abc
```

#### Metrics APIçš„ç¼–ç¨‹ä½¿ç”¨

**1. ç›´æ¥è°ƒç”¨API**

```bash
# æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹æŒ‡æ ‡
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes | jq .

# è¾“å‡ºç¤ºä¾‹:
# {
#   "kind": "NodeMetricsList",
#   "apiVersion": "metrics.k8s.io/v1beta1",
#   "metadata": {},
#   "items": [
#     {
#       "metadata": {
#         "name": "node1",
#         "creationTimestamp": "2024-01-20T10:30:00Z"
#       },
#       "timestamp": "2024-01-20T10:29:45Z",
#       "window": "30s",
#       "usage": {
#         "cpu": "450m",
#         "memory": "3500Mi"
#       }
#     }
#   ]
# }

# æŸ¥è¯¢ç‰¹å®šPodæŒ‡æ ‡
kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/default/pods/nginx-abc | jq .
```

**2. ä½¿ç”¨client-goè®¿é—®Metrics API (Go)**

```go
package main

import (
    "context"
    "fmt"
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/tools/clientcmd"
    metricsv "k8s.io/metrics/pkg/client/clientset/versioned"
)

func main() {
    // åŠ è½½kubeconfig
    config, err := clientcmd.BuildConfigFromFlags("", "/home/user/.kube/config")
    if err != nil {
        panic(err)
    }

    // åˆ›å»ºMetricså®¢æˆ·ç«¯
    metricsClient, err := metricsv.NewForConfig(config)
    if err != nil {
        panic(err)
    }

    // æŸ¥è¯¢èŠ‚ç‚¹æŒ‡æ ‡
    nodeMetrics, err := metricsClient.MetricsV1beta1().NodeMetricses().List(context.TODO(), metav1.ListOptions{})
    if err != nil {
        panic(err)
    }

    for _, node := range nodeMetrics.Items {
        cpu := node.Usage.Cpu().MilliValue()  // è½¬æ¢ä¸ºæ¯«æ ¸
        memory := node.Usage.Memory().Value() / 1024 / 1024  // è½¬æ¢ä¸ºMiB
        fmt.Printf("Node: %s, CPU: %dm, Memory: %dMi\n", node.Name, cpu, memory)
    }

    // æŸ¥è¯¢PodæŒ‡æ ‡
    podMetrics, err := metricsClient.MetricsV1beta1().PodMetricses("default").List(context.TODO(), metav1.ListOptions{})
    if err != nil {
        panic(err)
    }

    for _, pod := range podMetrics.Items {
        for _, container := range pod.Containers {
            cpu := container.Usage.Cpu().MilliValue()
            memory := container.Usage.Memory().Value() / 1024 / 1024
            fmt.Printf("Pod: %s, Container: %s, CPU: %dm, Memory: %dMi\n",
                pod.Name, container.Name, cpu, memory)
        }
    }
}
```

**3. ä½¿ç”¨Pythonè®¿é—®Metrics API**

```python
from kubernetes import client, config

# åŠ è½½kubeconfig
config.load_kube_config()

# åˆ›å»ºAPIå®¢æˆ·ç«¯
api_client = client.ApiClient()
custom_api = client.CustomObjectsApi(api_client)

# æŸ¥è¯¢èŠ‚ç‚¹æŒ‡æ ‡
node_metrics = custom_api.list_cluster_custom_object(
    group="metrics.k8s.io",
    version="v1beta1",
    plural="nodes"
)

for node in node_metrics['items']:
    name = node['metadata']['name']
    cpu = node['usage']['cpu']
    memory = node['usage']['memory']
    print(f"Node: {name}, CPU: {cpu}, Memory: {memory}")

# æŸ¥è¯¢PodæŒ‡æ ‡
pod_metrics = custom_api.list_namespaced_custom_object(
    group="metrics.k8s.io",
    version="v1beta1",
    namespace="default",
    plural="pods"
)

for pod in pod_metrics['items']:
    pod_name = pod['metadata']['name']
    for container in pod['containers']:
        container_name = container['name']
        cpu = container['usage']['cpu']
        memory = container['usage']['memory']
        print(f"Pod: {pod_name}, Container: {container_name}, CPU: {cpu}, Memory: {memory}")
```

#### HPAåŸºäºMetricsè‡ªåŠ¨æ‰©ç¼©å®¹

**1. åŸºäºCPUçš„HPA**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPUä½¿ç”¨ç‡è¶…è¿‡70%æ—¶æ‰©å®¹
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # ç¼©å®¹å‰ç­‰å¾…5åˆ†é’Ÿè§‚å¯Ÿ
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60  # æ¯åˆ†é’Ÿæœ€å¤šç¼©å®¹50%
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30  # æ¯30ç§’æœ€å¤šæ‰©å®¹100%ï¼ˆç¿»å€ï¼‰
      - type: Pods
        value: 4
        periodSeconds: 30  # æ¯30ç§’æœ€å¤šå¢åŠ 4ä¸ªPod
      selectPolicy: Max  # é€‰æ‹©æ‰©å®¹æœ€å¿«çš„ç­–ç•¥
```

**2. åŸºäºå†…å­˜çš„HPA**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: java-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: java-app
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%æ—¶æ‰©å®¹
```

**3. å¤šæŒ‡æ ‡ç»„åˆHPA**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web
  minReplicas: 5
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # ä»»æ„ä¸€ä¸ªæŒ‡æ ‡è¾¾åˆ°é˜ˆå€¼å°±è§¦å‘æ‰©å®¹
```

**4. éªŒè¯HPA**

```bash
# éƒ¨ç½²HPA
kubectl apply -f nginx-hpa.yaml

# æŸ¥çœ‹HPAçŠ¶æ€
kubectl get hpa nginx-hpa

# è¾“å‡ºç¤ºä¾‹:
# NAME        REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
# nginx-hpa   Deployment/nginx   15%/70%   2         10        2          5m

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
kubectl describe hpa nginx-hpa

# æ¨¡æ‹Ÿè´Ÿè½½æµ‹è¯•ï¼ˆè§¦å‘æ‰©å®¹ï¼‰
kubectl run -it --rm load-generator --image=busybox --restart=Never -- sh -c "while true; do wget -q -O- http://nginx; done"

# è§‚å¯ŸHPAè‡ªåŠ¨æ‰©å®¹
kubectl get hpa nginx-hpa --watch
```

---

### 9.1.4 ç›‘æ§æ•°æ®é‡‡é›†è·¯å¾„

#### kubeletçš„cAdvisor

**cAdvisor (Container Advisor)** æ˜¯kubeletå†…ç½®çš„å®¹å™¨èµ„æºç›‘æ§ç»„ä»¶ï¼Œè´Ÿè´£æ”¶é›†èŠ‚ç‚¹ä¸Šæ‰€æœ‰å®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µã€‚

**cAdvisoræš´éœ²çš„APIç«¯ç‚¹**ï¼š

```bash
# 1. Summary API (Metrics Serverä½¿ç”¨)
# æä¾›èŠ‚ç‚¹å’ŒPodçº§åˆ«çš„èšåˆæ•°æ®
curl -k https://NODE_IP:10250/stats/summary \
  --header "Authorization: Bearer $(kubectl get secret -n kube-system -o jsonpath='{.items[?(@.metadata.annotations.kubernetes\.io/service-account\.name=="default")].data.token}' | base64 -d)"

# è¿”å›ç¤ºä¾‹:
# {
#   "node": {
#     "nodeName": "node1",
#     "cpu": {
#       "time": "2024-01-20T10:30:00Z",
#       "usageNanoCores": 450000000,  // 450m CPU
#       "usageCoreNanoSeconds": 1234567890
#     },
#     "memory": {
#       "time": "2024-01-20T10:30:00Z",
#       "usageBytes": 3670016000,  // 3.5GB
#       "workingSetBytes": 3500000000
#     }
#   },
#   "pods": [...]
# }

# 2. Metrics API (Prometheusä½¿ç”¨)
# æä¾›æ›´è¯¦ç»†çš„å®¹å™¨çº§åˆ«æ•°æ®
curl -k https://NODE_IP:10250/metrics

# è¿”å›Prometheusæ ¼å¼:
# container_cpu_usage_seconds_total{container="nginx",namespace="default",pod="nginx-abc"} 12.34
# container_memory_working_set_bytes{container="nginx",namespace="default",pod="nginx-abc"} 52428800
```

**cAdvisorç›‘æ§çš„æŒ‡æ ‡ç»´åº¦**ï¼š

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | è¯´æ˜ |
|---------|---------|------|
| **CPU** | cpu.usageNanoCores | å½“å‰CPUä½¿ç”¨ï¼ˆçº³æ ¸ï¼‰ |
|  | cpu.usageCoreNanoSeconds | ç´¯è®¡CPUä½¿ç”¨æ—¶é—´ |
| **å†…å­˜** | memory.usageBytes | æ€»å†…å­˜ä½¿ç”¨ï¼ˆåŒ…æ‹¬ç¼“å­˜ï¼‰ |
|  | memory.workingSetBytes | å·¥ä½œé›†å†…å­˜ï¼ˆçœŸå®ä½¿ç”¨ï¼‰ |
|  | memory.rssBytes | RSSå†…å­˜ï¼ˆåŒ¿åå†…å­˜ï¼‰ |
|  | memory.pageFaults | é¡µé¢é”™è¯¯æ¬¡æ•° |
| **ç½‘ç»œ** | network.rxBytes | æ¥æ”¶å­—èŠ‚æ•° |
|  | network.txBytes | å‘é€å­—èŠ‚æ•° |
|  | network.rxErrors | æ¥æ”¶é”™è¯¯æ•° |
| **ç£ç›˜** | fs.usedBytes | æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨é‡ |
|  | fs.capacityBytes | æ–‡ä»¶ç³»ç»Ÿæ€»å®¹é‡ |
| **å®¹å™¨** | startTime | å®¹å™¨å¯åŠ¨æ—¶é—´ |
|  | restartCount | é‡å¯æ¬¡æ•° |

#### Prometheusæ•°æ®é‡‡é›†æµç¨‹

Prometheusé‡‡ç”¨**æ‹‰æ¨¡å¼ (Pull Model)** é‡‡é›†æ•°æ®ï¼Œä¸ä¼ ç»Ÿçš„æ¨æ¨¡å¼ï¼ˆå¦‚StatsDï¼‰ä¸åŒã€‚

**å®Œæ•´çš„æ•°æ®æµ**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Prometheus Server                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Service Discovery (æœåŠ¡å‘ç°)                       â”‚     â”‚
â”‚  â”‚  - Kubernetes API (è‡ªåŠ¨å‘ç°Pod/Service/Node)        â”‚     â”‚
â”‚  â”‚  - é™æ€é…ç½®æ–‡ä»¶                                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Scraper (æŠ“å–å™¨)                                   â”‚     â”‚
â”‚  â”‚  - å®šæœŸHTTP GET /metrics                            â”‚     â”‚
â”‚  â”‚  - é»˜è®¤é—´éš”: 15s-60s                                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  TSDB (æ—¶åºæ•°æ®åº“)                                  â”‚     â”‚
â”‚  â”‚  - å‹ç¼©å­˜å‚¨ (æ¯ä¸ªæ ·æœ¬çº¦1-2å­—èŠ‚)                      â”‚     â”‚
â”‚  â”‚  - é»˜è®¤ä¿ç•™15å¤©                                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ HTTP GET /metrics (æ¯15s)
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚                â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚kubelet   â”‚    â”‚kube-stateâ”‚    â”‚  Node    â”‚      â”‚  App     â”‚
    â”‚/metrics  â”‚    â”‚-metrics  â”‚    â”‚ Exporter â”‚      â”‚ /metrics â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    (å®¹å™¨èµ„æº)       (K8sèµ„æºçŠ¶æ€)   (èŠ‚ç‚¹ç³»ç»ŸæŒ‡æ ‡)     (åº”ç”¨æŒ‡æ ‡)
```

**Prometheusé…ç½®ç¤ºä¾‹**ï¼š

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s  # å…¨å±€æŠ“å–é—´éš”
      evaluation_interval: 15s  # è§„åˆ™è¯„ä¼°é—´éš”
      external_labels:
        cluster: 'production'
        region: 'us-west-2'

    # æŠ“å–é…ç½®
    scrape_configs:
    # 1. æŠ“å–kubelet (å®¹å™¨èµ„æºæŒ‡æ ‡)
    - job_name: 'kubernetes-kubelet'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node  # æœåŠ¡å‘ç°: æ‰€æœ‰èŠ‚ç‚¹
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

    # 2. æŠ“å–kube-state-metrics (K8sèµ„æºçŠ¶æ€)
    - job_name: 'kube-state-metrics'
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
        action: keep
        regex: kube-state-metrics

    # 3. æŠ“å–Node Exporter (èŠ‚ç‚¹ç³»ç»ŸæŒ‡æ ‡)
    - job_name: 'node-exporter'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__

    # 4. æŠ“å–åº”ç”¨Pod (è‡ªå®šä¹‰æŒ‡æ ‡)
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      # åªæŠ“å–å¸¦æœ‰ prometheus.io/scrape=true æ³¨è§£çš„Pod
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      # è‡ªå®šä¹‰æŠ“å–ç«¯å£ (é»˜è®¤/metrics)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: (.+)
        replacement: $1
      # è‡ªå®šä¹‰æŠ“å–è·¯å¾„
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      # æ·»åŠ å‘½åç©ºé—´æ ‡ç­¾
      - source_labels: [__meta_kubernetes_namespace]
        target_label: kubernetes_namespace
      # æ·»åŠ Podåç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: kubernetes_pod_name
```

**åº”ç”¨å¦‚ä½•æš´éœ²Metrics**ï¼š

```yaml
# ç¤ºä¾‹: Goåº”ç”¨æš´éœ²PrometheusæŒ‡æ ‡
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  annotations:
    prometheus.io/scrape: "true"  # å‘Šè¯‰PrometheusæŠ“å–æ­¤Pod
    prometheus.io/port: "8080"    # æŒ‡æ ‡ç«¯å£
    prometheus.io/path: "/metrics"  # æŒ‡æ ‡è·¯å¾„
spec:
  containers:
  - name: app
    image: my-app:v1.0
    ports:
    - containerPort: 8080
      name: metrics
```

```go
// Goåº”ç”¨ä»£ç ç¤ºä¾‹
package main

import (
    "net/http"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    // è‡ªå®šä¹‰CounteræŒ‡æ ‡
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    // è‡ªå®šä¹‰HistogramæŒ‡æ ‡
    httpRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request latency",
            Buckets: []float64{0.01, 0.05, 0.1, 0.5, 1, 2, 5},
        },
        []string{"method", "endpoint"},
    )
)

func init() {
    // æ³¨å†ŒæŒ‡æ ‡
    prometheus.MustRegister(httpRequestsTotal)
    prometheus.MustRegister(httpRequestDuration)
}

func main() {
    // æš´éœ²/metricsç«¯ç‚¹
    http.Handle("/metrics", promhttp.Handler())
    
    // ä¸šåŠ¡Handler
    http.HandleFunc("/api/users", func(w http.ResponseWriter, r *http.Request) {
        timer := prometheus.NewTimer(httpRequestDuration.WithLabelValues(r.Method, "/api/users"))
        defer timer.ObserveDuration()

        // ä¸šåŠ¡é€»è¾‘...
        
        httpRequestsTotal.WithLabelValues(r.Method, "/api/users", "200").Inc()
        w.Write([]byte("OK"))
    })

    http.ListenAndServe(":8080", nil)
}
```

**è®¿é—®/metricsç«¯ç‚¹çš„è¾“å‡º**ï¼š

```
# HELP http_requests_total Total number of HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",endpoint="/api/users",status="200"} 15840

# HELP http_request_duration_seconds HTTP request latency
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.01"} 8500
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.05"} 14200
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.1"} 15600
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="0.5"} 15820
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="1"} 15838
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",le="+Inf"} 15840
http_request_duration_seconds_sum{method="GET",endpoint="/api/users"} 458.92
http_request_duration_seconds_count{method="GET",endpoint="/api/users"} 15840
```

#### æ—¥å¿—é‡‡é›†æµç¨‹

**å®¹å™¨æ—¥å¿—çš„ç”Ÿå‘½å‘¨æœŸ**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Pod                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Application Container                          â”‚     â”‚
â”‚  â”‚  - stdout: æ ‡å‡†è¾“å‡º                              â”‚     â”‚
â”‚  â”‚  - stderr: æ ‡å‡†é”™è¯¯                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Container Runtime (Docker/containerd) â”‚
  â”‚  - å†™å…¥æ—¥å¿—æ–‡ä»¶:                     â”‚
  â”‚    /var/log/pods/<namespace>_<pod>_<uid>/<container>/0.log  â”‚
  â”‚  - JSONæ ¼å¼:                         â”‚
  â”‚    {"log":"[INFO] User logged in\n", "stream":"stdout", "time":"2024-01-20T10:30:00Z"} â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  kubelet (æ—¥å¿—è½®è½¬)                 â”‚
  â”‚  - é»˜è®¤å•æ–‡ä»¶ä¸Šé™: 10MB              â”‚
  â”‚  - é»˜è®¤ä¿ç•™æ–‡ä»¶æ•°: 5                â”‚
  â”‚  - è¶…è¿‡é™åˆ¶è‡ªåŠ¨è½®è½¬                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Fluentd/Fluent Bit (DaemonSet)    â”‚
  â”‚  - ä½¿ç”¨tail -fç›‘å¬æ—¥å¿—æ–‡ä»¶           â”‚
  â”‚  - è§£æJSONæ ¼å¼                     â”‚
  â”‚  - æ·»åŠ K8så…ƒæ•°æ®(Podå/å‘½åç©ºé—´)     â”‚
  â”‚  - è¿‡æ»¤/è½¬æ¢/è·¯ç”±                   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Elasticsearch / Loki              â”‚
  â”‚  - ç´¢å¼•å’Œå­˜å‚¨æ—¥å¿—                   â”‚
  â”‚  - æ”¯æŒå…¨æ–‡æœç´¢                     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluentdé…ç½®ç¤ºä¾‹**ï¼š

```yaml
# fluentd-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.monitoring.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_UID
          value: "0"  # ä»¥rootè¿è¡Œï¼ˆéœ€è¦è¯»å–æ—¥å¿—æ–‡ä»¶ï¼‰
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 1000m
            memory: 512Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluentd-config
          mountPath: /fluentd/etc/
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluentd-config
        configMap:
          name: fluentd-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
data:
  fluent.conf: |
    # è¾“å…¥: å®¹å™¨æ—¥å¿—
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    # è¿‡æ»¤: æ·»åŠ Kuberneteså…ƒæ•°æ®
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
    </filter>

    # è¿‡æ»¤: æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´çš„DEBUGæ—¥å¿—
    <filter kubernetes.**>
      @type grep
      <exclude>
        key log
        pattern /DEBUG/
      </exclude>
      <exclude>
        key $.kubernetes.namespace_name
        pattern /^(kube-system|kube-public)$/
      </exclude>
    </filter>

    # è¾“å‡º: å‘é€åˆ°Elasticsearch
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.monitoring.svc.cluster.local
      port 9200
      logstash_format true
      logstash_prefix kubernetes
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.buffer
        flush_mode interval
        flush_interval 5s
        flush_at_shutdown true
        retry_max_interval 30
      </buffer>
    </match>
```

---

**ğŸ“Š 9.1èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Kubernetesç›‘æ§çš„åŸºç¡€æ¦‚å¿µå’Œæ¶æ„è®¾è®¡ï¼š

âœ… **å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±**ï¼š
- Metrics: èšåˆçš„æ—¶åºæ•°æ®ï¼Œå¿«é€Ÿå‘ç°å¼‚å¸¸
- Logging: ç¦»æ•£çš„äº‹ä»¶è®°å½•ï¼ŒæŸ¥çœ‹è¯¦ç»†ä¸Šä¸‹æ–‡
- Tracing: åˆ†å¸ƒå¼è°ƒç”¨é“¾è·¯ï¼Œå®šä½æ€§èƒ½ç“¶é¢ˆ

âœ… **Kubernetesç›‘æ§æ¶æ„**ï¼š
- 6å±‚ç›‘æ§ä½“ç³»ï¼ˆåº”ç”¨â†’å®¹å™¨â†’Podâ†’K8sèµ„æºâ†’èŠ‚ç‚¹â†’æ§åˆ¶å¹³é¢ï¼‰
- Metrics Serveræä¾›åŸºç¡€èµ„æºæŒ‡æ ‡
- Prometheusç”Ÿæ€æä¾›å®Œæ•´ç›‘æ§æ–¹æ¡ˆ

âœ… **Metrics APIå®æˆ˜**ï¼š
- éƒ¨ç½²Metrics Server
- ä½¿ç”¨kubectl topæŸ¥çœ‹èµ„æº
- é…ç½®HPAè‡ªåŠ¨æ‰©ç¼©å®¹
- ç¼–ç¨‹è®¿é—®Metrics API

âœ… **ç›‘æ§æ•°æ®é‡‡é›†**ï¼š
- kubeletçš„cAdvisoræš´éœ²å®¹å™¨æŒ‡æ ‡
- Prometheusæ‹‰æ¨¡å¼é‡‡é›†æ•°æ®
- Fluentdæ”¶é›†å’Œè½¬å‘æ—¥å¿—

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ Prometheusçš„æ ¸å¿ƒåŸç†ï¼ŒåŒ…æ‹¬æ•°æ®æ¨¡å‹ã€PromQLæŸ¥è¯¢è¯­è¨€ã€æœåŠ¡å‘ç°æœºåˆ¶ï¼Œä»¥åŠå¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²é«˜å¯ç”¨çš„Prometheusé›†ç¾¤ã€‚

---

## 9.2 Prometheusæ ¸å¿ƒåŸç†ä¸å®æˆ˜

åœ¨9.1èŠ‚ä¸­ï¼Œæˆ‘ä»¬äº†è§£äº†Kubernetesç›‘æ§çš„æ•´ä½“æ¶æ„ï¼Œä»¥åŠMetrics APIçš„åŸºç¡€ç”¨æ³•ã€‚ä½†Metrics Serverçš„åŠŸèƒ½éå¸¸æœ‰é™ï¼ˆä»…CPU/å†…å­˜ï¼Œä»…ä¿ç•™15åˆ†é’Ÿï¼‰ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ã€å¯æ‰©å±•çš„ç›‘æ§è§£å†³æ–¹æ¡ˆï¼Œè¿™å°±æ˜¯**Prometheus**ã€‚

Prometheusæ˜¯ç”±SoundCloudå¼€å‘å¹¶äº2016å¹´åŠ å…¥CNCFçš„å¼€æºç›‘æ§ç³»ç»Ÿï¼Œç›®å‰å·²æˆä¸ºäº‘åŸç”Ÿç›‘æ§çš„äº‹å®æ ‡å‡†ã€‚å®ƒè¢«Netflixã€Uberã€DigitalOceanã€GitLabç­‰æ•°åƒå®¶å…¬å¸åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚

**ä¸ºä»€ä¹ˆé€‰æ‹©Prometheusï¼Ÿ**

| ç‰¹æ€§ | Prometheus | ä¼ ç»Ÿç›‘æ§(Zabbix/Nagios) |
|------|-----------|----------------------|
| **æ•°æ®æ¨¡å‹** | å¤šç»´æ—¶åºæ•°æ®(æ ‡ç­¾) | å•ç»´æ•°æ®(ä¸»æœº+æŒ‡æ ‡) |
| **æŸ¥è¯¢è¯­è¨€** | PromQL(çµæ´»å¼ºå¤§) | å›ºå®šæ¨¡æ¿ |
| **æœåŠ¡å‘ç°** | åŸç”Ÿæ”¯æŒK8s | éœ€æ‰‹åŠ¨é…ç½® |
| **å­˜å‚¨** | æœ¬åœ°æ—¶åºæ•°æ®åº“ | å…³ç³»å‹æ•°æ®åº“ |
| **å‘Šè­¦** | å†…ç½®AlertManager | ä¾èµ–å¤–éƒ¨æ’ä»¶ |
| **ç”Ÿæ€** | Grafana/Exportersä¸°å¯Œ | ç”Ÿæ€è¾ƒå° |

### 9.2.1 Prometheusæ¶æ„ä¸æ•°æ®æ¨¡å‹

#### Prometheusæ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Prometheusç”Ÿæ€ç³»ç»Ÿ                          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚               Prometheus Server                        â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  Retrieval (æ•°æ®æŠ“å–)                         â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - Service Discovery (æœåŠ¡å‘ç°)               â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - HTTP Pull (æ‹‰å–/metricsç«¯ç‚¹)               â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - Scrapeé—´éš”: 15s-60s                       â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                 â”‚                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  TSDB (æ—¶åºæ•°æ®åº“)                            â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - æœ¬åœ°å­˜å‚¨ (é»˜è®¤15å¤©)                        â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - å‹ç¼©ç®—æ³• (æ¯æ ·æœ¬1-2å­—èŠ‚)                   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - å—å­˜å‚¨ (2å°æ—¶ä¸€ä¸ªå—)                       â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                 â”‚                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  PromQL Engine (æŸ¥è¯¢å¼•æ“)                     â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - å³æ—¶æŸ¥è¯¢ (instant query)                   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - èŒƒå›´æŸ¥è¯¢ (range query)                     â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                 â”‚                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  HTTP Server (APIæœåŠ¡å™¨)                      â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - /api/v1/query (å³æ—¶æŸ¥è¯¢)                   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - /api/v1/query_range (èŒƒå›´æŸ¥è¯¢)             â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  - /api/v1/series (æ—¶é—´åºåˆ—å…ƒæ•°æ®)            â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                    â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚                 â”‚                            â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  â”‚  Grafana            â”‚  â”‚  AlertManager         â”‚        â”‚
â”‚  â”‚  â”‚  (å¯è§†åŒ–)            â”‚  â”‚  (å‘Šè­¦ç®¡ç†)            â”‚        â”‚
â”‚  â”‚  â”‚  - Dashboard        â”‚  â”‚  - å‘Šè­¦è·¯ç”±            â”‚        â”‚
â”‚  â”‚  â”‚  - å›¾è¡¨/é¢æ¿         â”‚  â”‚  - åˆ†ç»„/æŠ‘åˆ¶/é™é»˜      â”‚        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â”‚                                        â”‚                    â”‚
â”‚  â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         â”‚  é€šçŸ¥æ¸ é“                    â”‚     â”‚
â”‚  â”‚                         â”‚  - Email / Slack / é’‰é’‰     â”‚     â”‚
â”‚  â”‚                         â”‚  - PagerDuty / Webhook     â”‚     â”‚
â”‚  â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚               ç›‘æ§ç›®æ ‡ (Targets)                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ Exporters  â”‚  â”‚ K8sèµ„æº    â”‚  â”‚ åº”ç”¨ç¨‹åº          â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - Node     â”‚  â”‚ - kubelet  â”‚  â”‚ - /metricsç«¯ç‚¹   â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - MySQL    â”‚  â”‚ - kube-    â”‚  â”‚ - Prometheus SDK â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - Redis    â”‚  â”‚   state-   â”‚  â”‚                  â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ - Nginx    â”‚  â”‚   metrics  â”‚  â”‚                  â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒç»„ä»¶è¯´æ˜**ï¼š

1. **Prometheus Server**: æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£æŠ“å–ã€å­˜å‚¨å’ŒæŸ¥è¯¢æŒ‡æ ‡
2. **Exporters**: ç¬¬ä¸‰æ–¹æœåŠ¡çš„æŒ‡æ ‡æš´éœ²å™¨ï¼ˆå¦‚MySQL Exporterï¼‰
3. **Pushgateway**: æ”¯æŒçŸ­ç”Ÿå‘½å‘¨æœŸä»»åŠ¡çš„æ¨é€ï¼ˆéK8såœºæ™¯ï¼‰
4. **AlertManager**: å‘Šè­¦ç®¡ç†å’Œé€šçŸ¥
5. **Grafana**: å¯è§†åŒ–å¹³å°

#### Prometheusæ•°æ®æ¨¡å‹

Prometheusçš„æ•°æ®æ¨¡å‹æ˜¯å…¶å¼ºå¤§çš„æ ¸å¿ƒã€‚å®ƒé‡‡ç”¨**å¤šç»´æ—¶åºæ•°æ®**æ¨¡å‹ï¼Œæ¯ä¸ªæŒ‡æ ‡ç”±**æŒ‡æ ‡å**å’Œ**æ ‡ç­¾é›†**å”¯ä¸€æ ‡è¯†ã€‚

**1. æŒ‡æ ‡æ ¼å¼**

```
<metric_name>{<label_name>=<label_value>, ...} <sample_value> [<timestamp>]
```

ç¤ºä¾‹ï¼š

```
# HTTPè¯·æ±‚æ€»æ•°
http_requests_total{method="GET", endpoint="/api/users", status="200"} 15840 1705752000000

# ç»„ä»¶æ‹†è§£:
# - metric_name: http_requests_total (æŒ‡æ ‡å)
# - labels: method="GET", endpoint="/api/users", status="200" (æ ‡ç­¾)
# - value: 15840 (æ ·æœ¬å€¼)
# - timestamp: 1705752000000 (æ—¶é—´æˆ³,æ¯«ç§’,å¯é€‰)
```

**2. æŒ‡æ ‡ç±»å‹**

Prometheuså®šä¹‰äº†4ç§æŒ‡æ ‡ç±»å‹ï¼š

##### (1) Counter (è®¡æ•°å™¨)

**ç‰¹ç‚¹**ï¼š
- å•è°ƒé€’å¢ï¼ˆåªèƒ½å¢åŠ ï¼Œä¸èƒ½å‡å°‘ï¼‰
- é‡å¯åå½’é›¶
- å¸¸ç”¨äºç´¯è®¡å‹æŒ‡æ ‡

**å…¸å‹åœºæ™¯**ï¼š
```
# HTTPè¯·æ±‚æ€»æ•°
http_requests_total{method="GET", endpoint="/api/users", status="200"} 15840

# é”™è¯¯æ€»æ•°
http_errors_total{type="timeout"} 127

# æ•°æ®åº“æŸ¥è¯¢æ€»æ•°
db_queries_total{database="users", operation="select"} 892340
```

**PromQLæŸ¥è¯¢**ï¼š
```promql
# æŸ¥è¯¢Counteré€šå¸¸ä½¿ç”¨rate()æˆ–irate()è®¡ç®—é€Ÿç‡

# æ¯ç§’è¯·æ±‚æ•° (QPS)
rate(http_requests_total[5m])

# æ¯ç§’é”™è¯¯ç‡
rate(http_errors_total[5m])

# 5åˆ†é’Ÿå†…çš„è¯·æ±‚å¢é‡
increase(http_requests_total[5m])
```

##### (2) Gauge (ä»ªè¡¨ç›˜)

**ç‰¹ç‚¹**ï¼š
- å¯å¢å¯å‡
- è¡¨ç¤ºå½“å‰çŠ¶æ€
- å¯ç›´æ¥ä½¿ç”¨

**å…¸å‹åœºæ™¯**ï¼š
```
# å½“å‰å†…å­˜ä½¿ç”¨é‡ (å­—èŠ‚)
node_memory_usage_bytes 3670016000

# å½“å‰è¿æ¥æ•°
mysql_connections_active 42

# CPUæ¸©åº¦
node_cpu_temperature_celsius{cpu="0"} 56.7

# é˜Ÿåˆ—é•¿åº¦
queue_length{queue="orders"} 1523
```

**PromQLæŸ¥è¯¢**ï¼š
```promql
# Gaugeå¯ä»¥ç›´æ¥ä½¿ç”¨,ä¹Ÿå¯ä»¥ç”¨èšåˆå‡½æ•°

# å½“å‰å†…å­˜ä½¿ç”¨ç‡
node_memory_usage_bytes / node_memory_total_bytes * 100

# æœ€å¤§è¿æ¥æ•°
max_over_time(mysql_connections_active[1h])

# å¹³å‡é˜Ÿåˆ—é•¿åº¦
avg_over_time(queue_length[5m])
```

##### (3) Histogram (ç›´æ–¹å›¾)

**ç‰¹ç‚¹**ï¼š
- ç»Ÿè®¡æ•°æ®åˆ†å¸ƒ
- è‡ªåŠ¨è®¡ç®—å¤šä¸ªåˆ†ä½æ•°æ¡¶
- é€‚åˆå»¶è¿Ÿ/å¤§å°ç­‰æŒ‡æ ‡

**æ•°æ®ç»“æ„**ï¼š
```
# å‡è®¾APIå»¶è¿Ÿçš„HistogramæŒ‡æ ‡
http_request_duration_seconds_bucket{le="0.01"} 8500     # â‰¤10msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="0.05"} 14200   # â‰¤50msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="0.1"} 15600    # â‰¤100msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="0.5"} 15820    # â‰¤500msçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="1"} 15838      # â‰¤1sçš„è¯·æ±‚æ•°
http_request_duration_seconds_bucket{le="+Inf"} 15840   # æ‰€æœ‰è¯·æ±‚æ•°
http_request_duration_seconds_sum 458.92                # æ€»è€—æ—¶
http_request_duration_seconds_count 15840               # è¯·æ±‚æ€»æ•°
```

**PromQLæŸ¥è¯¢**ï¼š
```promql
# P99å»¶è¿Ÿ (99%çš„è¯·æ±‚å»¶è¿Ÿä½äºæ­¤å€¼)
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

# P95å»¶è¿Ÿ
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# å¹³å‡å»¶è¿Ÿ
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])

# è¶…è¿‡500msçš„è¯·æ±‚å æ¯”
(http_request_duration_seconds_bucket{le="+Inf"} - http_request_duration_seconds_bucket{le="0.5"}) 
/ http_request_duration_seconds_bucket{le="+Inf"}
```

##### (4) Summary (æ‘˜è¦)

**ç‰¹ç‚¹**ï¼š
- ç±»ä¼¼Histogramï¼Œä½†åœ¨å®¢æˆ·ç«¯è®¡ç®—åˆ†ä½æ•°
- ä¸éœ€è¦é¢„å®šä¹‰æ¡¶
- è®¡ç®—æˆæœ¬é«˜

**æ•°æ®ç»“æ„**ï¼š
```
# Goåº”ç”¨çš„GCå»¶è¿ŸSummary
go_gc_duration_seconds{quantile="0.5"} 0.000123   # P50 (ä¸­ä½æ•°)
go_gc_duration_seconds{quantile="0.9"} 0.000456   # P90
go_gc_duration_seconds{quantile="0.99"} 0.001234  # P99
go_gc_duration_seconds_sum 12.456                 # æ€»è€—æ—¶
go_gc_duration_seconds_count 8234                 # GCæ€»æ¬¡æ•°
```

**Histogram vs Summaryå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | Histogram | Summary |
|------|----------|---------|
| **åˆ†ä½æ•°è®¡ç®—** | æœåŠ¡ç«¯(PromQL) | å®¢æˆ·ç«¯(åº”ç”¨) |
| **èšåˆèƒ½åŠ›** | å¯è·¨å®ä¾‹èšåˆ | ä¸å¯èšåˆ |
| **æ€§èƒ½å¼€é”€** | ä½(å®¢æˆ·ç«¯) | é«˜(å®¢æˆ·ç«¯) |
| **çµæ´»æ€§** | é«˜(å¯æŸ¥ä»»æ„åˆ†ä½æ•°) | ä½(å›ºå®šåˆ†ä½æ•°) |
| **æ¨èåœºæ™¯** | å¤§éƒ¨åˆ†åœºæ™¯ | å·²çŸ¥åˆ†ä½æ•°éœ€æ±‚ |

**æ¨èï¼šä¼˜å…ˆä½¿ç”¨Histogramï¼Œå®ƒæ›´çµæ´»ä¸”æ”¯æŒèšåˆ**

**3. æ ‡ç­¾ (Labels) çš„æœ€ä½³å®è·µ**

**è‰¯å¥½çš„æ ‡ç­¾è®¾è®¡**ï¼š

```promql
# âœ… å¥½çš„æ ‡ç­¾è®¾è®¡ (åŸºæ•°å¯æ§)
http_requests_total{
  method="GET",           # åŸºæ•°: ~10 (GET/POST/PUT/DELETE...)
  endpoint="/api/users",  # åŸºæ•°: ~100 (APIç«¯ç‚¹æ•°é‡)
  status="200",           # åŸºæ•°: ~20 (HTTPçŠ¶æ€ç )
  service="order",        # åŸºæ•°: ~50 (å¾®æœåŠ¡æ•°é‡)
  environment="prod"      # åŸºæ•°: 3 (dev/staging/prod)
}
# æ€»åŸºæ•°: 10 * 100 * 20 * 50 * 3 = 3,000,000 (å¯æ¥å—)
```

**é”™è¯¯çš„æ ‡ç­¾è®¾è®¡**ï¼š

```promql
# âŒ é”™è¯¯çš„æ ‡ç­¾è®¾è®¡ (åŸºæ•°çˆ†ç‚¸)
http_requests_total{
  user_id="12345",        # åŸºæ•°: ç™¾ä¸‡çº§ (ç”¨æˆ·æ•°é‡)
  request_id="uuid-...",  # åŸºæ•°: æ— é™ (æ¯æ¬¡è¯·æ±‚å”¯ä¸€)
  timestamp="1705752000"  # åŸºæ•°: æ— é™ (æ¯ç§’ä¸€ä¸ª)
}
# å¯¼è‡´: æ•°ç™¾ä¸‡ä¸ªæ—¶é—´åºåˆ—,å†…å­˜çˆ†ç‚¸,æŸ¥è¯¢ææ…¢
```

**æ ‡ç­¾è®¾è®¡åŸåˆ™**ï¼š

1. **ä½åŸºæ•°**: æ¯ä¸ªæ ‡ç­¾çš„å”¯ä¸€å€¼åº”æ§åˆ¶åœ¨æ•°ç™¾ä»¥å†…
2. **æœ‰æ„ä¹‰**: æ ‡ç­¾åº”è¯¥æ˜¯èšåˆ/è¿‡æ»¤çš„ç»´åº¦ï¼ˆå¦‚serviceã€ç¯å¢ƒï¼‰
3. **é¿å…é«˜åŸºæ•°**: ä¸è¦ç”¨user_idã€IPåœ°å€ã€UUIDä½œä¸ºæ ‡ç­¾
4. **ä¸€è‡´æ€§**: åŒä¸€æŒ‡æ ‡çš„æ ‡ç­¾ååº”ä¿æŒä¸€è‡´

**4. æŒ‡æ ‡å‘½åè§„èŒƒ**

Prometheuså®˜æ–¹æ¨èçš„å‘½åè§„èŒƒï¼š

```
<namespace>_<subsystem>_<name>_<unit>

ç¤ºä¾‹:
- node_cpu_seconds_total          # namespace=node, subsystem=cpu, name=seconds, unit=total
- http_request_duration_seconds   # namespace=http, subsystem=request, name=duration, unit=seconds
- mysql_slave_lag_seconds         # namespace=mysql, subsystem=slave, name=lag, unit=seconds
```

**å‘½åè§„åˆ™**ï¼š

1. **ä½¿ç”¨ä¸‹åˆ’çº¿**: ä¸è¦ç”¨é©¼å³°æˆ–è¿å­—ç¬¦
2. **åŒ…å«å•ä½**: ä½¿ç”¨åŸºç¡€å•ä½ï¼ˆseconds, bytes, ratioï¼‰
3. **CounteråŠ _total**: æ‰€æœ‰CounteræŒ‡æ ‡åº”ä»¥_totalç»“å°¾
4. **é¿å…é‡å¤**: ä¸è¦åœ¨æŒ‡æ ‡åä¸­é‡å¤æ ‡ç­¾ä¿¡æ¯

```promql
# âœ… è‰¯å¥½å‘½å
http_requests_total{method="GET"}
node_memory_bytes{type="free"}

# âŒ é”™è¯¯å‘½å
httpRequestsGET              # é©¼å³° + æ ‡ç­¾ä¿¡æ¯åœ¨åç§°ä¸­
node_memory_mb               # éåŸºç¡€å•ä½
requests                     # Counterç¼ºå°‘_total
```

#### æ•°æ®å­˜å‚¨æœºåˆ¶

**1. æ—¶åºæ•°æ®åº“ (TSDB) åŸç†**

Prometheusä½¿ç”¨è‡ªç ”çš„æ—¶åºæ•°æ®åº“ï¼Œé‡‡ç”¨**å—å­˜å‚¨**å’Œ**é«˜æ•ˆå‹ç¼©**ï¼š

```
æ•°æ®ç›®å½•ç»“æ„:
/data/prometheus/
â”œâ”€â”€ 01HQXXX/                    # å—ID (2å°æ—¶ä¸€ä¸ªå—)
â”‚   â”œâ”€â”€ chunks/                 # å‹ç¼©çš„æ—¶åºæ•°æ®
â”‚   â”‚   â””â”€â”€ 000001
â”‚   â”œâ”€â”€ index                   # å€’æ’ç´¢å¼• (æ ‡ç­¾â†’åºåˆ—ID)
â”‚   â”œâ”€â”€ meta.json               # å—å…ƒæ•°æ®
â”‚   â””â”€â”€ tombstones              # åˆ é™¤æ ‡è®°
â”œâ”€â”€ 01HQYYY/
â”œâ”€â”€ wal/                        # WAL (Write-Ahead Log)
â”‚   â”œâ”€â”€ 00000000
â”‚   â””â”€â”€ checkpoint.00000001
â””â”€â”€ queries.active              # æ´»è·ƒæŸ¥è¯¢
```

**å­˜å‚¨æµç¨‹**ï¼š

```
1. æ•°æ®å†™å…¥WAL (é¢„å†™æ—¥å¿—)
   â†’ é˜²æ­¢è¿›ç¨‹å´©æºƒä¸¢å¤±æ•°æ®

2. å†…å­˜ä¸­æ„å»ºå— (2å°æ—¶)
   â†’ é«˜æ€§èƒ½æŸ¥è¯¢æœ€è¿‘æ•°æ®

3. å—è½ç›˜ (æ¯2å°æ—¶)
   â†’ æŒä¹…åŒ–åˆ°ç£ç›˜

4. å‹ç¼©åˆå¹¶ (åå°)
   â†’ åˆå¹¶å¤šä¸ªå°å—ä¸ºå¤§å—
   â†’ å‹ç¼©æ¯”å¯è¾¾10:1

5. åˆ é™¤è¿‡æœŸæ•°æ®
   â†’ è¶…è¿‡ä¿ç•™æœŸé™è‡ªåŠ¨åˆ é™¤
```

**2. å‹ç¼©ç®—æ³•**

Prometheusä½¿ç”¨**Delta-of-Delta + XORç¼–ç **ï¼š

```
åŸå§‹æ•°æ® (æ—¶é—´æˆ³ + å€¼):
1705752000  100.5
1705752060  102.3
1705752120  101.8
1705752180  103.1

å‹ç¼©åå­˜å‚¨:
- ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³: 1705752000 (å®Œæ•´å­˜å‚¨)
- åç»­æ—¶é—´æˆ³: å­˜å‚¨å·®å€¼çš„å·®å€¼
  60, 0, 0, ... (å¤§éƒ¨åˆ†æ˜¯0,é«˜åº¦å‹ç¼©)
  
- ç¬¬ä¸€ä¸ªå€¼: 100.5 (å®Œæ•´å­˜å‚¨)
- åç»­å€¼: XORç¼–ç 
  1.8 XOR 100.5 = xxx (å­˜å‚¨XORç»“æœçš„å‰å¯¼é›¶å‹ç¼©)

å‹ç¼©æ¯”: å¹³å‡1.37å­—èŠ‚/æ ·æœ¬ (åŸå§‹éœ€è¦16å­—èŠ‚)
```

**3. æ•°æ®ä¿ç•™ç­–ç•¥**

```yaml
# Prometheusé…ç½®
global:
  scrape_interval: 15s

# å­˜å‚¨é…ç½®
storage:
  tsdb:
    path: /prometheus/data
    retention.time: 15d      # ä¿ç•™15å¤© (é»˜è®¤)
    retention.size: 50GB     # æˆ–è€…æŒ‰å¤§å°é™åˆ¶
```

**å­˜å‚¨å®¹é‡ä¼°ç®—**ï¼š

```
å…¬å¼:
needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample

ç¤ºä¾‹è®¡ç®—:
- ä¿ç•™æ—¶é—´: 15å¤© = 1,296,000ç§’
- æ¯ç§’é‡‡æ ·: 10,000ä¸ªæŒ‡æ ‡ * 1ä¸ªå€¼ = 10,000 samples/s
- æ¯æ ·æœ¬å¤§å°: 1.5å­—èŠ‚ (å‹ç¼©å)

å­˜å‚¨éœ€æ±‚ = 1,296,000 * 10,000 * 1.5 / 1024 / 1024 / 1024
         â‰ˆ 18 GB

å»ºè®®é¢„ç•™50%ç©ºé—´: 18 * 1.5 = 27 GB
```

**ç›‘æ§Prometheusè‡ªèº«çš„å­˜å‚¨**ï¼š

```promql
# ç£ç›˜ä½¿ç”¨é‡
prometheus_tsdb_storage_blocks_bytes

# å†…å­˜ä¸­åºåˆ—æ•°
prometheus_tsdb_head_series

# æ¯ç§’é‡‡æ ·é€Ÿç‡
rate(prometheus_tsdb_head_samples_appended_total[5m])

# å‹ç¼©è€—æ—¶
prometheus_tsdb_compaction_duration_seconds
```

---

### 9.2.2 æœåŠ¡å‘ç°ä¸ç›®æ ‡æŠ“å–

#### KubernetesæœåŠ¡å‘ç°æœºåˆ¶

PrometheusåŸç”Ÿæ”¯æŒKubernetesæœåŠ¡å‘ç°ï¼Œå¯ä»¥è‡ªåŠ¨å‘ç°é›†ç¾¤ä¸­çš„ç›‘æ§ç›®æ ‡ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

**æ”¯æŒçš„å‘ç°ç±»å‹**ï¼š

| å‘ç°ç±»å‹ | ç”¨é€” | å…¸å‹ç›®æ ‡ |
|---------|------|---------|
| **node** | å‘ç°æ‰€æœ‰èŠ‚ç‚¹ | Node Exporter, kubelet |
| **pod** | å‘ç°æ‰€æœ‰Pod | åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡ |
| **service** | å‘ç°æ‰€æœ‰Service | kube-state-metrics |
| **endpoints** | å‘ç°Serviceçš„Endpoint | è´Ÿè½½å‡è¡¡åçš„Pod |
| **ingress** | å‘ç°æ‰€æœ‰Ingress | Ingress Controller |

**å®Œæ•´çš„æœåŠ¡å‘ç°é…ç½®ç¤ºä¾‹**ï¼š

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: 'k8s-prod'
        region: 'us-west-2'

    # ============= 1. æŠ“å–èŠ‚ç‚¹æŒ‡æ ‡ (Node Exporter) =============
    scrape_configs:
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      
      # Relabelé…ç½® (é‡å†™æ ‡ç­¾)
      relabel_configs:
      # ä¿ç•™æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾ä¸º__meta_kubernetes_node_label_*
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      
      # å°†èŠ‚ç‚¹åè®¾ç½®ä¸ºinstanceæ ‡ç­¾
      - source_labels: [__meta_kubernetes_node_name]
        target_label: instance
      
      # è®¾ç½®æŠ“å–è·¯å¾„ä¸ºNode Exporterçš„ç«¯å£
      - source_labels: [__address__]
        regex: '([^:]+):.*'      # æå–IPéƒ¨åˆ†
        replacement: '${1}:9100'  # æ·»åŠ Node Exporterç«¯å£
        target_label: __address__

    # ============= 2. æŠ“å–kubelet (å®¹å™¨æŒ‡æ ‡) =============
    - job_name: 'kubernetes-kubelet'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
      kubernetes_sd_configs:
      - role: node
      
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

    # ============= 3. æŠ“å–cAdvisor (å®¹å™¨èµ„æº) =============
    - job_name: 'kubernetes-cadvisor'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
      kubernetes_sd_configs:
      - role: node
      
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

    # ============= 4. æŠ“å–kube-state-metrics (K8sèµ„æºçŠ¶æ€) =============
    - job_name: 'kube-state-metrics'
      kubernetes_sd_configs:
      - role: service
      
      relabel_configs:
      # åªæŠ“å–kube-state-metricsæœåŠ¡
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
        action: keep
        regex: kube-state-metrics
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_service_name]
        target_label: service

    # ============= 5. æŠ“å–Pod (åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡) =============
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      
      relabel_configs:
      # åªæŠ“å–å¸¦æœ‰prometheus.io/scrape=trueæ³¨è§£çš„Pod
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      
      # è‡ªå®šä¹‰æŠ“å–ç«¯å£ (é»˜è®¤ä½¿ç”¨Podçš„ç¬¬ä¸€ä¸ªç«¯å£)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
        action: replace
        regex: ([^;]+);(.+)
        replacement: ${2}:${1}
        target_label: __address__
      
      # è‡ªå®šä¹‰æŠ“å–è·¯å¾„ (é»˜è®¤/metrics)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      
      # æ·»åŠ å‘½åç©ºé—´æ ‡ç­¾
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      
      # æ·»åŠ Podåç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      
      # æ·»åŠ å®¹å™¨åç§°æ ‡ç­¾
      - source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container
      
      # ä¿ç•™Podçš„æ‰€æœ‰æ ‡ç­¾
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)

    # ============= 6. æŠ“å–Service (é€šè¿‡Serviceå‘ç°) =============
    - job_name: 'kubernetes-services'
      kubernetes_sd_configs:
      - role: service
      
      metrics_path: /probe
      params:
        module: [http_2xx]  # é»‘ç›’ç›‘æ§æ¨¡å—
      
      relabel_configs:
      # åªæŠ“å–å¸¦æœ‰prometheus.io/probe=trueæ³¨è§£çš„Service
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
        action: keep
        regex: true
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: __address__
        replacement: blackbox-exporter:9115
      - source_labels: [__param_target]
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
```

**Relabelé…ç½®è¯¦è§£**ï¼š

Relabelæ˜¯Prometheusæœ€å¼ºå¤§ä¹Ÿæœ€å¤æ‚çš„åŠŸèƒ½ä¹‹ä¸€ï¼Œå®ƒå¯ä»¥åœ¨æŠ“å–å‰é‡å†™æ ‡ç­¾ã€‚

**å¸¸ç”¨çš„Relabelæ“ä½œ**ï¼š

1. **keep**: åªä¿ç•™åŒ¹é…çš„ç›®æ ‡

```yaml
- source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
  action: keep
  regex: true
# å«ä¹‰: åªæŠ“å–annotationsä¸­prometheus.io/scrape=trueçš„Pod
```

2. **drop**: ä¸¢å¼ƒåŒ¹é…çš„ç›®æ ‡

```yaml
- source_labels: [__meta_kubernetes_namespace]
  action: drop
  regex: (kube-system|kube-public)
# å«ä¹‰: ä¸æŠ“å–kube-systemå’Œkube-publicå‘½åç©ºé—´çš„Pod
```

3. **replace**: æ›¿æ¢æ ‡ç­¾å€¼

```yaml
- source_labels: [__meta_kubernetes_pod_name]
  target_label: pod
  action: replace
# å«ä¹‰: å°†__meta_kubernetes_pod_nameçš„å€¼å¤åˆ¶åˆ°podæ ‡ç­¾
```

4. **labelmap**: æ‰¹é‡æ˜ å°„æ ‡ç­¾

```yaml
- action: labelmap
  regex: __meta_kubernetes_pod_label_(.+)
# å«ä¹‰: å°†Podçš„æ‰€æœ‰æ ‡ç­¾ (å¦‚app=nginx) æ˜ å°„ä¸ºPrometheusæ ‡ç­¾
```

5. **labeldrop**: åˆ é™¤æ ‡ç­¾

```yaml
- action: labeldrop
  regex: __meta_kubernetes_pod_.*
# å«ä¹‰: åˆ é™¤æ‰€æœ‰ä»¥__meta_kubernetes_pod_å¼€å¤´çš„ä¸´æ—¶æ ‡ç­¾
```

**åº”ç”¨å¦‚ä½•é…ç½®è¢«PrometheusæŠ“å–**ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  namespace: production
  annotations:
    prometheus.io/scrape: "true"    # å¯ç”¨æŠ“å–
    prometheus.io/port: "8080"      # æŒ‡æ ‡ç«¯å£
    prometheus.io/path: "/metrics"  # æŒ‡æ ‡è·¯å¾„ (å¯é€‰,é»˜è®¤/metrics)
  labels:
    app: my-app
    version: v1.0.0
    team: backend
spec:
  containers:
  - name: app
    image: my-app:v1.0.0
    ports:
    - containerPort: 8080
      name: metrics
```

Prometheusä¼šè‡ªåŠ¨å‘ç°è¿™ä¸ªPodå¹¶æŠ“å– `http://POD_IP:8080/metrics`ã€‚

#### ç›®æ ‡æŠ“å–æœºåˆ¶

**1. æŠ“å–æµç¨‹**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Prometheus Scrape Lifecycle                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. æœåŠ¡å‘ç° (Service Discovery)
   â†“
   å‘ç°ç›®æ ‡: Pod IP, ç«¯å£, æ ‡ç­¾ç­‰å…ƒæ•°æ®
   
2. Relabel (é‡å†™æ ‡ç­¾)
   â†“
   åº”ç”¨relabel_configsè§„åˆ™
   - keep/dropè¿‡æ»¤ç›®æ ‡
   - ä¿®æ”¹__address__, __metrics_path__ç­‰
   
3. HTTP GETè¯·æ±‚
   â†“
   GET http://<target>:<port>/<path>
   Headers: 
     - User-Agent: Prometheus/2.x
     - Accept: application/openmetrics-text
   
4. è§£æå“åº”
   â†“
   è§£æPrometheusæ–‡æœ¬æ ¼å¼:
   # HELP http_requests_total Total requests
   # TYPE http_requests_total counter
   http_requests_total{method="GET"} 123
   
5. å­˜å‚¨åˆ°TSDB
   â†“
   å†™å…¥æ—¶åºæ•°æ®åº“
   
6. ç­‰å¾…ä¸‹ä¸€ä¸ªscrape_interval
   â†“
   é»˜è®¤15ç§’åé‡å¤
```

**2. æŠ“å–é…ç½®å‚æ•°**

```yaml
scrape_configs:
- job_name: 'my-app'
  scrape_interval: 30s       # æŠ“å–é—´éš” (è¦†ç›–global)
  scrape_timeout: 10s        # è¶…æ—¶æ—¶é—´ (å¿…é¡» < scrape_interval)
  metrics_path: '/metrics'   # æŠ“å–è·¯å¾„
  scheme: http               # åè®® (http/https)
  
  # åŸºæœ¬è®¤è¯
  basic_auth:
    username: admin
    password: secret
  
  # Bearer Tokenè®¤è¯
  bearer_token_file: /var/run/secrets/token
  
  # TLSé…ç½®
  tls_config:
    ca_file: /etc/prometheus/ca.crt
    cert_file: /etc/prometheus/client.crt
    key_file: /etc/prometheus/client.key
    insecure_skip_verify: false
  
  # é™æ€ç›®æ ‡
  static_configs:
  - targets:
    - 'localhost:9090'
    - '192.168.1.10:9100'
    labels:
      environment: production
      region: us-west-2
```

**3. æŠ“å–çŠ¶æ€ç›‘æ§**

Prometheusæä¾›äº†ä¸°å¯Œçš„æŒ‡æ ‡æ¥ç›‘æ§è‡ªèº«çš„æŠ“å–çŠ¶æ€ï¼š

```promql
# å½“å‰æŠ“å–ç›®æ ‡æ•°é‡
count(up)

# æŠ“å–å¤±è´¥çš„ç›®æ ‡
count(up == 0)

# æŠ“å–å¤±è´¥ç‡
(count(up == 0) / count(up)) * 100

# æŠ“å–è€—æ—¶ (P99)
histogram_quantile(0.99, rate(prometheus_target_scrape_duration_seconds_bucket[5m]))

# æ¯ç§’æŠ“å–çš„æ ·æœ¬æ•°
rate(prometheus_target_scrapes_sample_scraped_total[5m])

# æŠ“å–è¶…æ—¶æ¬¡æ•°
rate(prometheus_target_scrapes_exceeded_sample_limit_total[5m])
```

**æŸ¥çœ‹æŠ“å–ç›®æ ‡çŠ¶æ€**ï¼š

è®¿é—®Prometheus Web UI: `http://<prometheus>:9090/targets`

å¯ä»¥çœ‹åˆ°ï¼š
- æ‰€æœ‰ç›®æ ‡çš„å¥åº·çŠ¶æ€ (UP/DOWN)
- æœ€åæŠ“å–æ—¶é—´
- æŠ“å–è€—æ—¶
- é”™è¯¯ä¿¡æ¯

---

### 9.2.3 PromQLæŸ¥è¯¢è¯­è¨€è¯¦è§£

PromQL (Prometheus Query Language) æ˜¯Prometheusçš„æŸ¥è¯¢è¯­è¨€ï¼Œå®ƒåŠŸèƒ½å¼ºå¤§ä½†å­¦ä¹ æ›²çº¿è¾ƒé™¡ã€‚æŒæ¡PromQLæ˜¯ä½¿ç”¨Prometheusçš„å…³é”®ã€‚

#### PromQLåŸºç¡€è¯­æ³•

**1. å³æ—¶å‘é‡é€‰æ‹©å™¨ (Instant Vector Selector)**

é€‰æ‹©æŸä¸ªæ—¶é—´ç‚¹çš„æ‰€æœ‰æ—¶é—´åºåˆ—ï¼š

```promql
# æœ€ç®€å•çš„æŸ¥è¯¢: é€‰æ‹©æ‰€æœ‰http_requests_totalåºåˆ—
http_requests_total

# å¸¦æ ‡ç­¾è¿‡æ»¤: ç²¾ç¡®åŒ¹é…
http_requests_total{method="GET", status="200"}

# æ ‡ç­¾åŒ¹é…æ“ä½œç¬¦:
=   # ç²¾ç¡®ç›¸ç­‰
!=  # ä¸ç›¸ç­‰
=~  # æ­£åˆ™åŒ¹é…
!~  # æ­£åˆ™ä¸åŒ¹é…

# ç¤ºä¾‹:
http_requests_total{status=~"2..", method!="POST"}
# å«ä¹‰: statusæ˜¯2xx, ä¸”methodä¸æ˜¯POST
```

**2. èŒƒå›´å‘é‡é€‰æ‹©å™¨ (Range Vector Selector)**

é€‰æ‹©ä¸€æ®µæ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰æ ·æœ¬ï¼š

```promql
# é€‰æ‹©æœ€è¿‘5åˆ†é’Ÿçš„æ‰€æœ‰æ ·æœ¬
http_requests_total[5m]

# æ—¶é—´å•ä½:
s  # ç§’
m  # åˆ†é’Ÿ
h  # å°æ—¶
d  # å¤©
w  # å‘¨
y  # å¹´

# ç¤ºä¾‹:
http_requests_total{method="GET"}[1h]  # æœ€è¿‘1å°æ—¶
node_cpu_seconds_total[30s]            # æœ€è¿‘30ç§’
```

**3. åç§»ä¿®é¥°ç¬¦ (Offset Modifier)**

æŸ¥è¯¢è¿‡å»æŸä¸ªæ—¶é—´ç‚¹çš„æ•°æ®ï¼š

```promql
# æŸ¥è¯¢5åˆ†é’Ÿå‰çš„å³æ—¶å€¼
http_requests_total offset 5m

# æŸ¥è¯¢1å°æ—¶å‰çš„5åˆ†é’ŸèŒƒå›´æ•°æ®
rate(http_requests_total[5m] offset 1h)

# æŸ¥è¯¢æ˜¨å¤©åŒä¸€æ—¶é—´çš„å€¼
http_requests_total offset 1d
```

#### PromQLèšåˆæ“ä½œç¬¦

**1. èšåˆå‡½æ•°**

| å‡½æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **sum** | æ±‚å’Œ | `sum(http_requests_total)` |
| **min** | æœ€å°å€¼ | `min(node_memory_free_bytes)` |
| **max** | æœ€å¤§å€¼ | `max(node_cpu_temperature)` |
| **avg** | å¹³å‡å€¼ | `avg(http_request_duration_seconds)` |
| **count** | è®¡æ•° | `count(up == 1)` |
| **stddev** | æ ‡å‡†å·® | `stddev(http_request_duration_seconds)` |
| **topk** | å‰Kä¸ªæœ€å¤§å€¼ | `topk(5, http_requests_total)` |
| **bottomk** | å‰Kä¸ªæœ€å°å€¼ | `bottomk(5, node_memory_free_bytes)` |
| **quantile** | åˆ†ä½æ•° | `quantile(0.95, http_request_duration_seconds)` |

**by / without å­å¥**ï¼š

```promql
# æŒ‰methodå’Œstatusåˆ†ç»„æ±‚å’Œ
sum(http_requests_total) by (method, status)

# ç»“æœç¤ºä¾‹:
# {method="GET", status="200"} 15000
# {method="GET", status="404"} 120
# {method="POST", status="200"} 8000

# without: æ’é™¤æŸäº›æ ‡ç­¾,ä¿ç•™å…¶ä»–æ‰€æœ‰æ ‡ç­¾
sum(http_requests_total) without (instance, pod)
# å«ä¹‰: èšåˆæ—¶ä¸åŒºåˆ†instanceå’Œpod,ä¿ç•™method/statusç­‰æ ‡ç­¾
```

**2. é€Ÿç‡å‡½æ•° (æœ€å¸¸ç”¨)**

```promql
# rate(): è®¡ç®—æ¯ç§’å¹³å‡å¢é•¿ç‡ (ç”¨äºCounter)
rate(http_requests_total[5m])
# å«ä¹‰: è¿‡å»5åˆ†é’Ÿçš„å¹³å‡æ¯ç§’è¯·æ±‚æ•° (QPS)

# irate(): è®¡ç®—ç¬æ—¶å¢é•¿ç‡ (æ›´æ•æ„Ÿ,ç”¨äºå¿«é€Ÿå˜åŒ–çš„æŒ‡æ ‡)
irate(http_requests_total[5m])
# å«ä¹‰: ä½¿ç”¨æœ€è¿‘ä¸¤ä¸ªæ•°æ®ç‚¹è®¡ç®—å¢é•¿ç‡

# increase(): è®¡ç®—æ—¶é—´èŒƒå›´å†…çš„å¢é‡
increase(http_requests_total[1h])
# å«ä¹‰: è¿‡å»1å°æ—¶çš„è¯·æ±‚æ€»å¢é‡

# rate vs irate:
# rate: å¹³æ»‘,é€‚åˆå‘Šè­¦
# irate: æ•æ„Ÿ,é€‚åˆå¿«é€Ÿå‘ç°å³°å€¼
```

**3. æ—¶é—´èšåˆå‡½æ•°**

```promql
# è¿‡å»ä¸€æ®µæ—¶é—´çš„æœ€å¤§å€¼
max_over_time(http_request_duration_seconds[1h])

# è¿‡å»ä¸€æ®µæ—¶é—´çš„æœ€å°å€¼
min_over_time(node_memory_free_bytes[1h])

# è¿‡å»ä¸€æ®µæ—¶é—´çš„å¹³å‡å€¼
avg_over_time(cpu_usage[5m])

# å…¶ä»–:
sum_over_time()    # æ±‚å’Œ
count_over_time()  # è®¡æ•°
stddev_over_time() # æ ‡å‡†å·®
quantile_over_time(0.95, http_request_duration_seconds[1h])  # P95
```

**4. äºŒå…ƒæ“ä½œç¬¦**

**ç®—æœ¯æ“ä½œç¬¦**ï¼š

```promql
# åŠ å‡ä¹˜é™¤
node_memory_total_bytes - node_memory_free_bytes  # å·²ç”¨å†…å­˜

# å†…å­˜ä½¿ç”¨ç‡
(node_memory_total_bytes - node_memory_free_bytes) / node_memory_total_bytes * 100

# å¹‚è¿ç®—
cpu_usage ^ 2

# æ¨¡è¿ç®—
node_time_seconds % 3600  # å½“å‰å°æ—¶å†…çš„ç§’æ•°
```

**æ¯”è¾ƒæ“ä½œç¬¦**ï¼š

```promql
# è¿”å›å¸ƒå°”å€¼ (0æˆ–1)
http_requests_total > 1000      # å¤§äº1000çš„åºåˆ—
node_memory_free_bytes < 1e9    # å°äº1GBçš„èŠ‚ç‚¹

# ä½œä¸ºè¿‡æ»¤å™¨ (ä¿ç•™åŸå€¼)
http_requests_total > bool 1000  # è¿”å›0æˆ–1
```

**é€»è¾‘æ“ä½œç¬¦**ï¼š

```promql
# and: äº¤é›†
http_requests_total > 1000 and http_errors_total > 10

# or: å¹¶é›†
up{job="api"} or up{job="web"}

# unless: å·®é›†
up unless on(instance) disk_full
# å«ä¹‰: è¿”å›upä¸­å­˜åœ¨ä½†disk_fullä¸­ä¸å­˜åœ¨çš„åºåˆ—
```

**å‘é‡åŒ¹é…**ï¼š

```promql
# one-to-oneåŒ¹é… (é»˜è®¤)
method:http_requests:rate5m / on(method) group_left method:http_requests:total

# many-to-oneåŒ¹é…
sum(rate(http_requests_total[5m])) by (method, status)
  /
sum(rate(http_requests_total[5m])) by (method)
# group_left: å·¦ä¾§å¤šä¸ªåºåˆ—åŒ¹é…å³ä¾§ä¸€ä¸ªåºåˆ—
```

#### å®ç”¨PromQLæŸ¥è¯¢ç¤ºä¾‹

**1. ç³»ç»Ÿèµ„æºç›‘æ§**

```promql
# CPUä½¿ç”¨ç‡ (%)
100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# å†…å­˜ä½¿ç”¨ç‡ (%)
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# ç£ç›˜ä½¿ç”¨ç‡ (%)
(node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100

# ç£ç›˜IO (IOPS)
rate(node_disk_reads_completed_total[5m]) + rate(node_disk_writes_completed_total[5m])

# ç½‘ç»œæµé‡ (MB/s)
rate(node_network_receive_bytes_total[5m]) / 1024 / 1024
```

**2. å®¹å™¨ç›‘æ§**

```promql
# å®¹å™¨CPUä½¿ç”¨ç‡ (%)
sum(rate(container_cpu_usage_seconds_total{pod!=""}[5m])) by (pod, namespace) * 100

# å®¹å™¨å†…å­˜ä½¿ç”¨é‡ (GB)
sum(container_memory_working_set_bytes{pod!=""}) by (pod, namespace) / 1024 / 1024 / 1024

# å®¹å™¨é‡å¯æ¬¡æ•°
kube_pod_container_status_restarts_total

# OOMæ¬¡æ•°
sum(increase(container_oom_events_total[1h])) by (pod, namespace)
```

**3. åº”ç”¨æ€§èƒ½ç›‘æ§ (REDæ–¹æ³•)**

REDæ–¹æ³•æ˜¯æœåŠ¡ç›‘æ§çš„é»„é‡‘æ ‡å‡†ï¼š
- **R**ate: è¯·æ±‚é€Ÿç‡
- **E**rrors: é”™è¯¯ç‡
- **D**uration: è¯·æ±‚å»¶è¿Ÿ

```promql
# Rate: æ¯ç§’è¯·æ±‚æ•° (QPS)
sum(rate(http_requests_total[5m])) by (service, method)

# Errors: é”™è¯¯ç‡ (%)
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
  /
sum(rate(http_requests_total[5m])) by (service)
  * 100

# Duration: P95å»¶è¿Ÿ (ç§’)
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)

# Duration: P99å»¶è¿Ÿ
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)
```

**4. Kubernetesèµ„æºç›‘æ§**

```promql
# Podæ•°é‡ (æŒ‰çŠ¶æ€)
count(kube_pod_status_phase{phase="Running"}) by (namespace)

# Deploymentå‰¯æœ¬æ•° vs æœŸæœ›å‰¯æœ¬æ•°
kube_deployment_status_replicas_available / kube_deployment_spec_replicas * 100

# PVCä½¿ç”¨ç‡
kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100

# èŠ‚ç‚¹çŠ¶æ€ (ReadyèŠ‚ç‚¹æ•°)
count(kube_node_status_condition{condition="Ready", status="true"})

# èŠ‚ç‚¹å¯è°ƒåº¦èµ„æº (CPU)
sum(kube_node_status_allocatable{resource="cpu"}) - sum(kube_pod_container_resource_requests{resource="cpu"})
```

**5. ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§**

```promql
# è®¢å•åˆ›å»ºé€Ÿç‡ (æ¯åˆ†é’Ÿ)
rate(order_created_total[5m]) * 60

# æ”¯ä»˜æˆåŠŸç‡ (%)
sum(rate(payment_total{status="success"}[5m]))
  /
sum(rate(payment_total[5m]))
  * 100

# æ´»è·ƒç”¨æˆ·æ•° (å»é‡è®¡æ•°)
count(sum by (user_id) (rate(user_activity_total[5m]) > 0))

# è¥æ”¶é€Ÿç‡ (ç¾å…ƒ/ç§’)
rate(revenue_dollars_total[5m])
```

#### PromQLæ€§èƒ½ä¼˜åŒ–

**1. é¿å…é«˜åŸºæ•°æŸ¥è¯¢**

```promql
# âŒ é”™è¯¯: æŸ¥è¯¢æ‰€æœ‰user_id (ç™¾ä¸‡çº§åŸºæ•°)
sum by (user_id) (http_requests_total)

# âœ… æ­£ç¡®: æŒ‰æœåŠ¡èšåˆ
sum by (service, method) (rate(http_requests_total[5m]))
```

**2. ä½¿ç”¨Recording Rulesé¢„è®¡ç®—**

å¯¹äºå¤æ‚çš„æŸ¥è¯¢ï¼Œå¯ä»¥ä½¿ç”¨Recording Rulesé¢„å…ˆè®¡ç®—å¹¶å­˜å‚¨ç»“æœï¼š

```yaml
# recording_rules.yml
groups:
- name: api_performance
  interval: 15s
  rules:
  # é¢„è®¡ç®—QPS
  - record: job:http_requests:rate5m
    expr: sum(rate(http_requests_total[5m])) by (job, method)
  
  # é¢„è®¡ç®—é”™è¯¯ç‡
  - record: job:http_errors:ratio
    expr: |
      sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
        /
      sum(rate(http_requests_total[5m])) by (job)
```

ä¹‹åå¯ä»¥ç›´æ¥æŸ¥è¯¢é¢„è®¡ç®—çš„ç»“æœï¼š

```promql
# ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—ç»“æœ (æ›´å¿«)
job:http_requests:rate5m{job="api"}

# è€Œä¸æ˜¯æ¯æ¬¡éƒ½è®¡ç®— (æ›´æ…¢)
sum(rate(http_requests_total{job="api"}[5m])) by (method)
```

**3. åˆç†ä½¿ç”¨æ—¶é—´èŒƒå›´**

```promql
# âŒ é”™è¯¯: èŒƒå›´è¿‡å¤§,æŸ¥è¯¢æ…¢
rate(http_requests_total[1d])

# âœ… æ­£ç¡®: 5åˆ†é’Ÿè¶³å¤Ÿè®¡ç®—é€Ÿç‡
rate(http_requests_total[5m])

# è§„åˆ™: rate()çš„èŒƒå›´åº”è¯¥æ˜¯scrape_intervalçš„4å€ä»¥ä¸Š
# å¦‚æœscrape_interval=15s, åˆ™rangeè‡³å°‘60s, æ¨è5m
```

---

### 9.2.4 Prometheuséƒ¨ç½²ä¸é…ç½®

#### åœ¨Kubernetesä¸­éƒ¨ç½²Prometheus

**æ–¹å¼1: ä½¿ç”¨Helm Chart (æ¨è)**

```bash
# æ·»åŠ Prometheusç¤¾åŒºHelmä»“åº“
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace monitoring

# å®‰è£…kube-prometheus-stack (åŒ…å«Prometheus + Grafana + AlertManager)
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set prometheus.prometheusSpec.retention=30d \
  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi \
  --set prometheus.prometheusSpec.resources.requests.memory=2Gi \
  --set prometheus.prometheusSpec.resources.limits.memory=4Gi \
  --set grafana.adminPassword=admin123

# æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
kubectl get pods -n monitoring
```

**æ–¹å¼2: æ‰‹åŠ¨éƒ¨ç½² (å®Œæ•´ç†è§£)**

ä¸‹é¢å±•ç¤ºå®Œæ•´çš„æ‰‹åŠ¨éƒ¨ç½²é…ç½®ï¼š

**1. åˆ›å»ºServiceAccountå’ŒRBAC**

```yaml
# prometheus-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
# è¯»å–èŠ‚ç‚¹ä¿¡æ¯
- apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
# è¯»å–é…ç½®
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]
# è¯»å–Ingress
- apiGroups: ["networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
# éèµ„æºURL (ç”¨äºå¥åº·æ£€æŸ¥)
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
```

**2. åˆ›å»ºConfigMap (Prometheusé…ç½®)**

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: 'k8s-production'
        region: 'us-west-2'

    # AlertManageré…ç½®
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    # è§„åˆ™æ–‡ä»¶
    rule_files:
    - '/etc/prometheus/rules/*.yml'

    # æŠ“å–é…ç½® (å‰é¢å·²è¯¦ç»†ä»‹ç»)
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - source_labels: [__address__]
        regex: '([^:]+):.*'
        replacement: '${1}:9100'
        target_label: __address__
    
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
        action: replace
        regex: ([^;]+);(.+)
        replacement: ${2}:${1}
        target_label: __address__
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
```

**3. åˆ›å»ºDeployment**

```yaml
# prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1  # å•å®ä¾‹ (é«˜å¯ç”¨éœ€è¦ä½¿ç”¨StatefulSet + Thanos)
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.48.0
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--storage.tsdb.retention.time=30d'      # ä¿ç•™30å¤©
        - '--storage.tsdb.retention.size=50GB'     # æˆ–50GBä¸Šé™
        - '--web.enable-lifecycle'                 # å…è®¸çƒ­é‡è½½
        - '--web.enable-admin-api'                 # å¯ç”¨ç®¡ç†API
        ports:
        - containerPort: 9090
          name: web
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: data
          mountPath: /prometheus
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: data
        persistentVolumeClaim:
          claimName: prometheus-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-data
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: gp3  # AWS EBS gp3
```

**4. åˆ›å»ºService**

```yaml
# prometheus-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  type: ClusterIP
  ports:
  - port: 9090
    targetPort: 9090
    name: web
  selector:
    app: prometheus
---
# å¦‚æœéœ€è¦å¤–éƒ¨è®¿é—®,åˆ›å»ºIngress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: prometheus
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
spec:
  ingressClassName: nginx
  rules:
  - host: prometheus.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus
            port:
              number: 9090
  tls:
  - hosts:
    - prometheus.example.com
    secretName: prometheus-tls
```

**5. éƒ¨ç½²**

```bash
# éƒ¨ç½²æ‰€æœ‰èµ„æº
kubectl apply -f prometheus-rbac.yaml
kubectl apply -f prometheus-config.yaml
kubectl apply -f prometheus-deployment.yaml
kubectl apply -f prometheus-service.yaml

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n monitoring
kubectl logs -n monitoring -l app=prometheus --tail=100

# ç«¯å£è½¬å‘è®¿é—® (å¦‚æœæ²¡æœ‰Ingress)
kubectl port-forward -n monitoring svc/prometheus 9090:9090

# è®¿é—®: http://localhost:9090
```

#### Prometheusé…ç½®çƒ­é‡è½½

Prometheusæ”¯æŒé…ç½®çƒ­é‡è½½ï¼Œæ— éœ€é‡å¯å®¹å™¨ï¼š

```bash
# æ–¹æ³•1: ä½¿ç”¨API (éœ€è¦å¯ç”¨--web.enable-lifecycle)
curl -X POST http://prometheus:9090/-/reload

# æ–¹æ³•2: å‘é€SIGHUPä¿¡å·
kubectl exec -n monitoring prometheus-xxx -- kill -HUP 1

# æ–¹æ³•3: ä¿®æ”¹ConfigMapåè‡ªåŠ¨é‡è½½ (éœ€è¦é…ç½®ConfigMap Reloader)
# ä½¿ç”¨kube-prometheus-stackæ—¶è‡ªåŠ¨åŒ…å«æ­¤åŠŸèƒ½
```

#### Prometheusé«˜å¯ç”¨æ¶æ„

å•å®ä¾‹Prometheuså­˜åœ¨å•ç‚¹æ•…éšœé£é™©ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨é«˜å¯ç”¨æ¶æ„ï¼š

**æ–¹æ¡ˆ1: Prometheusè”é‚¦ (Federation)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus 1 â”‚    â”‚ Prometheus 2 â”‚  (å¤šä¸ªç‹¬ç«‹Prometheus)
â”‚ (shard 1)    â”‚    â”‚ (shard 2)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Prometheus  â”‚  (å…¨å±€Prometheus)
        â”‚  (Global)    â”‚  (è”é‚¦èšåˆ)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ–¹æ¡ˆ2: Thanos (æ¨è)**

Thanosæä¾›é•¿æœŸå­˜å‚¨ã€å…¨å±€æŸ¥è¯¢ã€æ•°æ®å»é‡ç­‰é«˜çº§åŠŸèƒ½ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Thanosæ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Prometheus 1 â”‚     â”‚ Prometheus 2 â”‚                 â”‚
â”‚  â”‚ + Sidecar    â”‚     â”‚ + Sidecar    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                     â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚ Object      â”‚  (S3/GCS/MinIO)                â”‚
â”‚         â”‚ Storage     â”‚  (é•¿æœŸå­˜å‚¨)                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚ Thanos      â”‚  (æŸ¥è¯¢æ‰€æœ‰æ•°æ®æº)               â”‚
â”‚         â”‚ Query       â”‚                                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚  Grafana    â”‚                                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**éƒ¨ç½²Thanos (ä½¿ç”¨Helm)**

```bash
helm install thanos bitnami/thanos \
  --namespace monitoring \
  --set query.enabled=true \
  --set query.dnsDiscovery.enabled=true \
  --set query.dnsDiscovery.sidecarsService=prometheus-thanos-discovery \
  --set query.dnsDiscovery.sidecarsNamespace=monitoring \
  --set objstoreConfig.type=S3 \
  --set objstoreConfig.config.bucket=thanos-metrics \
  --set objstoreConfig.config.endpoint=s3.amazonaws.com \
  --set objstoreConfig.config.region=us-west-2
```

---

### 9.2.5 Recording Rulesä¸æ€§èƒ½ä¼˜åŒ–

#### Recording Rulesè¯¦è§£

Recording Ruleså…è®¸é¢„å…ˆè®¡ç®—å¤æ‚æŸ¥è¯¢å¹¶å­˜å‚¨ç»“æœï¼Œå¤§å¹…æå‡æŸ¥è¯¢æ€§èƒ½ã€‚

**1. Recording Rulesé…ç½®**

```yaml
# prometheus-rules.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  recording_rules.yml: |
    groups:
    # APIæ€§èƒ½æŒ‡æ ‡
    - name: api_performance
      interval: 15s  # è®¡ç®—é—´éš”
      rules:
      # QPS (æ¯ç§’è¯·æ±‚æ•°)
      - record: job:http_requests:rate5m
        expr: sum(rate(http_requests_total[5m])) by (job, method, status)
        labels:
          metric_type: rate
      
      # é”™è¯¯ç‡ (%)
      - record: job:http_errors:ratio
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
            /
          sum(rate(http_requests_total[5m])) by (job)
      
      # P95å»¶è¿Ÿ
      - record: job:http_request_duration:p95
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)
          )
      
      # P99å»¶è¿Ÿ
      - record: job:http_request_duration:p99
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)
          )

    # èŠ‚ç‚¹èµ„æºæŒ‡æ ‡
    - name: node_resources
      interval: 30s
      rules:
      # CPUä½¿ç”¨ç‡
      - record: instance:node_cpu:usage
        expr: |
          100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
      
      # å†…å­˜ä½¿ç”¨ç‡
      - record: instance:node_memory:usage_ratio
        expr: |
          1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)
      
      # ç£ç›˜ä½¿ç”¨ç‡
      - record: instance:node_disk:usage_ratio
        expr: |
          (node_filesystem_size_bytes - node_filesystem_free_bytes) 
            / node_filesystem_size_bytes

    # å®¹å™¨èµ„æºæŒ‡æ ‡
    - name: container_resources
      interval: 15s
      rules:
      # å®¹å™¨CPUä½¿ç”¨ (millicores)
      - record: namespace_pod_container:cpu_usage:rate5m
        expr: |
          sum(rate(container_cpu_usage_seconds_total{pod!=""}[5m])) 
            by (namespace, pod, container) * 1000
      
      # å®¹å™¨å†…å­˜ä½¿ç”¨ (bytes)
      - record: namespace_pod_container:memory_usage:bytes
        expr: |
          sum(container_memory_working_set_bytes{pod!=""}) 
            by (namespace, pod, container)
      
      # å®¹å™¨ç½‘ç»œæ¥æ”¶é€Ÿç‡ (bytes/s)
      - record: namespace_pod:network_receive:rate5m
        expr: |
          sum(rate(container_network_receive_bytes_total[5m])) 
            by (namespace, pod)
```

**2. åº”ç”¨Recording Rules**

```yaml
# ä¿®æ”¹Prometheus Deployment,æŒ‚è½½rules
spec:
  template:
    spec:
      containers:
      - name: prometheus
        volumeMounts:
        - name: rules
          mountPath: /etc/prometheus/rules
      volumes:
      - name: rules
        configMap:
          name: prometheus-rules

# ä¿®æ”¹prometheus.yml,å¼•ç”¨è§„åˆ™æ–‡ä»¶
rule_files:
- '/etc/prometheus/rules/*.yml'
```

```bash
# åº”ç”¨é…ç½®
kubectl apply -f prometheus-rules.yaml

# çƒ­é‡è½½Prometheus
curl -X POST http://prometheus:9090/-/reload

# éªŒè¯è§„åˆ™åŠ è½½
# è®¿é—®: http://prometheus:9090/rules
```

**3. ä½¿ç”¨Recording RulesæŸ¥è¯¢**

```promql
# ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—ç»“æœ (å¿«é€Ÿ)
job:http_requests:rate5m{job="api-server"}

# å¯¹æ¯”åŸå§‹æŸ¥è¯¢ (æ…¢)
sum(rate(http_requests_total{job="api-server"}[5m])) by (method, status)

# æ€§èƒ½å¯¹æ¯”:
# Recording Rule: ~10ms
# åŸå§‹æŸ¥è¯¢: ~500ms (50å€æå‡)
```

#### Prometheusæ€§èƒ½è°ƒä¼˜

**1. èµ„æºé…ç½®ä¼˜åŒ–**

```yaml
# æ ¹æ®æŒ‡æ ‡è§„æ¨¡è°ƒæ•´èµ„æº
spec:
  containers:
  - name: prometheus
    resources:
      requests:
        cpu: 2000m       # 2æ ¸èµ·æ­¥
        memory: 4Gi      # 4GBå†…å­˜èµ·æ­¥
      limits:
        cpu: 4000m
        memory: 8Gi

# ç»éªŒå…¬å¼:
# å†…å­˜éœ€æ±‚ = æ´»è·ƒæ—¶é—´åºåˆ—æ•° * 1KB + ç£ç›˜æ•°æ® * 0.0001
# ç¤ºä¾‹: 100ä¸‡åºåˆ— + 50GBç£ç›˜æ•°æ® = 1GB + 5MB â‰ˆ 1GBå†…å­˜
```

**2. å­˜å‚¨ä¼˜åŒ–**

```yaml
# è°ƒæ•´æ•°æ®ä¿ç•™ç­–ç•¥
args:
- '--storage.tsdb.retention.time=30d'  # ä¿ç•™30å¤©
- '--storage.tsdb.retention.size=50GB'  # æˆ–50GBä¸Šé™(äºŒé€‰ä¸€ç”Ÿæ•ˆ)

# è°ƒæ•´å—å¤§å° (é»˜è®¤2å°æ—¶)
- '--storage.tsdb.min-block-duration=2h'
- '--storage.tsdb.max-block-duration=36h'

# å‹ç¼©è®¾ç½®
- '--storage.tsdb.wal-compression'  # å¯ç”¨WALå‹ç¼©(èŠ‚çœ50%ç©ºé—´)
```

**3. æŸ¥è¯¢ä¼˜åŒ–**

```promql
# âŒ æ…¢æŸ¥è¯¢ (æ‰«æå¤§é‡æ•°æ®)
rate(http_requests_total[1d])

# âœ… ä¼˜åŒ– (ç¼©å°æ—¶é—´èŒƒå›´)
rate(http_requests_total[5m])

# âŒ æ…¢æŸ¥è¯¢ (é«˜åŸºæ•°æ ‡ç­¾)
sum by (user_id) (http_requests_total)

# âœ… ä¼˜åŒ– (ä½åŸºæ•°æ ‡ç­¾)
sum by (service, method) (http_requests_total)
```

**4. é‡‡æ ·ç‡ä¼˜åŒ–**

```yaml
# è°ƒæ•´é‡‡æ ·é—´éš”
scrape_configs:
- job_name: 'low-priority'
  scrape_interval: 60s    # ä½ä¼˜å…ˆçº§ç›®æ ‡: 60ç§’
  
- job_name: 'high-priority'
  scrape_interval: 15s    # é«˜ä¼˜å…ˆçº§ç›®æ ‡: 15ç§’
```

**5. ç›‘æ§Prometheusè‡ªèº«**

```promql
# Prometheuså†…å­˜ä½¿ç”¨
process_resident_memory_bytes / 1024 / 1024 / 1024

# æ´»è·ƒæ—¶é—´åºåˆ—æ•°
prometheus_tsdb_head_series

# æ¯ç§’é‡‡æ ·é€Ÿç‡
rate(prometheus_tsdb_head_samples_appended_total[5m])

# æŸ¥è¯¢å»¶è¿ŸP99
histogram_quantile(0.99, rate(prometheus_http_request_duration_seconds_bucket[5m]))

# WALæŸåæ¬¡æ•° (åº”è¯¥ä¸º0)
prometheus_tsdb_wal_corruptions_total
```

---

**ğŸ“Š 9.2èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Prometheusçš„æ ¸å¿ƒåŸç†ä¸å®æˆ˜éƒ¨ç½²ï¼š

âœ… **Prometheusæ¶æ„**ï¼š
- æ•´ä½“æ¶æ„ä¸æ ¸å¿ƒç»„ä»¶
- æ—¶åºæ•°æ®åº“TSDBåŸç†
- é«˜æ•ˆå‹ç¼©ç®—æ³• (Delta-of-Delta + XOR)

âœ… **æ•°æ®æ¨¡å‹**ï¼š
- 4ç§æŒ‡æ ‡ç±»å‹ (Counter/Gauge/Histogram/Summary)
- æ ‡ç­¾è®¾è®¡æœ€ä½³å®è·µ
- æŒ‡æ ‡å‘½åè§„èŒƒ

âœ… **æœåŠ¡å‘ç°**ï¼š
- KubernetesåŸç”ŸæœåŠ¡å‘ç°
- Relabelé…ç½®è¯¦è§£
- ç›®æ ‡æŠ“å–æœºåˆ¶

âœ… **PromQLæŸ¥è¯¢**ï¼š
- åŸºç¡€è¯­æ³• (å³æ—¶/èŒƒå›´å‘é‡)
- èšåˆæ“ä½œç¬¦ä¸é€Ÿç‡å‡½æ•°
- REDæ–¹æ³•å®ç”¨æŸ¥è¯¢
- æ€§èƒ½ä¼˜åŒ–æŠ€å·§

âœ… **ç”Ÿäº§éƒ¨ç½²**ï¼š
- Helm Chartå¿«é€Ÿéƒ¨ç½²
- æ‰‹åŠ¨éƒ¨ç½²å®Œæ•´é…ç½®
- é«˜å¯ç”¨æ¶æ„ (Federation/Thanos)
- Recording Rulesæ€§èƒ½ä¼˜åŒ–

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ Grafanaå¯è§†åŒ–å¹³å°ï¼ŒåŒ…æ‹¬æ•°æ®æºé›†æˆã€ä»ªè¡¨ç›˜è®¾è®¡æœ€ä½³å®è·µã€å˜é‡ä¸æ¨¡æ¿åº”ç”¨ï¼Œä»¥åŠä¼ä¸šçº§ç›‘æ§ä»ªè¡¨ç›˜çš„æ„å»ºã€‚

---

## 9.3 Grafanaå¯è§†åŒ–ä¸ä»ªè¡¨ç›˜

åœ¨9.2èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Prometheusçš„æ ¸å¿ƒåŸç†å’ŒPromQLæŸ¥è¯¢ã€‚è™½ç„¶Prometheusè‡ªå¸¦Web UIå¯ä»¥æŸ¥è¯¢æ•°æ®ï¼Œä½†å®ƒçš„å¯è§†åŒ–èƒ½åŠ›éå¸¸æœ‰é™ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¼ºå¤§çš„å¯è§†åŒ–å¹³å°æ¥ï¼š

- ğŸ“Š åˆ›å»ºç¾è§‚çš„å®æ—¶ç›‘æ§ä»ªè¡¨ç›˜
- ğŸ“ˆ å±•ç¤ºå¤šç»´åº¦çš„æŒ‡æ ‡è¶‹åŠ¿å›¾è¡¨
- ğŸ¯ é›†ä¸­ç®¡ç†å¤šä¸ªæ•°æ®æº
- ğŸš¨ å¯è§†åŒ–å‘Šè­¦çŠ¶æ€
- ğŸ‘¥ æ”¯æŒå›¢é˜Ÿåä½œå’Œæƒé™ç®¡ç†

**Grafana**æ˜¯ä¸šç•Œæœ€æµè¡Œçš„å¼€æºå¯è§†åŒ–å¹³å°ï¼Œå®ƒä¸Prometheuså®Œç¾é›†æˆï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾è¡¨ç±»å‹å’Œå¼ºå¤§çš„å®šåˆ¶èƒ½åŠ›ã€‚

**Grafanaæ ¸å¿ƒä¼˜åŠ¿**ï¼š

| ç‰¹æ€§ | è¯´æ˜ | ä»·å€¼ |
|------|------|------|
| **å¤šæ•°æ®æº** | æ”¯æŒ60+æ•°æ®æº (Prometheus/Loki/Jaeger/ES/MySQLç­‰) | ç»Ÿä¸€ç›‘æ§å¹³å° |
| **ä¸°å¯Œå›¾è¡¨** | æŠ˜çº¿å›¾/æŸ±çŠ¶å›¾/çƒ­åŠ›å›¾/Gauge/Table/Stat/Logsé¢æ¿ç­‰ | æ»¡è¶³å„ç§å±•ç¤ºéœ€æ±‚ |
| **å˜é‡æ¨¡æ¿** | åŠ¨æ€Dashboard (åˆ‡æ¢é›†ç¾¤/å‘½åç©ºé—´/æœåŠ¡ç­‰) | ä¸€ä¸ªDashboardé€‚é…å¤šç¯å¢ƒ |
| **å‘Šè­¦é›†æˆ** | åŸç”Ÿå‘Šè­¦è§„åˆ™+å¤šæ¸ é“é€šçŸ¥ | ç‹¬ç«‹äºPrometheusçš„å‘Šè­¦ |
| **æƒé™ç®¡ç†** | Organization/Team/Userä¸‰çº§æƒé™ | ä¼ä¸šçº§å¤šç§Ÿæˆ·æ”¯æŒ |
| **æ’ä»¶ç”Ÿæ€** | æ•°ç™¾ä¸ªç¤¾åŒºæ’ä»¶ | é«˜åº¦å¯æ‰©å±• |

### 9.3.1 Grafanaéƒ¨ç½²ä¸é…ç½®

#### åœ¨Kubernetesä¸­éƒ¨ç½²Grafana

**æ–¹å¼1: ä½¿ç”¨Helm Chart (æ¨è)**

```bash
# ä½¿ç”¨kube-prometheus-stack (å·²åŒ…å«Grafana)
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set grafana.enabled=true \
  --set grafana.adminPassword=admin123 \
  --set grafana.persistence.enabled=true \
  --set grafana.persistence.size=10Gi \
  --set grafana.ingress.enabled=true \
  --set grafana.ingress.hosts[0]=grafana.example.com

# æˆ–å•ç‹¬å®‰è£…Grafana
helm repo add grafana https://grafana.github.io/helm-charts
helm install grafana grafana/grafana \
  --namespace monitoring \
  --set adminPassword=admin123 \
  --set persistence.enabled=true \
  --set persistence.size=10Gi
```

**æ–¹å¼2: æ‰‹åŠ¨éƒ¨ç½²**

```yaml
# grafana-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
    # Prometheusæ•°æ®æº
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
      editable: true
      jsonData:
        timeInterval: 15s
        queryTimeout: 60s
    
    # Lokiæ•°æ®æº (å¦‚æœéƒ¨ç½²äº†Loki)
    - name: Loki
      type: loki
      access: proxy
      url: http://loki:3100
      editable: true
    
    # Jaegeræ•°æ®æº (å¦‚æœéƒ¨ç½²äº†Jaeger)
    - name: Jaeger
      type: jaeger
      access: proxy
      url: http://jaeger-query:16686
      editable: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: monitoring
data:
  grafana.ini: |
    [server]
    protocol = http
    http_port = 3000
    domain = grafana.example.com
    root_url = %(protocol)s://%(domain)s/
    
    [security]
    admin_user = admin
    admin_password = admin123
    secret_key = SW2YcwTIb9zpOOhoPsMm
    
    [auth]
    disable_login_form = false
    disable_signout_menu = false
    
    [auth.anonymous]
    enabled = false
    
    [users]
    allow_sign_up = false
    allow_org_create = false
    auto_assign_org = true
    auto_assign_org_role = Viewer
    
    [log]
    mode = console
    level = info
    
    [alerting]
    enabled = true
    execute_alerts = true
    
    [unified_alerting]
    enabled = true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      securityContext:
        fsGroup: 472
        runAsUser: 472
      containers:
      - name: grafana
        image: grafana/grafana:10.2.0
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: GF_SECURITY_ADMIN_USER
          value: admin
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-admin
              key: password
        volumeMounts:
        - name: config
          mountPath: /etc/grafana
        - name: datasources
          mountPath: /etc/grafana/provisioning/datasources
        - name: data
          mountPath: /var/lib/grafana
        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: grafana-config
      - name: datasources
        configMap:
          name: grafana-datasources
      - name: data
        persistentVolumeClaim:
          claimName: grafana-data
---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-admin
  namespace: monitoring
type: Opaque
stringData:
  password: admin123
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-data
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp3
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
    name: http
  selector:
    app: grafana
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: nginx
  rules:
  - host: grafana.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000
  tls:
  - hosts:
    - grafana.example.com
    secretName: grafana-tls
```

**éƒ¨ç½²å¹¶è®¿é—®**ï¼š

```bash
# éƒ¨ç½²Grafana
kubectl apply -f grafana-deployment.yaml

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n monitoring -l app=grafana
kubectl logs -n monitoring -l app=grafana --tail=50

# ç«¯å£è½¬å‘è®¿é—® (å¦‚æœæ²¡æœ‰Ingress)
kubectl port-forward -n monitoring svc/grafana 3000:3000

# æµè§ˆå™¨è®¿é—®: http://localhost:3000
# é»˜è®¤è´¦å·: admin / admin123
```

#### Grafanaé…ç½®è¯¦è§£

**1. é…ç½®æ–‡ä»¶ç»“æ„**

```
/etc/grafana/
â”œâ”€â”€ grafana.ini              # ä¸»é…ç½®æ–‡ä»¶
â””â”€â”€ provisioning/            # è‡ªåŠ¨é…ç½®ç›®å½•
    â”œâ”€â”€ datasources/         # æ•°æ®æºé…ç½®
    â”‚   â””â”€â”€ datasources.yaml
    â”œâ”€â”€ dashboards/          # Dashboardé…ç½®
    â”‚   â””â”€â”€ dashboards.yaml
    â”œâ”€â”€ notifiers/           # å‘Šè­¦é€šçŸ¥é…ç½®
    â”‚   â””â”€â”€ notifiers.yaml
    â””â”€â”€ plugins/             # æ’ä»¶é…ç½®
        â””â”€â”€ plugins.yaml
```

**2. é‡è¦é…ç½®é¡¹**

```ini
# grafana.ini

# æœåŠ¡å™¨é…ç½®
[server]
protocol = http             # httpæˆ–https
http_port = 3000           # ç›‘å¬ç«¯å£
domain = grafana.example.com
root_url = %(protocol)s://%(domain)s/
enable_gzip = true

# æ•°æ®åº“é…ç½® (é»˜è®¤SQLite,ç”Ÿäº§å»ºè®®MySQL/PostgreSQL)
[database]
type = mysql
host = mysql:3306
name = grafana
user = grafana
password = secret
max_open_conn = 100
max_idle_conn = 50

# å®‰å…¨é…ç½®
[security]
admin_user = admin
admin_password = $__env{GF_SECURITY_ADMIN_PASSWORD}  # ä»ç¯å¢ƒå˜é‡è¯»å–
secret_key = $__env{GF_SECURITY_SECRET_KEY}
disable_gravatar = false
cookie_secure = true
cookie_samesite = lax

# ç”¨æˆ·ç®¡ç†
[users]
allow_sign_up = false          # ç¦æ­¢è‡ªæ³¨å†Œ
allow_org_create = false       # ç¦æ­¢åˆ›å»ºOrganization
auto_assign_org = true
auto_assign_org_role = Viewer  # æ–°ç”¨æˆ·é»˜è®¤è§’è‰²

# è®¤è¯é…ç½®
[auth]
disable_login_form = false
disable_signout_menu = false
oauth_auto_login = false

# LDAPè®¤è¯ (ä¼ä¸šç¯å¢ƒ)
[auth.ldap]
enabled = false
config_file = /etc/grafana/ldap.toml

# åŒ¿åè®¿é—® (å…¬å…±Dashboard)
[auth.anonymous]
enabled = false
org_name = Main Org.
org_role = Viewer

# æ—¥å¿—é…ç½®
[log]
mode = console file
level = info
filters = rendering:debug

# å‘Šè­¦é…ç½®
[alerting]
enabled = true
execute_alerts = true
error_or_timeout = alerting
nodata_or_nullvalues = no_data
concurrent_render_limit = 5

# ç»Ÿä¸€å‘Šè­¦ (Grafana 8.0+)
[unified_alerting]
enabled = true
execute_alerts = true
evaluation_timeout = 30s
max_attempts = 3

# SMTPé…ç½® (é‚®ä»¶å‘Šè­¦)
[smtp]
enabled = true
host = smtp.gmail.com:587
user = alerts@example.com
password = secret
from_address = alerts@example.com
from_name = Grafana Alerts

# æ’ä»¶é…ç½®
[plugins]
enable_alpha = false
app_tls_skip_verify_insecure = false
```

---

### 9.3.2 æ•°æ®æºé›†æˆ

Grafanaæ”¯æŒ60+ç§æ•°æ®æºï¼Œä¸‹é¢ä»‹ç»Kubernetesç›‘æ§æœ€å¸¸ç”¨çš„å‡ ç§ã€‚

#### Prometheusæ•°æ®æºé…ç½®

**1. é€šè¿‡UIæ·»åŠ **

```
1. ç™»å½•Grafana
2. å·¦ä¾§èœå• â†’ Configuration â†’ Data Sources
3. ç‚¹å‡» "Add data source"
4. é€‰æ‹© "Prometheus"
5. å¡«å†™é…ç½®:
   - Name: Prometheus
   - URL: http://prometheus:9090 (K8så†…éƒ¨Serviceåœ°å€)
   - Access: Server (default)
   - Scrape interval: 15s
6. ç‚¹å‡» "Save & Test"
```

**2. é€šè¿‡Provisioningè‡ªåŠ¨é…ç½® (æ¨è)**

```yaml
# datasources.yaml
apiVersion: 1
datasources:
- name: Prometheus
  type: prometheus
  access: proxy
  url: http://prometheus:9090
  isDefault: true
  editable: true
  jsonData:
    timeInterval: 15s        # æŸ¥è¯¢é—´éš”
    queryTimeout: 60s        # æŸ¥è¯¢è¶…æ—¶
    httpMethod: POST         # ä½¿ç”¨POST (æ”¯æŒæ›´é•¿æŸ¥è¯¢)
    customQueryParameters: '' # è‡ªå®šä¹‰å‚æ•°
    manageAlerts: false      # ä¸ç®¡ç†Prometheuså‘Šè­¦
  version: 1
```

**3. Prometheusæ•°æ®æºé«˜çº§é…ç½®**

```yaml
datasources:
- name: Prometheus
  type: prometheus
  access: proxy
  url: http://prometheus:9090
  isDefault: true
  jsonData:
    # åŸºç¡€é…ç½®
    timeInterval: 15s
    queryTimeout: 60s
    httpMethod: POST
    
    # è®¤è¯é…ç½® (å¦‚æœPrometheuså¯ç”¨äº†è®¤è¯)
    basicAuth: true
    basicAuthUser: admin
  secureJsonData:
    basicAuthPassword: secret
    
    # TLSé…ç½®
    tlsAuth: true
    tlsCACert: |
      -----BEGIN CERTIFICATE-----
      ...
      -----END CERTIFICATE-----
    tlsClientCert: |
      -----BEGIN CERTIFICATE-----
      ...
      -----END CERTIFICATE-----
    tlsClientKey: |
      -----BEGIN PRIVATE KEY-----
      ...
      -----END PRIVATE KEY-----
    
    # è‡ªå®šä¹‰HTTPå¤´
    httpHeaderName1: X-Custom-Header
  secureJsonData:
    httpHeaderValue1: custom-value
```

**4. æµ‹è¯•Prometheusè¿æ¥**

```bash
# åœ¨Grafana Podä¸­æµ‹è¯•
kubectl exec -n monitoring -it grafana-xxx -- sh

# æµ‹è¯•è¿æ¥
curl http://prometheus:9090/api/v1/query?query=up

# åº”è¯¥è¿”å›JSONæ•°æ®
```

#### Lokiæ•°æ®æºé…ç½® (æ—¥å¿—)

Lokiæ˜¯Grafana Labså¼€å‘çš„è½»é‡çº§æ—¥å¿—èšåˆç³»ç»Ÿï¼Œä¸Prometheusæ¶æ„ç›¸ä¼¼ã€‚

```yaml
datasources:
- name: Loki
  type: loki
  access: proxy
  url: http://loki:3100
  editable: true
  jsonData:
    maxLines: 1000           # æœ€å¤§è¿”å›è¡Œæ•°
    timeout: 60              # æŸ¥è¯¢è¶…æ—¶ (ç§’)
    derivedFields:           # ä»æ—¥å¿—æå–å­—æ®µ
    - datasourceUid: jaeger  # å…³è”åˆ°Jaeger
      matcherRegex: "traceID=(\\w+)"
      name: TraceID
      url: "$${__value.raw}"
```

**LokiæŸ¥è¯¢ç¤ºä¾‹**ï¼š

```logql
# æŸ¥è¯¢ç‰¹å®šå‘½åç©ºé—´çš„æ—¥å¿—
{namespace="production"}

# æŸ¥è¯¢ç‰¹å®šPodçš„é”™è¯¯æ—¥å¿—
{namespace="production", pod=~"api-.*"} |= "ERROR"

# æ­£åˆ™è¿‡æ»¤
{app="nginx"} |~ "HTTP.*5[0-9]{2}"

# ç»Ÿè®¡é”™è¯¯ç‡
rate({namespace="production"} |= "ERROR" [5m])
```

#### Jaegeræ•°æ®æºé…ç½® (é“¾è·¯è¿½è¸ª)

```yaml
datasources:
- name: Jaeger
  type: jaeger
  access: proxy
  url: http://jaeger-query:16686
  editable: true
  jsonData:
    tracesToLogs:            # å…³è”æ—¥å¿—
      datasourceUid: loki
      tags: ['pod', 'namespace']
      spanStartTimeShift: '-1h'
      spanEndTimeShift: '1h'
```

#### Elasticsearchæ•°æ®æºé…ç½®

```yaml
datasources:
- name: Elasticsearch
  type: elasticsearch
  access: proxy
  url: http://elasticsearch:9200
  database: "[logstash-]YYYY.MM.DD"  # ç´¢å¼•æ¨¡å¼
  jsonData:
    esVersion: "7.10.0"
    timeField: "@timestamp"
    logMessageField: message
    logLevelField: level
    interval: Daily
```

#### å¤šPrometheusæ•°æ®æº (å¤šé›†ç¾¤ç›‘æ§)

```yaml
datasources:
# ç”Ÿäº§ç¯å¢ƒPrometheus
- name: Prometheus-Prod
  type: prometheus
  access: proxy
  url: http://prometheus-prod:9090
  isDefault: true
  jsonData:
    timeInterval: 15s
    customQueryParameters: 'cluster=production'

# æµ‹è¯•ç¯å¢ƒPrometheus
- name: Prometheus-Staging
  type: prometheus
  access: proxy
  url: http://prometheus-staging:9090
  jsonData:
    timeInterval: 15s
    customQueryParameters: 'cluster=staging'

# å¼€å‘ç¯å¢ƒPrometheus
- name: Prometheus-Dev
  type: prometheus
  access: proxy
  url: http://prometheus-dev:9090
  jsonData:
    timeInterval: 30s
    customQueryParameters: 'cluster=development'
```

---

### 9.3.3 ä»ªè¡¨ç›˜è®¾è®¡æœ€ä½³å®è·µ

#### DashboardåŸºç¡€æ¦‚å¿µ

**Dashboardç»“æ„**ï¼š

```
Dashboard (ä»ªè¡¨ç›˜)
â”œâ”€â”€ Rows (è¡Œ)
â”‚   â”œâ”€â”€ Panel 1 (é¢æ¿1: æŠ˜çº¿å›¾)
â”‚   â”œâ”€â”€ Panel 2 (é¢æ¿2: Gauge)
â”‚   â””â”€â”€ Panel 3 (é¢æ¿3: Table)
â”œâ”€â”€ Variables (å˜é‡)
â”‚   â”œâ”€â”€ $cluster
â”‚   â”œâ”€â”€ $namespace
â”‚   â””â”€â”€ $pod
â””â”€â”€ Settings (è®¾ç½®)
    â”œâ”€â”€ General (é€šç”¨)
    â”œâ”€â”€ Annotations (æ³¨é‡Š)
    â”œâ”€â”€ Variables (å˜é‡)
    â”œâ”€â”€ Links (é“¾æ¥)
    â””â”€â”€ JSON Model (JSONæ¨¡å‹)
```

#### åˆ›å»ºç¬¬ä¸€ä¸ªDashboard

**1. Kubernetesé›†ç¾¤æ¦‚è§ˆDashboard**

```
æ­¥éª¤1: åˆ›å»ºDashboard
- å·¦ä¾§èœå• â†’ Dashboards â†’ New Dashboard
- ç‚¹å‡» "Add visualization"
- é€‰æ‹©æ•°æ®æº: Prometheus

æ­¥éª¤2: æ·»åŠ é›†ç¾¤èŠ‚ç‚¹æ•°é¢æ¿
- Panel Title: Cluster Nodes
- Visualization: Stat (ç»Ÿè®¡)
- Query:
  count(kube_node_info)
- è®¾ç½®:
  - Value options â†’ Show: Calculate â†’ Last (éç©º)
  - Standard options â†’ Unit: none
  - Standard options â†’ Color scheme: Green
  - Thresholds: æ­£å¸¸(ç»¿è‰²), <3 è­¦å‘Š(é»„è‰²), <2 ä¸¥é‡(çº¢è‰²)

æ­¥éª¤3: æ·»åŠ Podæ•°é‡é¢æ¿
- Panel Title: Running Pods
- Visualization: Stat
- Query:
  count(kube_pod_status_phase{phase="Running"})

æ­¥éª¤4: æ·»åŠ CPUä½¿ç”¨ç‡é¢æ¿
- Panel Title: Cluster CPU Usage
- Visualization: Time series (æ—¶åºå›¾)
- Query:
  100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
- Legend: Hide (å› ä¸ºåªæœ‰ä¸€æ¡çº¿)

æ­¥éª¤5: æ·»åŠ å†…å­˜ä½¿ç”¨ç‡é¢æ¿
- Panel Title: Cluster Memory Usage
- Visualization: Time series
- Query:
  (1 - (sum(node_memory_MemAvailable_bytes) / sum(node_memory_MemTotal_bytes))) * 100
```

**2. Dashboardå®Œæ•´JSONç¤ºä¾‹**

```json
{
  "dashboard": {
    "title": "Kubernetes Cluster Overview",
    "tags": ["kubernetes", "cluster"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
        "type": "stat",
        "title": "Cluster Nodes",
        "targets": [
          {
            "expr": "count(kube_node_info)",
            "refId": "A"
          }
        ],
        "options": {
          "colorMode": "background",
          "graphMode": "none",
          "textMode": "value_and_name"
        },
        "fieldConfig": {
          "defaults": {
            "unit": "none",
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": null, "color": "red"},
                {"value": 3, "color": "yellow"},
                {"value": 5, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0},
        "type": "stat",
        "title": "Running Pods",
        "targets": [
          {
            "expr": "count(kube_pod_status_phase{phase=\"Running\"})",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "thresholds"},
            "thresholds": {
              "steps": [
                {"value": null, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "id": 3,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4},
        "type": "timeseries",
        "title": "CPU Usage",
        "targets": [
          {
            "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage %",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "color": {"mode": "palette-classic"}
          }
        }
      }
    ],
    "time": {
      "from": "now-6h",
      "to": "now"
    },
    "timepicker": {
      "refresh_intervals": ["5s", "10s", "30s", "1m", "5m"]
    },
    "refresh": "30s"
  }
}
```

#### å›¾è¡¨ç±»å‹é€‰æ‹©æŒ‡å—

| å›¾è¡¨ç±»å‹ | é€‚ç”¨åœºæ™¯ | å…¸å‹æŒ‡æ ‡ |
|---------|---------|---------|
| **Time series** | å±•ç¤ºæ—¶åºè¶‹åŠ¿ | CPUä½¿ç”¨ç‡ã€å†…å­˜ã€ç½‘ç»œæµé‡ |
| **Stat** | æ˜¾ç¤ºå•ä¸€æ•°å€¼ | èŠ‚ç‚¹æ•°ã€Podæ•°ã€å½“å‰QPS |
| **Gauge** | æ˜¾ç¤ºç™¾åˆ†æ¯” | CPUä½¿ç”¨ç‡ã€ç£ç›˜ä½¿ç”¨ç‡ |
| **Bar gauge** | å¤šä¸ªæ¡å½¢å¯¹æ¯” | å„èŠ‚ç‚¹å†…å­˜ä½¿ç”¨å¯¹æ¯” |
| **Table** | å±•ç¤ºæ˜ç»†æ•°æ® | Podåˆ—è¡¨ã€å‘Šè­¦åˆ—è¡¨ |
| **Heatmap** | å±•ç¤ºåˆ†å¸ƒ | å»¶è¿Ÿåˆ†å¸ƒã€é”™è¯¯ç åˆ†å¸ƒ |
| **Pie chart** | å±•ç¤ºå æ¯” | å„å‘½åç©ºé—´Podå æ¯” |
| **Logs** | æ—¥å¿—æµ | åº”ç”¨æ—¥å¿—ã€é”™è¯¯æ—¥å¿— |
| **Node Graph** | æœåŠ¡æ‹“æ‰‘ | å¾®æœåŠ¡è°ƒç”¨å…³ç³» |

#### Dashboardè®¾è®¡åŸåˆ™

**1. ä¿¡æ¯å±‚æ¬¡ (é‡‘å­—å¡”åŸåˆ™)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 1: å…¨å±€çŠ¶æ€ (é¡¶éƒ¨)                â”‚
â”‚  - å…³é”®æŒ‡æ ‡ (Stat/Gauge)                â”‚
â”‚  - ä¸€çœ¼çœ‹å‡ºç³»ç»Ÿå¥åº·çŠ¶æ€                  â”‚
â”‚  - ç¤ºä¾‹: èŠ‚ç‚¹æ•°ã€CPUã€å†…å­˜ã€å‘Šè­¦æ•°       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 2: æ ¸å¿ƒè¶‹åŠ¿ (ä¸­éƒ¨)                â”‚
â”‚  - æ—¶åºå›¾ (Time series)                 â”‚
â”‚  - å±•ç¤ºå…³é”®æŒ‡æ ‡çš„å†å²è¶‹åŠ¿                â”‚
â”‚  - ç¤ºä¾‹: CPU/å†…å­˜è¶‹åŠ¿ã€ç½‘ç»œæµé‡ã€QPS    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 3: è¯¦ç»†æ•°æ® (åº•éƒ¨)                â”‚
â”‚  - è¡¨æ ¼/æ˜ç»† (Table)                    â”‚
â”‚  - ç”¨äºæ·±å…¥åˆ†æå’Œæ’æŸ¥é—®é¢˜                â”‚
â”‚  - ç¤ºä¾‹: Podåˆ—è¡¨ã€Top 10 CPU Pod        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç¤ºä¾‹å¸ƒå±€**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Nodes: 10] [Pods: 127] [CPU: 45%] [Memory: 62%] [ğŸ”´ Alerts: 3] â”‚  â† Level 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   CPU Usage %       â”‚  â”‚   Memory Usage %    â”‚        â”‚  â† Level 2
â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Network I/O        â”‚  â”‚   Disk I/O          â”‚        â”‚
â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚  â”‚  [æŠ˜çº¿å›¾ - 6h]       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Top 10 Pods by CPU Usage                            â”‚ â”‚  â† Level 3
â”‚  â”‚  [Table: Podåç§° | å‘½åç©ºé—´ | CPU | å†…å­˜ | çŠ¶æ€]      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**2. é…è‰²åŸåˆ™**

```yaml
# ä½¿ç”¨è¯­ä¹‰åŒ–é¢œè‰²
å¥åº·çŠ¶æ€: ç»¿è‰² (#73BF69)
è­¦å‘ŠçŠ¶æ€: é»„è‰² (#F2CC0C)
é”™è¯¯çŠ¶æ€: çº¢è‰² (#E02F44)
ä¿¡æ¯å±•ç¤º: è“è‰² (#5794F2)

# é¿å…:
- è¿‡å¤šé¢œè‰² (ä¸è¶…è¿‡5ç§ä¸»è‰²)
- é¥±å’Œåº¦è¿‡é«˜ (åˆºçœ¼)
- çº¢ç»¿è‰²ç›²ä¸å‹å¥½çš„é…è‰²
```

**3. æ—¶é—´èŒƒå›´è®¾ç½®**

```yaml
é»˜è®¤æ—¶é—´èŒƒå›´å»ºè®®:
- å®æ—¶ç›‘æ§: Last 15 minutes (å¿«é€Ÿå‘ç°é—®é¢˜)
- è¶‹åŠ¿åˆ†æ: Last 6 hours (æŸ¥çœ‹æ—¥å†…è¶‹åŠ¿)
- å®¹é‡è§„åˆ’: Last 7 days (å‘¨æœŸæ€§åˆ†æ)
- æœˆåº¦æŠ¥å‘Š: Last 30 days

åˆ·æ–°é—´éš”å»ºè®®:
- å®æ—¶ç›‘æ§: 5s-10s
- æ™®é€šç›‘æ§: 30s-1m
- å†å²åˆ†æ: å…³é—­è‡ªåŠ¨åˆ·æ–° (Manual)
```

**4. Panelä¼˜åŒ–æŠ€å·§**

```yaml
# å‡å°‘æŸ¥è¯¢æ•°é‡
âŒ é”™è¯¯: æ¯ä¸ªPanelä¸€ä¸ªæŸ¥è¯¢
âœ… æ­£ç¡®: ä½¿ç”¨å¤šä¸ªSeriesåœ¨ä¸€ä¸ªPanelä¸­

# ä½¿ç”¨åˆç†çš„æ—¶é—´èŒƒå›´
âŒ é”™è¯¯: rate(http_requests_total[1d])
âœ… æ­£ç¡®: rate(http_requests_total[5m])

# æ·»åŠ æœ‰æ„ä¹‰çš„Legend
âŒ é”™è¯¯: {{instance}}
âœ… æ­£ç¡®: {{namespace}}/{{pod}} - {{container}}

# è®¾ç½®åˆç†çš„Yè½´èŒƒå›´
æ—¶é—´åºåˆ—: Min=0, Max=Auto (é¿å…Yè½´æŠ–åŠ¨)
ç™¾åˆ†æ¯”: Min=0, Max=100
```

---

### 9.3.4 å˜é‡ä¸æ¨¡æ¿åº”ç”¨

å˜é‡ (Variables) æ˜¯Grafanaæœ€å¼ºå¤§çš„åŠŸèƒ½ä¹‹ä¸€ï¼Œå®ƒè®©ä¸€ä¸ªDashboardå¯ä»¥é€‚é…å¤šä¸ªç¯å¢ƒ/é›†ç¾¤/æœåŠ¡ã€‚

#### å˜é‡ç±»å‹

**1. Queryå˜é‡ (ä»æ•°æ®æºæŸ¥è¯¢)**

æœ€å¸¸ç”¨çš„å˜é‡ç±»å‹ï¼Œä»PrometheusæŸ¥è¯¢æ ‡ç­¾å€¼ã€‚

```yaml
# å˜é‡å: cluster
# ç±»å‹: Query
# æ•°æ®æº: Prometheus
# Query:
label_values(kube_node_info, cluster)

# ç”¨æ³•: åœ¨Panelä¸­ä½¿ç”¨ $cluster
up{cluster="$cluster"}
```

**å®Œæ•´é…ç½®ç¤ºä¾‹**ï¼š

```json
{
  "name": "namespace",
  "type": "query",
  "datasource": "Prometheus",
  "query": "label_values(kube_pod_info, namespace)",
  "regex": "",
  "sort": 1,
  "refresh": 2,
  "multi": true,
  "includeAll": true,
  "allValue": ".*",
  "current": {
    "selected": true,
    "text": "All",
    "value": "$__all"
  }
}
```

**å…³é”®é…ç½®é¡¹**ï¼š

| é…ç½®é¡¹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|
| **multi** | æ˜¯å¦å…è®¸å¤šé€‰ | true: å¯é€‰å¤šä¸ªå‘½åç©ºé—´ |
| **includeAll** | æ˜¯å¦åŒ…å«"All"é€‰é¡¹ | true: æ˜¾ç¤ºæ‰€æœ‰å‘½åç©ºé—´ |
| **allValue** | "All"çš„å®é™…å€¼ | ".*" (æ­£åˆ™åŒ¹é…æ‰€æœ‰) |
| **refresh** | åˆ·æ–°ç­–ç•¥ | On Dashboard Load (åŠ è½½æ—¶) |
| **sort** | æ’åºæ–¹å¼ | 1: Alphabetical (å­—æ¯åº) |
| **regex** | è¿‡æ»¤ç»“æœ | /^prod-.*/ (åªæ˜¾ç¤ºprodå¼€å¤´) |

**2. Customå˜é‡ (è‡ªå®šä¹‰åˆ—è¡¨)**

æ‰‹åŠ¨å®šä¹‰çš„å›ºå®šåˆ—è¡¨ã€‚

```json
{
  "name": "environment",
  "type": "custom",
  "query": "production,staging,development",
  "current": {
    "text": "production",
    "value": "production"
  }
}
```

**3. Constantå˜é‡ (å¸¸é‡)**

å›ºå®šå€¼ï¼Œé€šå¸¸ç”¨äºå…¨å±€é…ç½®ã€‚

```json
{
  "name": "alert_threshold",
  "type": "constant",
  "query": "80",
  "hide": 2  // 0: æ˜¾ç¤º, 1: æ˜¾ç¤ºæ ‡ç­¾, 2: å®Œå…¨éšè—
}
```

**4. Intervalå˜é‡ (æ—¶é—´é—´éš”)**

åŠ¨æ€è°ƒæ•´æŸ¥è¯¢æ—¶é—´èŒƒå›´ã€‚

```json
{
  "name": "interval",
  "type": "interval",
  "query": "1m,5m,10m,30m,1h,6h,12h,1d",
  "auto": true,
  "auto_count": 30,
  "auto_min": "10s"
}
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```promql
# ä½¿ç”¨$intervalå˜é‡
rate(http_requests_total[$interval])

# Grafanaä¼šæ ¹æ®æ—¶é—´èŒƒå›´è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„interval
# æ—¶é—´èŒƒå›´: 1å°æ—¶ â†’ interval: 1m
# æ—¶é—´èŒƒå›´: 7å¤©  â†’ interval: 1h
```

**5. Data sourceå˜é‡ (æ•°æ®æº)**

åœ¨å¤šä¸ªæ•°æ®æºé—´åˆ‡æ¢ã€‚

```json
{
  "name": "datasource",
  "type": "datasource",
  "query": "prometheus",
  "current": {
    "text": "Prometheus-Prod",
    "value": "Prometheus-Prod"
  }
}
```

#### å˜é‡é«˜çº§ç”¨æ³•

**1. çº§è”å˜é‡ (Chained Variables)**

ä¸€ä¸ªå˜é‡ä¾èµ–å¦ä¸€ä¸ªå˜é‡çš„å€¼ã€‚

```yaml
# å˜é‡1: cluster
Query: label_values(kube_node_info, cluster)

# å˜é‡2: namespace (ä¾èµ–cluster)
Query: label_values(kube_pod_info{cluster="$cluster"}, namespace)

# å˜é‡3: pod (ä¾èµ–namespace)
Query: label_values(kube_pod_info{cluster="$cluster", namespace="$namespace"}, pod)
```

**ä½¿ç”¨æ•ˆæœ**ï¼š
```
é€‰æ‹© cluster=production â†’ namespaceä¸‹æ‹‰åˆ—è¡¨åªæ˜¾ç¤ºproductioné›†ç¾¤çš„å‘½åç©ºé—´
é€‰æ‹© namespace=api â†’ podä¸‹æ‹‰åˆ—è¡¨åªæ˜¾ç¤ºapiå‘½åç©ºé—´çš„Pod
```

**2. æ­£åˆ™è¿‡æ»¤**

```yaml
# åªæ˜¾ç¤ºä»¥"prod-"å¼€å¤´çš„å‘½åç©ºé—´
Query: label_values(kube_pod_info, namespace)
Regex: /^prod-.*/

# æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´
Query: label_values(kube_pod_info, namespace)
Regex: /^(?!kube-|default).*/
```

**3. å˜é‡æ ¼å¼åŒ–**

åœ¨æŸ¥è¯¢ä¸­ä½¿ç”¨å˜é‡æ—¶ï¼Œå¯ä»¥ç”¨ä¸åŒçš„æ ¼å¼ï¼š

```promql
# åŸå§‹å€¼
up{namespace="$namespace"}

# æ­£åˆ™åŒ¹é… (å¤šé€‰æ—¶)
up{namespace=~"$namespace"}

# Pipeåˆ†éš” (ç”¨äºLoki)
{namespace=~"${namespace:pipe}"}
# ç»“æœ: {namespace=~"api|web|worker"}

# CSVæ ¼å¼
# ç»“æœ: "api","web","worker"

# JSONæ ¼å¼
# ç»“æœ: ["api","web","worker"]
```

**å¸¸ç”¨æ ¼å¼åŒ–é€‰é¡¹**ï¼š

| æ ¼å¼ | è¯­æ³• | è¾“å‡ºç¤ºä¾‹ | ç”¨é€” |
|------|------|---------|------|
| **regex** | `${var:regex}` | `api\|web` | Prometheusæ ‡ç­¾åŒ¹é… |
| **pipe** | `${var:pipe}` | `api\|web` | LokiæŸ¥è¯¢ |
| **csv** | `${var:csv}` | `"api","web"` | SQL INæŸ¥è¯¢ |
| **json** | `${var:json}` | `["api","web"]` | JSON API |
| **raw** | `${var:raw}` | `$__all` | è·å–åŸå§‹å€¼ |

#### å®æˆ˜: å¤šé›†ç¾¤å¤šç¯å¢ƒé€šç”¨Dashboard

**å˜é‡é…ç½®**ï¼š

```yaml
# 1. æ•°æ®æºå˜é‡
Name: datasource
Type: Data source
Query: prometheus
Label: Prometheusæ•°æ®æº

# 2. é›†ç¾¤å˜é‡
Name: cluster
Type: Query
Datasource: $datasource
Query: label_values(kube_node_info, cluster)
Label: é›†ç¾¤
Multi-value: true
Include All: true

# 3. å‘½åç©ºé—´å˜é‡
Name: namespace
Type: Query
Datasource: $datasource
Query: label_values(kube_pod_info{cluster=~"$cluster"}, namespace)
Label: å‘½åç©ºé—´
Multi-value: true
Include All: true
Regex: /^(?!kube-|default).*/  # æ’é™¤ç³»ç»Ÿå‘½åç©ºé—´

# 4. åº”ç”¨å˜é‡
Name: app
Type: Query
Datasource: $datasource
Query: label_values(kube_pod_labels{cluster=~"$cluster", namespace=~"$namespace"}, label_app)
Label: åº”ç”¨
Multi-value: true
Include All: true

# 5. æ—¶é—´é—´éš”å˜é‡
Name: interval
Type: Interval
Query: 1m,5m,10m,30m,1h
Auto: true
Auto min: 30s
```

**PanelæŸ¥è¯¢ç¤ºä¾‹**ï¼š

```promql
# CPUä½¿ç”¨ç‡ (æ”¯æŒå¤šé›†ç¾¤/å¤šå‘½åç©ºé—´/å¤šåº”ç”¨)
sum(rate(container_cpu_usage_seconds_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  pod=~"$app.*"
}[$interval])) by (pod)

# å†…å­˜ä½¿ç”¨
sum(container_memory_working_set_bytes{
  cluster=~"$cluster",
  namespace=~"$namespace",
  pod=~"$app.*"
}) by (pod) / 1024 / 1024 / 1024

# QPS
sum(rate(http_requests_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app, method)

# é”™è¯¯ç‡
sum(rate(http_requests_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  app=~"$app",
  status=~"5.."
}[$interval])) by (app)
  /
sum(rate(http_requests_total{
  cluster=~"$cluster",
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app)
  * 100
```

**ä½¿ç”¨ä½“éªŒ**ï¼š

```
é¡¶éƒ¨å˜é‡æ :
[Prometheusæ•°æ®æº â–¼] [é›†ç¾¤: All â–¼] [å‘½åç©ºé—´: All â–¼] [åº”ç”¨: All â–¼] [é—´éš”: Auto â–¼]

ç”¨æˆ·æ“ä½œ:
1. é€‰æ‹©æ•°æ®æº: Prometheus-Prod
2. é€‰æ‹©é›†ç¾¤: production
3. é€‰æ‹©å‘½åç©ºé—´: api, web (å¤šé€‰)
4. é€‰æ‹©åº”ç”¨: user-service, order-service (å¤šé€‰)

â†’ Dashboardè‡ªåŠ¨åˆ·æ–°ï¼Œåªæ˜¾ç¤ºé€‰ä¸­çš„Podæ•°æ®
â†’ ä¸€ä¸ªDashboardé€‚é…æ‰€æœ‰ç¯å¢ƒï¼
```

---

### 9.3.5 ä¼ä¸šçº§ä»ªè¡¨ç›˜ç¤ºä¾‹

#### Dashboard 1: Kubernetesé›†ç¾¤æ€»è§ˆ

**ç›®æ ‡å—ä¼—**: è¿ç»´å›¢é˜Ÿã€ç®¡ç†å±‚
**åˆ·æ–°é—´éš”**: 30ç§’
**æ—¶é—´èŒƒå›´**: æœ€è¿‘6å°æ—¶

**å¸ƒå±€è®¾è®¡**ï¼š

```yaml
Row 1: å…³é”®æŒ‡æ ‡ (Stat)
- é›†ç¾¤èŠ‚ç‚¹æ•° (Ready/Total)
- è¿è¡Œä¸­çš„Podæ•°é‡
- å½“å‰CPUä½¿ç”¨ç‡
- å½“å‰å†…å­˜ä½¿ç”¨ç‡
- æ´»è·ƒå‘Šè­¦æ•°é‡

Row 2: èµ„æºè¶‹åŠ¿ (Time series)
- CPUä½¿ç”¨ç‡è¶‹åŠ¿ (6å°æ—¶)
- å†…å­˜ä½¿ç”¨ç‡è¶‹åŠ¿ (6å°æ—¶)
- ç½‘ç»œI/O (æ¥æ”¶/å‘é€)
- ç£ç›˜I/O (è¯»/å†™)

Row 3: èŠ‚ç‚¹çŠ¶æ€ (Table)
- èŠ‚ç‚¹åˆ—è¡¨ (åç§°/çŠ¶æ€/CPU/å†…å­˜/Podæ•°/å¹´é¾„)
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# èŠ‚ç‚¹Readyæ•°é‡
count(kube_node_status_condition{condition="Ready", status="true"})

# æ€»èŠ‚ç‚¹æ•°
count(kube_node_info)

# é›†ç¾¤CPUä½¿ç”¨ç‡
(1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100

# é›†ç¾¤å†…å­˜ä½¿ç”¨ç‡
(1 - sum(node_memory_MemAvailable_bytes) / sum(node_memory_MemTotal_bytes)) * 100

# è¿è¡Œä¸­çš„Pod
count(kube_pod_status_phase{phase="Running"})

# æ´»è·ƒå‘Šè­¦
count(ALERTS{alertstate="firing"})

# èŠ‚ç‚¹è¯¦æƒ…è¡¨æ ¼
sort_desc(
  (1 - avg by (node) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100
)
```

#### Dashboard 2: åº”ç”¨æ€§èƒ½ç›‘æ§ (REDæ–¹æ³•)

**ç›®æ ‡å—ä¼—**: å¼€å‘å›¢é˜Ÿã€SRE
**åˆ·æ–°é—´éš”**: 10ç§’
**æ—¶é—´èŒƒå›´**: æœ€è¿‘1å°æ—¶

**å¸ƒå±€è®¾è®¡**ï¼š

```yaml
Row 1: REDæŒ‡æ ‡ (Stat + Gauge)
- å½“å‰QPS
- å¹³å‡å»¶è¿Ÿ
- P95å»¶è¿Ÿ
- P99å»¶è¿Ÿ
- é”™è¯¯ç‡ (%)
- æˆåŠŸç‡ (%)

Row 2: è¶‹åŠ¿å›¾ (Time series)
- QPSè¶‹åŠ¿ (æŒ‰methodåˆ†ç»„)
- å»¶è¿Ÿè¶‹åŠ¿ (P50/P95/P99)
- é”™è¯¯ç‡è¶‹åŠ¿

Row 3: è¯¦ç»†åˆ†æ
- HTTPçŠ¶æ€ç åˆ†å¸ƒ (é¥¼å›¾)
- æ…¢è¯·æ±‚Top 10 (Table)
- é”™è¯¯æ—¥å¿— (Logsé¢æ¿)
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# Rate: QPS
sum(rate(http_requests_total{
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app, method)

# Errors: é”™è¯¯ç‡
sum(rate(http_requests_total{
  namespace=~"$namespace",
  app=~"$app",
  status=~"5.."
}[$interval])) by (app)
  /
sum(rate(http_requests_total{
  namespace=~"$namespace",
  app=~"$app"
}[$interval])) by (app)
  * 100

# Duration: P95å»¶è¿Ÿ
histogram_quantile(0.95,
  sum(rate(http_request_duration_seconds_bucket{
    namespace=~"$namespace",
    app=~"$app"
  }[$interval])) by (le, app)
)

# Duration: P99å»¶è¿Ÿ
histogram_quantile(0.99,
  sum(rate(http_request_duration_seconds_bucket{
    namespace=~"$namespace",
    app=~"$app"
  }[$interval])) by (le, app)
)

# HTTPçŠ¶æ€ç åˆ†å¸ƒ
sum by (status) (
  increase(http_requests_total{
    namespace=~"$namespace",
    app=~"$app"
  }[1h])
)
```

#### Dashboard 3: èŠ‚ç‚¹è¯¦ç»†ç›‘æ§

**ç›®æ ‡å—ä¼—**: è¿ç»´å›¢é˜Ÿ
**åˆ·æ–°é—´éš”**: 30ç§’
**æ—¶é—´èŒƒå›´**: æœ€è¿‘6å°æ—¶

```yaml
Variables:
- node: label_values(kube_node_info, node)

Row 1: èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯
- èŠ‚ç‚¹åç§°
- èŠ‚ç‚¹IP
- å†…æ ¸ç‰ˆæœ¬
- kubeletç‰ˆæœ¬
- è¿è¡Œæ—¶é—´

Row 2: CPUè¯¦æƒ…
- CPUä½¿ç”¨ç‡ (%)
- CPUå„æ¨¡å¼æ—¶é—´ (user/system/iowait/idle)
- CPUè´Ÿè½½ (1m/5m/15m)
- CPUæ ¸å¿ƒä½¿ç”¨åˆ†å¸ƒ

Row 3: å†…å­˜è¯¦æƒ…
- å†…å­˜ä½¿ç”¨ç‡ (%)
- å†…å­˜ä½¿ç”¨æ˜ç»† (used/free/buffers/cached)
- Swapä½¿ç”¨ç‡

Row 4: ç£ç›˜è¯¦æƒ…
- ç£ç›˜ä½¿ç”¨ç‡ (æŒ‰æŒ‚è½½ç‚¹)
- ç£ç›˜IOPS (è¯»/å†™)
- ç£ç›˜ååé‡ (è¯»/å†™ MB/s)

Row 5: ç½‘ç»œè¯¦æƒ…
- ç½‘ç»œæµé‡ (æ¥æ”¶/å‘é€ MB/s)
- ç½‘ç»œé”™è¯¯ç‡
- TCPè¿æ¥çŠ¶æ€åˆ†å¸ƒ
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# èŠ‚ç‚¹CPUä½¿ç”¨ç‡
100 - (avg by (instance) (
  irate(node_cpu_seconds_total{
    instance="$node",
    mode="idle"
  }[5m])
) * 100)

# èŠ‚ç‚¹å†…å­˜ä½¿ç”¨ç‡
(1 - (
  node_memory_MemAvailable_bytes{instance="$node"}
    /
  node_memory_MemTotal_bytes{instance="$node"}
)) * 100

# ç£ç›˜ä½¿ç”¨ç‡
(node_filesystem_size_bytes{instance="$node", fstype!~"tmpfs|fuse.*"}
  -
node_filesystem_free_bytes{instance="$node", fstype!~"tmpfs|fuse.*"})
  /
node_filesystem_size_bytes{instance="$node", fstype!~"tmpfs|fuse.*"}
  * 100

# ç½‘ç»œæ¥æ”¶é€Ÿç‡ (MB/s)
rate(node_network_receive_bytes_total{instance="$node", device!="lo"}[5m]) / 1024 / 1024

# ç½‘ç»œå‘é€é€Ÿç‡ (MB/s)
rate(node_network_transmit_bytes_total{instance="$node", device!="lo"}[5m]) / 1024 / 1024
```

#### Dashboard 4: Podè¯¦ç»†ç›‘æ§

```yaml
Variables:
- namespace
- pod

Row 1: PodåŸºæœ¬ä¿¡æ¯
- PodçŠ¶æ€
- é‡å¯æ¬¡æ•°
- Nodeä½ç½®
- IPåœ°å€
- åˆ›å»ºæ—¶é—´

Row 2: å®¹å™¨èµ„æºä½¿ç”¨
- CPUä½¿ç”¨ (millicores)
- å†…å­˜ä½¿ç”¨ (MB)
- CPUä½¿ç”¨ vs Requests/Limits
- å†…å­˜ä½¿ç”¨ vs Requests/Limits

Row 3: ç½‘ç»œä¸å­˜å‚¨
- ç½‘ç»œæµé‡
- æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨
- Volumeä½¿ç”¨ç‡

Row 4: æ—¥å¿—ä¸äº‹ä»¶
- å®¹å™¨æ—¥å¿— (Loki)
- Podäº‹ä»¶
```

**å…³é”®æŸ¥è¯¢**ï¼š

```promql
# Pod CPUä½¿ç”¨ (millicores)
sum(rate(container_cpu_usage_seconds_total{
  namespace="$namespace",
  pod="$pod",
  container!=""
}[5m])) by (container) * 1000

# Podå†…å­˜ä½¿ç”¨ (MB)
sum(container_memory_working_set_bytes{
  namespace="$namespace",
  pod="$pod",
  container!=""
}) by (container) / 1024 / 1024

# Podé‡å¯æ¬¡æ•°
kube_pod_container_status_restarts_total{
  namespace="$namespace",
  pod="$pod"
}

# Pod CPU Requests
sum(kube_pod_container_resource_requests{
  namespace="$namespace",
  pod="$pod",
  resource="cpu"
}) by (container)

# Pod CPU Limits
sum(kube_pod_container_resource_limits{
  namespace="$namespace",
  pod="$pod",
  resource="cpu"
}) by (container)
```

---

### 9.3.6 Dashboardå¯¼å…¥å¯¼å‡ºä¸å…±äº«

#### å¯¼å‡ºDashboard

**æ–¹å¼1: é€šè¿‡UIå¯¼å‡º**

```
1. æ‰“å¼€Dashboard
2. ç‚¹å‡»å³ä¸Šè§’ "Share" å›¾æ ‡
3. é€‰æ‹© "Export" æ ‡ç­¾
4. ç‚¹å‡» "Save to file" ä¸‹è½½JSONæ–‡ä»¶
```

**æ–¹å¼2: é€šè¿‡APIå¯¼å‡º**

```bash
# è·å–Dashboard UID
DASHBOARD_UID="abc123"

# å¯¼å‡ºDashboard JSON
curl -u admin:admin123 \
  http://grafana:3000/api/dashboards/uid/$DASHBOARD_UID \
  | jq '.dashboard' > dashboard.json
```

#### å¯¼å…¥Dashboard

**æ–¹å¼1: é€šè¿‡UIå¯¼å…¥**

```
1. å·¦ä¾§èœå• â†’ Dashboards â†’ Import
2. ä¸Šä¼ JSONæ–‡ä»¶æˆ–ç²˜è´´JSONå†…å®¹
3. é€‰æ‹©æ•°æ®æº
4. ç‚¹å‡» "Import"
```

**æ–¹å¼2: é€šè¿‡Provisioningè‡ªåŠ¨å¯¼å…¥**

```yaml
# dashboards.yaml
apiVersion: 1
providers:
- name: 'default'
  orgId: 1
  folder: ''
  type: file
  disableDeletion: false
  updateIntervalSeconds: 30
  allowUiUpdates: true
  options:
    path: /etc/grafana/provisioning/dashboards
```

```yaml
# åœ¨Kubernetesä¸­æŒ‚è½½Dashboard JSON
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: monitoring
data:
  k8s-cluster.json: |
    {
      "dashboard": {
        "title": "Kubernetes Cluster",
        ...
      }
    }
---
# åœ¨Deploymentä¸­æŒ‚è½½
spec:
  volumes:
  - name: dashboards
    configMap:
      name: grafana-dashboards
  containers:
  - name: grafana
    volumeMounts:
    - name: dashboards
      mountPath: /etc/grafana/provisioning/dashboards
```

#### ä»å®˜æ–¹åº“å¯¼å…¥Dashboard

Grafanaå®˜æ–¹æä¾›äº†æ•°åƒä¸ªç¤¾åŒºDashboardï¼šhttps://grafana.com/grafana/dashboards

**æ¨èçš„Kubernetes Dashboard**ï¼š

| Dashboard ID | åç§° | è¯´æ˜ |
|-------------|------|------|
| **315** | Kubernetes cluster monitoring | é›†ç¾¤æ•´ä½“ç›‘æ§ |
| **747** | Kubernetes Deployment | Deploymentç›‘æ§ |
| **1860** | Node Exporter Full | èŠ‚ç‚¹è¯¦ç»†ç›‘æ§ |
| **3119** | Kubernetes Cluster (Prometheus) | é›†ç¾¤èµ„æºç›‘æ§ |
| **6417** | Kubernetes Cluster Monitoring | å…¨é¢çš„é›†ç¾¤ç›‘æ§ |
| **7249** | Kubernetes Cluster | ç®€æ´çš„é›†ç¾¤è§†å›¾ |
| **12114** | Kubernetes Nodes | èŠ‚ç‚¹ç›‘æ§ |
| **13770** | Kubernetes / Views / Pods | Podè¯¦ç»†ç›‘æ§ |

**å¯¼å…¥æ­¥éª¤**ï¼š

```
1. è®¿é—® https://grafana.com/grafana/dashboards/315
2. å¤åˆ¶Dashboard ID: 315
3. åœ¨Grafanaä¸­: Dashboards â†’ Import
4. è¾“å…¥Dashboard ID: 315
5. é€‰æ‹©Prometheusæ•°æ®æº
6. ç‚¹å‡»Import
```

#### Dashboardæƒé™ç®¡ç†

**1. Organizationçº§åˆ«æƒé™**

```
Admin: å®Œå…¨æ§åˆ¶ (åˆ›å»º/ç¼–è¾‘/åˆ é™¤Dashboard)
Editor: å¯ç¼–è¾‘Dashboard
Viewer: åªè¯»è®¿é—®
```

**2. Dashboardçº§åˆ«æƒé™**

```yaml
# é€šè¿‡UIè®¾ç½®:
Dashboard â†’ Settings â†’ Permissions

# æ·»åŠ æƒé™:
- User: alice@example.com, Role: Editor
- Team: SRE Team, Role: Admin
- Organization: Main Org, Role: Viewer
```

**3. æ–‡ä»¶å¤¹æƒé™**

```yaml
# åˆ›å»ºæ–‡ä»¶å¤¹å¹¶è®¾ç½®æƒé™
Dashboards â†’ New Folder â†’ "Production"

# è®¾ç½®æƒé™:
- Team: SRE Team â†’ Admin
- Team: Dev Team â†’ Editor
- Everyone Else â†’ Viewer
```

---

**ğŸ“Š 9.3èŠ‚æ€»ç»“**

æœ¬èŠ‚æˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†Grafanaå¯è§†åŒ–å¹³å°çš„éƒ¨ç½²ä¸ä½¿ç”¨ï¼š

âœ… **Grafanaéƒ¨ç½²**ï¼š
- Helm Chartå¿«é€Ÿéƒ¨ç½²
- æ‰‹åŠ¨éƒ¨ç½²å®Œæ•´é…ç½®
- é…ç½®æ–‡ä»¶è¯¦è§£ (grafana.ini)

âœ… **æ•°æ®æºé›†æˆ**ï¼š
- Prometheusæ•°æ®æºé…ç½® (åŸºç¡€/é«˜çº§/å¤šé›†ç¾¤)
- Lokiæ—¥å¿—æ•°æ®æº
- Jaegeré“¾è·¯è¿½è¸ªæ•°æ®æº
- Elasticsearchæ•°æ®æº

âœ… **ä»ªè¡¨ç›˜è®¾è®¡**ï¼š
- DashboardåŸºç¡€æ¦‚å¿µä¸ç»“æ„
- å›¾è¡¨ç±»å‹é€‰æ‹©æŒ‡å—
- è®¾è®¡åŸåˆ™ (ä¿¡æ¯å±‚æ¬¡/é…è‰²/æ—¶é—´èŒƒå›´)
- Panelä¼˜åŒ–æŠ€å·§

âœ… **å˜é‡ä¸æ¨¡æ¿**ï¼š
- 5ç§å˜é‡ç±»å‹ (Query/Custom/Constant/Interval/Data source)
- å˜é‡é«˜çº§ç”¨æ³• (çº§è”/æ­£åˆ™/æ ¼å¼åŒ–)
- å¤šé›†ç¾¤å¤šç¯å¢ƒé€šç”¨Dashboard

âœ… **ä¼ä¸šçº§Dashboard**ï¼š
- é›†ç¾¤æ€»è§ˆDashboard
- REDæ–¹æ³•åº”ç”¨æ€§èƒ½ç›‘æ§
- èŠ‚ç‚¹è¯¦ç»†ç›‘æ§
- Podè¯¦ç»†ç›‘æ§

âœ… **Dashboardç®¡ç†**ï¼š
- å¯¼å…¥å¯¼å‡ºæ–¹æ³•
- å®˜æ–¹Dashboardåº“æ¨è
- æƒé™ç®¡ç†

**ä¸‹ä¸€èŠ‚é¢„å‘Š**ï¼šæˆ‘ä»¬å°†å­¦ä¹ AlertManagerå‘Šè­¦ç®¡ç†ï¼ŒåŒ…æ‹¬å‘Šè­¦è§„åˆ™ç¼–å†™ã€å‘Šè­¦è·¯ç”±ä¸åˆ†ç»„ã€æŠ‘åˆ¶ä¸é™é»˜ç­–ç•¥ï¼Œä»¥åŠå¤šæ¸ é“é€šçŸ¥é›†æˆï¼ˆé’‰é’‰/ä¼ä¸šå¾®ä¿¡/PagerDutyï¼‰ã€‚

---
