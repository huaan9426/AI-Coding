# 第7章：调度与资源管理

> 在第6章中，我们系统学习了Kubernetes的配置与安全管理，包括ResourceQuota资源配额、Pod安全策略、RBAC权限控制和网络策略。本章将深入探讨Kubernetes的调度机制和高级资源管理，揭示Pod如何被智能分配到合适的节点，以及如何优化资源利用率。

**本章学习目标：**
- 深入理解Kubernetes调度器（kube-scheduler）工作原理
- 掌握节点选择器（NodeSelector）和节点亲和性（Node Affinity）
- 学习Pod亲和性与反亲和性（Pod Affinity/Anti-Affinity）
- 掌握污点（Taints）和容忍（Tolerations）机制
- 理解优先级（Priority）和抢占（Preemption）
- 实战：构建高可用的多层应用架构

---

## 7.1 Kubernetes调度器原理

Kubernetes调度器（kube-scheduler）是集群的"交通指挥官"，负责将新创建的Pod分配到合适的节点上运行。理解调度器的工作原理，是优化应用性能和资源利用率的关键。

### 7.1.1 为什么需要调度器

#### 7.1.1.1 资源分配的挑战

在一个包含数百个节点和数千个Pod的Kubernetes集群中，如何高效地分配资源是一个复杂的问题：

```
典型的生产集群场景：
┌──────────────────────────────────────────────────┐
│  集群规模：                                       │
│  - 节点数量：200个                                │
│  - Pod总数：5000+                                │
│  - 每天新建Pod：1000+                            │
│                                                   │
│  节点异构性：                                     │
│  - CPU型节点：64核CPU，128GB内存                 │
│  - 内存型节点：32核CPU，512GB内存                │
│  - GPU节点：16核CPU，256GB内存，8卡V100          │
│  - 边缘节点：8核CPU，16GB内存（低延迟）          │
│                                                   │
│  应用多样性：                                     │
│  - Web应用：CPU中等，内存中等，需要高可用        │
│  - 数据库：CPU低，内存高，需要持久化存储         │
│  - 机器学习：CPU高/GPU，内存极高，计算密集       │
│  - 消息队列：CPU中等，内存高，网络IO密集         │
│                                                   │
│  调度约束：                                       │
│  - 亲和性：前端Pod需要靠近后端Pod（降低延迟）   │
│  - 反亲和性：同一应用的多个副本分散到不同节点    │
│  - 污点容忍：只有特定Pod能运行在GPU节点          │
│  - 资源预留：保证关键应用的资源需求              │
└──────────────────────────────────────────────────┘
```

**没有智能调度的后果：**

| 问题 | 场景 | 影响 |
|-----|------|------|
| **资源浪费** | 小Pod调度到大节点 | 资源碎片化，浪费严重 |
| **性能下降** | CPU密集Pod和内存密集Pod挤在同一节点 | 资源竞争，性能下降 |
| **高可用性差** | 同一应用的多个副本都在一个节点 | 节点故障导致服务中断 |
| **负载不均** | 部分节点超载，部分节点空闲 | 集群利用率低 |
| **延迟增加** | 前后端应用跨可用区部署 | 网络延迟增加 |

#### 7.1.1.2 调度器的价值

**Kubernetes调度器提供的核心价值：**

```
┌─────────────────────────────────────────────────┐
│          调度器核心价值                          │
├─────────────────────────────────────────────────┤
│  ✅ 智能资源分配                                 │
│     根据节点资源和Pod需求，找到最佳匹配         │
│                                                  │
│  ✅ 高可用保障                                   │
│     通过反亲和性将副本分散到不同节点/可用区     │
│                                                  │
│  ✅ 性能优化                                     │
│     将相互依赖的Pod调度到同一节点/可用区        │
│                                                  │
│  ✅ 资源利用率最大化                             │
│     Bin Packing算法，尽量减少资源碎片           │
│                                                  │
│  ✅ 灵活的调度策略                               │
│     支持自定义调度规则和优先级                  │
│                                                  │
│  ✅ 故障自愈                                     │
│     节点故障时自动将Pod重新调度到健康节点       │
└─────────────────────────────────────────────────┘
```

**真实案例对比：**

```yaml
# ❌ 场景1：没有调度约束
# 结果：3个Nginx副本都调度到了Node1
kubectl get pods -o wide
NAME                     NODE
nginx-7c5ddbdf54-abc12   node1
nginx-7c5ddbdf54-def34   node1  # ❌ 高可用性差！
nginx-7c5ddbdf54-ghi56   node1  # ❌ Node1故障则全部宕机！

# ✅ 场景2：使用反亲和性
# 结果：3个副本分散到不同节点
kubectl get pods -o wide
NAME                     NODE
nginx-7c5ddbdf54-abc12   node1
nginx-7c5ddbdf54-def34   node2  # ✅ 高可用！
nginx-7c5ddbdf54-ghi56   node3  # ✅ 单节点故障不影响服务！
```

#### 7.1.1.3 调度的类型

Kubernetes支持多种调度方式：

```
┌────────────────┬───────────────────┬─────────────────────┐
│  调度类型      │    触发条件       │    使用场景         │
├────────────────┼───────────────────┼─────────────────────┤
│ 默认调度       │ Pod创建时         │ 大部分应用          │
│ (Default)      │ nodeName字段为空  │ (90%+场景)          │
├────────────────┼───────────────────┼─────────────────────┤
│ 绑定调度       │ Pod创建时         │ 特定节点部署        │
│ (NodeName)     │ nodeName字段指定  │ (DaemonSet等)       │
├────────────────┼───────────────────┼─────────────────────┤
│ 重新调度       │ 节点故障          │ 故障恢复            │
│ (Rescheduling) │ Pod被驱逐         │                     │
├────────────────┼───────────────────┼─────────────────────┤
│ 抢占调度       │ 资源不足          │ 高优先级Pod         │
│ (Preemption)   │ 高优先级Pod到达   │                     │
├────────────────┼───────────────────┼─────────────────────┤
│ 自定义调度     │ 配置自定义调度器  │ 特殊调度需求        │
│ (Custom)       │ schedulerName字段 │ (AI/大数据场景)     │
└────────────────┴───────────────────┴─────────────────────┘
```

### 7.1.2 调度器工作流程

#### 7.1.2.1 调度流程概览

Kubernetes调度器采用两阶段调度策略：**预选（Predicates）→ 优选（Priorities）**

```
┌─────────────────────────────────────────────────────────────┐
│              Kubernetes调度器工作流程                        │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1. 监听Pod创建                                              │
│     kube-scheduler通过Watch机制监听API Server              │
│     发现新创建的、nodeName为空的Pod                         │
│          ↓                                                   │
│  2. 预选阶段（Predicates/Filtering）                        │
│     过滤掉不符合条件的节点                                  │
│     ┌─────────────────────────────────────────┐            │
│     │ 所有节点（200个）                       │            │
│     └─────────────────────────────────────────┘            │
│          ↓                                                   │
│     [ 预选算法 ]                                             │
│     - PodFitsResources：资源是否足够？                      │
│     - PodFitsHostPorts：端口是否冲突？                      │
│     - PodMatchNodeSelector：是否匹配NodeSelector？         │
│     - PodToleratesNodeTaints：是否容忍污点？               │
│     - CheckNodeMemoryPressure：内存压力是否过大？          │
│     - CheckNodeDiskPressure：磁盘压力是否过大？            │
│          ↓                                                   │
│     ┌─────────────────────────────────────────┐            │
│     │ 可行节点（50个）                        │            │
│     └─────────────────────────────────────────┘            │
│          ↓                                                   │
│  3. 优选阶段（Priorities/Scoring）                          │
│     对可行节点打分，选择最优节点                            │
│     ┌───────────┬───────────┬───────────┐                  │
│     │ Node1: 85 │ Node2: 92 │ Node3: 78 │  ...             │
│     └───────────┴───────────┴───────────┘                  │
│          ↓                                                   │
│     [ 优选算法 ]                                             │
│     - LeastRequestedPriority：资源请求最少                 │
│     - BalancedResourceAllocation：CPU/内存均衡             │
│     - SelectorSpreadPriority：副本分散                     │
│     - NodeAffinityPriority：节点亲和性得分                 │
│     - InterPodAffinityPriority：Pod亲和性得分              │
│          ↓                                                   │
│     ┌─────────────────────────────────────────┐            │
│     │ 最优节点：Node2（得分92）              │            │
│     └─────────────────────────────────────────┘            │
│          ↓                                                   │
│  4. 绑定（Binding）                                          │
│     将Pod绑定到选定的节点                                   │
│     - 更新Pod.spec.nodeName = "node2"                       │
│     - 通知kubelet启动Pod                                    │
│          ↓                                                   │
│  5. 假设调度（Assume）                                       │
│     乐观假设Pod已调度，允许后续Pod调度                     │
│     （避免多个Pod同时调度导致资源超售）                    │
└─────────────────────────────────────────────────────────────┘
```

**详细调度流程：**

```go
// 调度器伪代码
func scheduleOne(pod *v1.Pod) {
    // 1. 预选：过滤不可行节点
    feasibleNodes := findNodesThatFit(pod, allNodes)

    if len(feasibleNodes) == 0 {
        // 没有可行节点，触发抢占或失败
        return preemptOrFail(pod)
    }

    // 2. 优选：对可行节点打分
    prioritizedNodes := prioritizeNodes(pod, feasibleNodes)

    // 3. 选择得分最高的节点
    bestNode := selectHost(prioritizedNodes)

    // 4. 假设调度（乐观锁）
    assumedPod := pod.DeepCopy()
    assumedPod.Spec.NodeName = bestNode
    scheduler.Cache.AssumePod(assumedPod)

    // 5. 异步绑定
    go func() {
        err := bind(pod, bestNode)
        if err != nil {
            scheduler.Cache.ForgetPod(assumedPod)
        }
    }()
}
```

#### 7.1.2.2 预选（Predicates）详解

预选阶段会运行一系列预选函数（Predicate Functions），过滤掉不满足条件的节点：

**核心预选算法：**

| 预选算法 | 检查内容 | 示例 |
|---------|---------|------|
| **PodFitsResources** | 节点资源是否满足Pod需求 | Pod请求2核4GB，节点剩余1核2GB → ❌ |
| **PodFitsHostPorts** | 节点端口是否被占用 | Pod使用hostPort 8080，节点已有Pod占用 → ❌ |
| **PodMatchNodeSelector** | Pod的nodeSelector是否匹配节点标签 | nodeSelector: {disk: ssd}，节点无此标签 → ❌ |
| **PodToleratesNodeTaints** | Pod是否容忍节点污点 | 节点有gpu=true:NoSchedule，Pod无容忍 → ❌ |
| **CheckNodeMemoryPressure** | 节点内存压力是否过大 | 节点内存使用>85% → ❌ |
| **CheckNodeDiskPressure** | 节点磁盘压力是否过大 | 节点磁盘使用>85% → ❌ |
| **CheckNodePIDPressure** | 节点PID资源是否耗尽 | PID数量接近上限 → ❌ |
| **CheckVolumeBinding** | 存储卷是否可绑定 | PVC要求local-storage，节点无此类型 → ❌ |
| **NoDiskConflict** | 存储卷是否冲突 | Pod使用同一GCE PD的多个Pod在同一节点 → ❌ |
| **NoVolumeZoneConflict** | 存储卷可用区是否匹配 | Pod使用us-east-1a的EBS，节点在us-east-1b → ❌ |

**预选示例：**

```yaml
# Pod资源请求
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        memory: "4Gi"
        cpu: "2"
      limits:
        memory: "8Gi"
        cpu: "4"
```

```
预选过程：

节点1：16核64GB，已使用12核58GB
  ├─ 剩余资源：4核6GB
  ├─ Pod请求：2核4GB
  └─ ✅ 通过 PodFitsResources

节点2：8核32GB，已使用7核30GB
  ├─ 剩余资源：1核2GB
  ├─ Pod请求：2核4GB
  └─ ❌ 失败 PodFitsResources（资源不足）

节点3：32核128GB，有污点gpu=true:NoSchedule
  ├─ 剩余资源：30核120GB（充足）
  ├─ Pod无toleration
  └─ ❌ 失败 PodToleratesNodeTaints

节点4：8核16GB，已有Pod使用hostPort 80
  ├─ 剩余资源：6核12GB
  ├─ Pod使用hostPort 80
  └─ ❌ 失败 PodFitsHostPorts

结果：只有节点1通过预选
```

#### 7.1.2.3 优选（Priorities）详解

优选阶段对通过预选的节点进行打分（0-100分），得分最高的节点被选中：

**核心优选算法：**

| 优选算法 | 打分逻辑 | 权重 |
|---------|---------|------|
| **LeastRequestedPriority** | 资源请求越少得分越高（Bin Packing） | 1 |
| **BalancedResourceAllocation** | CPU和内存使用率越均衡得分越高 | 1 |
| **SelectorSpreadPriority** | 同一Service/RC的Pod分散得分越高 | 1 |
| **NodeAffinityPriority** | 满足NodeAffinity偏好得分越高 | 1 |
| **InterPodAffinityPriority** | 满足PodAffinity偏好得分越高 | 1 |
| **TaintTolerationPriority** | 匹配Toleration越多得分越高 | 1 |
| **ImageLocalityPriority** | 节点已有镜像得分越高 | 1 |
| **NodePreferAvoidPodsPriority** | 避免调度到特定节点 | 10000 |

**1. LeastRequestedPriority（最少资源请求）**

鼓励将Pod调度到资源利用率低的节点，实现Bin Packing：

```
得分公式：
score = (capacity - requestedResources - podRequest) * 100 / capacity

示例：
节点1：16核64GB，已使用4核16GB
  Pod请求：2核4GB
  CPU得分 = (16 - 4 - 2) * 100 / 16 = 62.5
  内存得分 = (64 - 16 - 4) * 100 / 64 = 68.75
  平均得分 = (62.5 + 68.75) / 2 = 65.6

节点2：16核64GB，已使用8核32GB
  Pod请求：2核4GB
  CPU得分 = (16 - 8 - 2) * 100 / 16 = 37.5
  内存得分 = (64 - 32 - 4) * 100 / 64 = 43.75
  平均得分 = (37.5 + 43.75) / 2 = 40.6

结果：节点1得分更高（资源利用率低）
```

**2. BalancedResourceAllocation（资源均衡分配）**

鼓励CPU和内存使用率接近，避免某一维度资源过度使用：

```
得分公式：
cpuFraction = (podRequest.cpu + node.allocatedCPU) / node.capacity.cpu
memFraction = (podRequest.mem + node.allocatedMem) / node.capacity.mem
score = 100 - abs(cpuFraction - memFraction) * 10

示例：
节点1：16核64GB，已使用8核16GB
  Pod请求：2核8GB
  CPU使用率 = (2 + 8) / 16 = 62.5%
  内存使用率 = (8 + 16) / 64 = 37.5%
  得分 = 100 - |62.5 - 37.5| * 10 = 75

节点2：16核64GB，已使用8核32GB
  Pod请求：2核8GB
  CPU使用率 = (2 + 8) / 16 = 62.5%
  内存使用率 = (8 + 32) / 64 = 62.5%
  得分 = 100 - |62.5 - 62.5| * 10 = 100

结果：节点2得分更高（CPU/内存使用率均衡）
```

**3. SelectorSpreadPriority（副本分散）**

鼓励将同一Service/ReplicaSet的Pod分散到不同节点：

```yaml
# 假设有一个Deployment，3个副本
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
```

```
打分逻辑：

节点1：已有0个web Pod
  得分 = 100

节点2：已有1个web Pod
  得分 = 50

节点3：已有2个web Pod
  得分 = 0

结果：节点1得分最高（实现高可用）
```

**综合打分示例：**

```
假设有3个候选节点，Pod请求2核4GB：

节点1：16核64GB，已使用4核16GB，无web Pod
  LeastRequested: 65.6
  Balanced: 85
  Spread: 100
  综合得分 = (65.6 + 85 + 100) / 3 = 83.5

节点2：16核64GB，已使用8核32GB，有1个web Pod
  LeastRequested: 40.6
  Balanced: 100
  Spread: 50
  综合得分 = (40.6 + 100 + 50) / 3 = 63.5

节点3：16核64GB，已使用12核48GB，有2个web Pod
  LeastRequested: 25
  Balanced: 90
  Spread: 0
  综合得分 = (25 + 90 + 0) / 3 = 38.3

最终选择：节点1（得分83.5最高）
```

### 7.1.3 调度性能优化

#### 7.1.3.1 调度性能指标

Kubernetes调度器的性能直接影响集群的整体效率：

```
┌────────────────┬───────────────┬──────────────────┐
│  性能指标      │   目标值      │   影响            │
├────────────────┼───────────────┼──────────────────┤
│ 调度延迟       │ <100ms        │ Pod启动速度      │
│ (Scheduling    │ (P99 <500ms)  │                  │
│  Latency)      │               │                  │
├────────────────┼───────────────┼──────────────────┤
│ 调度吞吐量     │ >100 pods/s   │ 大规模扩容速度   │
│ (Throughput)   │               │                  │
├────────────────┼───────────────┼──────────────────┤
│ 调度成功率     │ >99%          │ Pod Pending时间  │
│ (Success Rate) │               │                  │
├────────────────┼───────────────┼──────────────────┤
│ 抢占次数       │ 尽量少        │ 应用稳定性       │
│ (Preemptions)  │               │                  │
└────────────────┴───────────────┴──────────────────┘
```

**查看调度器性能指标：**

```bash
# 查看调度器Metrics
kubectl get --raw /metrics | grep scheduler

# 关键指标：
# scheduler_scheduling_duration_seconds - 调度延迟
# scheduler_pod_scheduling_attempts - 调度尝试次数
# scheduler_pending_pods - 等待调度的Pod数量
# scheduler_schedule_attempts_total - 总调度次数
# scheduler_preemption_attempts_total - 抢占次数
```

#### 7.1.3.2 调度器配置优化

**1. 调整调度器并发度**

```yaml
# kube-scheduler配置文件
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
- schedulerName: default-scheduler

# 并发度配置
parallelism: 16  # 并发处理的Pod数量（默认16）
percentageOfNodesToScore: 50  # 预选阶段评估节点百分比（默认50%）
```

**2. 启用调度缓存**

```yaml
# 缓存配置
clientConnection:
  qps: 100      # API Server请求速率
  burst: 200    # 突发请求数量

# 缓存大小
# 默认情况下，调度器会缓存所有节点和Pod信息
# 对于超大集群（>5000节点），可以考虑：
# - 使用多调度器
# - 按namespace分片
```

**3. 禁用不必要的预选/优选算法**

```yaml
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
- pluginConfig:
  # 禁用某些插件
  - name: InterPodAffinity
    args:
      hardPodAffinityWeight: 0  # 禁用硬亲和性
```

#### 7.1.3.3 大规模集群调度优化

**场景：10000节点集群**

```yaml
# 优化策略1：限制预选节点数量
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
- schedulerName: high-performance-scheduler

# 只评估50%的节点
percentageOfNodesToScore: 50

# 优化策略2：使用节点分组
# 通过NodeSelector预先筛选节点池
spec:
  nodeSelector:
    node-pool: compute-intensive  # 只在特定节点池调度
```

**调度性能对比：**

```
默认配置（100%节点评估）：
- 10000节点 × 每节点1ms = 10秒
- P99延迟：15秒 ❌

优化配置（50%节点评估）：
- 5000节点 × 每节点1ms = 5秒
- P99延迟：7秒 ✅（提升53%）

进一步优化（NodeSelector + 50%评估）：
- 1000节点池 × 50% × 1ms = 500ms
- P99延迟：1秒 ✅（提升93%）
```

### 7.1.4 调度失败处理

#### 7.1.4.1 常见调度失败原因

```
┌────────────────────┬─────────────────────────────┐
│  失败原因          │   解决方案                  │
├────────────────────┼─────────────────────────────┤
│ Insufficient CPU   │ 增加节点或降低资源请求      │
│ Insufficient Memory│                             │
├────────────────────┼─────────────────────────────┤
│ No nodes available │ 检查节点是否Ready           │
│                    │ 检查是否有污点              │
├────────────────────┼─────────────────────────────┤
│ Pod affinity       │ 放宽亲和性要求              │
│ not satisfied      │ 或增加匹配的节点            │
├────────────────────┼─────────────────────────────┤
│ Node doesn't match │ 修改nodeSelector            │
│ node selector      │ 或给节点添加标签            │
├────────────────────┼─────────────────────────────┤
│ Didn't tolerate    │ 添加toleration              │
│ node taints        │ 或移除节点污点              │
├────────────────────┼─────────────────────────────┤
│ PVC not bound      │ 检查StorageClass            │
│                    │ 或创建PV                    │
└────────────────────┴─────────────────────────────┘
```

**查看调度失败事件：**

```bash
# 查看Pod事件
kubectl describe pod <pod-name>

# 示例输出
Events:
  Type     Reason            Message
  ----     ------            -------
  Warning  FailedScheduling  0/3 nodes are available: 1 Insufficient cpu,
                             2 node(s) didn't match Pod's node affinity/selector.

# 查看所有Pending的Pod
kubectl get pods --field-selector=status.phase=Pending -A

# 查看调度器日志
kubectl logs -n kube-system kube-scheduler-<node>
```

#### 7.1.4.2 调度失败示例与排查

**示例1：资源不足**

```yaml
# Pod定义
apiVersion: v1
kind: Pod
metadata:
  name: big-app
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "32"        # 请求32核
        memory: "128Gi"  # 请求128GB内存
```

```bash
# 调度失败
kubectl describe pod big-app

Events:
  Warning  FailedScheduling  0/5 nodes are available:
           5 Insufficient cpu (available: 16, requested: 32).

# 解决方案1：降低资源请求
resources:
  requests:
    cpu: "8"
    memory: "32Gi"

# 解决方案2：添加更大的节点
kubectl get nodes -o custom-columns=NAME:.metadata.name,CPU:.status.capacity.cpu,MEMORY:.status.capacity.memory
```

**示例2：节点选择器不匹配**

```yaml
# Pod定义
apiVersion: v1
kind: Pod
metadata:
  name: gpu-app
spec:
  nodeSelector:
    gpu: "true"  # 要求节点有gpu=true标签
  containers:
  - name: app
    image: tensorflow
```

```bash
# 调度失败
kubectl describe pod gpu-app

Events:
  Warning  FailedScheduling  0/5 nodes are available:
           5 node(s) didn't match Pod's node selector.

# 排查：检查节点标签
kubectl get nodes --show-labels | grep gpu
# 发现所有节点都没有gpu=true标签

# 解决方案：给GPU节点添加标签
kubectl label node node-gpu-1 gpu=true
```

**示例3：污点容忍不匹配**

```yaml
# 节点有污点
kubectl describe node node-gpu-1
Taints: nvidia.com/gpu=present:NoSchedule

# Pod没有容忍
apiVersion: v1
kind: Pod
metadata:
  name: gpu-app
spec:
  containers:
  - name: app
    image: tensorflow
  # ❌ 缺少tolerations
```

```bash
# 调度失败
Events:
  Warning  FailedScheduling  0/1 nodes are available:
           1 node(s) had untolerated taint {nvidia.com/gpu: present}.

# 解决方案：添加容忍
spec:
  tolerations:
  - key: nvidia.com/gpu
    operator: Equal
    value: present
    effect: NoSchedule
```

### 7.1.5 调度器监控与调试

#### 7.1.5.1 调度器监控指标

```yaml
# 部署Prometheus监控调度器
apiVersion: v1
kind: Service
metadata:
  name: kube-scheduler
  namespace: kube-system
  labels:
    component: kube-scheduler
spec:
  ports:
  - name: metrics
    port: 10259
    protocol: TCP
  selector:
    component: kube-scheduler
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-scheduler
  namespace: kube-system
spec:
  selector:
    matchLabels:
      component: kube-scheduler
  endpoints:
  - port: metrics
    interval: 30s
```

**关键监控指标：**

```promql
# 调度延迟（P99）
histogram_quantile(0.99,
  sum(rate(scheduler_scheduling_duration_seconds_bucket[5m])) by (le)
)

# 调度失败率
sum(rate(scheduler_schedule_attempts_total{result="error"}[5m]))
/
sum(rate(scheduler_schedule_attempts_total[5m]))

# Pending Pod数量
sum(kube_pod_status_phase{phase="Pending"}) by (namespace)

# 调度吞吐量
sum(rate(scheduler_schedule_attempts_total{result="scheduled"}[5m]))
```

**Grafana仪表板示例：**

```json
{
  "dashboard": {
    "title": "Kubernetes Scheduler监控",
    "panels": [
      {
        "title": "调度延迟 (P50/P95/P99)",
        "targets": [{
          "expr": "histogram_quantile(0.99, sum(rate(scheduler_scheduling_duration_seconds_bucket[5m])) by (le))"
        }]
      },
      {
        "title": "调度成功率",
        "targets": [{
          "expr": "sum(rate(scheduler_schedule_attempts_total{result=\"scheduled\"}[5m])) / sum(rate(scheduler_schedule_attempts_total[5m]))"
        }]
      },
      {
        "title": "Pending Pod趋势",
        "targets": [{
          "expr": "sum(kube_pod_status_phase{phase=\"Pending\"}) by (namespace)"
        }]
      },
      {
        "title": "抢占事件",
        "targets": [{
          "expr": "sum(rate(scheduler_preemption_attempts_total[5m]))"
        }]
      }
    ]
  }
}
```

#### 7.1.5.2 调度器调试技巧

**1. 启用调度器详细日志**

```bash
# 修改kube-scheduler启动参数
--v=4  # 日志级别（0-10，越大越详细）

# 查看详细调度日志
kubectl logs -n kube-system kube-scheduler-master-1 --tail=100 -f | grep -i "schedule"
```

**2. 使用调度模拟器**

```bash
# 安装scheduler simulator
go install sigs.k8s.io/kube-scheduler-simulator@latest

# 启动模拟器
kube-scheduler-simulator

# 导入集群状态
kubectl get nodes -o json > nodes.json
kubectl get pods -A -o json > pods.json

# 模拟调度
./simulator --nodes=nodes.json --pods=pods.json --simulate=new-pod.yaml
```

**3. 手动模拟调度过程**

```bash
# 查看Pod的调度约束
kubectl get pod <pod-name> -o yaml | grep -A 10 "nodeSelector\|affinity\|tolerations"

# 查看节点资源
kubectl describe nodes | grep -A 5 "Allocated resources"

# 检查节点是否有污点
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints

# 检查节点是否Ready
kubectl get nodes
```

### 7.1.6 调度器最佳实践

#### 7.1.6.1 资源请求最佳实践

**✅ 推荐做法：**

```yaml
# 1. 始终设置资源请求和限制
apiVersion: v1
kind: Pod
metadata:
  name: best-practice-pod
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:        # ✅ 调度依据
        cpu: "500m"
        memory: "512Mi"
      limits:          # ✅ 资源上限
        cpu: "1"
        memory: "1Gi"
```

**❌ 避免的陷阱：**

```yaml
# ❌ 陷阱1：不设置requests
# 后果：调度器无法准确评估，可能导致节点过载
resources:
  limits:
    cpu: "1"
    memory: "1Gi"

# ❌ 陷阱2：requests == limits (QoS: Guaranteed)
# 后果：资源利用率低，浪费严重
resources:
  requests:
    cpu: "2"
    memory: "4Gi"
  limits:
    cpu: "2"        # requests == limits
    memory: "4Gi"   # 即使应用只用了500m/1Gi，也预留了2核/4GB

# ✅ 推荐：requests < limits (QoS: Burstable)
resources:
  requests:
    cpu: "500m"     # 平时使用
    memory: "1Gi"
  limits:
    cpu: "2"        # 高峰时可用
    memory: "4Gi"
```

**资源请求建议值：**

| 应用类型 | CPU Requests | Memory Requests | CPU Limits | Memory Limits |
|---------|--------------|-----------------|------------|---------------|
| **Web前端** | 100-500m | 128-512Mi | 1-2 | 512Mi-1Gi |
| **API服务** | 500m-1 | 512Mi-2Gi | 2-4 | 2-4Gi |
| **数据库** | 1-2 | 2-8Gi | 2-4 | 8-16Gi |
| **消息队列** | 500m-1 | 1-4Gi | 2-4 | 4-8Gi |
| **批处理** | 1-2 | 1-2Gi | 不限制 | 4-8Gi |

#### 7.1.6.2 调度策略最佳实践

**1. 高可用部署**

```yaml
# ✅ 使用Pod反亲和性确保副本分散
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 3
  template:
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web
              topologyKey: kubernetes.io/hostname  # 分散到不同节点
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web
              topologyKey: topology.kubernetes.io/zone  # 分散到不同可用区
```

**2. 性能优化部署**

```yaml
# ✅ 使用Pod亲和性将相关服务部署在一起
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  template:
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - database  # 靠近数据库部署，降低延迟
              topologyKey: kubernetes.io/hostname
```

**3. 专用节点池**

```yaml
# ✅ 使用污点和容忍将特定工作负载调度到专用节点
# 1. 给GPU节点打污点
kubectl taint nodes node-gpu-1 gpu=true:NoSchedule

# 2. GPU应用添加容忍
apiVersion: v1
kind: Pod
metadata:
  name: ml-training
spec:
  tolerations:
  - key: gpu
    operator: Equal
    value: "true"
    effect: NoSchedule
  nodeSelector:
    gpu: "true"  # 确保调度到GPU节点
  containers:
  - name: trainer
    image: tensorflow/tensorflow:latest-gpu
    resources:
      limits:
        nvidia.com/gpu: 1
```

---

本节我们深入学习了Kubernetes调度器的工作原理，包括两阶段调度策略（预选和优选）、性能优化技巧、调度失败处理、监控调试方法以及最佳实践。理解调度器原理是优化应用性能和资源利用率的关键。在下一节中，我们将学习如何使用节点选择器和节点亲和性来精确控制Pod的调度位置。

---

**本节知识点回顾：**
- ✅ 调度器的核心价值和工作流程
- ✅ 预选（Predicates）和优选（Priorities）算法
- ✅ 调度性能优化和大规模集群调度
- ✅ 调度失败原因排查和解决方案
- ✅ 调度器监控指标和调试技巧
- ✅ 资源请求和调度策略最佳实践
## 7.2 节点选择器与节点亲和性

在上一节中，我们学习了Kubernetes调度器的工作原理。本节将深入探讨如何通过节点选择器（NodeSelector）和节点亲和性（Node Affinity）来精确控制Pod的调度位置，实现更灵活的调度策略。

### 7.2.1 节点选择器（NodeSelector）

#### 7.2.1.1 NodeSelector基础概念

NodeSelector是Kubernetes最简单的节点选择机制，通过标签（Label）匹配将Pod调度到特定节点。

**工作原理：**

```
┌─────────────────────────────────────────────────────┐
│          NodeSelector工作流程                        │
├─────────────────────────────────────────────────────┤
│                                                      │
│  1. 给节点打标签                                     │
│     kubectl label nodes node1 disktype=ssd          │
│                                                      │
│  2. Pod中指定nodeSelector                           │
│     spec:                                            │
│       nodeSelector:                                  │
│         disktype: ssd                                │
│                                                      │
│  3. 调度器过滤                                       │
│     只考虑标签匹配的节点                            │
│     ┌──────┐  ┌──────┐  ┌──────┐                  │
│     │Node1 │  │Node2 │  │Node3 │                  │
│     │ssd   │  │hdd   │  │ssd   │                  │
│     └──┬───┘  └──────┘  └──┬───┘                  │
│        │                    │                       │
│        └──────── ✅ ────────┘                       │
│        候选节点：Node1、Node3                       │
│                                                      │
│  4. 在候选节点中应用优选算法                        │
│     选择最优节点                                     │
└─────────────────────────────────────────────────────┘
```

**基本示例：**

```yaml
# 1. 给节点打标签
apiVersion: v1
kind: Node
metadata:
  name: node1
  labels:
    disktype: ssd
    region: us-west-1
    gpu: "true"
---
# 2. Pod使用nodeSelector
apiVersion: v1
kind: Pod
metadata:
  name: nginx-ssd
spec:
  nodeSelector:
    disktype: ssd    # 要求节点有disktype=ssd标签
  containers:
  - name: nginx
    image: nginx:1.25
```

#### 7.2.1.2 常用节点标签

**系统内置标签（自动添加）：**

```bash
# 查看节点标签
kubectl get nodes --show-labels

# 常见内置标签
kubernetes.io/hostname: node1                    # 节点主机名
kubernetes.io/os: linux                          # 操作系统
kubernetes.io/arch: amd64                        # CPU架构
node.kubernetes.io/instance-type: m5.2xlarge    # 实例类型（云环境）
topology.kubernetes.io/zone: us-west-1a         # 可用区
topology.kubernetes.io/region: us-west-1        # 区域
```

**自定义标签最佳实践：**

| 标签用途 | 标签键 | 示例值 |
|---------|--------|--------|
| **硬件类型** | disktype | ssd, hdd, nvme |
| **GPU** | gpu | true, false |
| **网络** | network | 10g, 1g |
| **环境** | environment | production, staging, dev |
| **业务线** | business-unit | payment, order, user |
| **节点池** | node-pool | compute, memory, gpu |
| **专用节点** | dedicated | database, cache, ml |

**给节点添加标签：**

```bash
# 添加单个标签
kubectl label nodes node1 disktype=ssd

# 添加多个标签
kubectl label nodes node1 \
  disktype=ssd \
  gpu=true \
  environment=production

# 修改标签
kubectl label nodes node1 disktype=nvme --overwrite

# 删除标签
kubectl label nodes node1 disktype-

# 批量打标签
kubectl label nodes node{1..3} node-pool=compute
```

#### 7.2.1.3 NodeSelector使用场景

**场景1：SSD存储节点**

```yaml
# 数据库Pod需要高性能存储
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 3
  template:
    spec:
      nodeSelector:
        disktype: ssd      # 调度到SSD节点
      containers:
      - name: mysql
        image: mysql:8.0
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-ssd
      resources:
        requests:
          storage: 100Gi
```

**场景2：GPU节点**

```yaml
# 机器学习训练任务
apiVersion: v1
kind: Pod
metadata:
  name: tensorflow-training
spec:
  nodeSelector:
    gpu: "true"              # 调度到GPU节点
    gpu-type: nvidia-v100    # 指定GPU型号
  containers:
  - name: trainer
    image: tensorflow/tensorflow:latest-gpu
    resources:
      limits:
        nvidia.com/gpu: 2    # 请求2块GPU
```

**场景3：区域/可用区调度**

```yaml
# 指定可用区部署（多可用区高可用）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-us-west-1a
spec:
  replicas: 3
  template:
    spec:
      nodeSelector:
        topology.kubernetes.io/zone: us-west-1a  # 部署在us-west-1a
      containers:
      - name: web
        image: nginx:1.25
```

**场景4：专用节点池**

```yaml
# 支付服务部署在专用节点池
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-service
spec:
  replicas: 5
  template:
    spec:
      nodeSelector:
        node-pool: payment    # 专用支付节点池
        environment: production
      containers:
      - name: payment
        image: payment:v2.0
```

#### 7.2.1.4 NodeSelector的局限性

```
┌────────────────────┬──────────────────────────────┐
│  局限性            │   说明                        │
├────────────────────┼──────────────────────────────┤
│ ❌ 只支持AND逻辑   │ 多个标签必须全部匹配          │
│                    │ 无法实现OR逻辑                │
├────────────────────┼──────────────────────────────┤
│ ❌ 不支持软约束     │ 标签不匹配则调度失败          │
│                    │ 无法实现"尽量满足"            │
├────────────────────┼──────────────────────────────┤
│ ❌ 表达能力有限     │ 无法使用In、NotIn等操作符     │
│                    │ 无法基于标签值范围选择        │
├────────────────────┼──────────────────────────────┤
│ ❌ 无法指定权重     │ 无法表达偏好程度              │
└────────────────────┴──────────────────────────────┘

解决方案：使用Node Affinity（节点亲和性）
```

**示例：NodeSelector的限制**

```yaml
# ❌ 无法实现：调度到ssd=true OR nvme=true的节点
spec:
  nodeSelector:
    disktype: ssd    # 只能是AND关系
    disktype: nvme   # ❌ 这样写会冲突

# ✅ 解决方案：使用Node Affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
            - nvme    # ✅ 支持OR逻辑
```

### 7.2.2 节点亲和性（Node Affinity）

#### 7.2.2.1 Node Affinity概述

Node Affinity是NodeSelector的增强版，提供更强大和灵活的节点选择能力。

**Node Affinity vs NodeSelector：**

```
┌───────────────────┬────────────────┬────────────────┐
│      特性         │  NodeSelector  │ Node Affinity  │
├───────────────────┼────────────────┼────────────────┤
│ 表达能力          │ 基础（仅等于） │ 强大（In/NotIn等）│
│ 逻辑运算          │ 仅AND          │ AND + OR       │
│ 软约束/硬约束     │ 仅硬约束       │ 都支持         │
│ 权重              │ 不支持         │ 支持           │
│ 反亲和性          │ 不支持         │ 支持           │
│ 配置复杂度        │ 简单           │ 中等           │
│ 推荐使用场景      │ 简单场景       │ 复杂调度需求   │
└───────────────────┴────────────────┴────────────────┘
```

**Node Affinity两种类型：**

```yaml
spec:
  affinity:
    nodeAffinity:
      # 1. 硬约束（必须满足）
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms: [...]
      
      # 2. 软约束（尽量满足）
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions: [...]
```

**命名规则解析：**

```
requiredDuringSchedulingIgnoredDuringExecution
    ↓             ↓              ↓
  必须满足      调度阶段      执行阶段忽略
  
解释：
- requiredDuringScheduling：调度时必须满足
- IgnoredDuringExecution：Pod运行时节点标签变化不影响

preferredDuringSchedulingIgnoredDuringExecution
    ↓             ↓              ↓
  尽量满足      调度阶段      执行阶段忽略
```

#### 7.2.2.2 硬亲和性（Required）

硬亲和性是强制性约束，如果没有满足条件的节点，Pod将无法调度（Pending状态）。

**基本语法：**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: affinity-required
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:    # OR关系（任一term满足即可）
        - matchExpressions:   # AND关系（同一term内所有表达式必须满足）
          - key: disktype
            operator: In      # 支持In、NotIn、Exists、DoesNotExist、Gt、Lt
            values:
            - ssd
            - nvme
  containers:
  - name: app
    image: nginx
```

**支持的操作符：**

| 操作符 | 说明 | 示例 |
|-------|------|------|
| **In** | 标签值在列表中 | disktype In [ssd, nvme] |
| **NotIn** | 标签值不在列表中 | disktype NotIn [hdd] |
| **Exists** | 标签键存在（不关心值） | gpu Exists |
| **DoesNotExist** | 标签键不存在 | legacy DoesNotExist |
| **Gt** | 标签值大于（数值） | cpu-count Gt 16 |
| **Lt** | 标签值小于（数值） | cpu-count Lt 32 |

**示例1：In操作符（OR逻辑）**

```yaml
# 调度到SSD或NVMe节点
apiVersion: v1
kind: Pod
metadata:
  name: database
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd      # disktype=ssd 或
            - nvme     # disktype=nvme
  containers:
  - name: mysql
    image: mysql:8.0
```

**示例2：NotIn操作符（排除）**

```yaml
# 不调度到HDD节点
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: NotIn
            values:
            - hdd      # 排除hdd节点
  containers:
  - name: app
    image: myapp:latest
```

**示例3：Exists操作符（标签存在性）**

```yaml
# 调度到有GPU的节点（不关心GPU具体型号）
apiVersion: v1
kind: Pod
metadata:
  name: ml-training
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: gpu
            operator: Exists    # 只要有gpu标签即可
  containers:
  - name: trainer
    image: tensorflow/tensorflow:latest-gpu
```

**示例4：Gt/Lt操作符（数值比较）**

```yaml
# 调度到CPU核心数大于16的节点
apiVersion: v1
kind: Pod
metadata:
  name: compute-intensive
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: cpu-count
            operator: Gt
            values:
            - "16"     # 必须是字符串
  containers:
  - name: app
    image: compute-app:latest
```

**示例5：多条件AND逻辑**

```yaml
# 调度到SSD+GPU+生产环境节点
apiVersion: v1
kind: Pod
metadata:
  name: production-ml-app
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
          - key: gpu           # AND 关系
            operator: Exists
          - key: environment   # AND 关系
            operator: In
            values:
            - production
  containers:
  - name: app
    image: ml-app:v2.0
```

**示例6：多个nodeSelectorTerms（OR逻辑）**

```yaml
# 调度到（SSD节点）OR（GPU节点）
apiVersion: v1
kind: Pod
metadata:
  name: flexible-scheduling
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:   # Term 1：SSD节点
          - key: disktype
            operator: In
            values:
            - ssd
        - matchExpressions:   # Term 2：GPU节点（OR关系）
          - key: gpu
            operator: Exists
  containers:
  - name: app
    image: myapp:latest
```

#### 7.2.2.3 软亲和性（Preferred）

软亲和性是偏好性约束，调度器会尽量满足，但不满足也可以调度到其他节点。

**基本语法：**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: affinity-preferred
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100          # 权重（1-100）
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
      - weight: 50           # 第二优先级
        preference:
          matchExpressions:
          - key: zone
            operator: In
            values:
            - us-west-1a
  containers:
  - name: app
    image: nginx
```

**权重计算机制：**

```
调度器打分流程：

1. 基础得分（LeastRequested、Balanced等）
2. + Node Affinity权重得分
3. = 最终得分

示例：
节点1：SSD=true, zone=us-west-1a
  基础得分：70
  匹配disktype=ssd：+100（权重100）
  匹配zone=us-west-1a：+50（权重50）
  最终得分：70 + 100 + 50 = 220

节点2：HDD=true, zone=us-west-1a
  基础得分：80
  不匹配disktype=ssd：+0
  匹配zone=us-west-1a：+50（权重50）
  最终得分：80 + 0 + 50 = 130

结果：选择节点1（得分更高）
```

**示例1：单个软约束**

```yaml
# 优先调度到SSD节点，但HDD节点也可以
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 5
  template:
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            preference:
              matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
      containers:
      - name: nginx
        image: nginx:1.25
```

**示例2：多级优先级**

```yaml
# 优先级：SSD(100) > us-west-1a(80) > 16核以上(50)
apiVersion: v1
kind: Pod
metadata:
  name: multi-preference
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100        # 第一优先级：SSD
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
      - weight: 80         # 第二优先级：可用区
        preference:
          matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - us-west-1a
      - weight: 50         # 第三优先级：CPU核心数
        preference:
          matchExpressions:
          - key: cpu-count
            operator: Gt
            values:
            - "16"
  containers:
  - name: app
    image: myapp:latest
```

**示例3：硬约束+软约束组合**

```yaml
# 硬约束：必须有GPU
# 软约束：优先V100，其次A100
apiVersion: v1
kind: Pod
metadata:
  name: gpu-training
spec:
  affinity:
    nodeAffinity:
      # 硬约束：必须有GPU
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: gpu
            operator: Exists
      
      # 软约束：优先V100
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: gpu-type
            operator: In
            values:
            - nvidia-v100
      - weight: 80
        preference:
          matchExpressions:
          - key: gpu-type
            operator: In
            values:
            - nvidia-a100
  containers:
  - name: trainer
    image: tensorflow/tensorflow:latest-gpu
    resources:
      limits:
        nvidia.com/gpu: 1
```

#### 7.2.2.4 区域与可用区调度

**多可用区高可用部署：**

```yaml
# Deployment：跨可用区部署（高可用）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-ha
spec:
  replicas: 6
  template:
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：必须在us-west-1区域
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/region
                operator: In
                values:
                - us-west-1
          
          # 软约束：优先级 a > b > c
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - us-west-1a
          - weight: 80
            preference:
              matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - us-west-1b
          - weight: 60
            preference:
              matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - us-west-1c
      
      # Pod反亲和性：确保副本分散
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - web-ha
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: nginx
        image: nginx:1.25
```

**结果分布示例：**

```
期望结果（6个副本跨3个可用区）：

us-west-1a: 2个Pod  ✅ 高可用
us-west-1b: 2个Pod  ✅ 高可用
us-west-1c: 2个Pod  ✅ 高可用

如果某个可用区故障：
us-west-1a: ❌ 故障
us-west-1b: 2个Pod  ✅ 正常
us-west-1c: 2个Pod  ✅ 正常
服务可用性：66.7%（而非0%）
```

### 7.2.3 实战案例

#### 7.2.3.1 案例1：数据库高可用部署

**需求：**
- MySQL主从复制（1主2从）
- 主库部署在SSD节点
- 从库分散到不同可用区
- 优先使用高性能节点

```yaml
# MySQL主库：必须SSD，优先高配节点
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-master
spec:
  serviceName: mysql-master
  replicas: 1
  template:
    metadata:
      labels:
        app: mysql
        role: master
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：必须SSD
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
                - nvme
          
          # 软约束：优先高配节点
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node-tier
                operator: In
                values:
                - high-performance
          - weight: 80
            preference:
              matchExpressions:
              - key: cpu-count
                operator: Gt
                values:
                - "32"
      
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
          limits:
            cpu: "8"
            memory: "32Gi"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
  
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-ssd
      resources:
        requests:
          storage: 500Gi
---
# MySQL从库：跨可用区部署
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-slave
spec:
  serviceName: mysql-slave
  replicas: 2
  template:
    metadata:
      labels:
        app: mysql
        role: slave
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：必须SSD
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
        
        # Pod反亲和性：分散到不同可用区
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - mysql
              - key: role
                operator: In
                values:
                - slave
            topologyKey: topology.kubernetes.io/zone  # 不同可用区
      
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        - name: MYSQL_MASTER_HOST
          value: mysql-master-0.mysql-master
        resources:
          requests:
            cpu: "2"
            memory: "8Gi"
          limits:
            cpu: "4"
            memory: "16Gi"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
  
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-ssd
      resources:
        requests:
          storage: 500Gi
```

**部署结果：**

```
Master节点选择：
✅ Node-SSD-1（高性能节点，SSD，32核64GB）

Slave节点选择：
✅ Node-SSD-2（us-west-1a，SSD，16核32GB）
✅ Node-SSD-3（us-west-1b，SSD，16核32GB）

高可用性分析：
- 主从分离 ✅
- 从库跨可用区 ✅
- 单可用区故障，主库+1个从库仍可用 ✅
```

#### 7.2.3.2 案例2：机器学习训练集群

**需求：**
- GPU训练节点（必须有GPU）
- 优先使用V100，其次A100
- 数据预处理任务使用CPU节点
- 训练和预处理Pod不能在同一节点（避免资源竞争）

```yaml
# GPU训练任务
apiVersion: batch/v1
kind: Job
metadata:
  name: ml-training
spec:
  parallelism: 4    # 4个并行训练任务
  template:
    metadata:
      labels:
        app: ml-training
        component: trainer
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：必须有GPU
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu
                operator: Exists
              - key: gpu-count
                operator: Gt
                values:
                - "0"
          
          # 软约束：优先V100
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: gpu-type
                operator: In
                values:
                - nvidia-v100
          - weight: 80
            preference:
              matchExpressions:
              - key: gpu-type
                operator: In
                values:
                - nvidia-a100
        
        # Pod反亲和性：避免与数据预处理任务共存
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values:
                  - preprocessor
              topologyKey: kubernetes.io/hostname
      
      restartPolicy: OnFailure
      containers:
      - name: trainer
        image: tensorflow/tensorflow:latest-gpu
        command: ["python", "train.py"]
        resources:
          limits:
            nvidia.com/gpu: 2    # 每个任务使用2块GPU
            memory: "64Gi"
            cpu: "16"
        volumeMounts:
        - name: data
          mountPath: /data
        - name: model
          mountPath: /model
      
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: training-data
      - name: model
        persistentVolumeClaim:
          claimName: model-output
---
# 数据预处理任务（CPU密集型）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-preprocessor
spec:
  replicas: 10
  template:
    metadata:
      labels:
        app: ml-training
        component: preprocessor
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：CPU节点（无GPU）
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu
                operator: DoesNotExist
          
          # 软约束：优先高核心数节点
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: cpu-count
                operator: Gt
                values:
                - "16"
        
        # Pod反亲和性：避免与训练任务共存
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values:
                  - trainer
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: preprocessor
        image: python:3.9
        command: ["python", "preprocess.py"]
        resources:
          requests:
            cpu: "8"
            memory: "16Gi"
          limits:
            cpu: "16"
            memory: "32Gi"
```

**部署结果：**

```
训练任务分布（4个Pod）：
✅ GPU-Node-1（2×V100）- 2个训练Pod
✅ GPU-Node-2（2×V100）- 2个训练Pod

预处理任务分布（10个Pod）：
✅ CPU-Node-1（32核） - 3个预处理Pod
✅ CPU-Node-2（32核） - 3个预处理Pod
✅ CPU-Node-3（32核） - 4个预处理Pod

资源隔离验证：
- 训练任务仅在GPU节点 ✅
- 预处理任务仅在CPU节点 ✅
- 训练和预处理不共存节点 ✅
```

### 7.2.4 常见问题与排查

#### 7.2.4.1 Pod一直Pending

**问题现象：**

```bash
kubectl get pods
NAME                   READY   STATUS    RESTARTS   AGE
myapp-7c5ddbdf54-abc   0/1     Pending   0          5m

kubectl describe pod myapp-7c5ddbdf54-abc
Events:
  Warning  FailedScheduling  0/5 nodes are available:
           5 node(s) didn't match Pod's node affinity/selector.
```

**排查步骤：**

```bash
# 1. 查看Pod的节点亲和性配置
kubectl get pod myapp-7c5ddbdf54-abc -o yaml | grep -A 20 "affinity"

# 2. 查看所有节点的标签
kubectl get nodes --show-labels

# 3. 检查是否有节点匹配要求
kubectl get nodes -l disktype=ssd
# 如果为空，说明没有节点有该标签

# 4. 解决方案1：给节点添加标签
kubectl label nodes node1 disktype=ssd

# 5. 解决方案2：修改Pod的亲和性配置
# 将required改为preferred，或放宽条件
```

**常见错误示例：**

```yaml
# ❌ 错误1：标签键拼写错误
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktpye    # ❌ 拼写错误（disktype）
            operator: In
            values:
            - ssd

# ❌ 错误2：值大小写错误
spec:
  nodeSelector:
    disktype: SSD    # ❌ 节点标签是小写ssd

# ✅ 正确
spec:
  nodeSelector:
    disktype: ssd    # ✅ 匹配节点标签
```

#### 7.2.4.2 调度不均衡

**问题现象：**

```bash
# 所有Pod都调度到了同一个节点
kubectl get pods -o wide
NAME                   NODE
web-7c5ddbdf54-abc     node1
web-7c5ddbdf54-def     node1
web-7c5ddbdf54-ghi     node1
```

**原因分析：**

```yaml
# 原因：软亲和性权重过高，导致其他优选算法失效
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd

# 如果只有node1是SSD，所有Pod都会调度到node1
```

**解决方案：**

```yaml
# 方案1：降低权重，让其他优选算法生效
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 30    # ✅ 降低权重
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd

# 方案2：添加Pod反亲和性，强制分散
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - web
          topologyKey: kubernetes.io/hostname
```

### 7.2.5 最佳实践

#### 7.2.5.1 标签管理最佳实践

**✅ 推荐的标签命名规范：**

```yaml
# 使用分层命名空间
labels:
  # 基础设施层
  topology.kubernetes.io/region: us-west-1
  topology.kubernetes.io/zone: us-west-1a
  
  # 硬件层
  hardware.example.com/disktype: ssd
  hardware.example.com/gpu: "true"
  hardware.example.com/gpu-type: nvidia-v100
  hardware.example.com/cpu-count: "32"
  
  # 业务层
  business.example.com/environment: production
  business.example.com/team: payment
  business.example.com/cost-center: engineering
  
  # 应用层
  app.kubernetes.io/name: mysql
  app.kubernetes.io/component: database
  app.kubernetes.io/version: "8.0"
```

**❌ 避免的陷阱：**

```yaml
# ❌ 1. 使用空格或特殊字符
labels:
  disk type: ssd         # ❌ 空格
  gpu-type!: v100        # ❌ 感叹号

# ❌ 2. 过长的标签值
labels:
  description: "This is a very very very long description..."  # ❌ >63字符

# ❌ 3. 使用敏感信息
labels:
  password: secret123    # ❌ 安全风险

# ✅ 正确做法
labels:
  disktype: ssd
  gpu-type: v100
  description: high-performance-node
```

#### 7.2.5.2 亲和性配置最佳实践

**1. 优先使用软约束（Preferred）**

```yaml
# ✅ 推荐：使用软约束提高灵活性
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd

# ❌ 避免：过度使用硬约束
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
# 后果：如果所有SSD节点资源不足，Pod将无法调度
```

**2. 硬约束+软约束组合**

```yaml
# ✅ 最佳实践：关键要求用硬约束，偏好用软约束
spec:
  affinity:
    nodeAffinity:
      # 硬约束：必须在生产环境
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: environment
            operator: In
            values:
            - production
      
      # 软约束：优先SSD
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
```

**3. 合理设置权重**

```yaml
# ✅ 权重设置建议
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100    # 最高优先级：关键要求
        preference:
          matchExpressions:
          - key: environment
            operator: In
            values:
            - production
      
      - weight: 50     # 中等优先级：性能优化
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
      
      - weight: 20     # 低优先级：成本优化
        preference:
          matchExpressions:
          - key: instance-type
            operator: In
            values:
            - spot    # Spot实例（便宜但可能被回收）
```

**权重设置原则：**

| 优先级 | 权重范围 | 使用场景 |
|-------|---------|---------|
| **最高** | 80-100 | 关键业务要求（环境、合规性） |
| **高** | 60-79 | 重要性能要求（GPU、SSD） |
| **中** | 40-59 | 一般性能优化（CPU核心数） |
| **低** | 20-39 | 成本优化（可用区、实例类型） |
| **极低** | 1-19 | 次要偏好（便利性） |

#### 7.2.5.3 生产环境配置模板

**模板1：无状态应用（高可用）**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stateless-app
spec:
  replicas: 6
  template:
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：生产环境
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: environment
                operator: In
                values:
                - production
          
          # 软约束：性能优化
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            preference:
              matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
        
        # Pod反亲和性：跨节点+跨可用区
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - stateless-app
              topologyKey: kubernetes.io/hostname
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - stateless-app
              topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: app
        image: myapp:v2.0
```

**模板2：有状态应用（数据库）**

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
spec:
  replicas: 3
  template:
    spec:
      affinity:
        nodeAffinity:
          # 硬约束：SSD+生产环境
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
                - nvme
              - key: environment
                operator: In
                values:
                - production
          
          # 软约束：高配节点
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            preference:
              matchExpressions:
              - key: node-tier
                operator: In
                values:
                - high-performance
        
        # Pod反亲和性：强制跨可用区
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - database
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: mysql
        image: mysql:8.0
```

---

本节我们深入学习了节点选择器（NodeSelector）和节点亲和性（Node Affinity），包括基本概念、使用场景、硬约束与软约束的区别、实战案例以及最佳实践。通过合理使用这些调度约束，可以实现精确的Pod调度控制，优化应用性能和高可用性。在下一节中，我们将学习Pod亲和性与反亲和性，探讨如何基于Pod之间的关系来调度。

---

**本节知识点回顾：**
- ✅ NodeSelector的基本用法和局限性
- ✅ Node Affinity的硬约束（Required）和软约束（Preferred）
- ✅ 6种操作符（In、NotIn、Exists、DoesNotExist、Gt、Lt）
- ✅ 多条件AND/OR逻辑组合
- ✅ 区域与可用区调度策略
- ✅ 实战案例（数据库高可用、机器学习集群）
- ✅ 常见问题排查和最佳实践
## 7.3 Pod亲和性与反亲和性

在上一节中，我们学习了如何使用节点选择器和节点亲和性来控制Pod调度到特定节点。本节将深入探讨Pod亲和性（Pod Affinity）和Pod反亲和性（Pod Anti-Affinity），学习如何基于Pod之间的关系来调度，实现更复杂的调度策略。

### 7.3.1 Pod亲和性与反亲和性概述

#### 7.3.1.1 核心概念

Pod亲和性/反亲和性允许根据**已经运行在节点上的Pod的标签**来约束新Pod的调度位置，而不是基于节点标签。

```
┌─────────────────────────────────────────────────────────────┐
│        Node Affinity vs Pod Affinity 对比                   │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Node Affinity (节点亲和性):                                 │
│  ┌──────────────────────────────────────┐                  │
│  │  基于节点标签调度                    │                  │
│  │                                      │                  │
│  │  Pod ──检查──> Node Labels          │                  │
│  │         (disktype=ssd?)             │                  │
│  └──────────────────────────────────────┘                  │
│                                                              │
│  Pod Affinity (Pod亲和性):                                  │
│  ┌──────────────────────────────────────┐                  │
│  │  基于已运行的Pod标签调度              │                  │
│  │                                      │                  │
│  │  新Pod ──检查──> 已有Pod的Labels     │                  │
│  │         (app=database?)             │                  │
│  │  └─> 调度到同一拓扑域                │                  │
│  └──────────────────────────────────────┘                  │
│                                                              │
│  Pod Anti-Affinity (Pod反亲和性):                           │
│  ┌──────────────────────────────────────┐                  │
│  │  避免与特定Pod在同一拓扑域            │                  │
│  │                                      │                  │
│  │  新Pod ──检查──> 已有Pod的Labels     │                  │
│  │         (app=web?)                  │                  │
│  │  └─> 调度到不同拓扑域                │                  │
│  └──────────────────────────────────────┘                  │
└─────────────────────────────────────────────────────────────┘
```

**典型使用场景：**

| 场景 | 使用类型 | 目的 |
|-----|---------|------|
| **前后端就近部署** | Pod Affinity | 降低网络延迟 |
| **缓存和应用部署** | Pod Affinity | 数据本地性 |
| **高可用部署** | Pod Anti-Affinity | 副本分散，容错 |
| **资源隔离** | Pod Anti-Affinity | 避免资源竞争 |

#### 7.3.1.2 拓扑域（Topology Key）

拓扑域是Pod亲和性/反亲和性的核心概念，定义了"同一位置"的范围。

```
拓扑域示例：

topologyKey: kubernetes.io/hostname
└─> 同一主机（节点）
    ┌────────────────┐
    │    Node-1      │
    │  ┌──────────┐  │
    │  │  Pod A   │  │  <- 同一拓扑域
    │  │  Pod B   │  │  <- 同一拓扑域
    │  └──────────┘  │
    └────────────────┘

topologyKey: topology.kubernetes.io/zone
└─> 同一可用区
    ┌─────────────────────────────────┐
    │      us-west-1a (可用区)         │
    │  ┌────────────┐  ┌────────────┐ │
    │  │   Node-1   │  │   Node-2   │ │
    │  │  ┌──────┐  │  │  ┌──────┐  │ │
    │  │  │Pod A │  │  │  │Pod B │  │ │ <- 同一拓扑域
    │  │  └──────┘  │  │  └──────┘  │ │
    │  └────────────┘  └────────────┘ │
    └─────────────────────────────────┘

topologyKey: topology.kubernetes.io/region
└─> 同一区域
    ┌──────────────────────────────────────────────┐
    │           us-west-1 (区域)                    │
    │  ┌──────────────┐      ┌──────────────┐     │
    │  │ us-west-1a   │      │ us-west-1b   │     │
    │  │  ┌────────┐  │      │  ┌────────┐  │     │
    │  │  │ Pod A  │  │      │  │ Pod B  │  │     │ <- 同一拓扑域
    │  │  └────────┘  │      │  └────────┘  │     │
    │  └──────────────┘      └──────────────┘     │
    └──────────────────────────────────────────────┘
```

**常用拓扑键：**

| 拓扑键 | 作用域 | 使用场景 |
|-------|--------|---------|
| **kubernetes.io/hostname** | 节点级别 | 同节点/避免同节点 |
| **topology.kubernetes.io/zone** | 可用区级别 | 跨可用区高可用 |
| **topology.kubernetes.io/region** | 区域级别 | 跨区域容灾 |
| **自定义标签** | 自定义 | 机架、数据中心等 |

### 7.3.2 Pod亲和性（Pod Affinity）

#### 7.3.2.1 Pod亲和性基本语法

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-affinity
spec:
  affinity:
    podAffinity:
      # 硬亲和性（必须满足）
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - cache
        topologyKey: kubernetes.io/hostname
      
      # 软亲和性（尽量满足）
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - database
          topologyKey: topology.kubernetes.io/zone
  
  containers:
  - name: app
    image: myapp:latest
```

**语法结构：**

```
podAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:  # 硬亲和性
  - labelSelector:                  # 匹配哪些Pod
      matchExpressions:             # 标签选择器
      - key: app
        operator: In
        values:
        - cache
    topologyKey: kubernetes.io/hostname  # 在什么范围内
  
  preferredDuringSchedulingIgnoredDuringExecution:  # 软亲和性
  - weight: 100                     # 权重
    podAffinityTerm:
      labelSelector:                # 匹配哪些Pod
        matchExpressions:
        - key: app
          operator: In
          values:
          - database
      topologyKey: topology.kubernetes.io/zone  # 在什么范围内
```

#### 7.3.2.2 硬亲和性示例

**示例1：应用与Redis缓存部署在同一节点**

```yaml
# Redis缓存
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis        # ← 重要：这个标签会被应用Pod引用
        component: cache
    spec:
      containers:
      - name: redis
        image: redis:7.0
        ports:
        - containerPort: 6379
---
# 应用Pod：要求与Redis在同一节点
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      affinity:
        podAffinity:
          # 硬亲和性：必须与Redis在同一节点
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - redis    # 匹配Redis Pod
            topologyKey: kubernetes.io/hostname  # 同一节点
      
      containers:
      - name: web
        image: web-app:v2.0
        env:
        - name: REDIS_HOST
          value: localhost  # 因为在同一节点，可以用localhost
```

**部署结果：**

```
Node-1:
  ├─ redis-abc123    (Redis Pod)
  └─ web-xyz789      (Web Pod)  ✅ 调度到同一节点

Node-2:
  ├─ redis-def456    (Redis Pod)
  └─ web-uvw012      (Web Pod)  ✅ 调度到同一节点

Node-3:
  ├─ redis-ghi789    (Redis Pod)
  └─ web-rst345      (Web Pod)  ✅ 调度到同一节点

优势：
- 应用和缓存在同一节点，访问延迟极低
- 减少网络开销
```

**示例2：前端和后端部署在同一可用区**

```yaml
# 后端API服务
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  replicas: 6
  selector:
    matchLabels:
      app: backend
      tier: api
  template:
    metadata:
      labels:
        app: backend
        tier: api
    spec:
      containers:
      - name: api
        image: backend-api:v3.0
---
# 前端服务：部署在后端所在的可用区
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 6
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      affinity:
        podAffinity:
          # 硬亲和性：必须与后端在同一可用区
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - backend
              - key: tier
                operator: In
                values:
                - api
            topologyKey: topology.kubernetes.io/zone  # 同一可用区
      
      containers:
      - name: frontend
        image: frontend:v2.0
```

**部署结果：**

```
us-west-1a (可用区):
  ├─ backend-api Pod × 2
  └─ frontend Pod × 2     ✅ 同一可用区

us-west-1b (可用区):
  ├─ backend-api Pod × 2
  └─ frontend Pod × 2     ✅ 同一可用区

us-west-1c (可用区):
  ├─ backend-api Pod × 2
  └─ frontend Pod × 2     ✅ 同一可用区

优势：
- 前后端跨可用区延迟低（同区域1-2ms）
- 跨可用区高可用
```

#### 7.3.2.3 软亲和性示例

**示例：应用优先与数据库在同一可用区**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
spec:
  replicas: 5
  selector:
    matchLabels:
      app: order
  template:
    metadata:
      labels:
        app: order
    spec:
      affinity:
        podAffinity:
          # 软亲和性：优先与MySQL在同一可用区
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - mysql
                - key: role
                  operator: In
                  values:
                  - master
              topologyKey: topology.kubernetes.io/zone
          
          # 次优：与Redis在同一节点
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - redis
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: order
        image: order-service:v1.5
```

**调度决策：**

```
假设集群状态：
- us-west-1a: MySQL主库，3个节点
- us-west-1b: 无MySQL，5个节点
- us-west-1c: 无MySQL，4个节点

调度结果（5个order-service Pod）：
- us-west-1a: 3个Pod  ✅ 权重100，优先与MySQL同区
- us-west-1b: 1个Pod  ⚠️  资源不足时溢出
- us-west-1c: 1个Pod  ⚠️  资源不足时溢出

如果设置为硬亲和性：
- 只能调度3个Pod到us-west-1a
- 另外2个Pod会Pending（无满足条件的节点）❌
```

### 7.3.3 Pod反亲和性（Pod Anti-Affinity）

#### 7.3.3.1 Pod反亲和性基本概念

Pod反亲和性用于确保Pod**不会**调度到运行特定Pod的拓扑域，主要用于：
- **高可用部署**：将副本分散到不同节点/可用区
- **资源隔离**：避免资源密集型Pod在同一节点

```yaml
spec:
  affinity:
    podAntiAffinity:
      # 硬反亲和性：绝不允许
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - web
        topologyKey: kubernetes.io/hostname  # 不同节点
      
      # 软反亲和性：尽量避免
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - web
          topologyKey: topology.kubernetes.io/zone  # 尽量不同可用区
```

#### 7.3.3.2 高可用部署示例

**示例1：Web应用副本分散到不同节点**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-ha
spec:
  replicas: 5
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      affinity:
        podAntiAffinity:
          # 硬反亲和性：强制分散到不同节点
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - web
            topologyKey: kubernetes.io/hostname
      
      containers:
      - name: nginx
        image: nginx:1.25
```

**部署结果：**

```
假设集群有3个节点：

Node-1: web-pod-1  ✅
Node-2: web-pod-2  ✅
Node-3: web-pod-3  ✅
Pending: web-pod-4, web-pod-5  ❌ 无可用节点

问题：硬反亲和性导致无法调度所有副本

改进方案：使用软反亲和性
```

**改进：使用软反亲和性**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-ha-improved
spec:
  replicas: 5
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      affinity:
        podAntiAffinity:
          # 软反亲和性：尽量分散，但允许共存
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: nginx
        image: nginx:1.25
```

**部署结果（软反亲和性）：**

```
Node-1: web-pod-1            ✅
Node-2: web-pod-2            ✅
Node-3: web-pod-3            ✅
Node-1: web-pod-4 (共存)     ✅ 软约束允许
Node-2: web-pod-5 (共存)     ✅ 软约束允许

优势：
- 优先分散到不同节点
- 节点不足时允许共存
- 所有副本都能调度
```

**示例2：跨可用区高可用部署**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-service
spec:
  replicas: 6
  selector:
    matchLabels:
      app: critical
  template:
    metadata:
      labels:
        app: critical
    spec:
      affinity:
        podAntiAffinity:
          # 硬反亲和性：强制跨节点
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - critical
            topologyKey: kubernetes.io/hostname
          
          # 软反亲和性：尽量跨可用区
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - critical
              topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: app
        image: critical-service:v2.0
```

**部署结果：**

```
假设集群：3个可用区，每个可用区2个节点

us-west-1a:
  Node-1: critical-pod-1  ✅
  Node-2: critical-pod-2  ✅

us-west-1b:
  Node-3: critical-pod-3  ✅
  Node-4: critical-pod-4  ✅

us-west-1c:
  Node-5: critical-pod-5  ✅
  Node-6: critical-pod-6  ✅

高可用分析：
- 单节点故障：影响1/6 (16.7%)
- 单可用区故障：影响2/6 (33.3%)
- 剩余4个Pod仍可服务 ✅
```

#### 7.3.3.3 资源隔离示例

**示例：GPU训练任务与CPU任务隔离**

```yaml
# GPU训练任务
apiVersion: batch/v1
kind: Job
metadata:
  name: gpu-training
spec:
  parallelism: 4
  template:
    metadata:
      labels:
        workload: gpu-training
        resource-intensive: "true"
    spec:
      affinity:
        podAntiAffinity:
          # 避免与CPU密集型任务共存
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: workload
                  operator: In
                  values:
                  - cpu-intensive
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: trainer
        image: tensorflow/tensorflow:latest-gpu
        resources:
          limits:
            nvidia.com/gpu: 2
---
# CPU密集型任务
apiVersion: batch/v1
kind: Job
metadata:
  name: data-processing
spec:
  parallelism: 10
  template:
    metadata:
      labels:
        workload: cpu-intensive
        resource-intensive: "true"
    spec:
      affinity:
        podAntiAffinity:
          # 避免与GPU任务共存
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: workload
                  operator: In
                  values:
                  - gpu-training
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: processor
        image: data-processor:v1.0
        resources:
          limits:
            cpu: "16"
            memory: "32Gi"
```

**部署结果：**

```
GPU节点：
  Node-GPU-1: gpu-training Pod × 2  ✅
  Node-GPU-2: gpu-training Pod × 2  ✅

CPU节点：
  Node-CPU-1: data-processing Pod × 3  ✅
  Node-CPU-2: data-processing Pod × 3  ✅
  Node-CPU-3: data-processing Pod × 4  ✅

隔离效果：
- GPU和CPU任务不会共存
- 避免资源竞争
- 各自性能最优
```

### 7.3.4 组合使用亲和性策略

#### 7.3.4.1 亲和性+反亲和性组合

**场景：Web应用+数据库高可用部署**

```yaml
# MySQL数据库（StatefulSet）
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
        component: database
    spec:
      affinity:
        # Pod反亲和性：MySQL副本分散到不同可用区
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - mysql
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: mysql
        image: mysql:8.0
---
# Web应用
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 9
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
        component: frontend
    spec:
      affinity:
        # Pod亲和性：Web应用靠近MySQL
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - mysql
              topologyKey: topology.kubernetes.io/zone
        
        # Pod反亲和性：Web副本分散到不同节点
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: web
        image: web-app:v2.0
```

**部署结果：**

```
us-west-1a (可用区):
  Node-1: mysql-0, web-1, web-2
  Node-2: web-3

us-west-1b (可用区):
  Node-3: mysql-1, web-4, web-5
  Node-4: web-6

us-west-1c (可用区):
  Node-5: mysql-2, web-7, web-8
  Node-6: web-9

优势分析：
✅ MySQL跨可用区高可用（3个可用区）
✅ Web应用靠近MySQL（低延迟）
✅ Web副本分散到不同节点（单节点故障影响小）
✅ 可用区级别容灾（单可用区故障，服务仍可用）
```

#### 7.3.4.2 节点亲和性+Pod亲和性组合

**场景：SSD节点上的高性能应用集群**

```yaml
# 数据库：必须在SSD节点
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: database
        tier: data
    spec:
      affinity:
        # 节点亲和性：必须SSD节点
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
                - nvme
        
        # Pod反亲和性：跨节点部署
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - database
            topologyKey: kubernetes.io/hostname
      
      containers:
      - name: db
        image: postgresql:14
---
# 应用服务：靠近数据库，优先SSD
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-service
spec:
  replicas: 6
  template:
    metadata:
      labels:
        app: app-service
        tier: application
    spec:
      affinity:
        # 节点亲和性：优先SSD节点
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            preference:
              matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
        
        # Pod亲和性：靠近数据库
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - database
              topologyKey: kubernetes.io/hostname
        
        # Pod反亲和性：尽量分散
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - app-service
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: app
        image: app-service:v3.0
```

**调度优先级分析：**

```
调度决策权重：
1. 数据库硬约束：必须SSD节点 (权重∞)
2. 数据库反亲和性：必须不同节点 (权重∞)
3. 应用Pod亲和性：靠近数据库 (权重100)
4. 应用节点亲和性：优先SSD (权重80)
5. 应用反亲和性：尽量分散 (权重50)

部署结果（假设3个SSD节点，2个HDD节点）：

SSD-Node-1: database-0, app-service-1, app-service-2
SSD-Node-2: database-1, app-service-3, app-service-4
SSD-Node-3: database-2, app-service-5, app-service-6

优势：
✅ 数据库在SSD节点（高性能）
✅ 应用靠近数据库（低延迟）
✅ 数据库副本分散（高可用）
✅ 应用副本分散（容错）
```

### 7.3.5 实战案例

#### 7.3.5.1 案例1：电商平台多层架构

**架构设计：**
- 前端（Nginx）：3副本，跨可用区
- API网关：6副本，靠近前端
- 业务服务：9副本，靠近API网关
- 数据库（MySQL）：3副本，跨可用区

```yaml
# 1. MySQL数据库（最底层）
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
  namespace: ecommerce
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
      tier: database
  template:
    metadata:
      labels:
        app: mysql
        tier: database
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disktype
                operator: In
                values:
                - ssd
        
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - mysql
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: mysql
        image: mysql:8.0
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
          limits:
            cpu: "8"
            memory: "32Gi"
---
# 2. 业务服务（中间层）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: business-service
  namespace: ecommerce
spec:
  replicas: 9
  selector:
    matchLabels:
      app: business
      tier: service
  template:
    metadata:
      labels:
        app: business
        tier: service
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - mysql
              topologyKey: topology.kubernetes.io/zone
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - business
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: business
        image: business-service:v2.0
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
---
# 3. API网关
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: ecommerce
spec:
  replicas: 6
  selector:
    matchLabels:
      app: gateway
      tier: api
  template:
    metadata:
      labels:
        app: gateway
        tier: api
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - business
              topologyKey: topology.kubernetes.io/zone
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - gateway
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: gateway
        image: api-gateway:v1.5
---
# 4. 前端Nginx（最上层）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: ecommerce
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
      tier: web
  template:
    metadata:
      labels:
        app: frontend
        tier: web
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - gateway
              topologyKey: topology.kubernetes.io/zone
        
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - frontend
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: nginx
        image: nginx:1.25
```

**部署拓扑：**

```
us-west-1a (可用区):
  ├─ MySQL-0 (主库)
  ├─ Business-Service × 3
  ├─ API-Gateway × 2
  └─ Frontend-1

us-west-1b (可用区):
  ├─ MySQL-1 (从库)
  ├─ Business-Service × 3
  ├─ API-Gateway × 2
  └─ Frontend-2

us-west-1c (可用区):
  ├─ MySQL-2 (从库)
  ├─ Business-Service × 3
  ├─ API-Gateway × 2
  └─ Frontend-3

流量路径：
用户 → Frontend (us-west-1a)
     → API-Gateway (us-west-1a, 低延迟)
     → Business-Service (us-west-1a, 低延迟)
     → MySQL (us-west-1a, 低延迟)

容灾能力：
- 单可用区故障：影响1/3流量
- 其他2个可用区继续服务 ✅
```

#### 7.3.5.2 案例2：大数据处理集群

**需求：**
- Spark Master：3副本，跨可用区
- Spark Worker：12副本，靠近Master
- HDFS DataNode：6副本，专用节点
- 隔离计算和存储任务

```yaml
# Spark Master
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: spark-master
spec:
  serviceName: spark-master
  replicas: 3
  template:
    metadata:
      labels:
        app: spark
        component: master
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: component
                operator: In
                values:
                - master
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: spark-master
        image: spark:3.5.0
---
# Spark Worker
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker
spec:
  replicas: 12
  template:
    metadata:
      labels:
        app: spark
        component: worker
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values:
                  - master
              topologyKey: topology.kubernetes.io/zone
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values:
                  - worker
              topologyKey: kubernetes.io/hostname
          
          # 避免与HDFS DataNode共存
          - weight: 60
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values:
                  - datanode
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: spark-worker
        image: spark:3.5.0
---
# HDFS DataNode
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: hdfs-datanode
spec:
  selector:
    matchLabels:
      app: hdfs
      component: datanode
  template:
    metadata:
      labels:
        app: hdfs
        component: datanode
    spec:
      nodeSelector:
        storage-node: "true"  # 专用存储节点
      
      containers:
      - name: datanode
        image: hadoop:3.3.0
```

### 7.3.6 常见问题与排查

#### 7.3.6.1 Pod无法调度（Pending）

**问题1：硬亲和性导致无可用节点**

```yaml
# 问题配置
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - nonexistent-app  # ❌ 不存在这个app
        topologyKey: kubernetes.io/hostname
```

```bash
# 排查
kubectl describe pod <pod-name>

Events:
  Warning  FailedScheduling  0/10 nodes are available:
           10 node(s) didn't match pod affinity rules.

# 解决方案1：检查目标Pod是否存在
kubectl get pods -l app=nonexistent-app
# 如果为空，说明没有匹配的Pod

# 解决方案2：改为软亲和性
preferredDuringSchedulingIgnoredDuringExecution:

# 解决方案3：修改标签选择器
- key: app
  operator: In
  values:
  - existing-app  # ✅ 存在的app
```

**问题2：反亲和性过于严格**

```yaml
# 问题配置：5个副本，硬反亲和性，只有3个节点
spec:
  replicas: 5
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - web
        topologyKey: kubernetes.io/hostname  # ❌ 节点不够
```

```bash
# 现象
kubectl get pods
NAME        READY   STATUS    AGE
web-1       1/1     Running   5m
web-2       1/1     Running   5m
web-3       1/1     Running   5m
web-4       0/1     Pending   5m  # ❌ 无可用节点
web-5       0/1     Pending   5m  # ❌ 无可用节点

# 解决方案：改为软反亲和性
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:  # ✅
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - web
          topologyKey: kubernetes.io/hostname
```

#### 7.3.6.2 topologyKey配置错误

```yaml
# ❌ 错误1：topologyKey对应的标签不存在
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - web
        topologyKey: nonexistent-key  # ❌ 节点没有这个标签
```

```bash
# 排查
kubectl get nodes --show-labels | grep nonexistent-key
# 如果为空，说明没有这个标签

# 解决方案：使用正确的标签
topologyKey: kubernetes.io/hostname  # ✅ 节点主机名
topologyKey: topology.kubernetes.io/zone  # ✅ 可用区
```

### 7.3.7 最佳实践

#### 7.3.7.1 亲和性配置原则

**1. 优先使用软亲和性**

```yaml
# ✅ 推荐：软约束提供灵活性
spec:
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - database
          topologyKey: topology.kubernetes.io/zone

# ❌ 避免：过度使用硬约束
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:  # 可能导致无法调度
      - labelSelector:
          ...
```

**2. 反亲和性分层策略**

```yaml
# ✅ 推荐：硬约束跨节点，软约束跨可用区
spec:
  affinity:
    podAntiAffinity:
      # 硬约束：必须不同节点
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - web
        topologyKey: kubernetes.io/hostname
      
      # 软约束：尽量不同可用区
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - web
          topologyKey: topology.kubernetes.io/zone
```

**3. 权重设置指南**

| 优先级 | 权重 | 使用场景 |
|-------|------|---------|
| **极高** | 100 | 关键性能要求（数据本地性） |
| **高** | 80 | 重要性能优化（低延迟） |
| **中** | 50-60 | 一般优化（负载均衡） |
| **低** | 20-40 | 次要偏好（成本优化） |

#### 7.3.7.2 常用配置模板

**模板1：高可用Web服务**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-ha-template
spec:
  replicas: 6
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      affinity:
        podAntiAffinity:
          # 硬约束：不同节点
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - web
            topologyKey: kubernetes.io/hostname
          
          # 软约束：不同可用区
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web
              topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: web
        image: nginx:1.25
```

**模板2：应用+缓存亲和部署**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-cache-template
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: application
    spec:
      affinity:
        # Pod亲和性：靠近Redis
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - redis
              topologyKey: kubernetes.io/hostname
        
        # Pod反亲和性：应用副本分散
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - application
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: app
        image: myapp:latest
```

---

本节我们深入学习了Pod亲和性和Pod反亲和性，包括基本概念、拓扑域机制、硬约束与软约束的使用、组合策略、实战案例以及最佳实践。通过合理使用Pod亲和性/反亲和性，可以实现基于Pod关系的精确调度控制，优化应用性能、提升高可用性并实现资源隔离。在下一节中，我们将学习污点（Taints）和容忍（Tolerations）机制，探讨如何实现节点的专用化和隔离。

---

**本节知识点回顾：**
- ✅ Pod Affinity和Pod Anti-Affinity核心概念
- ✅ 拓扑域（topologyKey）机制详解
- ✅ 硬亲和性和软亲和性的使用场景
- ✅ 高可用部署和资源隔离策略
- ✅ 亲和性策略组合使用（节点+Pod）
- ✅ 实战案例（电商平台、大数据集群）
- ✅ 常见问题排查和最佳实践
## 7.4 污点与容忍（Taints and Tolerations）

在上一节中，我们学习了Pod亲和性和反亲和性，掌握了如何基于Pod之间的关系进行调度。本节将深入探讨污点（Taints）和容忍（Tolerations）机制，学习如何通过"排斥"策略实现节点的专用化、资源隔离和故障自动处理。

### 7.4.1 污点与容忍概述

#### 7.4.1.1 核心概念

**污点（Taint）** 是应用在节点上的"排斥标记"，用于拒绝Pod调度到该节点，除非Pod明确声明可以"容忍"（Tolerate）这个污点。

```
┌─────────────────────────────────────────────────────────────┐
│           Taint与Affinity的对比（互补机制）                  │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Affinity（亲和性）- 吸引策略：                               │
│  ┌────────────────────────────────────┐                     │
│  │  Pod主动选择节点                    │                     │
│  │                                    │                     │
│  │  Pod ──"我想去"──> Node            │                     │
│  │        (选择加入)                  │                     │
│  └────────────────────────────────────┘                     │
│                                                              │
│  Taint（污点）- 排斥策略：                                    │
│  ┌────────────────────────────────────┐                     │
│  │  Node主动拒绝Pod                    │                     │
│  │                                    │                     │
│  │  Node ──"禁止进入"──X Pod          │                     │
│  │         (默认拒绝)                 │                     │
│  │                                    │                     │
│  │  Node ──"除非你有通行证"──> Pod    │                     │
│  │         (Toleration容忍)           │                     │
│  └────────────────────────────────────┘                     │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

**关键特性：**
- **默认排斥**：有污点的节点默认拒绝所有Pod
- **容忍通行**：只有带有匹配Toleration的Pod才能调度
- **主动控制**：由节点管理员控制节点可接受的工作负载类型

#### 7.4.1.2 Taint与Toleration工作流程

```
┌─────────────────────────────────────────────────────────────┐
│              Taint与Toleration调度流程                       │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Step 1: 节点打上污点                                         │
│  ┌──────────────────────────────────────┐                   │
│  │ Node: gpu-node-1                     │                   │
│  │ Taint: gpu=true:NoSchedule           │                   │
│  │ (只允许GPU任务)                       │                   │
│  └──────────────────────────────────────┘                   │
│                   │                                          │
│                   ▼                                          │
│  Step 2: Pod尝试调度                                          │
│  ┌──────────────────────────────────────┐                   │
│  │ Pod A (普通应用，无Toleration)        │                   │
│  │  → 调度器检查 → 发现Taint             │                   │
│  │  → 匹配失败 → ❌ 拒绝调度             │                   │
│  └──────────────────────────────────────┘                   │
│                                                              │
│  ┌──────────────────────────────────────┐                   │
│  │ Pod B (GPU应用，有Toleration)         │                   │
│  │  Toleration:                         │                   │
│  │    key: gpu                          │                   │
│  │    value: true                       │                   │
│  │    effect: NoSchedule                │                   │
│  │  → 调度器检查 → 容忍匹配              │                   │
│  │  → ✅ 允许调度到gpu-node-1            │                   │
│  └──────────────────────────────────────┘                   │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

#### 7.4.1.3 使用场景

**1. 节点专用化（Dedicated Nodes）**
- GPU节点专用于机器学习任务
- 高性能节点专用于数据库
- 特殊硬件节点（FPGA、高内存）

**2. 资源隔离**
- 生产环境与测试环境隔离
- 多租户资源隔离
- 不同团队/项目隔离

**3. 故障处理**
- 节点维护时驱逐Pod
- 节点故障时自动迁移
- 磁盘压力、内存压力自动驱逐

### 7.4.2 Taint详解

#### 7.4.2.1 Taint语法

Taint由三部分组成：`key=value:effect`

```yaml
# Taint结构
key=value:effect

# 示例
gpu=true:NoSchedule           # 带值的污点
special-hardware:NoSchedule   # 不带值的污点（value为空）
memory-pressure:NoExecute     # 系统自动添加的污点
```

**各部分说明：**

| 组成部分 | 说明 | 示例 |
|---------|------|------|
| **key** | 污点的键名（必填） | `gpu`, `env`, `node-role` |
| **value** | 污点的值（可选） | `true`, `prod`, `master` |
| **effect** | 污点效果（必填） | `NoSchedule`, `PreferNoSchedule`, `NoExecute` |

#### 7.4.2.2 三种Taint效果

**1. NoSchedule（硬性约束-调度阶段）**

```
效果：新Pod如果不容忍该污点，绝对不会被调度到该节点
影响：仅影响调度决策，不影响已运行的Pod
时机：调度阶段生效
```

```bash
# 为节点添加NoSchedule污点
kubectl taint nodes node1 env=prod:NoSchedule

# 效果示例
# ✅ 已在node1上运行的Pod → 继续运行（不受影响）
# ❌ 新Pod（无Toleration）→ 无法调度到node1
# ✅ 新Pod（有Toleration）→ 可以调度到node1
```

**2. PreferNoSchedule（软性约束-尽量避免）**

```
效果：调度器尽量避免将Pod调度到该节点，但不是硬性要求
影响：软性建议，集群资源紧张时可能仍会调度
时机：调度阶段生效，优先级较低
```

```bash
# 为节点添加PreferNoSchedule污点
kubectl taint nodes node2 disktype=hdd:PreferNoSchedule

# 效果示例
# 场景1：集群有其他可用节点
#   → 调度器优先选择其他节点
# 场景2：集群资源紧张，无其他节点可用
#   → 即使Pod无Toleration，也可能调度到node2
```

**3. NoExecute（最严格-立即驱逐）**

```
效果：不仅拒绝新Pod调度，还会驱逐已运行的不容忍Pod
影响：立即生效，影响新旧Pod
时机：添加污点后立即执行驱逐
驱逐宽限期：可通过tolerationSeconds控制
```

```bash
# 为节点添加NoExecute污点
kubectl taint nodes node3 maintenance=true:NoExecute

# 效果示例
# ✅ 有Toleration的Pod → 继续运行
# ❌ 无Toleration的Pod → 立即被驱逐（默认30秒宽限期）
# ❌ 新Pod（无Toleration）→ 无法调度
```

**三种效果对比表：**

| 效果 | 调度新Pod | 影响已运行Pod | 严格程度 | 使用场景 |
|------|----------|--------------|---------|---------|
| **NoSchedule** | ❌ 拒绝 | ✅ 不影响 | 硬约束 | 节点专用化 |
| **PreferNoSchedule** | ⚠️ 尽量避免 | ✅ 不影响 | 软约束 | 优化调度 |
| **NoExecute** | ❌ 拒绝 | ❌ 驱逐 | 最严格 | 维护/故障处理 |

#### 7.4.2.3 管理Taint

```bash
# 1. 添加Taint
kubectl taint nodes <node-name> <key>=<value>:<effect>

# 示例：标记GPU节点
kubectl taint nodes gpu-node-1 gpu=true:NoSchedule

# 示例：标记生产节点（无value）
kubectl taint nodes prod-node-1 env:NoSchedule

# 2. 查看节点的Taint
kubectl describe node <node-name> | grep Taints

# 输出示例：
# Taints:  gpu=true:NoSchedule
#          env=prod:NoExecute

# 3. 删除Taint（在key后加"-"）
kubectl taint nodes <node-name> <key>:<effect>-

# 示例：删除gpu污点
kubectl taint nodes gpu-node-1 gpu:NoSchedule-

# 4. 删除所有同key的Taint
kubectl taint nodes <node-name> <key>-

# 5. 更新Taint（先删后加）
kubectl taint nodes node1 env:NoSchedule- && \
kubectl taint nodes node1 env=prod:NoSchedule

# 6. 批量为多个节点添加Taint
kubectl taint nodes node1 node2 node3 dedicated=special:NoSchedule
```

### 7.4.3 Toleration详解

#### 7.4.3.1 Toleration语法

Toleration是Pod的属性，声明在`spec.tolerations`中。

```yaml
# 完整Toleration示例
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  tolerations:
  - key: "gpu"              # 容忍的污点key
    operator: "Equal"       # 匹配操作符：Equal或Exists
    value: "true"           # 容忍的污点value（operator为Equal时必填）
    effect: "NoSchedule"    # 容忍的污点effect（可选，为空表示容忍所有effect）
  
  containers:
  - name: app
    image: tensorflow/tensorflow:latest-gpu
```

**Toleration字段说明：**

| 字段 | 必填 | 说明 | 可选值 |
|------|------|------|--------|
| **key** | 否* | 污点的key | 任意字符串（为空表示匹配所有key） |
| **operator** | 否 | 匹配操作符 | `Equal`（默认）、`Exists` |
| **value** | 否* | 污点的value | 任意字符串（operator为Exists时忽略） |
| **effect** | 否 | 污点的effect | `NoSchedule`、`PreferNoSchedule`、`NoExecute`（为空表示匹配所有） |
| **tolerationSeconds** | 否 | NoExecute驱逐宽限期 | 秒数（仅NoExecute生效） |

#### 7.4.3.2 两种匹配操作符

**1. Equal（精确匹配）- 默认**

```yaml
# Taint: gpu=true:NoSchedule
# Toleration需要精确匹配key、value、effect

tolerations:
- key: "gpu"
  operator: "Equal"   # 可省略，默认为Equal
  value: "true"       # 必须与Taint的value完全一致
  effect: "NoSchedule"
```

**2. Exists（存在性匹配）**

```yaml
# 场景1：容忍特定key的所有值
# Taint: gpu=true:NoSchedule 或 gpu=v100:NoSchedule 都匹配
tolerations:
- key: "gpu"
  operator: "Exists"  # 不检查value
  effect: "NoSchedule"

# 场景2：容忍特定key的所有effect
# Taint: env=prod:NoSchedule 或 env=prod:NoExecute 都匹配
tolerations:
- key: "env"
  operator: "Exists"
  # effect为空，匹配所有effect

# 场景3：容忍节点上的所有污点（危险！）
tolerations:
- operator: "Exists"  # key、effect都为空
  # 匹配所有污点，慎用！
```

**匹配规则对比：**

| Toleration配置 | 匹配的Taint示例 | 说明 |
|---------------|----------------|------|
| `key=gpu, op=Equal, value=true, effect=NoSchedule` | `gpu=true:NoSchedule` | 精确匹配 |
| `key=gpu, op=Exists, effect=NoSchedule` | `gpu=true:NoSchedule`<br>`gpu=v100:NoSchedule` | 匹配key和effect，忽略value |
| `key=gpu, op=Exists` | `gpu=true:NoSchedule`<br>`gpu=true:NoExecute` | 匹配key，忽略value和effect |
| `op=Exists` | 所有污点 | ⚠️ 容忍所有污点（慎用） |

#### 7.4.3.3 tolerationSeconds驱逐宽限期

仅对`effect=NoExecute`生效，控制Pod被驱逐前的存活时间。

```yaml
# 场景：节点进入维护模式，给Pod 300秒时间完成任务
apiVersion: v1
kind: Pod
metadata:
  name: batch-job
spec:
  tolerations:
  - key: "maintenance"
    operator: "Equal"
    value: "true"
    effect: "NoExecute"
    tolerationSeconds: 300  # 5分钟宽限期
  
  containers:
  - name: job
    image: batch-processor:latest
```

**驱逐时间线：**

```
T+0s:    节点添加Taint: maintenance=true:NoExecute
T+0s:    Pod检测到Taint，开始倒计时300秒
T+300s:  宽限期结束，Pod被驱逐
T+330s:  Pod在其他节点重新调度（如果是Deployment管理）

特殊值：
- tolerationSeconds未设置：永久容忍，不会被驱逐
- tolerationSeconds: 0：立即驱逐
```

### 7.4.4 实战案例

#### 7.4.4.1 案例1：GPU节点专用化

**需求：** 集群中有3个GPU节点，仅允许机器学习任务使用，防止普通应用占用宝贵的GPU资源。

```bash
# Step 1: 为GPU节点打上污点
kubectl taint nodes gpu-node-1 gpu=true:NoSchedule
kubectl taint nodes gpu-node-2 gpu=true:NoSchedule
kubectl taint nodes gpu-node-3 gpu=true:NoSchedule

# Step 2: 验证污点
kubectl get nodes -l gpu=true -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
```

```yaml
# Step 3: 机器学习任务Pod（可以调度到GPU节点）
apiVersion: v1
kind: Pod
metadata:
  name: ml-training
  labels:
    app: ml-training
spec:
  tolerations:
  - key: "gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  
  containers:
  - name: trainer
    image: tensorflow/tensorflow:2.13.0-gpu
    resources:
      limits:
        nvidia.com/gpu: 1  # 请求1个GPU
    command:
    - python
    - train.py
---
# 普通Web应用（无Toleration，无法调度到GPU节点）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 5
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      # 无tolerations字段，无法调度到GPU节点
      containers:
      - name: nginx
        image: nginx:1.25
```

**效果验证：**

```bash
# 检查Pod调度情况
kubectl get pods -o wide

# 输出示例：
# NAME                       NODE          STATUS
# ml-training                gpu-node-1    Running   # ✅ GPU任务在GPU节点
# web-app-7d8f9c-abc12       worker-1      Running   # ✅ Web应用在普通节点
# web-app-7d8f9c-def34       worker-2      Running
```

#### 7.4.4.2 案例2：生产与测试环境隔离

**需求：** 生产节点仅运行生产应用，测试应用只能在测试节点运行，避免资源争抢。

```bash
# Step 1: 标记节点环境
# 生产节点
kubectl label nodes prod-node-1 prod-node-2 env=prod
kubectl taint nodes prod-node-1 prod-node-2 env=prod:NoSchedule

# 测试节点
kubectl label nodes test-node-1 test-node-2 env=test
kubectl taint nodes test-node-1 test-node-2 env=test:NoSchedule
```

```yaml
# Step 2: 生产应用配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-service
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: payment
  template:
    metadata:
      labels:
        app: payment
        env: prod
    spec:
      # 容忍生产环境污点
      tolerations:
      - key: "env"
        operator: "Equal"
        value: "prod"
        effect: "NoSchedule"
      
      # 节点亲和性：确保只调度到生产节点
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: env
                operator: In
                values:
                - prod
      
      containers:
      - name: payment
        image: payment-service:v2.1.0
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
---
# Step 3: 测试应用配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-service-test
  namespace: testing
spec:
  replicas: 1
  selector:
    matchLabels:
      app: payment-test
  template:
    metadata:
      labels:
        app: payment-test
        env: test
    spec:
      # 容忍测试环境污点
      tolerations:
      - key: "env"
        operator: "Equal"
        value: "test"
        effect: "NoSchedule"
      
      # 节点亲和性：确保只调度到测试节点
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: env
                operator: In
                values:
                - test
      
      containers:
      - name: payment
        image: payment-service:v2.2.0-beta
```

**最佳实践：Toleration + Node Affinity组合**

```
┌──────────────────────────────────────────────────────────┐
│         双重保障机制（推荐生产使用）                      │
├──────────────────────────────────────────────────────────┤
│                                                           │
│  仅Toleration（不推荐）：                                  │
│  ┌────────────────────────────────────────┐              │
│  │ Pod有生产环境Toleration                 │              │
│  │ ✅ 可以调度到生产节点                   │              │
│  │ ⚠️ 也可能调度到测试节点（如果测试节点   │              │
│  │    没有Taint或Pod也容忍测试Taint）     │              │
│  └────────────────────────────────────────┘              │
│                                                           │
│  Toleration + Node Affinity（推荐）：                     │
│  ┌────────────────────────────────────────┐              │
│  │ Step 1: Toleration让Pod可以进入生产节点 │              │
│  │         (通过污点检查)                  │              │
│  │ Step 2: Node Affinity确保只选择生产节点 │              │
│  │         (主动选择)                      │              │
│  │ ✅ 结果：Pod只会调度到生产节点           │              │
│  └────────────────────────────────────────┘              │
│                                                           │
└──────────────────────────────────────────────────────────┘
```

#### 7.4.4.3 案例3：节点维护与自动驱逐

**需求：** 对节点进行硬件升级，需要在维护前自动驱逐所有Pod，关键任务Pod给予5分钟宽限期完成任务。

```bash
# Step 1: 标记节点进入维护模式
kubectl taint nodes worker-3 maintenance=true:NoExecute

# 立即效果：
# - 无Toleration的Pod立即被驱逐（30秒宽限期）
# - 有Toleration的Pod根据tolerationSeconds决定
```

```yaml
# Step 2: 关键任务Pod配置（带宽限期）
apiVersion: batch/v1
kind: Job
metadata:
  name: data-backup
spec:
  template:
    spec:
      tolerations:
      # 容忍维护污点，给予5分钟完成备份
      - key: "maintenance"
        operator: "Equal"
        value: "true"
        effect: "NoExecute"
        tolerationSeconds: 300  # 5分钟
      
      restartPolicy: Never
      containers:
      - name: backup
        image: backup-tool:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "开始数据备份..."
          # 执行备份任务（需在5分钟内完成）
          /usr/local/bin/backup.sh
          echo "备份完成"
---
# Step 3: 普通应用（立即驱逐，在其他节点重建）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      # 无tolerations，立即被驱逐
      containers:
      - name: nginx
        image: nginx:1.25
```

**驱逐过程时间线：**

```
T+0s:     管理员执行: kubectl taint nodes worker-3 maintenance=true:NoExecute
T+0s:     Kubernetes开始处理：
          - web-frontend Pod → 无Toleration → 标记为删除（30秒宽限期）
          - data-backup Job → 有Toleration(300s) → 开始倒计时

T+30s:    web-frontend Pod被驱逐
T+31s:    Deployment控制器在worker-1上重建web-frontend Pod

T+120s:   data-backup Job正常完成备份，自动退出（Job Completed）

T+300s:   如果data-backup Job仍在运行，被强制驱逐

维护完成后：
kubectl taint nodes worker-3 maintenance:NoExecute-  # 移除污点
节点恢复正常调度
```

#### 7.4.4.4 案例4：Master节点保护

**背景：** Kubernetes默认为Master节点添加污点，防止用户工作负载调度到控制平面。

```bash
# 查看Master节点污点
kubectl describe node master-1 | grep Taints

# 输出示例：
# Taints: node-role.kubernetes.io/master:NoSchedule
#         node-role.kubernetes.io/control-plane:NoSchedule
```

```yaml
# 特殊场景：允许监控DaemonSet运行在Master节点
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      # 容忍Master节点污点，确保每个节点都有监控
      tolerations:
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
      
      hostNetwork: true  # 使用主机网络
      hostPID: true
      
      containers:
      - name: node-exporter
        image: quay.io/prometheus/node-exporter:v1.6.1
        ports:
        - containerPort: 9100
          protocol: TCP
```

### 7.4.5 系统自动添加的Taint

Kubernetes会在检测到节点问题时自动添加Taint，实现故障自动转移。

#### 7.4.5.1 节点状态Taint

| Taint Key | Effect | 触发条件 | 说明 |
|-----------|--------|---------|------|
| `node.kubernetes.io/not-ready` | NoExecute | Node状态为NotReady | 节点不健康 |
| `node.kubernetes.io/unreachable` | NoExecute | Node无法访问 | 网络分区 |
| `node.kubernetes.io/memory-pressure` | NoSchedule | 内存压力 | 可用内存不足 |
| `node.kubernetes.io/disk-pressure` | NoSchedule | 磁盘压力 | 磁盘空间不足 |
| `node.kubernetes.io/pid-pressure` | NoSchedule | PID压力 | 进程数过多 |
| `node.kubernetes.io/network-unavailable` | NoSchedule | 网络不可用 | 网络插件未就绪 |
| `node.kubernetes.io/unschedulable` | NoSchedule | 节点标记为不可调度 | `kubectl cordon` |

#### 7.4.5.2 自动驱逐行为

```yaml
# Pod默认自动容忍节点故障（给予恢复时间）
# Kubernetes自动为所有Pod添加以下Toleration：

apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  # 以下Toleration由Kubernetes自动添加，无需手动配置
  tolerations:
  - key: "node.kubernetes.io/not-ready"
    operator: "Exists"
    effect: "NoExecute"
    tolerationSeconds: 300  # 5分钟后驱逐
  
  - key: "node.kubernetes.io/unreachable"
    operator: "Exists"
    effect: "NoExecute"
    tolerationSeconds: 300  # 5分钟后驱逐
```

**故障转移时间线（默认行为）：**

```
T+0s:     节点宕机，kubelet停止心跳
T+40s:    Node Controller标记节点为NotReady
T+40s:    自动添加Taint: node.kubernetes.io/not-ready:NoExecute
T+40s:    Pod开始tolerationSeconds倒计时（300秒）
T+340s:   Pod被标记为Terminating，在其他节点重建

总故障转移时间：约6分钟（40s检测 + 300s宽限期）
```

#### 7.4.5.3 自定义故障转移时间

```yaml
# 关键应用：缩短故障转移时间到30秒
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: critical
  template:
    metadata:
      labels:
        app: critical
    spec:
      # 覆盖默认的300秒，改为30秒快速转移
      tolerations:
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 30
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 30
      
      containers:
      - name: app
        image: critical-service:v1.0
---
# 有状态应用：延长宽限期到10分钟，避免频繁重建
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
spec:
  serviceName: db
  replicas: 3
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      # 延长到10分钟，给节点足够恢复时间
      tolerations:
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 600
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 600
      
      containers:
      - name: mysql
        image: mysql:8.0
```

### 7.4.6 常见问题与排查

#### 7.4.6.1 Pod一直处于Pending状态

**问题现象：**

```bash
kubectl get pods
# NAME           READY   STATUS    RESTARTS   AGE
# my-app-abc12   0/1     Pending   0          5m
```

**排查步骤：**

```bash
# Step 1: 查看Pod事件
kubectl describe pod my-app-abc12

# 关键输出示例：
# Events:
#   Warning  FailedScheduling  1m (x12 over 5m)  default-scheduler  
#   0/5 nodes are available: 3 node(s) had taints that the pod didn't tolerate, 
#   2 Insufficient cpu.

# Step 2: 检查节点Taint
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
TAINTS:.spec.taints

# 输出示例：
# NAME         TAINTS
# node1        [map[effect:NoSchedule key:gpu value:true]]
# node2        [map[effect:NoSchedule key:env value:prod]]
# node3        [map[effect:NoExecute key:maintenance value:true]]

# Step 3: 查看Pod的Toleration配置
kubectl get pod my-app-abc12 -o jsonpath='{.spec.tolerations}'
```

**解决方案：**

```yaml
# 方案1：为Pod添加匹配的Toleration
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  tolerations:
  - key: "gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  containers:
  - name: app
    image: myapp:latest
```

```bash
# 方案2：删除不必要的Taint
kubectl taint nodes node1 gpu:NoSchedule-

# 方案3：临时允许调度到特定节点
kubectl taint nodes node2 env:NoSchedule-
```

#### 7.4.6.2 Pod被意外驱逐

**问题现象：**

```bash
kubectl get pods
# NAME           READY   STATUS        RESTARTS   AGE
# my-app-def34   1/1     Terminating   0          10m

kubectl get events --sort-by='.lastTimestamp'
# LAST SEEN   TYPE      REASON     MESSAGE
# 1m          Normal    Killing    Stopping container app
```

**排查步骤：**

```bash
# Step 1: 检查节点是否添加了NoExecute污点
kubectl describe node worker-2 | grep Taints

# 输出示例：
# Taints: node.kubernetes.io/unreachable:NoExecute

# Step 2: 检查Pod的Toleration
kubectl get pod my-app-def34 -o yaml | grep -A 10 tolerations

# Step 3: 查看节点事件
kubectl describe node worker-2

# Events:
#   Normal  NodeNotReady  5m  Node worker-2 status is now: NotReady
```

**解决方案：**

```yaml
# 方案1：为关键Pod添加永久容忍（慎用）
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  tolerations:
  - key: "node.kubernetes.io/unreachable"
    operator: "Exists"
    effect: "NoExecute"
    # 不设置tolerationSeconds，永久容忍

# 方案2: 修复节点问题
# - 检查节点网络
# - 重启kubelet
# - 检查系统资源

# 方案3：移除手动添加的维护污点
kubectl taint nodes worker-2 maintenance:NoExecute-
```

#### 7.4.6.3 DaemonSet无法在所有节点运行

**问题现象：**

```bash
kubectl get daemonset -n kube-system
# NAME              DESIRED   CURRENT   READY   NODE SELECTOR
# kube-proxy        5         3         3       <none>

# 期望5个节点都运行，实际只有3个
```

**排查步骤：**

```bash
# Step 1: 检查DaemonSet Pod状态
kubectl get pods -n kube-system -l app=kube-proxy -o wide

# Step 2: 检查未运行节点的Taint
kubectl get nodes -o json | jq -r '.items[] | 
  select(.spec.taints != null) | 
  {name: .metadata.name, taints: .spec.taints}'

# 输出示例：
# {
#   "name": "master-1",
#   "taints": [
#     {"key": "node-role.kubernetes.io/master", "effect": "NoSchedule"}
#   ]
# }
```

**解决方案：**

```yaml
# 为DaemonSet添加容忍Master节点污点
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-proxy
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: kube-proxy
  template:
    metadata:
      labels:
        app: kube-proxy
    spec:
      tolerations:
      # 容忍Master节点污点
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
      
      # 容忍所有NoExecute污点（确保即使节点故障也运行）
      - operator: "Exists"
        effect: "NoExecute"
      
      containers:
      - name: kube-proxy
        image: k8s.gcr.io/kube-proxy:v1.28.0
```

### 7.4.7 最佳实践

#### 7.4.7.1 设计原则

**1. Taint使用原则**

```yaml
# ✅ 推荐：使用语义化的key
gpu=true:NoSchedule                    # 清晰表达节点特性
env=prod:NoSchedule                    # 明确环境类型
disktype=ssd:PreferNoSchedule          # 描述硬件属性

# ❌ 不推荐：使用模糊的key
special:NoSchedule                     # 不明确
node1:NoSchedule                       # 缺乏语义
test:NoSchedule                        # 过于简单
```

**2. 效果选择原则**

| 场景 | 推荐效果 | 原因 |
|------|---------|------|
| 节点专用化（GPU、高性能） | NoSchedule | 仅阻止新调度，不影响已运行Pod |
| 资源优化建议 | PreferNoSchedule | 软性约束，提供调度灵活性 |
| 节点维护 | NoExecute | 需要清空节点 |
| 紧急故障 | NoExecute | 立即驱逐，快速转移 |
| 环境隔离 | NoSchedule | 防止误调度 |

**3. 组合使用原则**

```yaml
# 最佳实践：Toleration + Node Affinity + Resource Limits
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-training
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-training
  template:
    metadata:
      labels:
        app: ml-training
    spec:
      # 第1层：Toleration允许进入GPU节点
      tolerations:
      - key: "gpu"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
      
      # 第2层：Node Affinity确保选择GPU节点
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: accelerator
                operator: In
                values:
                - nvidia-tesla-v100
                - nvidia-a100
        
        # 第3层：Pod反亲和性确保分散部署
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - ml-training
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: trainer
        image: tensorflow/tensorflow:2.13.0-gpu
        # 第4层：Resource Limits明确资源需求
        resources:
          requests:
            memory: "16Gi"
            cpu: "4"
            nvidia.com/gpu: "1"
          limits:
            memory: "32Gi"
            cpu: "8"
            nvidia.com/gpu: "1"
```

#### 7.4.7.2 常用配置模板

**模板1：生产环境节点保护**

```bash
# 节点配置
kubectl label nodes prod-node-{1..5} env=prod tier=production
kubectl taint nodes prod-node-{1..5} env=prod:NoSchedule
```

```yaml
# Pod配置模板
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  labels:
    env: prod
spec:
  tolerations:
  - key: "env"
    operator: "Equal"
    value: "prod"
    effect: "NoSchedule"
  
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: env
            operator: In
            values:
            - prod
  
  containers:
  - name: app
    image: myapp:v1.0
```

**模板2：节点维护脚本**

```bash
#!/bin/bash
# 节点维护标准流程

NODE_NAME=$1

echo "开始维护节点: $NODE_NAME"

# Step 1: 标记节点不可调度
kubectl cordon $NODE_NAME

# Step 2: 添加NoExecute污点，给予5分钟宽限期
kubectl taint nodes $NODE_NAME maintenance=true:NoExecute

# Step 3: 等待Pod驱逐完成
echo "等待Pod驱逐（最多6分钟）..."
timeout 360 bash -c "
  while kubectl get pods --all-namespaces --field-selector spec.nodeName=$NODE_NAME | grep -v Terminating > /dev/null; do
    sleep 10
  done
"

# Step 4: 验证节点已清空
POD_COUNT=$(kubectl get pods --all-namespaces --field-selector spec.nodeName=$NODE_NAME --no-headers 2>/dev/null | wc -l)

if [ "$POD_COUNT" -eq 0 ]; then
  echo "✅ 节点已清空，可以进行维护"
else
  echo "⚠️  仍有 $POD_COUNT 个Pod运行，请检查"
  kubectl get pods --all-namespaces --field-selector spec.nodeName=$NODE_NAME
fi

# 维护完成后执行：
# kubectl uncordon $NODE_NAME
# kubectl taint nodes $NODE_NAME maintenance:NoExecute-
```

**模板3：关键应用快速故障转移**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-api
spec:
  replicas: 5
  selector:
    matchLabels:
      app: critical-api
  template:
    metadata:
      labels:
        app: critical-api
    spec:
      # 快速故障转移：30秒宽限期
      tolerations:
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 30
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 30
      
      # 跨可用区高可用
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - critical-api
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: api
        image: critical-api:v1.0
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 3
```

#### 7.4.7.3 监控与告警

**Prometheus监控指标：**

```yaml
# 监控节点Taint数量
sum(kube_node_spec_taint) by (node, key, effect)

# 监控Pending Pod（因Taint无法调度）
count(kube_pod_status_phase{phase="Pending"})

# 监控Pod驱逐事件
rate(kube_pod_deletion_timestamp[5m])
```

**告警规则示例：**

```yaml
groups:
- name: taint-alerts
  rules:
  # 节点污点异常增加
  - alert: NodeTaintIncreased
    expr: |
      increase(kube_node_spec_taint[10m]) > 5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "节点污点异常增加"
      description: "过去10分钟内有{{ $value }}个节点被添加污点"
  
  # 大量Pod因Taint无法调度
  - alert: PodsUnschedulableDueToTaint
    expr: |
      count(kube_pod_status_phase{phase="Pending"}) > 10
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: "大量Pod无法调度"
      description: "当前有{{ $value }}个Pod处于Pending状态，可能是Taint配置问题"
```

---

本节我们深入学习了污点（Taints）和容忍（Tolerations）机制，包括核心概念、三种污点效果（NoSchedule、PreferNoSchedule、NoExecute）、Toleration匹配规则、节点专用化、环境隔离、故障自动转移等实战案例，以及常见问题排查和最佳实践。通过合理使用Taint和Toleration，可以实现节点的专用化管理、资源隔离和自动故障处理。在下一节中，我们将学习优先级（Priority）和抢占（Preemption）机制，探讨如何管理Pod的调度优先级和资源抢占策略。

---

**本节知识点回顾：**
- ✅ Taint与Toleration核心概念和工作流程
- ✅ 三种Taint效果（NoSchedule、PreferNoSchedule、NoExecute）
- ✅ Toleration两种匹配操作符（Equal、Exists）
- ✅ tolerationSeconds驱逐宽限期机制
- ✅ GPU节点专用化、环境隔离实战案例
- ✅ 系统自动添加的Taint和故障转移机制
- ✅ Taint + Node Affinity组合使用最佳实践
- ✅ 常见问题排查和监控告警配置
## 7.5 优先级与抢占（Priority and Preemption）

在上一节中，我们学习了污点与容忍机制，掌握了节点级别的调度控制。本节将深入探讨优先级（Priority）和抢占（Preemption）机制，学习如何在资源紧张时保证关键应用的调度，通过优先级管理实现资源的合理分配。

### 7.5.1 优先级与抢占概述

#### 7.5.1.1 核心概念

**优先级（Priority）** 是Pod的一个数值属性，表示Pod相对于其他Pod的重要程度。当集群资源不足时，调度器会根据优先级做出调度决策。

**抢占（Preemption）** 是指高优先级Pod在无法调度时，调度器主动驱逐（Evict）低优先级Pod以腾出资源的机制。

```
┌─────────────────────────────────────────────────────────────┐
│              优先级调度工作原理                               │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  场景：集群资源已满，高优先级Pod尝试调度                       │
│                                                              │
│  初始状态：                                                   │
│  ┌────────────────────────────────────────┐                 │
│  │ Node-1 (8C 16G)  已使用：7C 14G        │                 │
│  │ ┌──────────────┐ ┌──────────────┐     │                 │
│  │ │ Pod A (低)   │ │ Pod B (低)   │     │                 │
│  │ │ 3C 6G        │ │ 4C 8G        │     │                 │
│  │ │ Priority: 0  │ │ Priority: 0  │     │                 │
│  │ └──────────────┘ └──────────────┘     │                 │
│  └────────────────────────────────────────┘                 │
│                   ▲                                          │
│                   │                                          │
│  新Pod到来：                                                  │
│  ┌────────────────────────────────────────┐                 │
│  │ Pod C (高优先级)                        │                 │
│  │ 请求：2C 4G                             │                 │
│  │ Priority: 1000                         │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  Step 1: 调度器检测资源不足                                   │
│  - 可用资源：1C 2G                                           │
│  - 需求资源：2C 4G                                           │
│  - 结论：无法调度 → 触发抢占流程                              │
│                   │                                          │
│                   ▼                                          │
│  Step 2: 抢占算法寻找受害者                                   │
│  - 遍历所有低优先级Pod                                        │
│  - 计算最小驱逐集合：驱逐Pod B即可满足                        │
│  - 标记Pod B为Preempted                                      │
│                   │                                          │
│                   ▼                                          │
│  Step 3: 执行抢占                                             │
│  ┌────────────────────────────────────────┐                 │
│  │ Node-1 (8C 16G)                        │                 │
│  │ ┌──────────────┐ ┌──────────────┐     │                 │
│  │ │ Pod A (低)   │ │ Pod C (高)   │     │                 │
│  │ │ 3C 6G        │ │ 2C 4G        │     │                 │
│  │ │ Priority: 0  │ │ Priority:1000│     │                 │
│  │ └──────────────┘ └──────────────┘     │                 │
│  └────────────────────────────────────────┘                 │
│  Pod B被驱逐到其他节点或Pending                               │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

#### 7.5.1.2 为什么需要优先级与抢占

**1. 资源紧张时的应用保障**

```
问题场景：
- 集群资源利用率已达90%
- 关键业务Pod（支付服务）需要紧急扩容
- 同时运行着大量低优先级批处理任务

没有优先级机制：
❌ 支付服务Pod处于Pending状态
❌ 业务受影响，可能导致资金损失
❌ 需要人工介入删除低优先级Pod

有优先级机制：
✅ 支付服务自动抢占批处理任务资源
✅ 关键业务优先保障
✅ 批处理任务稍后在资源空闲时自动恢复
```

**2. 多租户资源管理**

```
场景：共享集群中多个团队共存
- VIP客户应用优先级：高
- 普通客户应用优先级：中
- 内部测试应用优先级：低

优势：
✅ 资源紧张时，VIP客户业务不受影响
✅ 测试任务自动让出资源
✅ 公平调度与差异化服务并存
```

**3. 业务分级管理**

| 业务类型 | 优先级 | 特征 | 示例 |
|---------|-------|------|------|
| **核心业务** | 高（1000+） | 必须保证可用 | 交易、支付、核心API |
| **重要业务** | 中（100-999） | 尽量保证 | 用户服务、数据同步 |
| **批处理** | 低（0-99） | 可中断 | 数据分析、日志处理 |
| **开发测试** | 最低（负数） | 可随时牺牲 | 功能测试、性能测试 |

#### 7.5.1.3 优先级值范围

```yaml
优先级值：32位有符号整数

范围：-2147483648 至 2147483647

推荐分级：
┌────────────────────────────────────────┐
│  2,000,000,000  系统关键组件（保留）    │  ← Kubernetes系统Pod
│  1,000,000,000  系统组件（保留）        │  ← kube-system命名空间
├────────────────────────────────────────┤
│  10,000         用户最高优先级          │  ← 核心业务
│  1,000          高优先级                │  ← 重要业务
│  100            中等优先级              │  ← 普通业务
│  0              默认优先级（未设置）     │  ← 默认值
│  -100           低优先级                │  ← 批处理
│  -1000          最低优先级              │  ← 测试任务
└────────────────────────────────────────┘
```

### 7.5.2 PriorityClass资源

#### 7.5.2.1 PriorityClass定义

PriorityClass是集群级别（Cluster-scoped）资源，用于定义优先级类别。

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority        # PriorityClass名称
value: 1000000              # 优先级数值（越大越高）
globalDefault: false        # 是否作为全局默认（仅一个可为true）
description: "用于关键业务应用的高优先级类" # 描述信息
preemptionPolicy: PreemptLowerPriority  # 抢占策略
```

**字段说明：**

| 字段 | 必填 | 说明 | 可选值 |
|------|------|------|--------|
| **metadata.name** | 是 | PriorityClass名称 | 符合DNS标准的名称 |
| **value** | 是 | 优先级数值 | -2147483648 到 2147483647 |
| **globalDefault** | 否 | 是否为默认值 | true/false（集群仅一个可为true） |
| **description** | 否 | 描述信息 | 字符串 |
| **preemptionPolicy** | 否 | 抢占策略 | PreemptLowerPriority（默认）、Never |

#### 7.5.2.2 创建PriorityClass

```yaml
# 1. 核心业务优先级（最高）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: mission-critical
value: 10000
globalDefault: false
description: "核心业务应用，必须保证可用性"
preemptionPolicy: PreemptLowerPriority
---
# 2. 高优先级（重要业务）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000
globalDefault: false
description: "重要业务应用，优先保障"
preemptionPolicy: PreemptLowerPriority
---
# 3. 中等优先级（默认）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: normal-priority
value: 100
globalDefault: true          # 设为全局默认
description: "普通业务应用，默认优先级"
preemptionPolicy: PreemptLowerPriority
---
# 4. 低优先级（批处理）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority
value: 10
globalDefault: false
description: "批处理任务，可被抢占"
preemptionPolicy: PreemptLowerPriority
---
# 5. 测试环境（最低）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: test-priority
value: -100
globalDefault: false
description: "测试任务，资源紧张时优先牺牲"
preemptionPolicy: PreemptLowerPriority
```

```bash
# 应用PriorityClass
kubectl apply -f priority-classes.yaml

# 查看所有PriorityClass
kubectl get priorityclasses

# 输出示例：
# NAME               VALUE        GLOBAL-DEFAULT   AGE
# mission-critical   10000        false            1m
# high-priority      1000         false            1m
# normal-priority    100          true             1m
# low-priority       10           false            1m
# test-priority      -100         false            1m
# system-cluster-critical   2000000000   false     10d  # 系统预定义
# system-node-critical      2000001000   false     10d  # 系统预定义

# 查看详情
kubectl describe priorityclass mission-critical
```

#### 7.5.2.3 系统预定义PriorityClass

Kubernetes默认提供两个系统级PriorityClass：

```yaml
# 1. system-cluster-critical（集群关键组件）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: system-cluster-critical
value: 2000000000
globalDefault: false
description: "用于集群关键组件（kube-apiserver、etcd等）"

# 使用场景：
# - kube-apiserver
# - kube-controller-manager
# - kube-scheduler
# - etcd
# - coredns
---
# 2. system-node-critical（节点关键组件）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: system-node-critical
value: 2000001000
globalDefault: false
description: "用于节点关键组件（kubelet、kube-proxy等）"

# 使用场景：
# - kube-proxy
# - kubelet（静态Pod）
# - 容器运行时
```

**⚠️ 重要限制：**

```yaml
# 用户应用禁止使用系统级PriorityClass
# 以下配置会被拒绝（除非在kube-system命名空间）

apiVersion: v1
kind: Pod
metadata:
  name: my-app
  namespace: default
spec:
  priorityClassName: system-cluster-critical  # ❌ 拒绝
  containers:
  - name: app
    image: myapp:latest

# 错误信息：
# Error: pods "my-app" is forbidden: 
# pods with system-cluster-critical priorityClassName 
# is not permitted in default namespace
```

### 7.5.3 Pod使用优先级

#### 7.5.3.1 为Pod指定优先级

```yaml
# 方式1：通过priorityClassName指定（推荐）
apiVersion: v1
kind: Pod
metadata:
  name: payment-service
  labels:
    app: payment
spec:
  priorityClassName: mission-critical  # 引用PriorityClass名称
  containers:
  - name: payment
    image: payment:v1.0
    resources:
      requests:
        memory: "2Gi"
        cpu: "1"
---
# 方式2：直接指定priority值（不推荐，已废弃）
apiVersion: v1
kind: Pod
metadata:
  name: old-style-pod
spec:
  priority: 1000  # 直接指定数值（不推荐）
  containers:
  - name: app
    image: myapp:latest
```

**最佳实践：始终使用priorityClassName**

```
✅ 推荐：使用priorityClassName
- 语义清晰（mission-critical比10000更易理解）
- 集中管理（修改PriorityClass即可调整所有Pod）
- 避免魔法数字（1000、10000等硬编码值）

❌ 不推荐：直接使用priority
- 不直观，难以理解1000代表什么
- 分散管理，修改困难
- 未来可能废弃
```

#### 7.5.3.2 Deployment使用优先级

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: core-api
  namespace: production
spec:
  replicas: 5
  selector:
    matchLabels:
      app: core-api
  template:
    metadata:
      labels:
        app: core-api
        tier: backend
    spec:
      priorityClassName: high-priority  # 为所有Pod设置高优先级
      
      containers:
      - name: api
        image: core-api:v2.5.0
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
```

#### 7.5.3.3 查看Pod优先级

```bash
# 查看Pod的优先级
kubectl get pods -o custom-columns=\
NAME:.metadata.name,\
PRIORITY:.spec.priority,\
PRIORITY_CLASS:.spec.priorityClassName

# 输出示例：
# NAME                PRIORITY    PRIORITY_CLASS
# payment-abc123      10000       mission-critical
# user-service-def    1000        high-priority
# batch-job-ghi       10          low-priority
# test-pod-jkl        -100        test-priority

# 查看详细信息
kubectl describe pod payment-abc123

# 输出包含：
# Priority:         10000
# Priority Class Name:  mission-critical
```

### 7.5.4 抢占机制详解

#### 7.5.4.1 抢占触发条件

```
抢占发生的三个必要条件：

1. 资源不足
   - 集群所有节点都无法满足高优先级Pod的资源请求
   - 调度器经过预选和优选阶段，未找到合适节点

2. 优先级差异
   - 待调度Pod的优先级 > 某些已运行Pod的优先级
   - 存在可被抢占的"受害者"Pod

3. 抢占策略允许
   - 高优先级Pod的preemptionPolicy = PreemptLowerPriority（默认）
   - 低优先级Pod未设置保护机制
```

#### 7.5.4.2 抢占流程详解

```
┌─────────────────────────────────────────────────────────────┐
│                 抢占调度完整流程                             │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  T+0s: 高优先级Pod提交                                        │
│  ┌────────────────────────────────────────┐                 │
│  │ Pod: payment-service                   │                 │
│  │ Priority: 10000                        │                 │
│  │ Requests: 4C 8G                        │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+0.1s: Step 1 - 常规调度尝试                                │
│  ┌────────────────────────────────────────┐                 │
│  │ 调度器执行Predicates算法                │                 │
│  │ - 检查所有节点资源                      │                 │
│  │ - 结果：所有节点资源不足                │                 │
│  │ - 常规调度失败                          │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+0.2s: Step 2 - 触发抢占流程                                │
│  ┌────────────────────────────────────────┐                 │
│  │ 检查是否满足抢占条件：                   │                 │
│  │ ✅ 资源不足                             │                 │
│  │ ✅ 存在低优先级Pod（Priority < 10000）  │                 │
│  │ ✅ preemptionPolicy允许抢占             │                 │
│  │ → 进入抢占算法                          │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+0.3s: Step 3 - 寻找受害者节点                              │
│  ┌────────────────────────────────────────┐                 │
│  │ 遍历所有节点，计算抢占可行性：           │                 │
│  │                                        │                 │
│  │ Node-1: 驱逐2个Pod（Priority=100）     │                 │
│  │         可满足需求                      │                 │
│  │                                        │                 │
│  │ Node-2: 驱逐5个Pod（Priority=10）      │                 │
│  │         可满足需求                      │                 │
│  │                                        │                 │
│  │ Node-3: 无低优先级Pod，无法抢占         │                 │
│  │                                        │                 │
│  │ 选择策略：驱逐Pod数量最少的节点          │                 │
│  │ → 选择Node-1                           │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+0.4s: Step 4 - 标记受害者Pod                               │
│  ┌────────────────────────────────────────┐                 │
│  │ 为受害者Pod添加标记：                    │                 │
│  │ - status.nominatedNodeName: node-1     │                 │
│  │ - status.phase: Terminating            │                 │
│  │                                        │                 │
│  │ 给予优雅终止期：30秒                     │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+0.5s: Step 5 - 预留节点                                    │
│  ┌────────────────────────────────────────┐                 │
│  │ 高优先级Pod标记为"假定调度"：            │                 │
│  │ - nominatedNodeName: node-1            │                 │
│  │ - status: Pending                      │                 │
│  │                                        │                 │
│  │ 等待受害者Pod完成驱逐                    │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+30s: Step 6 - 受害者Pod驱逐完成                            │
│  ┌────────────────────────────────────────┐                 │
│  │ 受害者Pod已删除，资源释放                │                 │
│  │ Node-1可用资源：6C 12G                  │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+30.1s: Step 7 - 重新调度                                   │
│  ┌────────────────────────────────────────┐                 │
│  │ 高优先级Pod重新进入调度队列              │                 │
│  │ 执行常规调度流程                         │                 │
│  │ ✅ 成功调度到Node-1                     │                 │
│  └────────────────────────────────────────┘                 │
│                   │                                          │
│                   ▼                                          │
│  T+35s: Step 8 - Pod启动完成                                  │
│  ┌────────────────────────────────────────┐                 │
│  │ payment-service Running on Node-1      │                 │
│  └────────────────────────────────────────┘                 │
│                                                              │
│  受害者Pod（如果是Deployment管理）：                          │
│  T+30s: 在其他节点重新调度（如果有资源）                       │
│  T+30s: 否则处于Pending状态，等待资源                         │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

#### 7.5.4.3 抢占算法选择受害者

**选择原则（按优先级执行）：**

1. **优先级最低的Pod优先被驱逐**
2. **驱逐Pod数量最少**
3. **所有受害者Pod的优先级之和最低**
4. **受害者Pod运行时间最短**

```yaml
# 示例场景：高优先级Pod需要4C 8G

节点候选受害者分析：

Node-1:
  受害者方案1: Pod-A (Priority=0, 2C 4G) + Pod-B (Priority=0, 2C 4G)
    - 驱逐数量: 2个
    - 优先级和: 0
    - 总运行时间: 2小时
  
  受害者方案2: Pod-C (Priority=10, 4C 8G)
    - 驱逐数量: 1个
    - 优先级和: 10
    - 总运行时间: 1小时

Node-2:
  受害者方案3: Pod-D (Priority=0, 5C 10G)
    - 驱逐数量: 1个
    - 优先级和: 0
    - 总运行时间: 3小时

选择结果：
1. 优先级最低：方案1和方案3（Priority=0）
2. 驱逐数量最少：方案3（1个Pod）
3. 最终选择：Node-2的Pod-D
```

#### 7.5.4.4 抢占策略：preemptionPolicy

```yaml
# 策略1：PreemptLowerPriority（默认）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000
preemptionPolicy: PreemptLowerPriority  # 允许抢占低优先级Pod

# 使用场景：
# ✅ 关键业务，必须保证调度
# ✅ 生产环境核心服务
# ✅ 高可用应用
---
# 策略2：Never（禁止抢占）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: important-but-patient
value: 1000
preemptionPolicy: Never  # 禁止抢占，宁可等待

# 使用场景：
# ✅ 重要但可以等待的任务
# ✅ 避免干扰已运行的稳定服务
# ✅ 批处理任务（即使优先级高也不抢占）
```

**对比示例：**

```yaml
# Pod-A：允许抢占
apiVersion: v1
kind: Pod
metadata:
  name: critical-app
spec:
  priorityClassName: high-priority  # preemptionPolicy=PreemptLowerPriority
  containers:
  - name: app
    image: critical:v1

# 行为：资源不足时，驱逐低优先级Pod
---
# Pod-B：禁止抢占
apiVersion: v1
kind: Pod
metadata:
  name: patient-app
spec:
  priorityClassName: important-but-patient  # preemptionPolicy=Never
  containers:
  - name: app
    image: patient:v1

# 行为：资源不足时，进入Pending状态等待，不驱逐任何Pod
```

### 7.5.5 实战案例

#### 7.5.5.1 案例1：电商平台分级调度

**需求：** 电商平台有多种类型的工作负载，需要在大促期间保证交易服务优先，牺牲数据分析任务。

```yaml
# Step 1: 定义优先级体系
---
# 最高优先级：交易相关
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: transaction-critical
value: 10000
description: "交易核心服务，绝对保障"
preemptionPolicy: PreemptLowerPriority
---
# 高优先级：用户服务
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: user-service-high
value: 5000
description: "用户相关服务，高优先级"
preemptionPolicy: PreemptLowerPriority
---
# 中优先级：内容服务
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: content-medium
value: 1000
description: "内容展示服务，中等优先级"
preemptionPolicy: PreemptLowerPriority
---
# 低优先级：数据分析
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: analytics-low
value: 100
description: "数据分析任务，可被抢占"
preemptionPolicy: Never  # 自己也不抢占别人
---
# Step 2: 交易服务配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-service
  namespace: transaction
spec:
  replicas: 10
  selector:
    matchLabels:
      app: payment
  template:
    metadata:
      labels:
        app: payment
        tier: critical
    spec:
      priorityClassName: transaction-critical  # 最高优先级
      
      # 跨可用区高可用
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - payment
            topologyKey: topology.kubernetes.io/zone
      
      containers:
      - name: payment
        image: payment-service:v3.2.0
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
        env:
        - name: ENVIRONMENT
          value: "production"
---
# Step 3: 用户服务配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-api
  namespace: user
spec:
  replicas: 8
  selector:
    matchLabels:
      app: user-api
  template:
    metadata:
      labels:
        app: user-api
    spec:
      priorityClassName: user-service-high  # 高优先级
      
      containers:
      - name: api
        image: user-api:v2.1.0
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
---
# Step 4: 数据分析任务（低优先级）
apiVersion: batch/v1
kind: CronJob
metadata:
  name: sales-analytics
  namespace: analytics
spec:
  schedule: "0 2 * * *"  # 每天凌晨2点执行
  jobTemplate:
    spec:
      template:
        spec:
          priorityClassName: analytics-low  # 低优先级
          
          restartPolicy: OnFailure
          
          containers:
          - name: analytics
            image: analytics-job:v1.5
            resources:
              requests:
                memory: "16Gi"
                cpu: "8"
            command:
            - python
            - /app/analyze_sales.py
```

**大促期间行为模拟：**

```
场景：双11期间，流量暴增，需要紧急扩容支付服务

T+0:    正常运行状态
        - payment-service: 10 副本
        - user-api: 8 副本
        - sales-analytics: 5 Job Pods运行中
        - 集群资源利用率: 85%

T+1h:   流量增长3倍，触发HPA自动扩容
        - payment-service目标副本: 10 → 30
        - 新增20个payment Pod进入调度队列

T+1h:   调度器处理
        - 常规调度: 成功调度5个Pod（可用资源）
        - 剩余15个Pod: Pending（资源不足）

T+1h:   触发抢占机制
        - 抢占算法分析：
          * sales-analytics（Priority=100）占用资源多
          * 驱逐3个analytics Job Pod
          * 释放资源：48C 96G

T+1.5h: 抢占完成
        - payment-service: 成功调度到30副本
        - sales-analytics: 3个Job被驱逐，2个继续运行
        - 被驱逐的Job进入Pending状态

T+6h:   大促高峰结束，HPA缩容
        - payment-service: 30 → 15副本
        - 释放资源

T+6.5h: analytics Job自动恢复
        - 3个Pending的Job Pod重新调度
        - 继续执行数据分析任务

结果：
✅ 支付服务优先保障，交易无损失
✅ 数据分析任务自动让路
✅ 高峰过后，分析任务自动恢复
✅ 全程无需人工介入
```

#### 7.5.5.2 案例2：AI训练任务与在线服务共存

**需求：** GPU集群中，在线推理服务（低延迟要求）和离线训练任务（可中断）共享资源。

```yaml
# Step 1: 定义优先级
---
# 在线推理：高优先级
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: inference-high
value: 8000
description: "在线推理服务，低延迟要求"
preemptionPolicy: PreemptLowerPriority
---
# 离线训练：低优先级
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: training-low
value: 500
description: "离线训练任务，可被抢占"
preemptionPolicy: Never  # 训练任务不抢占别人
---
# Step 2: 在线推理服务
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-inference
  namespace: ai-prod
spec:
  replicas: 5
  selector:
    matchLabels:
      app: inference
  template:
    metadata:
      labels:
        app: inference
        service: online
    spec:
      priorityClassName: inference-high  # 高优先级
      
      # 节点亲和性：选择GPU节点
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: accelerator
                operator: In
                values:
                - nvidia-tesla-v100
      
      # 容忍GPU节点污点
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      
      containers:
      - name: inference
        image: model-inference:v2.0
        resources:
          requests:
            memory: "8Gi"
            cpu: "4"
            nvidia.com/gpu: "1"
          limits:
            memory: "16Gi"
            cpu: "8"
            nvidia.com/gpu: "1"
---
# Step 3: 离线训练任务
apiVersion: batch/v1
kind: Job
metadata:
  name: model-training
  namespace: ai-train
spec:
  parallelism: 4  # 4个并行训练Pod
  completions: 4
  template:
    spec:
      priorityClassName: training-low  # 低优先级
      
      restartPolicy: OnFailure
      
      # 节点亲和性：选择GPU节点
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: accelerator
                operator: In
                values:
                - nvidia-tesla-v100
      
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      
      containers:
      - name: trainer
        image: pytorch-training:v1.12
        resources:
          requests:
            memory: "32Gi"
            cpu: "16"
            nvidia.com/gpu: "2"
          limits:
            memory: "64Gi"
            cpu: "32"
            nvidia.com/gpu: "2"
        command:
        - python
        - train.py
        - --checkpoint-dir=/mnt/checkpoints
        volumeMounts:
        - name: checkpoints
          mountPath: /mnt/checkpoints
      
      volumes:
      - name: checkpoints
        persistentVolumeClaim:
          claimName: training-checkpoints
```

**运行时行为：**

```
初始状态（GPU集群：5个节点，每节点4个GPU）：
┌────────────────────────────────────────┐
│ inference: 5 Pods (每个1 GPU) = 5 GPU  │
│ training:  4 Pods (每个2 GPU) = 8 GPU  │
│ 空闲GPU: 7个                            │
│ 总GPU利用率: 13/20 = 65%                │
└────────────────────────────────────────┘

场景1：在线推理扩容
├─ T+0:   业务高峰，inference需要扩容到10副本
├─ T+1:   常规调度成功3个（使用空闲GPU）
├─ T+2:   剩余2个Pending（GPU不足）
├─ T+3:   触发抢占：
│         - 选择2个training Pod作为受害者
│         - 驱逐training-3、training-4
│         - 释放4个GPU
├─ T+33:  受害者驱逐完成（30秒宽限期）
│         - training任务checkpoint保存
├─ T+34:  inference成功调度到10副本
└─ T+?:   业务低峰，inference缩容到5副本
          - training任务从checkpoint恢复

场景2：训练任务启动
├─ T+0:   新训练任务提交（需要8 GPU）
├─ T+1:   检查资源：空闲GPU=7（不足）
├─ T+2:   preemptionPolicy=Never，不抢占
├─ T+3:   训练任务进入Pending状态
└─ T+?:   等待GPU释放（inference缩容或其他任务完成）

优势：
✅ 在线服务优先保障，用户体验不受影响
✅ 训练任务充分利用空闲资源
✅ 资源紧张时，训练自动让路
✅ Checkpoint机制保证训练可恢复
```

#### 7.5.5.3 案例3：多租户集群资源保障

**需求：** SaaS平台为不同等级的租户提供差异化服务保障。

```yaml
# Step 1: 租户优先级体系
---
# 企业版租户（最高）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: tenant-enterprise
value: 5000
description: "企业版租户，最高优先级"
preemptionPolicy: PreemptLowerPriority
---
# 专业版租户（高）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: tenant-professional
value: 2000
description: "专业版租户，高优先级"
preemptionPolicy: PreemptLowerPriority
---
# 标准版租户（中）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: tenant-standard
value: 1000
description: "标准版租户，中等优先级"
preemptionPolicy: Never  # 不抢占其他租户
---
# 免费版租户（低）
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: tenant-free
value: 100
description: "免费版租户，最低优先级"
preemptionPolicy: Never
---
# Step 2: 企业版租户应用部署
apiVersion: v1
kind: Namespace
metadata:
  name: tenant-acme-corp
  labels:
    tenant: acme-corp
    tier: enterprise
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: acme-app
  namespace: tenant-acme-corp
spec:
  replicas: 10
  selector:
    matchLabels:
      app: acme-app
  template:
    metadata:
      labels:
        app: acme-app
        tenant: acme-corp
    spec:
      priorityClassName: tenant-enterprise  # 企业版优先级
      
      containers:
      - name: app
        image: saas-app:v2.0
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
        env:
        - name: TENANT_ID
          value: "acme-corp"
        - name: TIER
          value: "enterprise"
---
# Step 3: 免费版租户应用部署
apiVersion: v1
kind: Namespace
metadata:
  name: tenant-free-user123
  labels:
    tenant: free-user123
    tier: free
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user123-app
  namespace: tenant-free-user123
spec:
  replicas: 2
  selector:
    matchLabels:
      app: user123-app
  template:
    metadata:
      labels:
        app: user123-app
        tenant: free-user123
    spec:
      priorityClassName: tenant-free  # 免费版优先级
      
      containers:
      - name: app
        image: saas-app:v2.0
        resources:
          requests:
            memory: "512Mi"
            cpu: "0.25"
        env:
        - name: TENANT_ID
          value: "free-user123"
        - name: TIER
          value: "free"
---
# Step 4: ResourceQuota配合使用
apiVersion: v1
kind: ResourceQuota
metadata:
  name: tenant-quota
  namespace: tenant-free-user123
spec:
  hard:
    requests.cpu: "2"        # 免费版最多2核
    requests.memory: "4Gi"   # 最多4GB内存
    pods: "10"               # 最多10个Pod
```

**资源争抢场景模拟：**

```
集群状态：20节点，总资源 400C 800G

租户分布：
- 企业版租户: 10个 (Priority=5000, 使用 200C 400G)
- 专业版租户: 20个 (Priority=2000, 使用 100C 200G)
- 标准版租户: 50个 (Priority=1000, 使用 60C 120G)
- 免费版租户: 200个(Priority=100,  使用 30C 60G)
总使用: 390C 780G (97.5%利用率)

场景：新企业版租户上线，需要50C 100G

Step 1: 常规调度
- 可用资源: 10C 20G
- 需求资源: 50C 100G
- 结果: 资源不足

Step 2: 触发抢占
- 分析受害者:
  * 免费版租户优先级最低
  * 计算最小驱逐集合
  * 选择20个免费版Pod驱逐（释放55C 110G）

Step 3: 执行抢占
- 20个免费版Pod被标记为Terminating
- 30秒后驱逐完成

Step 4: 企业版租户成功调度
- 新企业版租户应用Running
- 免费版租户部分Pod进入Pending状态

Step 5: 资源重平衡（业务低峰期）
- 企业版租户缩容
- 免费版Pod自动恢复

SLA保障：
✅ 企业版: 99.95%可用性（优先保障）
✅ 专业版: 99.5%可用性（高优先级）
✅ 标准版: 99%可用性（尽力而为）
✅ 免费版: 无SLA保障（资源紧张时牺牲）
```

### 7.5.6 常见问题与排查

#### 7.5.6.1 高优先级Pod仍然Pending

**问题现象：**

```bash
kubectl get pods
# NAME                    READY   STATUS    AGE
# critical-app-abc123     0/1     Pending   5m

kubectl describe pod critical-app-abc123
# Events:
#   Warning  FailedScheduling  2m  Insufficient cpu, preemption is not helpful
```

**原因分析：**

```
可能原因1：抢占后仍无法满足
├─ 即使驱逐所有低优先级Pod，资源仍不足
├─ 例如：Pod需要32C，单个节点最大16C
└─ 解决：调整Pod资源请求或扩容集群

可能原因2：所有Pod优先级相同或更高
├─ 集群中所有Pod的Priority >= 当前Pod
├─ 无可抢占的受害者
└─ 解决：检查其他Pod的priorityClassName

可能原因3：preemptionPolicy=Never
├─ Pod配置了不抢占策略
└─ 解决：修改PriorityClass的preemptionPolicy

可能原因4：Pod设置了特殊约束
├─ nodeSelector、节点亲和性限制了可调度节点
├─ 即使抢占也无法满足特定节点要求
└─ 解决：放宽调度约束
```

**排查步骤：**

```bash
# 1. 查看Pod优先级配置
kubectl get pod critical-app-abc123 -o jsonpath='{.spec.priority}'

# 2. 查看集群中所有Pod的优先级分布
kubectl get pods --all-namespaces -o custom-columns=\
NAME:.metadata.name,\
NAMESPACE:.metadata.namespace,\
PRIORITY:.spec.priority,\
STATUS:.status.phase | sort -k3 -n

# 3. 查看PriorityClass的抢占策略
kubectl get priorityclass critical-priority -o yaml | grep preemptionPolicy

# 4. 检查Pod的调度约束
kubectl get pod critical-app-abc123 -o yaml | grep -A 20 affinity

# 5. 模拟调度决策
kubectl describe node | grep -E "Name:|Allocatable:|Allocated"

# 6. 查看抢占事件
kubectl get events --sort-by='.lastTimestamp' | grep -i preempt
```

**解决方案：**

```yaml
# 方案1：提高优先级（如果合理）
apiVersion: v1
kind: Pod
metadata:
  name: critical-app
spec:
  priorityClassName: mission-critical  # 使用更高优先级
  containers:
  - name: app
    image: myapp:latest
    resources:
      requests:
        memory: "2Gi"  # 降低资源请求
        cpu: "1"
---
# 方案2：放宽调度约束
apiVersion: v1
kind: Pod
metadata:
  name: critical-app
spec:
  priorityClassName: high-priority
  affinity:
    nodeAffinity:
      # 从required改为preferred
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
  containers:
  - name: app
    image: myapp:latest
```

#### 7.5.6.2 低优先级Pod频繁被驱逐

**问题现象：**

```bash
kubectl get pods -n batch-jobs
# NAME            READY   STATUS        RESTARTS   AGE
# job-1-abc       0/1     Terminating   0          10m
# job-2-def       0/1     Terminating   0          15m
# job-3-ghi       1/1     Running       3          1h  # 重启3次

kubectl get events -n batch-jobs --sort-by='.lastTimestamp' | grep Preempted
# 10m   Normal   Preempted   pod/job-1-abc   Preempted by high-priority pod
# 15m   Normal   Preempted   pod/job-2-def   Preempted by high-priority pod
```

**原因分析：**

```
原因1：集群资源长期紧张
├─ 高优先级Pod持续扩容
├─ 低优先级Pod反复被抢占
└─ 陷入"调度-驱逐-调度"循环

原因2：优先级差距过大
├─ 批处理任务Priority=0
├─ 在线服务Priority=10000
└─ 任何在线服务扩容都会驱逐批处理

原因3：资源碎片化
├─ 低优先级Pod被分散调度
├─ 抢占时容易成为受害者
└─ 缺乏亲和性保护
```

**解决方案：**

```yaml
# 方案1：设置PodDisruptionBudget（PDB）保护
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: batch-job-pdb
  namespace: batch-jobs
spec:
  maxUnavailable: 30%  # 最多30%的Pod可被中断
  selector:
    matchLabels:
      app: batch-job

# 效果：抢占时，调度器会尊重PDB，避免驱逐过多Pod
---
# 方案2：调整优先级策略
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: batch-protected
value: 500  # 提高批处理优先级（原来是0）
description: "受保护的批处理任务"
preemptionPolicy: Never
---
# 方案3：使用节点池隔离
# 为批处理任务预留专用节点

# 批处理节点打标签
kubectl label nodes batch-node-{1..5} workload=batch

# 批处理任务使用节点选择器
apiVersion: batch/v1
kind: Job
metadata:
  name: protected-job
spec:
  template:
    spec:
      priorityClassName: batch-protected
      
      nodeSelector:
        workload: batch  # 只调度到批处理节点
      
      containers:
      - name: job
        image: batch-processor:v1
---
# 方案4：错峰调度
apiVersion: batch/v1
kind: CronJob
metadata:
  name: analytics-job
spec:
  schedule: "0 2 * * *"  # 凌晨2点（业务低峰期）
  jobTemplate:
    spec:
      template:
        spec:
          priorityClassName: low-priority
          containers:
          - name: analytics
            image: analytics:v1
```

#### 7.5.6.3 抢占导致服务抖动

**问题现象：**

```
监控告警：
- 服务延迟P99激增：50ms → 500ms
- 错误率上升：0.01% → 1%
- Pod重启频率增加

时间线：
14:00 - 高优先级Pod扩容
14:01 - 20个低优先级Pod被驱逐
14:02 - 数据库连接数激增（新Pod连接）
14:03 - 部分请求超时
14:05 - 服务恢复正常
```

**原因分析：**

```
问题：抢占驱逐导致的雪崩效应
├─ 大量Pod同时被驱逐
├─ 连接中断、缓存失效
├─ 新Pod启动，连接池重建
├─ 短时间内流量冲击
└─ 数据库、缓存压力激增
```

**解决方案：**

```yaml
# 方案1：优雅终止配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-service
spec:
  template:
    spec:
      priorityClassName: medium-priority
      
      # 延长优雅终止时间
      terminationGracePeriodSeconds: 60  # 默认30秒
      
      containers:
      - name: api
        image: api-service:v1
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - |
                # 优雅停止脚本
                echo "Stopping gracefully..."
                # 1. 停止接受新请求
                kill -TERM 1
                # 2. 等待现有请求处理完成
                sleep 30
                # 3. 关闭数据库连接
                /app/cleanup.sh
---
# 方案2：分批驱逐控制
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-pdb
spec:
  minAvailable: 70%  # 保证至少70%的Pod可用
  selector:
    matchLabels:
      app: api-service

# 效果：抢占时最多驱逐30%的Pod，避免大规模同时驱逐
---
# 方案3：连接池配置优化
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  application.yaml: |
    database:
      pool:
        min-idle: 5
        max-active: 20
        max-wait: 3000
        # 连接验证
        test-on-borrow: true
        validation-query: "SELECT 1"
    
    cache:
      # 持久化缓存，避免重启后冷启动
      persistence:
        enabled: true
        path: /var/cache/app
---
# 方案4：readinessProbe延迟
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-service
spec:
  template:
    spec:
      containers:
      - name: api
        image: api-service:v1
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 15  # 启动后15秒再检查
          periodSeconds: 5
          successThreshold: 2      # 连续2次成功才标记为Ready
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10

# 效果：新Pod启动后充分预热，避免冷启动流量冲击
```

### 7.5.7 最佳实践

#### 7.5.7.1 优先级设计原则

**1. 分层设计**

```yaml
# 推荐：5级优先级体系（足够区分，不过度复杂）

系统级（保留，不可用）：
├─ system-node-critical:     2000001000
└─ system-cluster-critical:  2000000000

用户级优先级：
├─ P0 - 核心业务:    10000   # 交易、支付、核心API
├─ P1 - 重要业务:    5000    # 用户服务、订单处理
├─ P2 - 普通业务:    1000    # 内容展示、推荐服务
├─ P3 - 批处理:      100     # 数据分析、报表生成
└─ P4 - 测试开发:    -100    # 功能测试、性能测试

❌ 不推荐：过度细分（10+个优先级）
- 管理复杂
- 难以区分
- 抢占频繁
```

**2. 语义化命名**

```yaml
✅ 推荐：清晰的语义
- mission-critical      # 一看就知道是最关键的
- user-facing-high      # 面向用户的高优先级
- background-batch      # 后台批处理
- dev-test-low          # 开发测试低优先级

❌ 不推荐：模糊命名
- priority-1, priority-2, priority-3  # 不知道具体含义
- high, medium, low                   # 过于简单
- p1, p2, p3                          # 不直观
```

**3. 文档化**

```yaml
# 为每个PriorityClass添加详细描述
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: mission-critical
  annotations:
    description.long: |
      核心业务应用优先级类
      
      适用范围：
      - 交易相关服务（支付、订单）
      - 核心API接口
      - 实时数据处理
      
      SLA要求：
      - 可用性：99.99%
      - 延迟：P99 < 100ms
      
      使用限制：
      - 需要Tech Lead审批
      - 仅限production命名空间
      
      联系人：platform-team@company.com
value: 10000
description: "核心业务应用，必须保证可用性"
```

#### 7.5.7.2 抢占策略选择

| 场景 | preemptionPolicy | 原因 |
|------|------------------|------|
| **核心在线服务** | PreemptLowerPriority | 必须保证调度，可抢占低优先级 |
| **数据库、缓存** | Never | 避免频繁驱逐导致数据不一致 |
| **批处理任务** | Never | 自己也不抢占别人，避免连锁反应 |
| **AI训练** | Never | 训练可中断但不应抢占其他服务 |
| **临时测试Pod** | PreemptLowerPriority | 测试紧急时可抢占其他测试Pod |

#### 7.5.7.3 配合其他机制使用

**1. 优先级 + PodDisruptionBudget**

```yaml
# 保护关键服务不被大规模驱逐
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-service-pdb
spec:
  minAvailable: 80%  # 至少保持80%可用
  selector:
    matchLabels:
      app: critical-service
      tier: production
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-service
spec:
  replicas: 10
  template:
    spec:
      priorityClassName: mission-critical
      # PDB保护，即使被抢占也最多驱逐2个Pod（20%）
```

**2. 优先级 + ResourceQuota**

```yaml
# 限制高优先级资源总量，避免滥用
apiVersion: v1
kind: ResourceQuota
metadata:
  name: high-priority-quota
  namespace: production
spec:
  hard:
    pods: "100"
    requests.cpu: "200"
    requests.memory: "400Gi"
  scopeSelector:
    matchExpressions:
    - operator: In
      scopeName: PriorityClass
      values:
      - mission-critical
      - high-priority

# 效果：production命名空间最多使用200C高优先级资源
```

**3. 优先级 + LimitRange**

```yaml
# 防止单个高优先级Pod占用过多资源
apiVersion: v1
kind: LimitRange
metadata:
  name: high-priority-limits
  namespace: production
spec:
  limits:
  - max:
      cpu: "8"
      memory: "16Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    type: Container
  - max:
      cpu: "16"
      memory: "32Gi"
    type: Pod
```

#### 7.5.7.4 监控与告警

**Prometheus监控指标：**

```yaml
# 1. Pod按优先级分布
sum(kube_pod_info) by (priority_class)

# 2. 抢占事件频率
rate(scheduler_preemption_attempts_total[5m])

# 3. 抢占成功率
rate(scheduler_preemption_victims_total[5m]) / 
rate(scheduler_preemption_attempts_total[5m])

# 4. Pending Pod按优先级统计
sum(kube_pod_status_phase{phase="Pending"}) by (priority_class)

# 5. 高优先级Pod调度延迟
histogram_quantile(0.99, 
  rate(scheduler_pod_scheduling_duration_seconds_bucket{
    priority_class="mission-critical"
  }[5m])
)
```

**告警规则：**

```yaml
groups:
- name: priority-alerts
  rules:
  # 高优先级Pod调度失败
  - alert: HighPriorityPodPending
    expr: |
      sum(kube_pod_status_phase{
        phase="Pending",
        priority_class=~"mission-critical|high-priority"
      }) > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "高优先级Pod无法调度"
      description: "{{ $value }}个高优先级Pod处于Pending状态超过5分钟"
  
  # 抢占频率过高
  - alert: FrequentPreemption
    expr: |
      rate(scheduler_preemption_attempts_total[10m]) > 10
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "抢占频率过高"
      description: "过去10分钟平均每分钟{{ $value }}次抢占，可能需要扩容"
  
  # 低优先级Pod长期Pending
  - alert: LowPriorityPodStarving
    expr: |
      sum(kube_pod_status_phase{
        phase="Pending",
        priority_class=~"low-priority|batch-.*"
      }) > 50
    for: 1h
    labels:
      severity: info
    annotations:
      summary: "大量低优先级Pod资源不足"
      description: "{{ $value }}个低优先级Pod Pending超过1小时，考虑扩容或调整优先级"
```

#### 7.5.7.5 配置模板

**完整生产环境配置示例：**

```yaml
# 1. PriorityClass定义
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: production-critical
value: 10000
globalDefault: false
description: "生产环境核心服务"
preemptionPolicy: PreemptLowerPriority
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: production-standard
value: 5000
globalDefault: true  # 生产环境默认
description: "生产环境标准服务"
preemptionPolicy: PreemptLowerPriority
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: background-batch
value: 1000
description: "后台批处理任务"
preemptionPolicy: Never
---
# 2. 核心服务部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-api
  namespace: production
  labels:
    app: payment-api
    tier: critical
spec:
  replicas: 10
  selector:
    matchLabels:
      app: payment-api
  template:
    metadata:
      labels:
        app: payment-api
        tier: critical
    spec:
      priorityClassName: production-critical
      
      # 跨zone高可用
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: payment-api
            topologyKey: topology.kubernetes.io/zone
      
      # 优雅终止
      terminationGracePeriodSeconds: 60
      
      containers:
      - name: api
        image: payment-api:v3.0
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
          successThreshold: 2
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
---
# 3. PodDisruptionBudget保护
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: payment-api-pdb
  namespace: production
spec:
  minAvailable: 80%
  selector:
    matchLabels:
      app: payment-api
---
# 4. ResourceQuota限制
apiVersion: v1
kind: ResourceQuota
metadata:
  name: critical-quota
  namespace: production
spec:
  hard:
    requests.cpu: "100"
    requests.memory: "200Gi"
    pods: "50"
  scopeSelector:
    matchExpressions:
    - operator: In
      scopeName: PriorityClass
      values:
      - production-critical
```

---

本节我们深入学习了优先级（Priority）和抢占（Preemption）机制，包括核心概念、PriorityClass资源定义、抢占流程详解、电商分级调度、AI任务共存、多租户资源保障等实战案例，以及常见问题排查和最佳实践。通过合理使用优先级与抢占，可以在资源紧张时保证关键应用的调度，实现差异化的服务质量保障。在下一节中，我们将学习资源配额（ResourceQuota）和限制范围（LimitRange）机制，探讨如何实现命名空间级别的资源管理和限制。

---

**本节知识点回顾：**
- ✅ 优先级与抢占核心概念和工作原理
- ✅ PriorityClass资源定义和字段详解
- ✅ 优先级值范围和分级体系设计
- ✅ 抢占流程8步详解和受害者选择算法
- ✅ preemptionPolicy两种策略（PreemptLowerPriority/Never）
- ✅ 电商分级、AI训练、多租户实战案例
- ✅ 高优先级Pod Pending、频繁驱逐问题排查
- ✅ 优先级+PDB+ResourceQuota组合使用最佳实践
- ✅ 监控指标和告警规则配置
## 7.6 资源配额与限制范围（ResourceQuota and LimitRange）

在上一节中，我们学习了优先级与抢占机制，掌握了Pod级别的调度优先级控制。本节将深入探讨资源配额（ResourceQuota）和限制范围（LimitRange）机制，学习如何在命名空间级别实现资源管理、配额限制和多租户资源隔离。

### 7.6.1 资源配额与限制范围概述

#### 7.6.1.1 核心概念

**ResourceQuota（资源配额）** 是命名空间级别的资源，用于限制该命名空间中所有资源的总量，包括计算资源（CPU、内存）、存储资源、对象数量等。

**LimitRange（限制范围）** 是命名空间级别的资源，用于限制该命名空间中单个对象（Pod、Container）的资源使用范围，包括最小值、最大值和默认值。

```
┌─────────────────────────────────────────────────────────────┐
│        ResourceQuota vs LimitRange 对比                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ResourceQuota（总量控制）：                                  │
│  ┌────────────────────────────────────────┐                 │
│  │  Namespace: production                 │                 │
│  │  ┌──────────────────────────────────┐  │                 │
│  │  │ ResourceQuota:                   │  │                 │
│  │  │ - CPU总量: 最多100核             │  │                 │
│  │  │ - 内存总量: 最多200GB            │  │                 │
│  │  │ - Pod总数: 最多50个              │  │                 │
│  │  └──────────────────────────────────┘  │                 │
│  │                                        │                 │
│  │  Pod-1  Pod-2  Pod-3  ...  Pod-N      │                 │
│  │  (2C4G) (4C8G) (1C2G)      (总和≤配额) │                 │
│  └────────────────────────────────────────┘                 │
│                                                              │
│  LimitRange（单体控制）：                                     │
│  ┌────────────────────────────────────────┐                 │
│  │  Namespace: production                 │                 │
│  │  ┌──────────────────────────────────┐  │                 │
│  │  │ LimitRange:                      │  │                 │
│  │  │ - 单Pod CPU: 0.1-8核             │  │                 │
│  │  │ - 单Pod内存: 128M-16G            │  │                 │
│  │  │ - 默认请求: 1C 2G                │  │                 │
│  │  │ - 默认限制: 2C 4G                │  │                 │
│  │  └──────────────────────────────────┘  │                 │
│  │                                        │                 │
│  │  每个Pod必须符合单体限制               │                 │
│  │  ✅ Pod-A (2C 4G) → 在范围内           │                 │
│  │  ❌ Pod-B (16C 32G) → 超出最大值       │                 │
│  └────────────────────────────────────────┘                 │
│                                                              │
│  组合使用效果：                                               │
│  ┌────────────────────────────────────────┐                 │
│  │ ResourceQuota: 控制"总预算"            │                 │
│  │ LimitRange: 控制"单笔消费上限"         │                 │
│  │                                        │                 │
│  │ 双重保障：                              │                 │
│  │ 1. 防止单个Pod占用过多资源（LimitRange）│                 │
│  │ 2. 防止命名空间资源总量超标(ResourceQuota)│               │
│  └────────────────────────────────────────┘                 │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

#### 7.6.1.2 为什么需要资源配额与限制

**1. 多租户资源隔离**

```
问题场景：共享集群中多个团队/项目共存
- 团队A提交大量Pod，占用80%集群资源
- 团队B、C无资源可用，业务受影响
- 资源分配不公平，导致团队冲突

解决方案：ResourceQuota
✅ 为每个团队分配固定配额（如30%资源）
✅ 超出配额的请求被拒绝
✅ 保证资源公平分配
```

**2. 成本控制**

```
问题：云环境按资源付费
- 开发人员随意申请资源
- 测试环境Pod请求32C 64G（实际只用2C 4G）
- 月底账单爆炸

解决方案：ResourceQuota + LimitRange
✅ 限制测试环境总资源（如10核20G）
✅ 限制单Pod最大资源（如4核8G）
✅ 强制设置合理的requests和limits
```

**3. 防止资源滥用**

```
问题：恶意或错误配置
- 用户提交"挖矿"Pod，请求1000核
- 错误配置导致Pod无限扩容
- 资源耗尽导致集群崩溃

解决方案：LimitRange
✅ 限制单Pod资源上限（如8核16G）
✅ 拒绝不合理的资源请求
✅ 保护集群稳定性
```

**4. 资源规划**

| 命名空间类型 | CPU配额 | 内存配额 | Pod数量 | 存储配额 |
|------------|--------|---------|--------|---------|
| **生产环境** | 200核 | 400GB | 100个 | 1TB |
| **预发布环境** | 50核 | 100GB | 50个 | 200GB |
| **测试环境** | 20核 | 40GB | 30个 | 100GB |
| **开发环境** | 10核 | 20GB | 20个 | 50GB |

### 7.6.2 ResourceQuota详解

#### 7.6.2.1 ResourceQuota基本语法

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota           # 配额名称
  namespace: production          # 所属命名空间
spec:
  hard:                          # 硬性限制
    # 计算资源
    requests.cpu: "100"          # CPU请求总量
    requests.memory: "200Gi"     # 内存请求总量
    limits.cpu: "200"            # CPU限制总量
    limits.memory: "400Gi"       # 内存限制总量

    # 存储资源
    requests.storage: "500Gi"    # 存储请求总量
    persistentvolumeclaims: "10" # PVC数量

    # 对象数量
    pods: "50"                   # Pod总数
    services: "20"               # Service总数
    configmaps: "30"             # ConfigMap总数
    secrets: "30"                # Secret总数
    replicationcontrollers: "10" # RC总数

  # 作用域选择器（可选）
  scopeSelector:
    matchExpressions:
    - operator: In
      scopeName: PriorityClass
      values:
      - high-priority
```

**字段说明：**

| 字段类别 | 资源类型 | 说明 | 单位 |
|---------|---------|------|------|
| **计算资源** | requests.cpu | CPU请求总量 | 核心数 |
|  | requests.memory | 内存请求总量 | 字节（支持Gi、Mi） |
|  | limits.cpu | CPU限制总量 | 核心数 |
|  | limits.memory | 内存限制总量 | 字节 |
| **存储资源** | requests.storage | 存储请求总量 | 字节 |
|  | persistentvolumeclaims | PVC数量 | 个数 |
| **对象数量** | pods | Pod总数 | 个数 |
|  | services | Service总数 | 个数 |
|  | configmaps | ConfigMap总数 | 个数 |
|  | secrets | Secret总数 | 个数 |

#### 7.6.2.2 计算资源配额

```yaml
# 示例1：基本计算资源配额
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
  namespace: team-a
spec:
  hard:
    requests.cpu: "50"        # 该命名空间所有Pod的CPU requests总和 ≤ 50核
    requests.memory: "100Gi"  # 内存requests总和 ≤ 100GB
    limits.cpu: "100"         # CPU limits总和 ≤ 100核
    limits.memory: "200Gi"    # 内存limits总和 ≤ 200GB
```

**配额生效示例：**

```yaml
# 当前命名空间已使用资源：
# - requests.cpu: 45/50
# - requests.memory: 90Gi/100Gi

# Pod-1：成功创建（未超配额）
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  namespace: team-a
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "2"
        memory: "4Gi"
      limits:
        cpu: "4"
        memory: "8Gi"

# 结果：✅ 成功
# 新增requests: 2C + 4G
# 总requests: 47C/50, 94Gi/100Gi（未超配额）
---
# Pod-2：创建失败（超出配额）
apiVersion: v1
kind: Pod
metadata:
  name: pod-2
  namespace: team-a
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "10"
        memory: "20Gi"

# 结果：❌ 失败
# 错误信息：
# Error from server (Forbidden): pods "pod-2" is forbidden:
# exceeded quota: compute-resources,
# requested: requests.cpu=10,
# used: requests.cpu=47,
# limited: requests.cpu=50
```

#### 7.6.2.3 查看和管理ResourceQuota

```bash
# 1. 查看命名空间的所有ResourceQuota
kubectl get resourcequota -n production

# 输出示例：
# NAME               AGE   REQUEST
# compute-quota      10d   requests.cpu: 45/50, requests.memory: 90Gi/100Gi

# 2. 查看详细使用情况
kubectl describe resourcequota compute-quota -n production

# 输出示例：
# Name:            compute-quota
# Namespace:       production
# Resource         Used   Hard
# --------         ----   ----
# limits.cpu       90     100
# limits.memory    180Gi  200Gi
# requests.cpu     45     50
# requests.memory  90Gi   100Gi

# 3. 删除ResourceQuota
kubectl delete resourcequota compute-quota -n production
```

### 7.6.3 LimitRange详解

#### 7.6.3.1 LimitRange基本语法

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: resource-limits
  namespace: production
spec:
  limits:
  # 容器级别限制
  - type: Container
    max:                        # 单容器最大值
      cpu: "4"
      memory: "8Gi"
    min:                        # 单容器最小值
      cpu: "100m"
      memory: "128Mi"
    default:                    # 默认limits（未指定时）
      cpu: "1"
      memory: "1Gi"
    defaultRequest:             # 默认requests（未指定时）
      cpu: "500m"
      memory: "512Mi"
    maxLimitRequestRatio:       # limits/requests最大比例
      cpu: "4"                  # limits最多是requests的4倍
      memory: "2"               # limits最多是requests的2倍

  # Pod级别限制
  - type: Pod
    max:                        # 单Pod所有容器总和最大值
      cpu: "16"
      memory: "32Gi"
```

**字段说明：**

| 字段 | 说明 | 适用类型 |
|------|------|---------|
| **max** | 最大值限制 | Container、Pod、PVC |
| **min** | 最小值限制 | Container、Pod、PVC |
| **default** | 默认limits（未指定时自动添加） | Container |
| **defaultRequest** | 默认requests（未指定时自动添加） | Container |
| **maxLimitRequestRatio** | limits/requests最大比例 | Container、Pod |

#### 7.6.3.2 容器级别限制

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: container-limits
  namespace: development
spec:
  limits:
  - type: Container
    max:
      cpu: "2"          # 单容器最多2核
      memory: "4Gi"     # 单容器最多4GB
    min:
      cpu: "50m"        # 单容器至少50毫核
      memory: "64Mi"    # 单容器至少64MB
    default:
      cpu: "500m"       # 未指定limits时，默认500毫核
      memory: "512Mi"   # 未指定limits时，默认512MB
    defaultRequest:
      cpu: "250m"       # 未指定requests时，默认250毫核
      memory: "256Mi"   # 未指定requests时，默认256MB
    maxLimitRequestRatio:
      cpu: "4"          # CPU limits ≤ requests * 4
      memory: "2"       # 内存limits ≤ requests * 2
```

**LimitRange自动注入示例：**

```yaml
# 用户提交的Pod（未指定资源）
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  namespace: development
spec:
  containers:
  - name: app
    image: nginx
    # 未指定resources
---
# Kubernetes自动注入后（实际创建的Pod）
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  namespace: development
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:        # 自动添加defaultRequest
        cpu: "250m"
        memory: "256Mi"
      limits:          # 自动添加default
        cpu: "500m"
        memory: "512Mi"
```

**LimitRange验证示例：**

```yaml
# 场景1：超出最大值（拒绝）
apiVersion: v1
kind: Pod
metadata:
  name: oversized-pod
  namespace: development
spec:
  containers:
  - name: app
    image: nginx
    resources:
      limits:
        cpu: "5"        # ❌ 超出max.cpu=2
        memory: "8Gi"   # ❌ 超出max.memory=4Gi

# 结果：❌ 拒绝创建
# Error: maximum cpu usage per Container is 2, but limit is 5
```

### 7.6.4 实战案例

#### 7.6.4.1 案例1：多租户SaaS平台资源隔离

**需求：** SaaS平台为不同等级租户提供隔离的资源环境。

```yaml
# 企业版租户配置
---
apiVersion: v1
kind: Namespace
metadata:
  name: tenant-enterprise-acme
  labels:
    tier: enterprise
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: enterprise-quota
  namespace: tenant-enterprise-acme
spec:
  hard:
    requests.cpu: "100"
    requests.memory: "200Gi"
    limits.cpu: "200"
    limits.memory: "400Gi"
    pods: "100"
    services: "30"
    persistentvolumeclaims: "20"
    requests.storage: "2Ti"
---
apiVersion: v1
kind: LimitRange
metadata:
  name: enterprise-limits
  namespace: tenant-enterprise-acme
spec:
  limits:
  - type: Container
    max:
      cpu: "16"
      memory: "32Gi"
    default:
      cpu: "2"
      memory: "4Gi"
    defaultRequest:
      cpu: "1"
      memory: "2Gi"
```

**租户配额对比表：**

| 资源类型 | 企业版 | 标准版 | 免费版 |
|---------|-------|-------|-------|
| **CPU请求** | 100核 | 20核 | 2核 |
| **内存请求** | 200GB | 40GB | 4GB |
| **Pod数量** | 100个 | 30个 | 5个 |
| **存储总量** | 2TB | 200GB | 10GB |
| **单容器最大** | 16C 32G | 4C 8G | 1C 2G |

### 7.6.5 常见问题与排查

#### 7.6.5.1 Pod创建失败：超出ResourceQuota

**问题现象：**

```bash
kubectl apply -f deployment.yaml
# Error: exceeded quota: compute-quota,
# requested: requests.cpu=10,
# used: requests.cpu=95,
# limited: requests.cpu=100
```

**排查步骤：**

```bash
# 1. 查看命名空间配额使用情况
kubectl describe resourcequota compute-quota -n production

# 2. 找出资源占用大的Pod
kubectl get pods -n production -o custom-columns=\
NAME:.metadata.name,\
CPU_REQ:.spec.containers[*].resources.requests.cpu,\
MEM_REQ:.spec.containers[*].resources.requests.memory
```

**解决方案：**

```yaml
# 方案1：提高配额
kubectl edit resourcequota compute-quota -n production
# 修改 requests.cpu: "100" → "150"

# 方案2：优化资源请求
resources:
  requests:
    cpu: "500m"    # 从10核降到500毫核
    memory: "1Gi"
```

#### 7.6.5.2 配额不足导致滚动更新卡住

**问题现象：**

```bash
kubectl rollout status deployment web-app -n production
# Waiting for deployment "web-app" rollout to finish:
# 2 out of 3 new replicas have been updated...
```

**解决方案：**

```yaml
# 调整滚动更新策略
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  strategy:
    rollingUpdate:
      maxSurge: 0          # 不创建额外Pod
      maxUnavailable: 1    # 允许1个Pod不可用
```

### 7.6.6 最佳实践

#### 7.6.6.1 配额设计原则

**分层配额体系：**

```yaml
# 集群总资源：400C 800G

# 层级1：按环境分配
production:     50%  (200C 400G)
staging:        20%  (80C  160G)
testing:        15%  (60C  120G)
development:    10%  (40C  80G)
```

**配额计算方法：**

```bash
# 基于历史数据计算
# Step 1: 收集P95值
# P95 CPU: 75核, P95 Mem: 150GB

# Step 2: 添加25%缓冲
# CPU配额 = 75 * 1.25 = 100核
# 内存配额 = 150 * 1.25 = 200GB
```

#### 7.6.6.2 组合使用策略

```yaml
# 完整命名空间配置模板
---
apiVersion: v1
kind: Namespace
metadata:
  name: production
---
# ResourceQuota（总量控制）
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: production
spec:
  hard:
    requests.cpu: "100"
    requests.memory: "200Gi"
    limits.cpu: "200"
    limits.memory: "400Gi"
    pods: "100"
---
# LimitRange（单体限制）
apiVersion: v1
kind: LimitRange
metadata:
  name: resource-limits
  namespace: production
spec:
  limits:
  - type: Container
    max:
      cpu: "8"
      memory: "16Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    default:
      cpu: "1"
      memory: "2Gi"
    defaultRequest:
      cpu: "500m"
      memory: "1Gi"
```

#### 7.6.6.3 监控与告警

**Prometheus监控指标：**

```yaml
# 1. 配额使用率
(kube_resourcequota{type="used"} / kube_resourcequota{type="hard"}) * 100

# 2. 接近配额上限的命名空间
(kube_resourcequota{type="used", resource="requests.cpu"} /
 kube_resourcequota{type="hard", resource="requests.cpu"}) > 0.8
```

**告警规则：**

```yaml
groups:
- name: quota-alerts
  rules:
  # 配额使用率超过80%
  - alert: QuotaUsageHigh
    expr: |
      (kube_resourcequota{type="used"} /
       kube_resourcequota{type="hard"}) > 0.8
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "命名空间配额使用率超过80%"
      description: "资源使用率：{{ $value }}%"

  # 配额使用率超过95%
  - alert: QuotaUsageCritical
    expr: |
      (kube_resourcequota{type="used"} /
       kube_resourcequota{type="hard"}) > 0.95
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "命名空间配额即将耗尽"
```

---

本节我们深入学习了资源配额（ResourceQuota）和限制范围（LimitRange）机制，包括核心概念、ResourceQuota总量控制（计算资源、对象数量、存储资源）、LimitRange单体限制（容器级别、Pod级别、默认值注入）、多租户SaaS平台隔离、常见问题排查和最佳实践。通过合理使用ResourceQuota和LimitRange，可以实现命名空间级别的资源管理、多租户隔离和成本控制。在下一节中，我们将通过完整的实战项目，综合应用本章学习的所有调度与资源管理技术，构建企业级的Kubernetes调度方案。

---

**本节知识点回顾：**
- ✅ ResourceQuota和LimitRange核心概念对比
- ✅ ResourceQuota计算资源配额和对象数量限制
- ✅ LimitRange容器/Pod级别限制和默认值注入
- ✅ 多租户SaaS平台三级配额体系（企业/标准/免费）
- ✅ 配额超限和滚动更新卡住问题解决
- ✅ 分层配额设计和配额计算方法（P95+25%缓冲）
- ✅ ResourceQuota+LimitRange组合使用策略
- ✅ Prometheus监控指标和告警规则配置
