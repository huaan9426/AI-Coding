# Docker åº•å±‚åŸç†ä¸ç”Ÿäº§å®æˆ˜æŒ‡å—

> **ç¡¬æ ¸æŠ€æœ¯æ–‡æ¡£ Â· ä»åº•å±‚åˆ°å®æˆ˜çš„å®Œæ•´çŸ¥è¯†ä½“ç³»**
>
> é€‚ç”¨äººç¾¤ï¼šDevOpså·¥ç¨‹å¸ˆã€åç«¯å¼€å‘ã€ç³»ç»Ÿæ¶æ„å¸ˆã€è¿ç»´å·¥ç¨‹å¸ˆ
>
> ç›®æ ‡ï¼šæŒæ¡Dockeråº•å±‚åŸç†ã€å®¹å™¨åŒ–æœ€ä½³å®è·µã€ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ä¸ä¼˜åŒ–

---

## ğŸ“š æ–‡æ¡£ç»“æ„

### ç¬¬ä¸€éƒ¨åˆ†ï¼šåº•å±‚åŸç†ä¸æ ¸å¿ƒæŠ€æœ¯ï¼ˆ1-5ç« ï¼‰
- ç¬¬1ç« ï¼šLinuxå®¹å™¨æŠ€æœ¯åŸºç¡€
- ç¬¬2ç« ï¼šDockeræ¶æ„ä¸ç»„ä»¶
- ç¬¬3ç« ï¼šé•œåƒåŸç†ä¸å­˜å‚¨é©±åŠ¨
- ç¬¬4ç« ï¼šç½‘ç»œåŸç†ä¸å®ç°
- ç¬¬5ç« ï¼šèµ„æºéš”ç¦»ä¸é™åˆ¶

### ç¬¬äºŒéƒ¨åˆ†ï¼šé•œåƒæ„å»ºä¸ä¼˜åŒ–ï¼ˆ6-8ç« ï¼‰
- ç¬¬6ç« ï¼šDockerfileæœ€ä½³å®è·µ
- ç¬¬7ç« ï¼šå¤šé˜¶æ®µæ„å»ºä¸ä¼˜åŒ–
- ç¬¬8ç« ï¼šé•œåƒå®‰å…¨ä¸æ‰«æ

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®¹å™¨è¿è¡Œæ—¶ä¸ç¼–æ’ï¼ˆ9-12ç« ï¼‰
- ç¬¬9ç« ï¼šå®¹å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
- ç¬¬10ç« ï¼šæ•°æ®æŒä¹…åŒ–ä¸å·ç®¡ç†
- ç¬¬11ç« ï¼šå®¹å™¨ç¼–æ’åŸºç¡€
- ç¬¬12ç« ï¼šDocker Composeå®æˆ˜

### ç¬¬å››éƒ¨åˆ†ï¼šç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆ13-16ç« ï¼‰
- ç¬¬13ç« ï¼šé«˜å¯ç”¨æ¶æ„è®¾è®¡
- ç¬¬14ç« ï¼šç›‘æ§ä¸æ—¥å¿—ç®¡ç†
- ç¬¬15ç« ï¼šCI/CDé›†æˆ
- ç¬¬16ç« ï¼šå®‰å…¨åŠ å›ºä¸åˆè§„

### ç¬¬äº”éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–ä¸æ•…éšœæ’æŸ¥ï¼ˆ17-19ç« ï¼‰
- ç¬¬17ç« ï¼šæ€§èƒ½è°ƒä¼˜å®æˆ˜
- ç¬¬18ç« ï¼šæ•…éšœæ’æŸ¥æŠ€å·§
- ç¬¬19ç« ï¼šç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåº•å±‚åŸç†ä¸æ ¸å¿ƒæŠ€æœ¯

---

## ç¬¬ 1 ç« ï¼šLinuxå®¹å™¨æŠ€æœ¯åŸºç¡€

### 1.1 å®¹å™¨æŠ€æœ¯çš„æœ¬è´¨

#### 1.1.1 å®¹å™¨ vs è™šæ‹Ÿæœº

**è™šæ‹Ÿæœºæ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Application (App)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Bins/   â”‚  â”‚  Bins/   â”‚  â”‚ Bins/  â”‚â”‚
â”‚  â”‚  Libs    â”‚  â”‚  Libs    â”‚  â”‚ Libs   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Guest OS â”‚  â”‚ Guest OS â”‚  â”‚Guest OSâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         Hypervisor (VMware/KVM)         â”‚
â”‚              Host OS                     â”‚
â”‚            Infrastructure                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®¹å™¨æ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Application (App)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Bins/   â”‚  â”‚  Bins/   â”‚  â”‚ Bins/  â”‚â”‚
â”‚  â”‚  Libs    â”‚  â”‚  Libs    â”‚  â”‚ Libs   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚      Docker Engine (Container Runtime)  â”‚
â”‚              Host OS (Linux)            â”‚
â”‚            Infrastructure                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒåŒºåˆ«**ï¼š

| ç‰¹æ€§ | è™šæ‹Ÿæœº | å®¹å™¨ |
|-----|-------|------|
| éš”ç¦»çº§åˆ« | ç¡¬ä»¶çº§åˆ« | è¿›ç¨‹çº§åˆ« |
| å¯åŠ¨æ—¶é—´ | åˆ†é’Ÿçº§ | ç§’çº§ |
| èµ„æºå ç”¨ | GBçº§å†…å­˜ | MBçº§å†…å­˜ |
| æ€§èƒ½æŸè€— | 5-10% | <2% |
| é•œåƒå¤§å° | GBçº§ | MBçº§ |
| æ“ä½œç³»ç»Ÿ | å®Œæ•´OS | å…±äº«å®¿ä¸»æœºå†…æ ¸ |

---

### 1.2 Linux Namespaceï¼ˆå‘½åç©ºé—´ï¼‰

#### 1.2.1 Namespace ç±»å‹è¯¦è§£

**7ç§Namespace**ï¼š

| Namespace | ç³»ç»Ÿè°ƒç”¨å‚æ•° | éš”ç¦»å†…å®¹ | å†…æ ¸ç‰ˆæœ¬ |
|-----------|-------------|---------|---------|
| **Mount** | CLONE_NEWNS | æ–‡ä»¶ç³»ç»ŸæŒ‚è½½ç‚¹ | 2.4.19 |
| **UTS** | CLONE_NEWUTS | ä¸»æœºåå’ŒåŸŸå | 2.6.19 |
| **IPC** | CLONE_NEWIPC | è¿›ç¨‹é—´é€šä¿¡ | 2.6.19 |
| **PID** | CLONE_NEWPID | è¿›ç¨‹ID | 2.6.24 |
| **Network** | CLONE_NEWNET | ç½‘ç»œæ ˆ | 2.6.29 |
| **User** | CLONE_NEWUSER | ç”¨æˆ·å’Œç”¨æˆ·ç»„ | 3.8 |
| **Cgroup** | CLONE_NEWCGROUP | Cgroupæ ¹ç›®å½• | 4.6 |

---

#### 1.2.2 PID Namespace å®æˆ˜

**æŸ¥çœ‹å®¹å™¨PIDéš”ç¦»**ï¼š
```bash
# å®¿ä¸»æœºè§†è§’
$ docker run -d --name nginx nginx:alpine
$ docker top nginx
UID    PID     PPID    ...    CMD
root   12345   12320   ...    nginx: master process

# å®¹å™¨å†…è§†è§’
$ docker exec nginx ps aux
PID   USER     COMMAND
1     root     nginx: master process    # åœ¨å®¹å™¨å†…PID=1
7     nginx    nginx: worker process

# æŸ¥çœ‹PID namespace
$ docker inspect nginx | grep Pid
"Pid": 12345,

$ ls -l /proc/12345/ns/
total 0
lrwxrwxrwx 1 root root 0 ... cgroup -> 'cgroup:[4026532454]'
lrwxrwxrwx 1 root root 0 ... ipc -> 'ipc:[4026532452]'
lrwxrwxrwx 1 root root 0 ... mnt -> 'mnt:[4026532450]'
lrwxrwxrwx 1 root root 0 ... net -> 'net:[4026532455]'
lrwxrwxrwx 1 root root 0 ... pid -> 'pid:[4026532453]'
lrwxrwxrwx 1 root root 0 ... uts -> 'uts:[4026532451]'
```

**æ‰‹åŠ¨åˆ›å»ºPID Namespaceï¼ˆCè¯­è¨€ç¤ºä¾‹ï¼‰**ï¼š
```c
#define _GNU_SOURCE
#include <sched.h>
#include <stdio.h>
#include <stdlib.h>
#include <sys/wait.h>
#include <unistd.h>

static char child_stack[1048576];

static int child_fn() {
    printf("å®¹å™¨å†… PID: %d\n", getpid());  // è¾“å‡º 1
    printf("å®¹å™¨å†… PPID: %d\n", getppid()); // è¾“å‡º 0

    // æ‰§è¡Œshell
    char *const args[] = {"/bin/bash", NULL};
    execvp(args[0], args);
    return 1;
}

int main() {
    printf("å®¿ä¸»æœº PID: %d\n", getpid());

    // åˆ›å»ºæ–°çš„PID namespace
    int child_pid = clone(child_fn,
                         child_stack + sizeof(child_stack),
                         CLONE_NEWPID | SIGCHLD,
                         NULL);

    waitpid(child_pid, NULL, 0);
    return 0;
}

// ç¼–è¯‘è¿è¡Œ:
// gcc -o pid_namespace pid_namespace.c
// sudo ./pid_namespace
```

---

#### 1.2.3 Network Namespace å®æˆ˜

**æ‰‹åŠ¨åˆ›å»ºç½‘ç»œå‘½åç©ºé—´**ï¼š
```bash
# åˆ›å»ºnetwork namespace
$ sudo ip netns add container1
$ sudo ip netns list
container1

# åœ¨namespaceå†…æ‰§è¡Œå‘½ä»¤
$ sudo ip netns exec container1 ip addr
1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00

# åˆ›å»ºveth pairï¼ˆè™šæ‹Ÿç½‘å¡å¯¹ï¼‰
$ sudo ip link add veth0 type veth peer name veth1

# å°†veth1ç§»åˆ°container1å‘½åç©ºé—´
$ sudo ip link set veth1 netns container1

# é…ç½®IPåœ°å€
$ sudo ip addr add 10.0.0.1/24 dev veth0
$ sudo ip link set veth0 up

$ sudo ip netns exec container1 ip addr add 10.0.0.2/24 dev veth1
$ sudo ip netns exec container1 ip link set veth1 up
$ sudo ip netns exec container1 ip link set lo up

# æµ‹è¯•è¿é€šæ€§
$ ping -c 2 10.0.0.2
PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.
64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.050 ms
```

**Dockerç½‘ç»œå‘½åç©ºé—´æŸ¥çœ‹**ï¼š
```bash
# æŸ¥çœ‹å®¹å™¨ç½‘ç»œnamespace
$ docker inspect nginx | grep SandboxKey
"SandboxKey": "/var/run/docker/netns/abc123def456",

# åˆ—å‡ºæ‰€æœ‰ç½‘ç»œå‘½åç©ºé—´
$ sudo ls -l /var/run/docker/netns/
-r--r--r-- 1 root root 0 ... abc123def456

# è¿›å…¥å®¹å™¨ç½‘ç»œå‘½åç©ºé—´
$ sudo nsenter --net=/var/run/docker/netns/abc123def456 ip addr
```

---

#### 1.2.4 Mount Namespace å®æˆ˜

**éš”ç¦»æ–‡ä»¶ç³»ç»ŸæŒ‚è½½ç‚¹**ï¼š
```bash
# åˆ›å»ºmount namespace
$ sudo unshare --mount --fork /bin/bash

# åœ¨æ–°namespaceä¸­æŒ‚è½½
$ mount -t tmpfs tmpfs /mnt
$ df -h /mnt
Filesystem      Size  Used Avail Use% Mounted on
tmpfs           1.0G     0  1.0G   0% /mnt

# åœ¨å®¿ä¸»æœºæ£€æŸ¥ï¼ˆçœ‹ä¸åˆ°è¿™ä¸ªæŒ‚è½½ç‚¹ï¼‰
$ df -h /mnt
```

**Dockerå®¹å™¨æŒ‚è½½éš”ç¦»éªŒè¯**ï¼š
```bash
# æŸ¥çœ‹å®¹å™¨æŒ‚è½½ç‚¹
$ docker exec nginx cat /proc/mounts
overlay / overlay rw,relatime,lowerdir=...,upperdir=...,workdir=... 0 0
proc /proc proc rw,nosuid,nodev,noexec,relatime 0 0
tmpfs /dev tmpfs rw,nosuid,size=65536k,mode=755 0 0

# å®¿ä¸»æœºçœ‹ä¸åˆ°å®¹å™¨å†…çš„æŒ‚è½½ç‚¹
$ mount | grep overlay
overlay on /var/lib/docker/overlay2/.../merged type overlay (rw,...)
```

---

### 1.3 Linux Cgroupsï¼ˆæ§åˆ¶ç»„ï¼‰

#### 1.3.1 Cgroups å­ç³»ç»Ÿè¯¦è§£

**12ä¸ªå­ç³»ç»Ÿï¼ˆSubsystemsï¼‰**ï¼š

| å­ç³»ç»Ÿ | åŠŸèƒ½ | å¸¸ç”¨é™åˆ¶å‚æ•° |
|--------|------|-------------|
| **cpu** | CPUæ—¶é—´åˆ†é… | cpu.shares, cpu.cfs_quota_us |
| **cpuacct** | CPUä½¿ç”¨ç»Ÿè®¡ | cpuacct.usage, cpuacct.stat |
| **cpuset** | CPUæ ¸å¿ƒç»‘å®š | cpuset.cpus, cpuset.mems |
| **memory** | å†…å­˜é™åˆ¶ | memory.limit_in_bytes, memory.soft_limit_in_bytes |
| **blkio** | å—è®¾å¤‡IOé™åˆ¶ | blkio.weight, blkio.throttle.read_bps_device |
| **devices** | è®¾å¤‡è®¿é—®æ§åˆ¶ | devices.allow, devices.deny |
| **net_cls** | ç½‘ç»œåˆ†ç±»æ ‡è®° | net_cls.classid |
| **net_prio** | ç½‘ç»œä¼˜å…ˆçº§ | net_prio.ifpriomap |
| **freezer** | å†»ç»“/æ¢å¤è¿›ç¨‹ | freezer.state |
| **pids** | è¿›ç¨‹æ•°é™åˆ¶ | pids.max |
| **hugetlb** | å¤§é¡µå†…å­˜é™åˆ¶ | hugetlb.*.limit_in_bytes |
| **perf_event** | æ€§èƒ½ç›‘æ§ | perf_event.* |

---

#### 1.3.2 Cgroups v1 vs v2

**æ¶æ„å¯¹æ¯”**ï¼š

```
Cgroups v1ï¼ˆå±‚çº§æ¶æ„ï¼‰:
/sys/fs/cgroup/
â”œâ”€â”€ cpu/
â”‚   â””â”€â”€ docker/
â”‚       â””â”€â”€ <container-id>/
â”‚           â”œâ”€â”€ cpu.shares
â”‚           â””â”€â”€ cpu.cfs_quota_us
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ docker/
â”‚       â””â”€â”€ <container-id>/
â”‚           â””â”€â”€ memory.limit_in_bytes
â””â”€â”€ blkio/
    â””â”€â”€ docker/
        â””â”€â”€ <container-id>/

Cgroups v2ï¼ˆç»Ÿä¸€å±‚çº§ï¼‰:
/sys/fs/cgroup/
â””â”€â”€ system.slice/
    â””â”€â”€ docker-<container-id>.scope/
        â”œâ”€â”€ cpu.max
        â”œâ”€â”€ memory.max
        â”œâ”€â”€ io.max
        â””â”€â”€ cgroup.controllers
```

**ä¸»è¦æ”¹è¿›**ï¼š
1. **ç»Ÿä¸€å±‚çº§**: æ‰€æœ‰æ§åˆ¶å™¨åœ¨åŒä¸€å±‚çº§
2. **çº¿ç¨‹æ”¯æŒ**: æ›´å¥½çš„çº¿ç¨‹çº§åˆ«æ§åˆ¶
3. **å‹åŠ›æ„ŸçŸ¥**: Pressure Stall Information (PSI)
4. **ç®€åŒ–æ¥å£**: æ›´ä¸€è‡´çš„APIè®¾è®¡

---

#### 1.3.3 CPUé™åˆ¶å®æˆ˜

**æ–¹å¼1ï¼šCPUä»½é¢ï¼ˆcpu.sharesï¼‰**ï¼š
```bash
# åˆ›å»ºä¸¤ä¸ªå®¹å™¨ï¼ŒCPUä»½é¢æ¯”ä¾‹ 2:1
$ docker run -d --name cpu_high --cpu-shares 2048 stress --cpu 4
$ docker run -d --name cpu_low --cpu-shares 1024 stress --cpu 4

# æŸ¥çœ‹CPUä½¿ç”¨ç‡
$ docker stats --no-stream
CONTAINER   CPU %     MEM USAGE / LIMIT
cpu_high    66.67%    ...          # è·å¾— 2/3 CPU
cpu_low     33.33%    ...          # è·å¾— 1/3 CPU

# æŸ¥çœ‹cgroupé…ç½®
$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.shares
2048
```

**æ–¹å¼2ï¼šCPUé…é¢ï¼ˆcpu.cfs_quota_us + cpu.cfs_period_usï¼‰**ï¼š
```bash
# é™åˆ¶å®¹å™¨åªèƒ½ä½¿ç”¨0.5ä¸ªCPUæ ¸å¿ƒ
$ docker run -d --name cpu_limited \
    --cpus="0.5" \
    stress --cpu 4

# ç­‰ä»·äºï¼š
# --cpu-period=100000 --cpu-quota=50000

# æŸ¥çœ‹cgroupé…ç½®
$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.cfs_period_us
100000

$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.cfs_quota_us
50000

# CPUä½¿ç”¨ç‡ä¸ä¼šè¶…è¿‡50%
$ docker stats cpu_limited
CONTAINER      CPU %
cpu_limited    49.87%
```

**æ–¹å¼3ï¼šCPUæ ¸å¿ƒç»‘å®šï¼ˆcpusetï¼‰**ï¼š
```bash
# ç»‘å®šåˆ°CPUæ ¸å¿ƒ0å’Œ1
$ docker run -d --name cpu_pinned \
    --cpuset-cpus="0,1" \
    nginx

# æŸ¥çœ‹ç»‘å®šçš„æ ¸å¿ƒ
$ cat /sys/fs/cgroup/cpuset/docker/<container-id>/cpuset.cpus
0-1

# éªŒè¯è¿›ç¨‹CPUäº²å’Œæ€§
$ docker exec cpu_pinned taskset -cp 1
pid 1's current affinity list: 0,1
```

---

#### 1.3.4 å†…å­˜é™åˆ¶å®æˆ˜

**åŸºç¡€å†…å­˜é™åˆ¶**ï¼š
```bash
# é™åˆ¶å†…å­˜512MBï¼Œswapä¹Ÿæ˜¯512MB
$ docker run -d --name mem_limited \
    --memory="512m" \
    --memory-swap="1g" \
    nginx

# æŸ¥çœ‹å†…å­˜é™åˆ¶
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.limit_in_bytes
536870912  # 512MB

$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.memsw.limit_in_bytes
1073741824  # 1GB (å†…å­˜+swap)

# æŸ¥çœ‹å®æ—¶å†…å­˜ä½¿ç”¨
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.usage_in_bytes
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.stat
```

**å†…å­˜é¢„ç•™ï¼ˆReservationï¼‰**ï¼š
```bash
# è½¯é™åˆ¶ï¼šæ­£å¸¸æƒ…å†µä¸‹ä½¿ç”¨256MBï¼Œå‹åŠ›å¤§æ—¶å¯ä»¥åˆ°512MB
$ docker run -d --name mem_reserved \
    --memory="512m" \
    --memory-reservation="256m" \
    nginx

# æŸ¥çœ‹é¢„ç•™å€¼
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.soft_limit_in_bytes
268435456  # 256MB
```

**OOMï¼ˆOut Of Memoryï¼‰è¡Œä¸ºæ§åˆ¶**ï¼š
```bash
# ç¦ç”¨OOM Killerï¼ˆå®¹å™¨è¢«æ€æ­»ï¼‰
$ docker run -d --name no_oom_kill \
    --memory="512m" \
    --oom-kill-disable \
    nginx

# âš ï¸ å±é™©ï¼šå¦‚æœæ²¡æœ‰swapï¼Œè¿›ç¨‹ä¼šæŒ‚èµ·è€Œä¸æ˜¯è¢«æ€æ­»

# è®¾ç½®OOMä¼˜å…ˆçº§ï¼ˆ-1000åˆ°1000ï¼Œè¶Šå°è¶Šä¸å®¹æ˜“è¢«æ€ï¼‰
$ docker run -d --name oom_low_priority \
    --memory="512m" \
    --oom-score-adj=500 \
    nginx

# æŸ¥çœ‹OOMåˆ†æ•°
$ cat /proc/$(docker inspect -f '{{.State.Pid}}' oom_low_priority)/oom_score_adj
500
```

**å†…å­˜å‹åŠ›æµ‹è¯•**ï¼š
```bash
# åˆ›å»ºå†…å­˜å‹åŠ›æµ‹è¯•å®¹å™¨
$ docker run -it --rm \
    --memory="512m" \
    --memory-swap="512m" \
    progrium/stress \
    --vm 1 --vm-bytes 600M --vm-hang 0

# è§‚å¯ŸOOMäº‹ä»¶
$ dmesg | tail
[12345.678] Memory cgroup out of memory: Kill process 12345 (stress) score 1000
[12345.679] Killed process 12345 (stress) total-vm:614400kB

# ç›‘æ§å†…å­˜äº‹ä»¶
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.oom_control
oom_kill_disable 0
under_oom 0
oom_kill 1
```

---

#### 1.3.5 å—è®¾å¤‡IOé™åˆ¶å®æˆ˜

**è¯»å†™é€Ÿç‡é™åˆ¶ï¼ˆbpsï¼‰**ï¼š
```bash
# é™åˆ¶è¯»é€Ÿç‡10MB/sï¼Œå†™é€Ÿç‡5MB/s
$ docker run -it --rm \
    --device-read-bps /dev/sda:10mb \
    --device-write-bps /dev/sda:5mb \
    ubuntu:20.04 bash

# æµ‹è¯•è¯»é€Ÿç‡
$ dd if=/dev/zero of=/tmp/test bs=1M count=100 oflag=direct
100+0 records in
100+0 records out
104857600 bytes (105 MB) copied, 20.0 s, 5.2 MB/s  # ç¬¦åˆé™åˆ¶

# æŸ¥çœ‹cgroupé…ç½®
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.throttle.read_bps_device
8:0 10485760  # ä¸»è®¾å¤‡å·:æ¬¡è®¾å¤‡å· é€Ÿç‡(bytes/s)
```

**IOPSé™åˆ¶**ï¼š
```bash
# é™åˆ¶éšæœºè¯»IOPS=100ï¼Œå†™IOPS=50
$ docker run -it --rm \
    --device-read-iops /dev/sda:100 \
    --device-write-iops /dev/sda:50 \
    ubuntu:20.04 bash

# æµ‹è¯•IOPS
$ fio --name=randread --ioengine=libaio --rw=randread --bs=4k --size=1G --numjobs=1 --iodepth=32
...
read: IOPS=99, BW=396KiB/s  # ç¬¦åˆé™åˆ¶
```

**IOæƒé‡ï¼ˆblkio.weightï¼‰**ï¼š
```bash
# åˆ›å»ºä¸¤ä¸ªå®¹å™¨ï¼ŒIOæƒé‡ 500:250ï¼ˆ2:1ï¼‰
$ docker run -d --name io_high --blkio-weight 500 ...
$ docker run -d --name io_low --blkio-weight 250 ...

# æŸ¥çœ‹æƒé‡
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.weight
500
```

---

#### 1.3.6 è¿›ç¨‹æ•°é™åˆ¶ï¼ˆPIDé™åˆ¶ï¼‰

```bash
# é™åˆ¶å®¹å™¨æœ€å¤šåˆ›å»º100ä¸ªè¿›ç¨‹
$ docker run -d --name pid_limited \
    --pids-limit 100 \
    nginx

# æŸ¥çœ‹é™åˆ¶
$ cat /sys/fs/cgroup/pids/docker/<container-id>/pids.max
100

# æŸ¥çœ‹å½“å‰è¿›ç¨‹æ•°
$ cat /sys/fs/cgroup/pids/docker/<container-id>/pids.current
2

# æµ‹è¯•forkç‚¸å¼¹é˜²æŠ¤
$ docker run -it --rm --pids-limit 10 ubuntu:20.04 bash
root@container:/# :(){ :|:& };:
bash: fork: retry: Resource temporarily unavailable
# å®¹å™¨è¢«ä¿æŠ¤ï¼Œä¸ä¼šå½±å“å®¿ä¸»æœº
```

---

### 1.4 UnionFSï¼ˆè”åˆæ–‡ä»¶ç³»ç»Ÿï¼‰

#### 1.4.1 UnionFS åŸç†

**åˆ†å±‚æ–‡ä»¶ç³»ç»Ÿç¤ºæ„å›¾**ï¼š
```
Dockeré•œåƒåˆ†å±‚ç»“æ„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Container Layer (Read-Write)   â”‚  â† å¯å†™å±‚ï¼ˆå®¹å™¨è¿è¡Œæ—¶ä¿®æ”¹ï¼‰
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Image Layer 4 (Read-Only)      â”‚  â† CMD ["nginx"]
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Image Layer 3 (Read-Only)      â”‚  â† COPY nginx.conf /etc/nginx/
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Image Layer 2 (Read-Only)      â”‚  â† RUN apt-get install nginx
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Image Layer 1 (Read-Only)      â”‚  â† FROM ubuntu:20.04
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    UnionFS åˆå¹¶
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Unified View (Container Root) â”‚  â† å®¹å™¨çœ‹åˆ°çš„å®Œæ•´æ–‡ä»¶ç³»ç»Ÿ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å†™æ—¶å¤åˆ¶ï¼ˆCopy-on-Write, COWï¼‰**ï¼š
```bash
# 1. å®¹å™¨å¯åŠ¨æ—¶ï¼Œæ‰€æœ‰å±‚åªè¯»
# 2. ä¿®æ”¹æ–‡ä»¶æ—¶ï¼š
#    - ä»åªè¯»å±‚å¤åˆ¶æ–‡ä»¶åˆ°å¯å†™å±‚
#    - åœ¨å¯å†™å±‚ä¿®æ”¹
#    - åŸå§‹å±‚ä¿æŒä¸å˜

# ç¤ºä¾‹
$ docker run -d --name test nginx
$ docker exec test bash -c "echo 'modified' > /etc/nginx/nginx.conf"

# æŸ¥çœ‹å·®å¼‚ï¼ˆåªæœ‰ä¿®æ”¹çš„æ–‡ä»¶åœ¨å¯å†™å±‚ï¼‰
$ docker diff test
C /etc
C /etc/nginx
C /etc/nginx/nginx.conf
```

---

#### 1.4.2 å­˜å‚¨é©±åŠ¨ç±»å‹

**ä¸»æµå­˜å‚¨é©±åŠ¨å¯¹æ¯”**ï¼š

| å­˜å‚¨é©±åŠ¨ | æ–‡ä»¶ç³»ç»Ÿ | æ€§èƒ½ | ç¨³å®šæ€§ | ä½¿ç”¨åœºæ™¯ | å†…æ ¸è¦æ±‚ |
|---------|---------|------|-------|---------|---------|
| **overlay2** | OverlayFS | â­â­â­â­â­ | â­â­â­â­â­ | ç”Ÿäº§æ¨è | â‰¥4.0 |
| **aufs** | AUFS | â­â­â­â­ | â­â­â­â­ | æ—§ç‰ˆUbuntu | <4.0 |
| **devicemapper** | LVM | â­â­â­ | â­â­â­ | RHEL 7.x | ä»»æ„ |
| **btrfs** | Btrfs | â­â­â­ | â­â­â­ | å®éªŒæ€§ | ä»»æ„ |
| **zfs** | ZFS | â­â­â­â­ | â­â­â­â­ | é«˜çº§ç‰¹æ€§ | ä»»æ„ |
| **vfs** | æ—  | â­ | â­â­â­â­â­ | æµ‹è¯•/è°ƒè¯• | ä»»æ„ |

---

#### 1.4.3 Overlay2 æ·±åº¦è§£æï¼ˆç”Ÿäº§æ¨èï¼‰

**Overlay2 æ–‡ä»¶ç³»ç»Ÿç»“æ„**ï¼š
```bash
# æŸ¥çœ‹å½“å‰å­˜å‚¨é©±åŠ¨
$ docker info | grep "Storage Driver"
Storage Driver: overlay2

# Overlay2ç›®å½•ç»“æ„
/var/lib/docker/overlay2/
â”œâ”€â”€ <layer-id>/
â”‚   â”œâ”€â”€ diff/           # è¯¥å±‚çš„å®é™…å†…å®¹
â”‚   â”œâ”€â”€ link            # çŸ­ç¬¦å·é“¾æ¥å
â”‚   â”œâ”€â”€ lower           # æŒ‡å‘ä¸‹å±‚çš„link
â”‚   â”œâ”€â”€ merged/         # åˆå¹¶åçš„è§†å›¾ï¼ˆå®¹å™¨çœ‹åˆ°çš„ï¼‰
â”‚   â””â”€â”€ work/           # OverlayFSå·¥ä½œç›®å½•
â””â”€â”€ l/                  # æ‰€æœ‰å±‚çš„çŸ­é“¾æ¥

# æŸ¥çœ‹å®¹å™¨ä½¿ç”¨çš„å±‚
$ docker inspect nginx | grep -A 20 GraphDriver
"GraphDriver": {
    "Data": {
        "LowerDir": "/var/lib/docker/overlay2/abc.../diff:/var/lib/docker/overlay2/def.../diff",
        "MergedDir": "/var/lib/docker/overlay2/xyz.../merged",
        "UpperDir": "/var/lib/docker/overlay2/xyz.../diff",
        "WorkDir": "/var/lib/docker/overlay2/xyz.../work"
    },
    "Name": "overlay2"
}
```

**Overlay2 æŒ‚è½½éªŒè¯**ï¼š
```bash
# æŸ¥çœ‹overlayæŒ‚è½½
$ mount | grep overlay
overlay on /var/lib/docker/overlay2/xyz.../merged type overlay (rw,relatime,
    lowerdir=/var/lib/docker/overlay2/l/ABC:/var/lib/docker/overlay2/l/DEF,
    upperdir=/var/lib/docker/overlay2/xyz.../diff,
    workdir=/var/lib/docker/overlay2/xyz.../work)

# lowerdir: åªè¯»å±‚ï¼ˆé•œåƒå±‚ï¼‰
# upperdir: å¯å†™å±‚ï¼ˆå®¹å™¨å±‚ï¼‰
# merged: åˆå¹¶è§†å›¾ï¼ˆå®¹å™¨æ ¹æ–‡ä»¶ç³»ç»Ÿï¼‰
```

**Overlay2 inodeé™åˆ¶é—®é¢˜**ï¼š
```bash
# æŸ¥çœ‹inodeä½¿ç”¨æƒ…å†µ
$ df -i
Filesystem      Inodes  IUsed   IFree IUse% Mounted on
/dev/sda1      6553600  500000  6053600   8% /

# é—®é¢˜ï¼šoverlay2æ¯å±‚ä½¿ç”¨ç‹¬ç«‹inodeï¼Œå¯èƒ½è€—å°½
# è§£å†³æ–¹æ¡ˆï¼š
# 1. å‡å°‘é•œåƒå±‚æ•°ï¼ˆå¤šé˜¶æ®µæ„å»ºï¼‰
# 2. å®šæœŸæ¸…ç†æœªä½¿ç”¨çš„é•œåƒ/å®¹å™¨
# 3. ä½¿ç”¨xfsæ–‡ä»¶ç³»ç»Ÿï¼ˆæ”¯æŒåŠ¨æ€inodeåˆ†é…ï¼‰

# æ¸…ç†æœªä½¿ç”¨èµ„æº
$ docker system prune -a --volumes
```

---

#### 1.4.4 å­˜å‚¨é©±åŠ¨æ€§èƒ½å¯¹æ¯”

**æ€§èƒ½æµ‹è¯•è„šæœ¬**ï¼š
```bash
#!/bin/bash
# benchmark_storage_driver.sh

test_driver() {
    DRIVER=$1

    # é…ç½®Dockerä½¿ç”¨æŒ‡å®šå­˜å‚¨é©±åŠ¨
    echo "Testing $DRIVER..."

    # åˆ›å»ºæµ‹è¯•å®¹å™¨
    docker run --rm -v /tmp/test:/test ubuntu:20.04 bash -c "
        # é¡ºåºå†™æµ‹è¯•
        dd if=/dev/zero of=/test/testfile bs=1M count=1000 conv=fdatasync

        # éšæœºå†™æµ‹è¯•
        fio --name=randwrite --ioengine=libaio --rw=randwrite \
            --bs=4k --size=1G --numjobs=4 --iodepth=32 \
            --filename=/test/fiotest

        # å…ƒæ•°æ®æ“ä½œæµ‹è¯•ï¼ˆåˆ›å»ºæ–‡ä»¶ï¼‰
        time for i in {1..10000}; do touch /test/file_\$i; done
    "
}

# æµ‹è¯•ä¸åŒå­˜å‚¨é©±åŠ¨
test_driver overlay2
test_driver devicemapper
test_driver aufs
```

**å…¸å‹æ€§èƒ½æ•°æ®**ï¼š

| æ“ä½œç±»å‹ | overlay2 | aufs | devicemapper |
|---------|----------|------|-------------|
| é¡ºåºè¯» | 3000 MB/s | 2800 MB/s | 2500 MB/s |
| é¡ºåºå†™ | 2500 MB/s | 2200 MB/s | 1800 MB/s |
| éšæœºè¯»IOPS | 50000 | 45000 | 35000 |
| éšæœºå†™IOPS | 40000 | 35000 | 25000 |
| å…ƒæ•°æ®æ“ä½œ | å¿« | ä¸­ | æ…¢ |
| å†…å­˜å ç”¨ | ä½ | ä¸­ | é«˜ |

---

### 1.5 å®¹å™¨è¿è¡Œæ—¶ï¼ˆContainer Runtimeï¼‰

#### 1.5.1 è¿è¡Œæ—¶æ¶æ„æ¼”è¿›

**OCIï¼ˆOpen Container Initiativeï¼‰æ ‡å‡†**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Container Orchestration              â”‚
â”‚         (Kubernetes, Docker Swarm, ...)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         High-Level Container Runtime            â”‚
â”‚      (containerd, CRI-O, Docker Engine)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ OCI Runtime Spec
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Low-Level Container Runtime            â”‚
â”‚           (runc, crun, kata, gvisor)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Linux Kernel (Namespaces, Cgroups)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 1.5.2 runc æ·±åº¦è§£æ

**runc æ˜¯ä»€ä¹ˆ**ï¼š
- OCI runtime-spec çš„å‚è€ƒå®ç°
- ç”± Docker æçŒ®ç»™ OCI
- ä½¿ç”¨Goè¯­è¨€ç¼–å†™
- ç›´æ¥æ“ä½œ namespace å’Œ cgroup

**æ‰‹åŠ¨ä½¿ç”¨ runc åˆ›å»ºå®¹å™¨**ï¼š
```bash
# 1. å®‰è£…runc
$ sudo apt-get install runc

# 2. å‡†å¤‡rootfs
$ mkdir -p /tmp/mycontainer/rootfs
$ docker export $(docker create ubuntu:20.04) | tar -C /tmp/mycontainer/rootfs -xf -

# 3. ç”ŸæˆOCIé…ç½®æ–‡ä»¶
$ cd /tmp/mycontainer
$ runc spec

# 4. ç¼–è¾‘config.jsonï¼ˆå¯é€‰ï¼‰
$ cat config.json
{
    "ociVersion": "1.0.2",
    "process": {
        "terminal": true,
        "user": {"uid": 0, "gid": 0},
        "args": ["/bin/bash"],
        "env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"],
        "cwd": "/",
        ...
    },
    "root": {
        "path": "rootfs",
        "readonly": false
    },
    "hostname": "mycontainer",
    "mounts": [...],
    "linux": {
        "namespaces": [
            {"type": "pid"},
            {"type": "network"},
            {"type": "ipc"},
            {"type": "uts"},
            {"type": "mount"}
        ],
        "resources": {
            "memory": {"limit": 536870912},
            "cpu": {"quota": 50000, "period": 100000}
        }
    }
}

# 5. è¿è¡Œå®¹å™¨
$ sudo runc run mycontainer
root@mycontainer:/#

# 6. æŸ¥çœ‹å®¹å™¨ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
$ sudo runc list
ID            PID       STATUS    BUNDLE
mycontainer   12345     running   /tmp/mycontainer

# 7. æŸ¥çœ‹å®¹å™¨çŠ¶æ€
$ sudo runc state mycontainer
{
  "ociVersion": "1.0.2",
  "id": "mycontainer",
  "pid": 12345,
  "status": "running",
  "bundle": "/tmp/mycontainer",
  "rootfs": "/tmp/mycontainer/rootfs",
  "created": "2024-01-01T00:00:00.000000000Z"
}
```

---

#### 1.5.3 containerd æ¶æ„

**containerd ç»„ä»¶æ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Docker CLI / API                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              dockerd (Docker Daemon)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ gRPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 containerd                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Metadata  â”‚   Snapshots  â”‚   Diff Service â”‚ â”‚
â”‚  â”‚   (boltdb) â”‚   (overlay2) â”‚                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚        containerd-shim (per container)     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚          runc (OCI runtime)          â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**containerd å‘½ä»¤è¡Œå·¥å…·ï¼ˆctrï¼‰**ï¼š
```bash
# åˆ—å‡ºå®¹å™¨
$ sudo ctr containers list
CONTAINER    IMAGE    RUNTIME

# åˆ—å‡ºä»»åŠ¡ï¼ˆè¿è¡Œä¸­çš„å®¹å™¨ï¼‰
$ sudo ctr tasks list
TASK    PID    STATUS

# æ‹‰å–é•œåƒ
$ sudo ctr images pull docker.io/library/nginx:alpine

# è¿è¡Œå®¹å™¨
$ sudo ctr run --rm -t docker.io/library/nginx:alpine my-nginx

# æŸ¥çœ‹å‘½åç©ºé—´
$ sudo ctr namespaces list
NAME    LABELS
default
moby    # Dockerä½¿ç”¨çš„å‘½åç©ºé—´
```

---

#### 1.5.4 å®¹å™¨å®‰å…¨è¿è¡Œæ—¶

**gVisorï¼ˆGoogleï¼‰**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application (untrusted)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ syscalls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Sentry (ç”¨æˆ·æ€å†…æ ¸)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Goå®ç°çš„éƒ¨åˆ†Linuxå†…æ ¸         â”‚ â”‚
â”‚  â”‚   (æ–‡ä»¶ç³»ç»Ÿã€ç½‘ç»œæ ˆã€å†…å­˜ç®¡ç†...)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ å—é™syscalls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Gofer (I/Oä»£ç†)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Linux Kernel               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®‰è£…å’Œä½¿ç”¨ gVisor**ï¼š
```bash
# å®‰è£…runscï¼ˆgVisorè¿è¡Œæ—¶ï¼‰
$ sudo apt-get update && sudo apt-get install -y apt-transport-https ca-certificates curl gnupg
$ curl -fsSL https://gvisor.dev/archive.key | sudo gpg --dearmor -o /usr/share/keyrings/gvisor-archive-keyring.gpg
$ echo "deb [signed-by=/usr/share/keyrings/gvisor-archive-keyring.gpg] https://storage.googleapis.com/gvisor/releases release main" | sudo tee /etc/apt/sources.list.d/gvisor.list
$ sudo apt-get update && sudo apt-get install -y runsc

# é…ç½®Dockerä½¿ç”¨gVisor
$ sudo tee /etc/docker/daemon.json <<EOF
{
  "runtimes": {
    "runsc": {
      "path": "/usr/bin/runsc"
    }
  }
}
EOF

$ sudo systemctl restart docker

# ä½¿ç”¨gVisorè¿è¡Œå®¹å™¨
$ docker run --runtime=runsc -d nginx

# éªŒè¯ï¼ˆå®¹å™¨å†…syscallè¢«æ‹¦æˆªï¼‰
$ docker exec <container-id> strace ls
# çœ‹ä¸åˆ°çœŸå®çš„syscallï¼Œè¢«Sentryå¤„ç†
```

**Kata Containersï¼ˆè½»é‡çº§è™šæ‹Ÿæœºï¼‰**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Application                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Guest Kernel (Mini OS)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Hypervisor (QEMU/Firecracker)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Host Kernel                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```bash
# å®‰è£…Kata Containers
$ sudo sh -c "echo 'deb http://download.opensuse.org/repositories/home:/katacontainers:/releases:/x86_64:/stable-2.0/xUbuntu_$(lsb_release -rs)/ /' > /etc/apt/sources.list.d/kata-containers.list"
$ curl -sL http://download.opensuse.org/repositories/home:/katacontainers:/releases:/x86_64:/stable-2.0/xUbuntu_$(lsb_release -rs)/Release.key | sudo apt-key add -
$ sudo apt-get update && sudo apt-get install -y kata-runtime kata-proxy kata-shim

# é…ç½®Docker
$ sudo tee -a /etc/docker/daemon.json <<EOF
{
  "runtimes": {
    "kata-runtime": {
      "path": "/usr/bin/kata-runtime"
    }
  }
}
EOF

$ sudo systemctl restart docker

# ä½¿ç”¨Kataè¿è¡Œå®¹å™¨ï¼ˆVMéš”ç¦»ï¼‰
$ docker run --runtime=kata-runtime -d nginx
```

**è¿è¡Œæ—¶å®‰å…¨å¯¹æ¯”**ï¼š

| è¿è¡Œæ—¶ | éš”ç¦»çº§åˆ« | æ€§èƒ½ | å¯åŠ¨æ—¶é—´ | å†…å­˜å¼€é”€ | é€‚ç”¨åœºæ™¯ |
|--------|---------|------|---------|---------|---------|
| **runc** | è¿›ç¨‹çº§ | åŸç”Ÿ | <100ms | ~5MB | å¯ä¿¡å·¥ä½œè´Ÿè½½ |
| **gVisor** | ç”¨æˆ·æ€å†…æ ¸ | 70-80% | ~200ms | ~15MB | ä¸å¯ä¿¡ä»£ç  |
| **Kata** | VMçº§ | 85-95% | ~500ms | ~130MB | å¤šç§Ÿæˆ·/é«˜å®‰å…¨ |

---

## å°ç»“ï¼šç¬¬1ç« æ ¸å¿ƒçŸ¥è¯†ç‚¹

âœ… **å·²æŒæ¡å†…å®¹**ï¼š
1. **Namespaceéš”ç¦»æœºåˆ¶**ï¼š7ç§namespaceç±»å‹åŠå®æˆ˜
2. **Cgroupsèµ„æºé™åˆ¶**ï¼šCPU/å†…å­˜/IO/PIDé™åˆ¶è¯¦è§£
3. **UnionFSæ–‡ä»¶ç³»ç»Ÿ**ï¼šOverlay2åŸç†ä¸æ€§èƒ½ä¼˜åŒ–
4. **å®¹å™¨è¿è¡Œæ—¶**ï¼šrunc/containerd/gVisor/Kataå¯¹æ¯”

ğŸ¯ **å®æˆ˜èƒ½åŠ›**ï¼š
- æ‰‹åŠ¨åˆ›å»ºnamespaceå’Œcgroup
- é…ç½®èµ„æºé™åˆ¶å‚æ•°
- é€‰æ‹©åˆé€‚çš„å­˜å‚¨é©±åŠ¨
- æ ¹æ®å®‰å…¨éœ€æ±‚é€‰æ‹©è¿è¡Œæ—¶

ğŸ“ **ä¸‹ä¸€ç« é¢„å‘Š**ï¼š
- Dockeræ¶æ„ä¸ç»„ä»¶äº¤äº’
- Docker Daemoné…ç½®ä¸ä¼˜åŒ–
- Docker Client APIä½¿ç”¨

---

## ç¬¬ 2 ç« ï¼šDocker æ¶æ„ä¸ç»„ä»¶

### 2.1 Docker æ•´ä½“æ¶æ„

#### 2.1.1 æ¶æ„æ¼”è¿›å†å²

**Docker 1.0-1.10 (å•ä½“æ¶æ„)**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Docker Client                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Daemon (dockerd)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Image Management                  â”‚ â”‚
â”‚  â”‚  Container Management              â”‚ â”‚
â”‚  â”‚  Network Management                â”‚ â”‚
â”‚  â”‚  Volume Management                 â”‚ â”‚
â”‚  â”‚  Build System                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    libcontainer (Goå®ç°çš„å®¹å™¨åº“)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Docker 1.11+ (ç»„ä»¶åŒ–æ¶æ„ - OCIæ ‡å‡†)**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Docker Client (docker)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ REST API / gRPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Docker Daemon (dockerd)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Image Management  â”‚  Network  â”‚  Volume  â”‚ Build â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ gRPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   containerd                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Container Lifecycle  â”‚  Image Store  â”‚ Snapshotsâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ (per container)
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ containerd-shim    â”‚   â”‚ containerd-shim    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     runc     â”‚  â”‚   â”‚  â”‚     runc     â”‚  â”‚
â”‚  â”‚  (Container) â”‚  â”‚   â”‚  â”‚  (Container) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ¶æ„æ”¹è¿›çš„å¥½å¤„**ï¼š
1. **è§£è€¦**: dockerdä¸å®¹å™¨è¿è¡Œæ—¶åˆ†ç¦»
2. **ç¨³å®šæ€§**: dockerdé‡å¯ä¸å½±å“è¿è¡Œä¸­çš„å®¹å™¨
3. **æ‰©å±•æ€§**: å¯æ’æ‹”çš„è¿è¡Œæ—¶(runc/kata/gvisor)
4. **æ ‡å‡†åŒ–**: éµå¾ªOCIæ ‡å‡†

---

#### 2.1.2 ç»„ä»¶è¯¦ç»†è¯´æ˜

**æ ¸å¿ƒç»„ä»¶è¡¨**:

| ç»„ä»¶ | ä½œç”¨ | è¿›ç¨‹å | é€šä¿¡æ–¹å¼ |
|-----|------|--------|---------|
| **Docker Client** | ç”¨æˆ·äº¤äº’ç•Œé¢ | docker | REST API / Unix Socket |
| **Docker Daemon** | æ ¸å¿ƒç®¡ç†æœåŠ¡ | dockerd | gRPC / Unix Socket |
| **containerd** | å®¹å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç† | containerd | gRPC |
| **containerd-shim** | å®¹å™¨è¿›ç¨‹å®ˆæŠ¤ | containerd-shim | - |
| **runc** | OCIå®¹å™¨è¿è¡Œæ—¶ | runc | - |

---

### 2.2 Docker Daemon æ·±åº¦è§£æ

#### 2.2.1 dockerd å¯åŠ¨è¿‡ç¨‹

**å¯åŠ¨æµç¨‹è¯¦è§£**:
```bash
# 1. systemdå¯åŠ¨dockerd
$ sudo systemctl start docker

# æŸ¥çœ‹å®Œæ•´å¯åŠ¨å‘½ä»¤
$ ps aux | grep dockerd
root  1234  /usr/bin/dockerd \
    -H fd:// \
    --containerd=/run/containerd/containerd.sock \
    --log-level=info \
    --storage-driver=overlay2

# 2. dockerdåˆå§‹åŒ–æµç¨‹
# (1) åŠ è½½é…ç½®æ–‡ä»¶
$ cat /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}

# (2) åˆå§‹åŒ–å­˜å‚¨é©±åŠ¨
# (3) è¿æ¥containerd
$ ls -l /run/containerd/containerd.sock
srw-rw---- 1 root docker 0 ... /run/containerd/containerd.sock

# (4) åŠ è½½å·²å­˜åœ¨çš„å®¹å™¨å’Œé•œåƒ
# (5) å¯åŠ¨APIæœåŠ¡å™¨

# 3. ç›‘å¬ç«¯å£
$ sudo ss -tulnp | grep dockerd
tcp   LISTEN  0  128  *:2375  *:*  users:(("dockerd",pid=1234,fd=10))
unix  LISTEN  0  128  /var/run/docker.sock  users:(("dockerd",pid=1234,fd=8))
```

---

#### 2.2.2 daemon.json å®Œæ•´é…ç½®è¯¦è§£

**ç”Ÿäº§çº§é…ç½®æ¨¡æ¿**:
```json
{
  // === åŸºç¡€é…ç½® ===
  "data-root": "/data/docker",              // æ•°æ®ç›®å½•(é»˜è®¤/var/lib/docker)
  "exec-root": "/var/run/docker",           // æ‰§è¡ŒçŠ¶æ€ç›®å½•
  "pidfile": "/var/run/docker.pid",         // PIDæ–‡ä»¶è·¯å¾„

  // === å­˜å‚¨é©±åŠ¨é…ç½® ===
  "storage-driver": "overlay2",             // å­˜å‚¨é©±åŠ¨ç±»å‹
  "storage-opts": [
    "overlay2.override_kernel_check=true"   // è¦†ç›–å†…æ ¸ç‰ˆæœ¬æ£€æŸ¥
  ],

  // === æ—¥å¿—é…ç½® ===
  "log-driver": "json-file",                // æ—¥å¿—é©±åŠ¨
  "log-opts": {
    "max-size": "100m",                     // å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§100MB
    "max-file": "10",                       // æœ€å¤šä¿ç•™10ä¸ªæ—¥å¿—æ–‡ä»¶
    "compress": "true",                     // å¯ç”¨å‹ç¼©
    "labels": "production"                  // æ—¥å¿—æ ‡ç­¾
  },
  "log-level": "info",                      // dockerdæ—¥å¿—çº§åˆ«

  // === ç½‘ç»œé…ç½® ===
  "bridge": "docker0",                      // é»˜è®¤ç½‘æ¡¥åç§°
  "bip": "172.17.0.1/16",                  // ç½‘æ¡¥IPåœ°å€
  "default-address-pools": [                // è‡ªå®šä¹‰ç½‘ç»œæ± 
    {
      "base": "172.80.0.0/16",
      "size": 24
    },
    {
      "base": "172.90.0.0/16",
      "size": 24
    }
  ],
  "dns": ["8.8.8.8", "8.8.4.4"],           // å®¹å™¨é»˜è®¤DNS
  "dns-search": ["example.com"],            // DNSæœç´¢åŸŸ
  "mtu": 1500,                              // ç½‘ç»œMTU

  // === é•œåƒé…ç½® ===
  "registry-mirrors": [                     // é•œåƒåŠ é€Ÿå™¨
    "https://mirror.ccs.tencentyun.com",
    "https://docker.mirrors.ustc.edu.cn"
  ],
  "insecure-registries": [                  // ä¸å®‰å…¨çš„é•œåƒä»“åº“
    "registry.internal.com:5000"
  ],
  "max-concurrent-downloads": 10,           // æœ€å¤§å¹¶å‘ä¸‹è½½æ•°
  "max-concurrent-uploads": 5,              // æœ€å¤§å¹¶å‘ä¸Šä¼ æ•°

  // === å®‰å…¨é…ç½® ===
  "live-restore": true,                     // dockerdé‡å¯æ—¶ä¿æŒå®¹å™¨è¿è¡Œ
  "userland-proxy": false,                  // ç¦ç”¨ç”¨æˆ·æ€ä»£ç†(æå‡æ€§èƒ½)
  "icc": false,                             // ç¦ç”¨å®¹å™¨é—´äº’é€š(æå‡å®‰å…¨)
  "userns-remap": "default",                // ç”¨æˆ·å‘½åç©ºé—´é‡æ˜ å°„
  "no-new-privileges": true,                // ç¦æ­¢å®¹å™¨è¿›ç¨‹è·å–æ–°æƒé™
  "selinux-enabled": false,                 // SELinuxæ”¯æŒ

  // === èµ„æºé™åˆ¶é»˜è®¤å€¼ ===
  "default-ulimits": {
    "nofile": {
      "Name": "nofile",
      "Hard": 64000,
      "Soft": 64000
    },
    "nproc": {
      "Name": "nproc",
      "Hard": 64000,
      "Soft": 64000
    }
  },
  "default-shm-size": "64M",                // å…±äº«å†…å­˜å¤§å°

  // === å…¶ä»–é…ç½® ===
  "experimental": false,                    // å®éªŒæ€§åŠŸèƒ½
  "metrics-addr": "0.0.0.0:9323",          // Prometheus metricsåœ°å€
  "ipv6": false,                            // IPv6æ”¯æŒ
  "fixed-cidr-v6": "2001:db8:1::/64",      // IPv6å›ºå®šCIDR
  "iptables": true,                         // å¯ç”¨iptablesè§„åˆ™
  "ip-forward": true,                       // å¯ç”¨IPè½¬å‘
  "ip-masq": true,                          // å¯ç”¨IPä¼ªè£…(NAT)

  // === è¿è¡Œæ—¶é…ç½® ===
  "runtimes": {
    "nvidia": {                             // NVIDIA GPUè¿è¡Œæ—¶
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    },
    "kata": {                               // Kata Containers
      "path": "/usr/bin/kata-runtime"
    }
  },
  "default-runtime": "runc",                // é»˜è®¤è¿è¡Œæ—¶

  // === é›†ç¾¤é…ç½® (Swarm) ===
  "cluster-store": "consul://localhost:8500",
  "cluster-advertise": "192.168.1.100:2376",

  // === è°ƒè¯•é…ç½® ===
  "debug": false,                           // è°ƒè¯•æ¨¡å¼
  "hosts": [                                // ç›‘å¬åœ°å€
    "unix:///var/run/docker.sock",
    "tcp://0.0.0.0:2375"
  ]
}
```

**é…ç½®ç”Ÿæ•ˆ**:
```bash
# ä¿®æ”¹é…ç½®åé‡å¯
$ sudo systemctl daemon-reload
$ sudo systemctl restart docker

# éªŒè¯é…ç½®
$ docker info | grep -A 10 "Storage Driver"
$ docker info | grep -A 5 "Registry Mirrors"
```

---

#### 2.2.3 Docker API ä½¿ç”¨

**ä¸‰ç§è®¿é—®æ–¹å¼**:

**1. Unix Socket (æœ¬åœ°)**:
```bash
# é»˜è®¤socketè·¯å¾„
$ curl --unix-socket /var/run/docker.sock \
    http://localhost/version | jq
{
  "Version": "24.0.5",
  "ApiVersion": "1.43",
  "GitCommit": "ced0996",
  "GoVersion": "go1.20.6",
  "Os": "linux",
  "Arch": "amd64",
  ...
}

# åˆ—å‡ºå®¹å™¨
$ curl --unix-socket /var/run/docker.sock \
    http://localhost/containers/json | jq

# åˆ›å»ºå®¹å™¨
$ curl --unix-socket /var/run/docker.sock \
    -X POST \
    -H "Content-Type: application/json" \
    -d '{
      "Image": "nginx:alpine",
      "HostConfig": {
        "PortBindings": {
          "80/tcp": [{"HostPort": "8080"}]
        }
      }
    }' \
    http://localhost/containers/create?name=my-nginx
```

**2. TCP Socket (è¿œç¨‹)**:
```bash
# âš ï¸ è­¦å‘Šï¼šæš´éœ²TCPç«¯å£æœ‰å®‰å…¨é£é™©ï¼Œç”Ÿäº§ç¯å¢ƒå¿…é¡»ä½¿ç”¨TLS

# daemon.jsoné…ç½®
{
  "hosts": ["tcp://0.0.0.0:2375", "unix:///var/run/docker.sock"]
}

# å®¢æˆ·ç«¯è¿æ¥
$ docker -H tcp://192.168.1.100:2375 ps

# ä½¿ç”¨curl
$ curl http://192.168.1.100:2375/version
```

**3. TLSåŠ å¯†è¿æ¥ï¼ˆç”Ÿäº§æ¨èï¼‰**:
```bash
# ç”ŸæˆCAè¯ä¹¦
$ openssl genrsa -aes256 -out ca-key.pem 4096
$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem

# ç”ŸæˆæœåŠ¡å™¨è¯ä¹¦
$ openssl genrsa -out server-key.pem 4096
$ openssl req -subj "/CN=docker.example.com" -sha256 -new -key server-key.pem -out server.csr

# é…ç½®SAN
$ echo "subjectAltName = DNS:docker.example.com,IP:192.168.1.100" > extfile.cnf
$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \
    -CAcreateserial -out server-cert.pem -extfile extfile.cnf

# ç”Ÿæˆå®¢æˆ·ç«¯è¯ä¹¦
$ openssl genrsa -out key.pem 4096
$ openssl req -subj '/CN=client' -new -key key.pem -out client.csr
$ echo "extendedKeyUsage = clientAuth" > extfile-client.cnf
$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \
    -CAcreateserial -out cert.pem -extfile extfile-client.cnf

# é…ç½®daemon.json
{
  "hosts": ["tcp://0.0.0.0:2376", "unix:///var/run/docker.sock"],
  "tls": true,
  "tlscacert": "/etc/docker/certs/ca.pem",
  "tlscert": "/etc/docker/certs/server-cert.pem",
  "tlskey": "/etc/docker/certs/server-key.pem",
  "tlsverify": true
}

# å®¢æˆ·ç«¯è¿æ¥
$ docker --tlsverify \
    --tlscacert=ca.pem \
    --tlscert=cert.pem \
    --tlskey=key.pem \
    -H tcp://192.168.1.100:2376 ps
```

---

#### 2.2.4 Docker API å®æˆ˜æ¡ˆä¾‹

**Python SDKä½¿ç”¨**:
```python
#!/usr/bin/env python3
import docker
from docker.errors import DockerException

# è¿æ¥Docker daemon
client = docker.from_env()  # è‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡

# æˆ–è€…æ˜¾å¼æŒ‡å®š
# client = docker.DockerClient(base_url='unix:///var/run/docker.sock')

# 1. é•œåƒæ“ä½œ
def manage_images():
    """é•œåƒç®¡ç†"""
    # æ‹‰å–é•œåƒ
    print("ğŸ“¥ æ‹‰å–nginxé•œåƒ...")
    image = client.images.pull('nginx', tag='alpine')
    print(f"âœ… é•œåƒID: {image.short_id}")

    # åˆ—å‡ºé•œåƒ
    images = client.images.list()
    for img in images:
        print(f"é•œåƒ: {img.tags}, å¤§å°: {img.attrs['Size'] / 1024 / 1024:.2f}MB")

    # æ„å»ºé•œåƒ
    image, build_logs = client.images.build(
        path='/path/to/dockerfile/dir',
        tag='myapp:latest',
        rm=True  # æ„å»ºååˆ é™¤ä¸­é—´å®¹å™¨
    )
    for log in build_logs:
        print(log)

# 2. å®¹å™¨æ“ä½œ
def manage_containers():
    """å®¹å™¨ç®¡ç†"""
    # åˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨
    container = client.containers.run(
        'nginx:alpine',
        name='my-nginx',
        detach=True,  # åå°è¿è¡Œ
        ports={'80/tcp': 8080},
        environment={'ENV': 'production'},
        volumes={'/data': {'bind': '/usr/share/nginx/html', 'mode': 'ro'}},
        restart_policy={'Name': 'unless-stopped'},
        mem_limit='512m',
        cpu_quota=50000,  # 0.5 CPU
        labels={'app': 'nginx', 'env': 'prod'}
    )
    print(f"âœ… å®¹å™¨å¯åŠ¨: {container.id[:12]}")

    # æŸ¥çœ‹å®¹å™¨æ—¥å¿—
    logs = container.logs(stream=False, tail=100)
    print(logs.decode('utf-8'))

    # æ‰§è¡Œå‘½ä»¤
    exec_result = container.exec_run('nginx -t')
    print(f"Exit code: {exec_result.exit_code}")
    print(exec_result.output.decode('utf-8'))

    # å®¹å™¨ç»Ÿè®¡ä¿¡æ¯
    stats = container.stats(stream=False)
    cpu_usage = stats['cpu_stats']['cpu_usage']['total_usage']
    mem_usage = stats['memory_stats']['usage']
    print(f"CPU: {cpu_usage}, Memory: {mem_usage / 1024 / 1024:.2f}MB")

    # åœæ­¢å¹¶åˆ é™¤
    container.stop(timeout=10)
    container.remove()

# 3. ç½‘ç»œæ“ä½œ
def manage_networks():
    """ç½‘ç»œç®¡ç†"""
    # åˆ›å»ºè‡ªå®šä¹‰ç½‘ç»œ
    network = client.networks.create(
        'my-network',
        driver='bridge',
        ipam=docker.types.IPAMConfig(
            pool_configs=[
                docker.types.IPAMPool(subnet='172.28.0.0/16')
            ]
        )
    )

    # è¿æ¥å®¹å™¨åˆ°ç½‘ç»œ
    container = client.containers.get('my-nginx')
    network.connect(container, ipv4_address='172.28.0.10')

    # æ–­å¼€è¿æ¥
    network.disconnect(container)

# 4. å·æ“ä½œ
def manage_volumes():
    """å·ç®¡ç†"""
    # åˆ›å»ºå·
    volume = client.volumes.create(
        name='my-volume',
        driver='local',
        labels={'env': 'prod'}
    )

    # ä½¿ç”¨å·
    container = client.containers.run(
        'nginx:alpine',
        volumes={volume.name: {'bind': '/data', 'mode': 'rw'}},
        detach=True
    )

    # æ¸…ç†æœªä½¿ç”¨çš„å·
    client.volumes.prune()

# 5. äº‹ä»¶ç›‘å¬
def monitor_events():
    """ç›‘å¬Dockeräº‹ä»¶"""
    events = client.events(decode=True)

    for event in events:
        if event['Type'] == 'container':
            action = event['Action']
            container_name = event['Actor']['Attributes'].get('name', 'unknown')
            print(f"ğŸ”” å®¹å™¨äº‹ä»¶: {container_name} - {action}")

        elif event['Type'] == 'image':
            action = event['Action']
            image_tag = event['Actor']['Attributes'].get('name', 'unknown')
            print(f"ğŸ–¼ï¸  é•œåƒäº‹ä»¶: {image_tag} - {action}")

# 6. æ‰¹é‡æ“ä½œ
def batch_operations():
    """æ‰¹é‡ç®¡ç†å®¹å™¨"""
    # åœæ­¢æ‰€æœ‰è¿è¡Œä¸­çš„å®¹å™¨
    for container in client.containers.list():
        print(f"åœæ­¢å®¹å™¨: {container.name}")
        container.stop()

    # æ¸…ç†æ‰€æœ‰é€€å‡ºçš„å®¹å™¨
    for container in client.containers.list(all=True, filters={'status': 'exited'}):
        print(f"åˆ é™¤å®¹å™¨: {container.name}")
        container.remove()

    # æ¸…ç†æ‚¬ç©ºé•œåƒ
    client.images.prune(filters={'dangling': True})

if __name__ == '__main__':
    try:
        manage_images()
        manage_containers()
        manage_networks()
        manage_volumes()
    except DockerException as e:
        print(f"âŒ Dockeré”™è¯¯: {e}")
```

---

### 2.3 containerd æ·±åº¦è§£æ

#### 2.3.1 containerd æ¶æ„

**containerd å†…éƒ¨ç»„ä»¶**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    containerd                         â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚            gRPC API Server                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚     Metadata Service        â”‚  Content Store    â”‚â”‚
â”‚  â”‚     (boltdb)                â”‚  (blobs)          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Snapshot Service                     â”‚  â”‚
â”‚  â”‚  (overlayfs/btrfs/zfs/native)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Task Service                         â”‚  â”‚
â”‚  â”‚  (container lifecycle)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ containerd-shimâ”‚ â”‚containerd-shim â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   runc   â”‚  â”‚ â”‚  â”‚   runc   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 2.3.2 containerd é…ç½®

**é…ç½®æ–‡ä»¶è·¯å¾„**: `/etc/containerd/config.toml`

```toml
# containerd é…ç½®æ–‡ä»¶

version = 2

# æ ¹ç›®å½•
root = "/var/lib/containerd"
state = "/run/containerd"

# OCIè¿è¡Œæ—¶é…ç½®
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"

  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
    SystemdCgroup = true  # ä½¿ç”¨systemd cgroupé©±åŠ¨

# é•œåƒåŠ é€Ÿé…ç½®
[plugins."io.containerd.grpc.v1.cri".registry.mirrors]
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
    endpoint = ["https://mirror.ccs.tencentyun.com"]

  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."k8s.gcr.io"]
    endpoint = ["https://registry.aliyuncs.com/google_containers"]

# ç§æœ‰é•œåƒä»“åº“è®¤è¯
[plugins."io.containerd.grpc.v1.cri".registry.configs."registry.example.com".auth]
  username = "myuser"
  password = "mypassword"

# Snapshotteré…ç½®ï¼ˆå­˜å‚¨é©±åŠ¨ï¼‰
[plugins."io.containerd.grpc.v1.cri".containerd]
  snapshotter = "overlayfs"
  default_runtime_name = "runc"

# CNIç½‘ç»œé…ç½®
[plugins."io.containerd.grpc.v1.cri".cni]
  bin_dir = "/opt/cni/bin"
  conf_dir = "/etc/cni/net.d"
```

**é‡å¯containerd**:
```bash
$ sudo systemctl restart containerd
$ sudo systemctl status containerd
```

---

#### 2.3.3 ctr å‘½ä»¤è¡Œå·¥å…·

**ctr vs docker å‘½ä»¤å¯¹æ¯”**:

| åŠŸèƒ½ | dockerå‘½ä»¤ | ctrå‘½ä»¤ |
|-----|-----------|---------|
| æ‹‰å–é•œåƒ | `docker pull nginx` | `ctr images pull docker.io/library/nginx:latest` |
| åˆ—å‡ºé•œåƒ | `docker images` | `ctr images list` |
| è¿è¡Œå®¹å™¨ | `docker run -d nginx` | `ctr run -d docker.io/library/nginx:latest my-nginx` |
| åˆ—å‡ºå®¹å™¨ | `docker ps` | `ctr tasks list` |
| åˆ é™¤å®¹å™¨ | `docker rm <id>` | `ctr tasks kill <id> && ctr containers delete <id>` |
| æŸ¥çœ‹æ—¥å¿— | `docker logs <id>` | `ctr tasks exec --exec-id sh <id> sh` |

**ctrå®æˆ˜ç¤ºä¾‹**:
```bash
# 1. å‘½åç©ºé—´ç®¡ç†ï¼ˆcontainerdæ”¯æŒå¤šç§Ÿæˆ·ï¼‰
$ sudo ctr namespaces list
NAME    LABELS
default
moby    # Dockerä½¿ç”¨çš„å‘½åç©ºé—´
k8s.io  # Kubernetesä½¿ç”¨çš„å‘½åç©ºé—´

$ sudo ctr -n k8s.io images list  # æŸ¥çœ‹k8så‘½åç©ºé—´çš„é•œåƒ

# 2. é•œåƒæ“ä½œ
$ sudo ctr images pull docker.io/library/nginx:alpine
$ sudo ctr images list -q
docker.io/library/nginx:alpine

# å¯¼å‡ºé•œåƒ
$ sudo ctr images export nginx.tar docker.io/library/nginx:alpine

# å¯¼å…¥é•œåƒ
$ sudo ctr images import nginx.tar

# 3. å®¹å™¨ç”Ÿå‘½å‘¨æœŸ
# åˆ›å»ºå®¹å™¨ï¼ˆä»…åˆ›å»ºï¼Œä¸è¿è¡Œï¼‰
$ sudo ctr containers create docker.io/library/nginx:alpine my-nginx

# å¯åŠ¨ä»»åŠ¡ï¼ˆè¿è¡Œå®¹å™¨ï¼‰
$ sudo ctr tasks start -d my-nginx

# æŸ¥çœ‹è¿è¡Œä¸­çš„ä»»åŠ¡
$ sudo ctr tasks list
TASK        PID     STATUS
my-nginx    12345   RUNNING

# æš‚åœå®¹å™¨
$ sudo ctr tasks pause my-nginx

# æ¢å¤å®¹å™¨
$ sudo ctr tasks resume my-nginx

# æ€æ­»ä»»åŠ¡
$ sudo ctr tasks kill my-nginx

# åˆ é™¤å®¹å™¨
$ sudo ctr containers delete my-nginx

# 4. å¿«ç…§ç®¡ç†
$ sudo ctr snapshots list
KEY                                                                 PARENT  KIND
sha256:abc123...                                                            Active
sha256:def456...  sha256:abc123...                                         Committed

# 5. å†…å®¹å­˜å‚¨
$ sudo ctr content list
DIGEST                                                                  SIZE
sha256:1234567890abcdef...                                            2.3 MB
sha256:fedcba0987654321...                                            5.1 MB

# 6. ç§Ÿæˆ·æ“ä½œ
$ sudo ctr -n custom-namespace images pull nginx:alpine
$ sudo ctr -n custom-namespace containers create nginx:alpine my-app
```

---

### 2.4 containerd-shim åŸç†

#### 2.4.1 shim çš„ä½œç”¨

**ä¸ºä»€ä¹ˆéœ€è¦shim**:
```
æ²¡æœ‰shimçš„é—®é¢˜:
dockerd -> containerd -> runc (ç›´æ¥ç®¡ç†å®¹å™¨)
é—®é¢˜ï¼š
1. runcé€€å‡ºåå®¹å™¨å˜æˆå­¤å„¿è¿›ç¨‹
2. containerdé‡å¯ä¼šå½±å“æ‰€æœ‰å®¹å™¨
3. æ— æ³•æ”¶é›†å®¹å™¨é€€å‡ºçŠ¶æ€

æœ‰shimçš„æ¶æ„:
dockerd -> containerd -> shim -> runc
ä¼˜åŠ¿ï¼š
1. runcå¯ä»¥åœ¨å¯åŠ¨å®¹å™¨åé€€å‡º(èŠ‚çœèµ„æº)
2. shimæŒç»­è¿è¡Œ,æ¥ç®¡å®¹å™¨
3. containerdé‡å¯ä¸å½±å“å®¹å™¨
4. æ”¶é›†å®¹å™¨é€€å‡ºçŠ¶æ€å’Œæ—¥å¿—
```

**shim è¿›ç¨‹æŸ¥çœ‹**:
```bash
# å¯åŠ¨ä¸€ä¸ªnginxå®¹å™¨
$ docker run -d --name nginx nginx:alpine

# æŸ¥çœ‹è¿›ç¨‹æ ‘
$ pstree -p $(pgrep dockerd)
dockerd(1234)â”€â”€â”€containerd(1235)â”€â”¬â”€containerd-shim(2345)â”€â”¬â”€nginx(2350)
                                  â”‚                        â””â”€nginx(2351)
                                  â””â”€containerd-shim(2400)â”€â”€â”€redis(2401)

# æŸ¥çœ‹shimè¿›ç¨‹è¯¦æƒ…
$ ps aux | grep containerd-shim
root  2345  /usr/bin/containerd-shim-runc-v2 \
    -namespace moby \
    -id abc123def456 \
    -address /run/containerd/containerd.sock

# shimç®¡ç†çš„å®¹å™¨
$ sudo ls -l /run/containerd/io.containerd.runtime.v2.task/moby/
drwx------ 2 root root 80 ... abc123def456/  # å®¹å™¨IDç›®å½•
```

---

#### 2.4.2 shim å®ç°ç»†èŠ‚

**shim èŒè´£**:
1. **ä¿æŒSTDIOæ‰“å¼€**: ä¸ºå®¹å™¨ä¿æŒstdin/stdout/stderr
2. **æŠ¥å‘Šå®¹å™¨é€€å‡º**: ç›‘æ§å®¹å™¨è¿›ç¨‹,ä¸ŠæŠ¥é€€å‡ºçŠ¶æ€
3. **å®ˆæŠ¤å®¹å™¨è¿›ç¨‹**: ä½œä¸ºå®¹å™¨è¿›ç¨‹çš„çˆ¶è¿›ç¨‹
4. **ä¸containerdé€šä¿¡**: é€šè¿‡gRPCä¸ŠæŠ¥äº‹ä»¶

**shim é€šä¿¡ç¤ºä¾‹**:
```bash
# æŸ¥çœ‹shim socket
$ sudo ls -l /run/containerd/s/
srw------- 1 root root 0 ... abc123def456  # æ¯ä¸ªå®¹å™¨ä¸€ä¸ªsocket

# ä½¿ç”¨grpcurlä¸shimé€šä¿¡(éœ€è¦å®‰è£…grpcurl)
$ sudo grpcurl -unix \
    -d '{"id": "abc123def456"}' \
    /run/containerd/s/abc123def456 \
    containerd.runtime.v2.Task/Stats
{
  "stats": {
    "cpu_stats": {...},
    "memory_stats": {...}
  }
}
```

---

### 2.5 Docker ä¸ Kubernetes é›†æˆ

#### 2.5.1 CRI (Container Runtime Interface)

**CRI æ¶æ„**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           kubelet                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ CRI (gRPC)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       CRI Runtime Shim              â”‚
â”‚  (containerd/CRI-O/Docker-shim)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       OCI Runtime (runc)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**dockershim è¢«å¼ƒç”¨**:
```bash
# Kubernetes 1.20+è­¦å‘Š
$ kubectl get nodes -o wide
NAME    STATUS   VERSION   CONTAINER-RUNTIME
node1   Ready    v1.24.0   containerd://1.6.8  # æ¨è
node2   Ready    v1.23.0   docker://20.10.17   # å·²å¼ƒç”¨(1.24+ç§»é™¤)

# è¿ç§»åˆ°containerd
# 1. å®‰è£…containerd
$ sudo apt-get install containerd

# 2. é…ç½®containerd
$ sudo mkdir -p /etc/containerd
$ containerd config default | sudo tee /etc/containerd/config.toml

# 3. ä¿®æ”¹kubeleté…ç½®
# /var/lib/kubelet/kubeadm-flags.env
KUBELET_KUBEADM_ARGS="--container-runtime=remote \
    --container-runtime-endpoint=unix:///run/containerd/containerd.sock"

# 4. é‡å¯æœåŠ¡
$ sudo systemctl restart containerd kubelet
```

---

## å°ç»“ï¼šç¬¬2ç« æ ¸å¿ƒçŸ¥è¯†ç‚¹

âœ… **å·²æŒæ¡å†…å®¹**ï¼š
1. **Dockeræ¶æ„æ¼”è¿›**: å•ä½“â†’ç»„ä»¶åŒ–â†’OCIæ ‡å‡†
2. **dockerdé…ç½®**: daemon.jsonå®Œæ•´é…ç½®è¯¦è§£
3. **Docker API**: Unix Socket/TCP/TLSä¸‰ç§æ–¹å¼
4. **containerdæ¶æ„**: gRPC APIã€å¿«ç…§ã€å†…å®¹å­˜å‚¨
5. **containerd-shim**: å®ˆæŠ¤å®¹å™¨è¿›ç¨‹çš„å…³é”®ç»„ä»¶
6. **CRIé›†æˆ**: Kuberneteså®¹å™¨è¿è¡Œæ—¶æ¥å£

ğŸ¯ **å®æˆ˜èƒ½åŠ›**ï¼š
- ç”Ÿäº§çº§dockerdé…ç½®
- ä½¿ç”¨Docker APIè‡ªåŠ¨åŒ–ç®¡ç†
- ç†è§£containerdå·¥ä½œæµç¨‹
- æ’æŸ¥shimç›¸å…³é—®é¢˜

---

## ç¬¬ 3 ç« ï¼šé•œåƒåŸç†ä¸å­˜å‚¨é©±åŠ¨

### 3.1 é•œåƒåˆ†å±‚åŸç†

#### 3.1.1 é•œåƒ vs å®¹å™¨å±‚

**é•œåƒåˆ†å±‚ç¤ºæ„å›¾**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Container Layer (Read-Write)             â”‚  â† å®¹å™¨è¿è¡Œæ—¶ä¿®æ”¹
â”‚  - æ–°åˆ›å»ºçš„æ–‡ä»¶                                 â”‚
â”‚  - ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆCOW from image layersï¼‰          â”‚
â”‚  - åˆ é™¤çš„æ–‡ä»¶ï¼ˆwhiteoutæ–‡ä»¶æ ‡è®°ï¼‰               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Image Layer N (Read-Only)                â”‚  â† CMD/ENTRYPOINT
â”‚  sha256:abc123...                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Image Layer N-1 (Read-Only)              â”‚  â† RUNæŒ‡ä»¤å±‚
â”‚  sha256:def456...                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Image Layer 2 (Read-Only)                â”‚  â† COPYæŒ‡ä»¤å±‚
â”‚  sha256:789ghi...                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Image Layer 1 (Read-Only)                â”‚  â† FROMåŸºç¡€é•œåƒ
â”‚  sha256:jkl012...                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ UnionFSåˆå¹¶
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Merged View (Container Root)             â”‚
â”‚       /bin, /etc, /usr, /var, ...              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 3.1.2 é•œåƒå±‚æŸ¥çœ‹

**inspectæŸ¥çœ‹é•œåƒå±‚**:
```bash
# æ‹‰å–nginxé•œåƒ
$ docker pull nginx:alpine

# æŸ¥çœ‹é•œåƒå±‚
$ docker inspect nginx:alpine | jq '.[0].RootFS'
{
  "Type": "layers",
  "Layers": [
    "sha256:01fd6df81c8ec7dd24bbbd72342671f41813f992999a3471b9d9cbc44ad88374",
    "sha256:1e94b4f87af7e61d4dea54b4da4a37a4c8c5a1f87c38a6f93d2c8d6d7f7bce67",
    "sha256:d8c1c7c1c2b3f9e8d5a9f3b4c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0",
    "sha256:a3c2e1f0d9b8c7a6f5e4d3c2b1a0f9e8d7c6b5a4f3e2d1c0b9a8f7e6d5c4b3a2",
    "sha256:f1e0d9c8b7a6f5e4d3c2b1a0f9e8d7c6b5a4f3e2d1c0b9a8f7e6d5c4b3a2c1b0",
    "sha256:e3d2c1b0a9f8e7d6c5b4a3f2e1d0c9b8a7f6e5d4c3b2a1f0e9d8c7b6a5f4e3d2"
  ]
}

# ä½¿ç”¨docker historyæŸ¥çœ‹å±‚æ„å»ºå†å²
$ docker history nginx:alpine
IMAGE          CREATED        CREATED BY                                      SIZE
abc123def456   2 weeks ago    CMD ["nginx" "-g" "daemon off;"]                0B
def456ghi789   2 weeks ago    STOPSIGNAL SIGQUIT                              0B
ghi789jkl012   2 weeks ago    EXPOSE 80                                       0B
jkl012mno345   2 weeks ago    COPY file:abc /etc/nginx/nginx.conf # bu...     643B
mno345pqr678   2 weeks ago    RUN /bin/sh -c set -x     && addgroup -g...     8.12MB
pqr678stu901   2 weeks ago    ENV NGINX_VERSION=1.25.2                        0B
stu901vwx234   2 weeks ago    /bin/sh -c #(nop)  LABEL maintainer=NGI...     0B
vwx234yz1345   3 weeks ago    /bin/sh -c #(nop) ADD file:abc123 in /          7.34MB
```

**å±‚çš„å­˜å‚¨ä½ç½®**:
```bash
# overlay2å­˜å‚¨ç›®å½•
$ sudo ls -l /var/lib/docker/overlay2/
drwx--x---  4 root root 55  l/               # å±‚çš„çŸ­é“¾æ¥ç›®å½•
drwx--x---  4 root root 55  <layer-id-1>/
drwx--x---  4 root root 55  <layer-id-2>/
drwx--x---  4 root root 55  <layer-id-3>/

# æŸ¥çœ‹æŸä¸€å±‚çš„å†…å®¹
$ sudo ls /var/lib/docker/overlay2/<layer-id>/diff/
bin  boot  dev  etc  home  lib  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var

# æŸ¥çœ‹å±‚çš„å…ƒæ•°æ®
$ sudo cat /var/lib/docker/overlay2/<layer-id>/link
ABCDEFGHIJKLMN  # çŸ­é“¾æ¥å(é¿å…è·¯å¾„è¿‡é•¿)

$ sudo cat /var/lib/docker/overlay2/<layer-id>/lower
l/MNOPQRSTUVWX:l/XYZVABCDEFGH  # ä¸‹å±‚çš„é“¾æ¥
```

---

#### 3.1.3 å†™æ—¶å¤åˆ¶ (Copy-on-Write) è¯¦è§£

**COW å·¥ä½œæµç¨‹**:
```bash
# 1. å¯åŠ¨å®¹å™¨
$ docker run -d --name test nginx:alpine

# 2. å®¹å™¨åˆå§‹çŠ¶æ€ï¼ˆæ‰€æœ‰å±‚åªè¯»ï¼‰
$ docker diff test
# è¾“å‡ºä¸ºç©ºï¼Œå› ä¸ºæ²¡æœ‰ä¿®æ”¹

# 3. ä¿®æ”¹æ–‡ä»¶ï¼ˆè§¦å‘COWï¼‰
$ docker exec test sh -c 'echo "modified" > /etc/nginx/nginx.conf'

# 4. æŸ¥çœ‹å·®å¼‚
$ docker diff test
C /etc
C /etc/nginx
C /etc/nginx/nginx.conf

# C = Changed (æ–‡ä»¶è¢«ä¿®æ”¹)
# A = Added (æ–‡ä»¶è¢«æ·»åŠ )
# D = Deleted (æ–‡ä»¶è¢«åˆ é™¤)

# 5. æŸ¥çœ‹COWåçš„æ–‡ä»¶ä½ç½®
$ docker inspect test | grep UpperDir
"UpperDir": "/var/lib/docker/overlay2/xyz123.../diff"

# åŸå§‹æ–‡ä»¶ä»åœ¨åªè¯»å±‚
$ sudo find /var/lib/docker/overlay2 -name nginx.conf
/var/lib/docker/overlay2/abc.../diff/etc/nginx/nginx.conf  # åªè¯»å±‚(åŸå§‹)
/var/lib/docker/overlay2/xyz.../diff/etc/nginx/nginx.conf  # å¯å†™å±‚(ä¿®æ”¹å)
```

**COW æ€§èƒ½å½±å“**:
```bash
# æµ‹è¯•å¤§æ–‡ä»¶COWæ€§èƒ½
$ docker run -it --rm ubuntu:20.04 bash

# å®¹å™¨å†…åˆ›å»ºå¤§æ–‡ä»¶
root@container:/# dd if=/dev/zero of=/bigfile bs=1M count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 2.5 s, 419 MB/s

# ç¬¬ä¸€æ¬¡ä¿®æ”¹ï¼ˆè§¦å‘COWï¼Œéœ€è¦å¤åˆ¶æ•´ä¸ªæ–‡ä»¶ï¼‰
root@container:/# echo "modified" >> /bigfile
# é€Ÿåº¦è¾ƒæ…¢ï¼Œå› ä¸ºéœ€è¦å¤åˆ¶1GBæ–‡ä»¶

# ç¬¬äºŒæ¬¡ä¿®æ”¹ï¼ˆæ–‡ä»¶å·²åœ¨å¯å†™å±‚ï¼Œæ— éœ€COWï¼‰
root@container:/# echo "modified again" >> /bigfile
# é€Ÿåº¦å¾ˆå¿«
```

**ä¼˜åŒ–å»ºè®®**:
- é¿å…åœ¨å®¹å™¨å†…ä¿®æ”¹å¤§æ–‡ä»¶
- ä½¿ç”¨å·(Volume)å­˜å‚¨å¤§æ–‡ä»¶
- ä½¿ç”¨tmpfså­˜å‚¨ä¸´æ—¶å¤§æ–‡ä»¶

---

### 3.2 é•œåƒå­˜å‚¨ç»“æ„

#### 3.2.1 é•œåƒå…ƒæ•°æ®

**é•œåƒé…ç½®æ–‡ä»¶**:
```bash
# å¯¼å‡ºé•œåƒé…ç½®
$ docker save nginx:alpine -o nginx.tar
$ tar -xf nginx.tar
$ ls
abc123def456.json  # é•œåƒé…ç½®æ–‡ä»¶
def456ghi789/      # å±‚ç›®å½•
manifest.json      # æ¸…å•æ–‡ä»¶
repositories       # ä»“åº“ä¿¡æ¯

# æŸ¥çœ‹manifest.json
$ cat manifest.json | jq
[
  {
    "Config": "abc123def456.json",
    "RepoTags": ["nginx:alpine"],
    "Layers": [
      "def456ghi789/layer.tar",
      "ghi789jkl012/layer.tar",
      "jkl012mno345/layer.tar"
    ]
  }
]

# æŸ¥çœ‹é•œåƒé…ç½®
$ cat abc123def456.json | jq
{
  "architecture": "amd64",
  "config": {
    "Hostname": "",
    "Domainname": "",
    "User": "",
    "AttachStdin": false,
    "AttachStdout": false,
    "AttachStderr": false,
    "ExposedPorts": {
      "80/tcp": {}
    },
    "Tty": false,
    "OpenStdin": false,
    "StdinOnce": false,
    "Env": [
      "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
      "NGINX_VERSION=1.25.2"
    ],
    "Cmd": ["nginx", "-g", "daemon off;"],
    "Image": "sha256:...",
    "Volumes": null,
    "WorkingDir": "",
    "Entrypoint": ["/docker-entrypoint.sh"],
    "OnBuild": null,
    "Labels": {
      "maintainer": "NGINX Docker Maintainers"
    },
    "StopSignal": "SIGQUIT"
  },
  "container": "abc123...",
  "container_config": {...},
  "created": "2024-01-01T00:00:00.000000000Z",
  "docker_version": "24.0.5",
  "history": [
    {
      "created": "2024-01-01T00:00:00Z",
      "created_by": "/bin/sh -c #(nop) ADD file:abc123 in / "
    },
    {
      "created": "2024-01-01T00:00:01Z",
      "created_by": "/bin/sh -c #(nop)  ENV NGINX_VERSION=1.25.2",
      "empty_layer": true
    },
    ...
  ],
  "os": "linux",
  "rootfs": {
    "type": "layers",
    "diff_ids": [
      "sha256:def456...",
      "sha256:ghi789...",
      "sha256:jkl012..."
    ]
  }
}
```

---

#### 3.2.2 Content Addressable Storage (å†…å®¹å¯»å€å­˜å‚¨)

**åŸºäºå“ˆå¸Œçš„å­˜å‚¨**:
```
é•œåƒå±‚å­˜å‚¨ç»“æ„:
/var/lib/docker/
â”œâ”€â”€ image/
â”‚   â””â”€â”€ overlay2/
â”‚       â”œâ”€â”€ imagedb/              # é•œåƒæ•°æ®åº“
â”‚       â”‚   â””â”€â”€ content/
â”‚       â”‚       â””â”€â”€ sha256/
â”‚       â”‚           â””â”€â”€ abc123... # é•œåƒé…ç½®(JSON)
â”‚       â”œâ”€â”€ layerdb/              # å±‚æ•°æ®åº“
â”‚       â”‚   â””â”€â”€ sha256/
â”‚       â”‚       â”œâ”€â”€ def456.../    # å±‚å…ƒæ•°æ®
â”‚       â”‚       â”‚   â”œâ”€â”€ cache-id  # æŒ‡å‘å®é™…å­˜å‚¨
â”‚       â”‚       â”‚   â”œâ”€â”€ diff      # diff ID
â”‚       â”‚       â”‚   â”œâ”€â”€ size      # å±‚å¤§å°
â”‚       â”‚       â”‚   â””â”€â”€ tar-split.json.gz
â”‚       â”‚       â””â”€â”€ ghi789.../
â”‚       â””â”€â”€ repositories.json     # ä»“åº“ç´¢å¼•
â””â”€â”€ overlay2/                     # å®é™…å­˜å‚¨
    â”œâ”€â”€ <cache-id-1>/
    â”‚   â”œâ”€â”€ diff/                 # å±‚å†…å®¹
    â”‚   â”œâ”€â”€ link                  # çŸ­é“¾æ¥
    â”‚   â””â”€â”€ lower                 # çˆ¶å±‚é“¾æ¥
    â””â”€â”€ <cache-id-2>/
```

**æŸ¥çœ‹å±‚çš„cache-id**:
```bash
# è·å–é•œåƒID
$ docker images --no-trunc nginx:alpine
REPOSITORY   TAG      IMAGE ID                     CREATED      SIZE
nginx        alpine   sha256:abc123def456...       2 weeks ago  43.2MB

# æŸ¥çœ‹å±‚å…ƒæ•°æ®
$ sudo ls /var/lib/docker/image/overlay2/layerdb/sha256/
def456ghi789...
ghi789jkl012...

# æŸ¥çœ‹cache-idï¼ˆæŒ‡å‘å®é™…å­˜å‚¨ç›®å½•ï¼‰
$ sudo cat /var/lib/docker/image/overlay2/layerdb/sha256/def456.../cache-id
xyz789abc123  # è¿™æ˜¯/var/lib/docker/overlay2/xyz789abc123/çš„ç›®å½•

# æŸ¥çœ‹å±‚å¤§å°
$ sudo cat /var/lib/docker/image/overlay2/layerdb/sha256/def456.../size
8120320

# æŸ¥çœ‹diff ID
$ sudo cat /var/lib/docker/image/overlay2/layerdb/sha256/def456.../diff
sha256:original-uncompressed-diff-id...
```

---

### 3.3 é•œåƒåˆ†å‘åŸç†

#### 3.3.1 Docker Registry Protocol

**OCI Distribution Spec (é•œåƒåˆ†å‘åè®®)**:
```bash
# 1. æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨
$ curl -I https://registry-1.docker.io/v2/library/nginx/manifests/alpine
HTTP/1.1 200 OK
Docker-Content-Digest: sha256:abc123...
Content-Type: application/vnd.docker.distribution.manifest.v2+json

# 2. æ‹‰å–manifest
$ curl -H "Accept: application/vnd.docker.distribution.manifest.v2+json" \
    https://registry-1.docker.io/v2/library/nginx/manifests/alpine
{
  "schemaVersion": 2,
  "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
  "config": {
    "mediaType": "application/vnd.docker.container.image.v1+json",
    "size": 7510,
    "digest": "sha256:abc123..."
  },
  "layers": [
    {
      "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",
      "size": 3370234,
      "digest": "sha256:def456..."
    },
    {
      "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",
      "size": 8120320,
      "digest": "sha256:ghi789..."
    }
  ]
}

# 3. æ‹‰å–é•œåƒé…ç½®
$ curl https://registry-1.docker.io/v2/library/nginx/blobs/sha256:abc123...

# 4. æ‹‰å–æ¯ä¸€å±‚
$ curl https://registry-1.docker.io/v2/library/nginx/blobs/sha256:def456... \
    -o layer1.tar.gz
```

---

#### 3.3.2 é•œåƒæ‹‰å–æµç¨‹è¯¦è§£

**å®Œæ•´æ‹‰å–è¿‡ç¨‹**:
```bash
# å¼€å¯Docker daemonè°ƒè¯•æ¨¡å¼
$ sudo dockerd --debug &

# æ‹‰å–é•œåƒï¼ˆè§‚å¯Ÿè¯¦ç»†æ—¥å¿—ï¼‰
$ docker pull nginx:alpine
alpine: Pulling from library/nginx
01fd6df81c8e: Pull complete   # Layer 1
1e94b4f87af7: Pull complete   # Layer 2
d8c1c7c1c2b3: Pull complete   # Layer 3
...
Digest: sha256:abc123def456...
Status: Downloaded newer image for nginx:alpine
docker.io/library/nginx:alpine

# æ‹‰å–æµç¨‹åˆ†è§£:
# 1. è§£æé•œåƒå (nginx:alpine -> registry-1.docker.io/library/nginx:alpine)
# 2. è®¤è¯ (å¦‚æœéœ€è¦)
# 3. è·å–manifest
# 4. æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰ç›¸åŒdigestçš„å±‚
# 5. å¹¶å‘ä¸‹è½½ç¼ºå¤±çš„å±‚
# 6. è§£å‹å±‚åˆ°overlay2ç›®å½•
# 7. æ›´æ–°imagedbå’Œlayerdbå…ƒæ•°æ®
# 8. åˆ›å»ºé•œåƒæ ‡ç­¾

# æŸ¥çœ‹æ‹‰å–çš„å¹¶å‘æ•°ï¼ˆé»˜è®¤3ï¼‰
$ docker info | grep "Max concurrent downloads"
Max concurrent downloads: 3

# ä¿®æ”¹å¹¶å‘æ•°
# daemon.json
{
  "max-concurrent-downloads": 10
}
```

---

#### 3.3.3 é•œåƒæ¨é€æµç¨‹

**å®Œæ•´æ¨é€è¿‡ç¨‹**:
```bash
# 1. æ„å»ºé•œåƒ
$ docker build -t myregistry.com/myapp:v1.0 .

# 2. ç™»å½•ç§æœ‰ä»“åº“
$ docker login myregistry.com
Username: myuser
Password:
Login Succeeded

# 3. æ¨é€é•œåƒ
$ docker push myregistry.com/myapp:v1.0
The push refers to repository [myregistry.com/myapp]
abc123def456: Pushed    # Layer 1
def456ghi789: Pushed    # Layer 2
ghi789jkl012: Mounted   # Layer 3 (å·²å­˜åœ¨ï¼Œç›´æ¥æŒ‚è½½)
v1.0: digest: sha256:xyz789... size: 2345

# æ¨é€æµç¨‹:
# 1. æ£€æŸ¥ä»“åº“æ˜¯å¦å­˜åœ¨
# 2. æ£€æŸ¥æ¯ä¸€å±‚åœ¨ä»“åº“ä¸­æ˜¯å¦å·²å­˜åœ¨ (é€šè¿‡digest)
# 3. ä¸Šä¼ ç¼ºå¤±çš„å±‚ (æ”¯æŒæ–­ç‚¹ç»­ä¼ )
# 4. ä¸Šä¼ é•œåƒé…ç½®
# 5. ä¸Šä¼ manifest

# æŸ¥çœ‹æ¨é€å¹¶å‘æ•°
$ docker info | grep "Max concurrent uploads"
Max concurrent uploads: 5
```

---

### 3.4 é•œåƒä¼˜åŒ–æŠ€å·§

#### 3.4.1 å‡å°‘é•œåƒå±‚æ•°

**âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆå±‚æ•°è¿‡å¤šï¼‰**:
```dockerfile
FROM ubuntu:20.04
RUN apt-get update
RUN apt-get install -y nginx
RUN apt-get install -y curl
RUN apt-get install -y vim
RUN apt-get clean
# 6å±‚ï¼Œæ¯ä¸ªRUNåˆ›å»ºä¸€å±‚
```

**âœ… æ­£ç¡®ç¤ºä¾‹ï¼ˆåˆå¹¶å±‚ï¼‰**:
```dockerfile
FROM ubuntu:20.04
RUN apt-get update && \
    apt-get install -y nginx curl vim && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*
# 2å±‚ï¼ˆFROM + RUNï¼‰
```

---

#### 3.4.2 å‡å°‘é•œåƒå¤§å°

**æŠ€å·§1ï¼šä½¿ç”¨AlpineåŸºç¡€é•œåƒ**:
```bash
# UbuntuåŸºç¡€é•±åƒ
$ docker images ubuntu:20.04
REPOSITORY   TAG      SIZE
ubuntu       20.04    72.8MB

# AlpineåŸºç¡€é•œåƒ
$ docker images alpine:3.18
REPOSITORY   TAG      SIZE
alpine       3.18     7.34MB

# å¤§å°å¯¹æ¯”: Alpineæ¯”Ubuntuå°10å€
```

**æŠ€å·§2ï¼šæ¸…ç†ç¼“å­˜æ–‡ä»¶**:
```dockerfile
FROM ubuntu:20.04

# âŒ é”™è¯¯ï¼šç¼“å­˜æ–‡ä»¶ä¼šä¿ç•™åœ¨å±‚ä¸­
RUN apt-get update
RUN apt-get install -y nginx
RUN apt-get clean  # è¿™ä¸ªæ¸…ç†æ— æ•ˆï¼Œå› ä¸ºåœ¨æ–°çš„ä¸€å±‚

# âœ… æ­£ç¡®ï¼šåœ¨åŒä¸€å±‚ä¸­æ¸…ç†
RUN apt-get update && \
    apt-get install -y nginx && \
    rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
```

**æŠ€å·§3ï¼šå¤šé˜¶æ®µæ„å»º**:
```dockerfile
# âŒ å•é˜¶æ®µæ„å»ºï¼ˆåŒ…å«ç¼–è¯‘å·¥å…·ï¼Œé•œåƒå¤§ï¼‰
FROM golang:1.20
WORKDIR /app
COPY . .
RUN go build -o myapp
CMD ["./myapp"]
# é•œåƒå¤§å°: 1.2GB

# âœ… å¤šé˜¶æ®µæ„å»ºï¼ˆä»…åŒ…å«è¿è¡Œæ—¶ï¼‰
FROM golang:1.20 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp

FROM alpine:3.18
COPY --from=builder /app/myapp /usr/local/bin/
CMD ["myapp"]
# é•œåƒå¤§å°: 15MB (å‡å°‘80å€!)
```

---

#### 3.4.3 ä½¿ç”¨.dockerignore

```bash
# .dockerignoreæ–‡ä»¶
# Gitç›¸å…³
.git
.gitignore
.github

# æ–‡æ¡£
*.md
docs/

# æµ‹è¯•æ–‡ä»¶
*_test.go
test/
coverage/

# ç¼–è¯‘äº§ç‰©
*.o
*.so
*.exe
target/
build/

# ä¾èµ–ç¼“å­˜
node_modules/
vendor/
.cache/

# IDEé…ç½®
.vscode/
.idea/
*.swp

# ä¸´æ—¶æ–‡ä»¶
*.log
*.tmp
.DS_Store

# ç¯å¢ƒæ–‡ä»¶
.env
.env.local
```

---

#### 3.4.4 é•œåƒæ‰«æä¸å®‰å…¨

**ä½¿ç”¨docker scoutæ‰«ææ¼æ´**:
```bash
# æ‰«æé•œåƒ
$ docker scout cves nginx:alpine
    âœ“ SBOM of image already cached, 14 packages indexed
    âœ“ Detected 2 vulnerable packages

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Package            â”‚ Version           â”‚ Severity â”‚ CVE ID â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ libcrypto3         â”‚ 3.0.8-r0          â”‚ HIGH     â”‚CVE-...â”‚
â”‚ libssl3            â”‚ 3.0.8-r0          â”‚ HIGH     â”‚CVE-...â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# ä½¿ç”¨Trivyæ‰«æï¼ˆæ›´å¼ºå¤§ï¼‰
$ docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
    aquasec/trivy:latest image nginx:alpine

# æ‰«æç»“æœ
nginx:alpine (alpine 3.18.2)
===========================
Total: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 2, CRITICAL: 0)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Library    â”‚ Vulnerability  â”‚ Severity â”‚ Installed Version â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ libcrypto3   â”‚ CVE-2023-1234  â”‚   HIGH   â”‚ 3.0.8-r0          â”‚
â”‚ libssl3      â”‚ CVE-2023-1234  â”‚   HIGH   â”‚ 3.0.8-r0          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å°ç»“ï¼šç¬¬3ç« æ ¸å¿ƒçŸ¥è¯†ç‚¹

âœ… **å·²æŒæ¡å†…å®¹**ï¼š
1. **é•œåƒåˆ†å±‚**: UnionFSã€å†™æ—¶å¤åˆ¶(COW)ã€å±‚åˆå¹¶
2. **å­˜å‚¨ç»“æ„**: imagedbã€layerdbã€overlay2å®é™…å­˜å‚¨
3. **Content Addressable Storage**: åŸºäºå“ˆå¸Œçš„å»é‡å­˜å‚¨
4. **é•œåƒåˆ†å‘**: OCI Distribution Specã€æ‹‰å–/æ¨é€æµç¨‹
5. **é•œåƒä¼˜åŒ–**: å‡å°‘å±‚æ•°ã€ç¼©å°ä½“ç§¯ã€å¤šé˜¶æ®µæ„å»ºã€å®‰å…¨æ‰«æ

ğŸ¯ **å®æˆ˜èƒ½åŠ›**ï¼š
- ç†è§£COWæ€§èƒ½å½±å“å¹¶ä¼˜åŒ–
- æŸ¥çœ‹é•œåƒå±‚å’Œå…ƒæ•°æ®
- ä¼˜åŒ–Dockerfileå‡å°‘é•œåƒå¤§å°
- ä½¿ç”¨å®‰å…¨æ‰«æå·¥å…·

ğŸ“ **ä¸‹ä¸€ç« é¢„å‘Š**ï¼š
- Dockerç½‘ç»œæ¨¡å¼è¯¦è§£ (bridge/host/none/overlay)
- iptablesè§„åˆ™ä¸NATåŸç†
- è·¨ä¸»æœºå®¹å™¨é€šä¿¡
- ç½‘ç»œæ€§èƒ½ä¼˜åŒ–

---

## ç¬¬ 4 ç« ï¼šDocker ç½‘ç»œåŸç†ä¸å®ç°

### 4.1 Docker ç½‘ç»œæ¶æ„æ¦‚è§ˆ

#### 4.1.1 ç½‘ç»œæ¨¡å¼å¯¹æ¯”

**Docker å››ç§ç½‘ç»œæ¨¡å¼**ï¼š

| ç½‘ç»œæ¨¡å¼ | è¯´æ˜ | æ€§èƒ½ | éš”ç¦»æ€§ | é€‚ç”¨åœºæ™¯ | ç«¯å£æ˜ å°„ |
|---------|------|------|--------|---------|---------|
| **bridge** | æ¡¥æ¥æ¨¡å¼(é»˜è®¤) | ä¸­ç­‰ | é«˜ | å•æœºå®¹å™¨äº’é€š | æ”¯æŒ |
| **host** | ä¸»æœºæ¨¡å¼ | åŸç”Ÿ | æ—  | é«˜æ€§èƒ½éœ€æ±‚ | ä¸éœ€è¦ |
| **none** | æ— ç½‘ç»œ | - | å®Œå…¨éš”ç¦» | è‡ªå®šä¹‰ç½‘ç»œæ ˆ | ä¸æ”¯æŒ |
| **overlay** | è¦†ç›–ç½‘ç»œ | è¾ƒä½ | é«˜ | è·¨ä¸»æœºé€šä¿¡ | æ”¯æŒ |
| **macvlan** | MACåœ°å€è™šæ‹ŸåŒ– | é«˜ | ä¸­ | å®¹å™¨ç›´æ¥æ¥å…¥ç‰©ç†ç½‘ç»œ | ä¸éœ€è¦ |
| **container** | å…±äº«å®¹å™¨ç½‘ç»œ | åŸç”Ÿ | å…±äº« | Podå†…å®¹å™¨é€šä¿¡ | ç»§æ‰¿ |

---

### 4.2 Bridge ç½‘ç»œæ¨¡å¼æ·±åº¦è§£æ

#### 4.2.1 é»˜è®¤ docker0 ç½‘æ¡¥

**ç½‘æ¡¥æ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Host (å®¿ä¸»æœº)                       â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           docker0 (172.17.0.1/16)            â”‚  â”‚
â”‚  â”‚               Linux Bridge                   â”‚  â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜  â”‚
â”‚     â”‚            â”‚            â”‚             â”‚     â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â–¼â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”  â”‚
â”‚  â”‚veth0â”‚     â”‚veth1â”‚     â”‚veth2â”‚      â”‚veth3 â”‚  â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜     â””â”€â”€â”¬â”€â”€â”˜     â””â”€â”€â”¬â”€â”€â”˜      â””â”€â”€â”€â”¬â”€â”€â”˜  â”‚
â”‚     â”‚            â”‚            â”‚             â”‚     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â–¼â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”  â”‚
â”‚  â”‚ eth0â”‚     â”‚ eth0â”‚     â”‚ eth0â”‚      â”‚ eth0 â”‚  â”‚
â”‚  â”‚.17.2â”‚     â”‚.17.3â”‚     â”‚.17.4â”‚      â”‚.17.5 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚ Container1  Container2  Container3   Container4  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æŸ¥çœ‹docker0ç½‘æ¡¥**ï¼š
```bash
# æŸ¥çœ‹ç½‘æ¡¥ä¿¡æ¯
$ ip addr show docker0
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:01 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever

# æŸ¥çœ‹ç½‘æ¡¥ä¸Šçš„æ¥å£
$ brctl show docker0
bridge name     bridge id               STP enabled     interfaces
docker0         8000.0242ac110001       no              veth1a2b3c4
                                                        veth5d6e7f8
                                                        veth9g0h1i2

# æŸ¥çœ‹è·¯ç”±è¡¨
$ ip route
default via 192.168.1.1 dev eth0
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1
192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.100
```

---

#### 4.2.2 å®¹å™¨ç½‘ç»œé…ç½®è¿‡ç¨‹

**å®¹å™¨å¯åŠ¨ç½‘ç»œé…ç½®æµç¨‹**ï¼š
```bash
# 1. åˆ›å»ºå®¹å™¨
$ docker run -d --name nginx nginx:alpine

# 2. æŸ¥çœ‹å®¹å™¨ç½‘ç»œé…ç½®
$ docker inspect nginx -f '{{.NetworkSettings.IPAddress}}'
172.17.0.2

$ docker inspect nginx -f '{{.NetworkSettings.Gateway}}'
172.17.0.1

# 3. æŸ¥çœ‹veth pair
$ docker exec nginx ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536
    inet 127.0.0.1/8 scope host lo
12: eth0@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0

# å®¿ä¸»æœºç«¯çš„veth
$ ip link | grep -A 1 ^13:
13: veth1a2b3c4@if12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500
    link/ether 12:34:56:78:9a:bc brd ff:ff:ff:ff:ff:ff link-netnsid 0

# 4. æµ‹è¯•å®¹å™¨é—´é€šä¿¡
$ docker run -d --name redis redis:alpine
$ docker exec nginx ping -c 2 172.17.0.3
PING 172.17.0.3 (172.17.0.3): 56 data bytes
64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.123 ms
64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.098 ms
```

**ç½‘ç»œé…ç½®è¯¦ç»†æ­¥éª¤**ï¼š
1. åˆ›å»ºveth pairï¼ˆè™šæ‹Ÿç½‘å¡å¯¹ï¼‰
2. ä¸€ç«¯è¿æ¥åˆ°docker0ç½‘æ¡¥
3. å¦ä¸€ç«¯æ”¾å…¥å®¹å™¨çš„network namespace
4. åˆ†é…IPåœ°å€ï¼ˆä»docker0çš„å­ç½‘ä¸­ï¼‰
5. è®¾ç½®é»˜è®¤è·¯ç”±ï¼ˆç½‘å…³æŒ‡å‘docker0ï¼‰
6. é…ç½®iptablesè§„åˆ™ï¼ˆNAT/FORWARDï¼‰

---

#### 4.2.3 è‡ªå®šä¹‰ç½‘æ¡¥

**åˆ›å»ºè‡ªå®šä¹‰ç½‘æ¡¥**ï¼š
```bash
# åˆ›å»ºè‡ªå®šä¹‰ç½‘ç»œ
$ docker network create \
    --driver bridge \
    --subnet 172.20.0.0/16 \
    --gateway 172.20.0.1 \
    --opt "com.docker.network.bridge.name=br-custom" \
    my-network

# æŸ¥çœ‹ç½‘ç»œè¯¦æƒ…
$ docker network inspect my-network
[
    {
        "Name": "my-network",
        "Id": "abc123def456",
        "Scope": "local",
        "Driver": "bridge",
        "IPAM": {
            "Config": [
                {
                    "Subnet": "172.20.0.0/16",
                    "Gateway": "172.20.0.1"
                }
            ]
        },
        "Containers": {},
        "Options": {
            "com.docker.network.bridge.name": "br-custom"
        }
    }
]

# æŸ¥çœ‹è‡ªå®šä¹‰ç½‘æ¡¥
$ ip addr show br-custom
15: br-custom: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500
    inet 172.20.0.1/16 brd 172.20.255.255 scope global br-custom

# è¿æ¥å®¹å™¨åˆ°è‡ªå®šä¹‰ç½‘ç»œ
$ docker run -d --name app1 --network my-network nginx:alpine
$ docker run -d --name app2 --network my-network redis:alpine

# éªŒè¯DNSè§£æï¼ˆè‡ªå®šä¹‰ç½‘ç»œæ”¯æŒå®¹å™¨åè§£æï¼‰
$ docker exec app1 ping -c 2 app2
PING app2 (172.20.0.3): 56 data bytes
64 bytes from 172.20.0.3: seq=0 ttl=64 time=0.156 ms
```

**è‡ªå®šä¹‰ç½‘ç»œ vs é»˜è®¤ç½‘æ¡¥**ï¼š

| ç‰¹æ€§ | é»˜è®¤docker0 | è‡ªå®šä¹‰ç½‘æ¡¥ |
|-----|-----------|-----------|
| DNSè§£æ | âŒ ä¸æ”¯æŒå®¹å™¨å | âœ… æ”¯æŒå®¹å™¨å |
| ç½‘ç»œéš”ç¦» | âŒ æ‰€æœ‰å®¹å™¨å…±äº« | âœ… ç½‘ç»œé—´éš”ç¦» |
| åŠ¨æ€è¿æ¥ | âœ… æ”¯æŒ | âœ… æ”¯æŒ |
| IPèŒƒå›´ | å›ºå®š172.17.0.0/16 | âœ… è‡ªå®šä¹‰ |
| ç½‘æ¡¥é€‰é¡¹ | æœ‰é™ | âœ… ä¸°å¯Œé…ç½® |

---

### 4.3 iptables ä¸ NAT åŸç†

#### 4.3.1 iptables åŸºç¡€

**iptables å››è¡¨äº”é“¾**ï¼š

```
                   PREROUTING
                       â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                       â”‚
       è·¯ç”±åˆ¤æ–­              [DNATè½¬æ¢]
           â”‚                       â”‚
           â†“                       â†“
        INPUT                  FORWARD
           â”‚                       â”‚
      æœ¬æœºè¿›ç¨‹                    â†“
           â”‚                   OUTPUT
           â†“                       â”‚
        OUTPUT                     â†“
           â”‚                  POSTROUTING
           â†“                       â†“
      POSTROUTING              [SNATè½¬æ¢]
           â†“                       â†“
       å¤–å‡ºæ•°æ®åŒ…              è½¬å‘æ•°æ®åŒ…
```

**å››è¡¨**ï¼š
- **filter**: åŒ…è¿‡æ»¤ï¼ˆé˜²ç«å¢™ï¼‰
- **nat**: ç½‘ç»œåœ°å€è½¬æ¢
- **mangle**: åŒ…ä¿®æ”¹
- **raw**: çŠ¶æ€è·Ÿè¸ªè±å…

**äº”é“¾**ï¼š
- **PREROUTING**: æ•°æ®åŒ…è¿›å…¥æ—¶
- **INPUT**: è¿›å…¥æœ¬æœºçš„åŒ…
- **FORWARD**: è½¬å‘çš„åŒ…
- **OUTPUT**: æœ¬æœºå‘å‡ºçš„åŒ…
- **POSTROUTING**: æ•°æ®åŒ…ç¦»å¼€æ—¶

---

#### 4.3.2 Docker iptables è§„åˆ™è¯¦è§£

**æŸ¥çœ‹Dockeråˆ›å»ºçš„iptablesè§„åˆ™**ï¼š
```bash
# NATè¡¨è§„åˆ™
$ sudo iptables -t nat -L -n -v --line-numbers

Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source      destination
1     1234 567K  DOCKER     all  --  *      *       0.0.0.0/0   0.0.0.0/0   ADDRTYPE match dst-type LOCAL

Chain DOCKER (2 references)
num   pkts bytes target     prot opt in     out     source      destination
1       10  600  RETURN     all  --  docker0 *      0.0.0.0/0   0.0.0.0/0
2       50 3000  DNAT       tcp  --  !docker0 *     0.0.0.0/0   0.0.0.0/0   tcp dpt:8080 to:172.17.0.2:80

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source           destination
1      100 6000  MASQUERADE all  --  *      !docker0 172.17.0.0/16   0.0.0.0/0
2       20 1200  MASQUERADE tcp  --  *      *       172.17.0.2       172.17.0.2  tcp dpt:80

# Filterè¡¨è§„åˆ™
$ sudo iptables -t filter -L DOCKER -n -v --line-numbers

Chain DOCKER (1 references)
num   pkts bytes target     prot opt in     out     source      destination
1      150 9000  ACCEPT     tcp  --  !docker0 docker0 0.0.0.0/0   172.17.0.2  tcp dpt:80

Chain DOCKER-ISOLATION-STAGE-1 (1 references)
num   pkts bytes target     prot opt in     out     source      destination
1      500 30K   DOCKER-ISOLATION-STAGE-2  all  --  docker0 !docker0  0.0.0.0/0   0.0.0.0/0
2        0     0 RETURN     all  --  *      *       0.0.0.0/0   0.0.0.0/0

Chain DOCKER-ISOLATION-STAGE-2 (1 references)
num   pkts bytes target     prot opt in     out     source      destination
1        0     0 DROP       all  --  *      docker0  0.0.0.0/0   0.0.0.0/0
2      500 30K   RETURN     all  --  *      *       0.0.0.0/0   0.0.0.0/0
```

---

#### 4.3.3 ç«¯å£æ˜ å°„åŸç†ï¼ˆDNAT + SNATï¼‰

**ç«¯å£æ˜ å°„ç¤ºä¾‹**ï¼š
```bash
# å¯åŠ¨nginxå¹¶æ˜ å°„ç«¯å£
$ docker run -d -p 8080:80 --name nginx nginx:alpine

# æŸ¥çœ‹ç«¯å£æ˜ å°„
$ docker port nginx
80/tcp -> 0.0.0.0:8080

# æŸ¥çœ‹DNATè§„åˆ™ï¼ˆç›®æ ‡åœ°å€è½¬æ¢ï¼‰
$ sudo iptables -t nat -L DOCKER -n | grep 8080
DNAT  tcp  --  0.0.0.0/0  0.0.0.0/0  tcp dpt:8080 to:172.17.0.2:80

# æŸ¥çœ‹SNATè§„åˆ™ï¼ˆæºåœ°å€ä¼ªè£…ï¼‰
$ sudo iptables -t nat -L POSTROUTING -n | grep 172.17.0.2
MASQUERADE  tcp  --  172.17.0.2  172.17.0.2  tcp dpt:80
```

**ç«¯å£æ˜ å°„æµç¨‹**ï¼š
```
å¤–éƒ¨è¯·æ±‚: 192.168.1.100:8080 â†’ å®¿ä¸»æœº:8080
    â†“ [DNATè§„åˆ™]
è½¬æ¢å: 192.168.1.100:8080 â†’ 172.17.0.2:80 (å®¹å™¨)
    â†“ [å®¹å™¨å¤„ç†]
å“åº”: 172.17.0.2:80 â†’ 192.168.1.100:éšæœºç«¯å£
    â†“ [SNATè§„åˆ™ MASQUERADE]
è½¬æ¢å: å®¿ä¸»æœº:8080 â†’ 192.168.1.100:éšæœºç«¯å£
```

**æ‰‹åŠ¨éªŒè¯ç«¯å£æ˜ å°„**ï¼š
```bash
# 1. ä»å¤–éƒ¨è®¿é—®
$ curl http://192.168.1.100:8080
<!DOCTYPE html>
<html>
<head><title>Welcome to nginx!</title></head>
...

# 2. æŠ“åŒ…éªŒè¯DNAT
$ sudo tcpdump -i any -nn 'port 8080 or port 80' -c 10
# å¯ä»¥çœ‹åˆ°:
# å®¿ä¸»æœºeth0: 192.168.1.101:12345 â†’ 192.168.1.100:8080
# docker0: 192.168.1.101:12345 â†’ 172.17.0.2:80
# å®¹å™¨eth0: 192.168.1.101:12345 â†’ 172.17.0.2:80
```

---

#### 4.3.4 å®¹å™¨è®¿é—®å¤–ç½‘åŸç†ï¼ˆMASQUERADEï¼‰

**MASQUERADEï¼ˆåœ°å€ä¼ªè£…ï¼‰**ï¼š
```bash
# å®¹å™¨è®¿é—®å¤–ç½‘æµç¨‹
$ docker exec nginx ping -c 2 8.8.8.8

# iptablesè§„åˆ™
$ sudo iptables -t nat -L POSTROUTING -n
Chain POSTROUTING (policy ACCEPT)
target     prot opt source           destination
MASQUERADE all  --  172.17.0.0/16    0.0.0.0/0

# æµç¨‹:
# å®¹å™¨: 172.17.0.2:12345 â†’ 8.8.8.8:53
#   â†“ è·¯ç”±åˆ°docker0
# docker0: 172.17.0.2:12345 â†’ 8.8.8.8:53
#   â†“ POSTROUTINGé“¾
# MASQUERADE: 192.168.1.100:54321 â†’ 8.8.8.8:53 (æ›¿æ¢æºIPä¸ºå®¿ä¸»æœºIP)
#   â†“ å‡ºeth0
# å¤–ç½‘: 192.168.1.100:54321 â†’ 8.8.8.8:53
```

**éªŒè¯IPä¼ªè£…**ï¼š
```bash
# å®¹å™¨å†…æŸ¥çœ‹è®¿é—®å¤–ç½‘
$ docker exec nginx sh -c 'apk add curl && curl -s ifconfig.me'
192.168.1.100  # æ˜¾ç¤ºå®¿ä¸»æœºå…¬ç½‘IPï¼Œè€Œéå®¹å™¨IP

# æŸ¥çœ‹conntrackè¿æ¥è·Ÿè¸ª
$ sudo conntrack -L | grep 172.17.0.2
tcp  6 117 TIME_WAIT src=172.17.0.2 dst=8.8.8.8 sport=12345 dport=53 \
     src=8.8.8.8 dst=192.168.1.100 sport=53 dport=54321 [ASSURED]
```

---

### 4.4 Host ç½‘ç»œæ¨¡å¼

#### 4.4.1 Host æ¨¡å¼åŸç†

**Hostæ¨¡å¼æ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Host Network Stack         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  eth0: 192.168.1.100           â”‚ â”‚
â”‚  â”‚  lo: 127.0.0.1                 â”‚ â”‚
â”‚  â”‚  docker0: 172.17.0.1           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â†‘                          â”‚
â”‚           â”‚ (å…±äº«)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Container (Host Network)      â”‚ â”‚
â”‚  â”‚  - æ— ç‹¬ç«‹ç½‘ç»œå‘½åç©ºé—´           â”‚ â”‚
â”‚  â”‚  - ç›´æ¥ä½¿ç”¨å®¿ä¸»æœºç½‘ç»œæ ˆ         â”‚ â”‚
â”‚  â”‚  - æ— éœ€NAT/ç«¯å£æ˜ å°„             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä½¿ç”¨Hostæ¨¡å¼**ï¼š
```bash
# å¯åŠ¨Hostæ¨¡å¼å®¹å™¨
$ docker run -d --name nginx-host --network host nginx:alpine

# å®¹å™¨å†…æŸ¥çœ‹ç½‘ç»œ
$ docker exec nginx-host ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536
    inet 127.0.0.1/8 scope host lo
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500
    inet 192.168.1.100/24 brd 192.168.1.255 scope global eth0
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0

# å®Œå…¨ç›¸åŒï¼å®¹å™¨ä¸å®¿ä¸»æœºå…±äº«ç½‘ç»œæ ˆ

# å®¹å™¨ç›´æ¥ç›‘å¬å®¿ä¸»æœºç«¯å£
$ docker run -d --network host nginx:alpine
$ curl http://localhost:80  # ç›´æ¥è®¿é—®ï¼Œæ— éœ€ç«¯å£æ˜ å°„
```

---

#### 4.4.2 Host æ¨¡å¼æ€§èƒ½å¯¹æ¯”

**æ€§èƒ½åŸºå‡†æµ‹è¯•**ï¼š
```bash
# æµ‹è¯•è„šæœ¬
#!/bin/bash

# Bridgeæ¨¡å¼ï¼ˆå¸¦NATï¼‰
docker run -d --name nginx-bridge -p 8080:80 nginx:alpine
ab -n 10000 -c 100 http://localhost:8080/ > bridge.txt

# Hostæ¨¡å¼ï¼ˆæ— NATï¼‰
docker run -d --name nginx-host --network host nginx:alpine
ab -n 10000 -c 100 http://localhost:80/ > host.txt

# æ€§èƒ½å¯¹æ¯”
echo "Bridgeæ¨¡å¼:"
grep "Requests per second" bridge.txt
echo "Hostæ¨¡å¼:"
grep "Requests per second" host.txt
```

**å…¸å‹æ€§èƒ½æ•°æ®**ï¼š

| ç½‘ç»œæ¨¡å¼ | QPS | å»¶è¿Ÿ(P50) | å»¶è¿Ÿ(P99) | CPUå¼€é”€ |
|---------|-----|----------|----------|---------|
| **Bridge** | 25,000 | 4ms | 12ms | 15% |
| **Host** | 45,000 | 2ms | 6ms | 8% |
| **æ€§èƒ½æå‡** | +80% | -50% | -50% | -47% |

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… é«˜æ€§èƒ½è¦æ±‚ï¼ˆæ•°æ®åº“ã€ç¼“å­˜ï¼‰
- âœ… éœ€è¦ä½å»¶è¿Ÿ
- âœ… å¯ä¿¡ç¯å¢ƒï¼ˆæ— éœ€ç½‘ç»œéš”ç¦»ï¼‰
- âŒ å¤šç§Ÿæˆ·ç¯å¢ƒï¼ˆå®‰å…¨é£é™©ï¼‰
- âŒ ç«¯å£å†²çªé£é™©

---

### 4.5 è‡ªå®šä¹‰ç½‘ç»œå®æˆ˜

#### 4.5.1 å¤šå®¹å™¨é€šä¿¡æ¶æ„

**ä¸‰å±‚ç½‘ç»œæ¶æ„**ï¼š
```bash
# 1. åˆ›å»ºå‰ç«¯ç½‘ç»œ
$ docker network create \
    --driver bridge \
    --subnet 172.25.0.0/16 \
    frontend

# 2. åˆ›å»ºåç«¯ç½‘ç»œ
$ docker network create \
    --driver bridge \
    --subnet 172.26.0.0/16 \
    backend

# 3. åˆ›å»ºæ•°æ®åº“ç½‘ç»œ
$ docker network create \
    --driver bridge \
    --subnet 172.27.0.0/16 \
    database

# 4. å¯åŠ¨å®¹å™¨å¹¶è¿æ¥åˆ°ç›¸åº”ç½‘ç»œ
# WebæœåŠ¡å™¨ï¼ˆè¿æ¥å‰ç«¯å’Œåç«¯ï¼‰
$ docker run -d --name web \
    --network frontend \
    nginx:alpine

$ docker network connect backend web

# åº”ç”¨æœåŠ¡å™¨ï¼ˆè¿æ¥åç«¯å’Œæ•°æ®åº“ï¼‰
$ docker run -d --name app \
    --network backend \
    myapp:latest

$ docker network connect database app

# æ•°æ®åº“ï¼ˆä»…è¿æ¥æ•°æ®åº“ç½‘ç»œï¼‰
$ docker run -d --name db \
    --network database \
    postgres:alpine

# 5. éªŒè¯ç½‘ç»œéš”ç¦»
$ docker exec web ping -c 1 app  # âœ… å¯ä»¥é€šä¿¡ï¼ˆéƒ½åœ¨backendï¼‰
$ docker exec web ping -c 1 db   # âŒ æ— æ³•é€šä¿¡ï¼ˆä¸åœ¨åŒä¸€ç½‘ç»œï¼‰
$ docker exec app ping -c 1 db   # âœ… å¯ä»¥é€šä¿¡ï¼ˆéƒ½åœ¨databaseï¼‰
```

**ç½‘ç»œæ‹“æ‰‘å›¾**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   frontend                          â”‚
â”‚                  172.25.0.0/16                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚  web (nginx)   â”‚                     â”‚
â”‚              â”‚  172.25.0.2    â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   backend                           â”‚
â”‚                  172.26.0.0/16                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚  web (nginx)   â”‚                     â”‚
â”‚              â”‚  172.26.0.2    â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚   app (API)    â”‚                     â”‚
â”‚              â”‚  172.26.0.3    â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   database                          â”‚
â”‚                  172.27.0.0/16                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚   app (API)    â”‚                     â”‚
â”‚              â”‚  172.27.0.2    â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚  db (postgres) â”‚                     â”‚
â”‚              â”‚  172.27.0.3    â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 4.5.2 ç½‘ç»œåˆ«åä¸æœåŠ¡å‘ç°

**ä½¿ç”¨ç½‘ç»œåˆ«å**ï¼š
```bash
# åˆ›å»ºç½‘ç»œ
$ docker network create app-network

# å¯åŠ¨å¤šä¸ªç›¸åŒæœåŠ¡å®ä¾‹ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
$ docker run -d --name api1 \
    --network app-network \
    --network-alias api \
    myapi:latest

$ docker run -d --name api2 \
    --network app-network \
    --network-alias api \
    myapi:latest

$ docker run -d --name api3 \
    --network app-network \
    --network-alias api \
    myapi:latest

# å®¢æˆ·ç«¯å®¹å™¨
$ docker run -it --name client \
    --network app-network \
    alpine sh

# å®¹å™¨å†…DNSæŸ¥è¯¢ï¼ˆè½®è¯¢è´Ÿè½½å‡è¡¡ï¼‰
$ nslookup api
Name:      api
Address 1: 172.28.0.2 api1.app-network
Address 2: 172.28.0.3 api2.app-network
Address 3: 172.28.0.4 api3.app-network

# æµ‹è¯•è´Ÿè½½å‡è¡¡
$ for i in {1..6}; do
    wget -qO- http://api:8080/hostname
    echo
done
# è¾“å‡º:
# api1
# api2
# api3
# api1
# api2
# api3
```

---

### 4.6 è·¨ä¸»æœºå®¹å™¨é€šä¿¡ (Overlay ç½‘ç»œ)

#### 4.6.1 Overlay ç½‘ç»œåŸç†

**Overlayç½‘ç»œæ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç‰©ç†ç½‘ç»œ                          â”‚
â”‚           192.168.1.0/24                           â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Host1       â”‚              â”‚  Host2       â”‚  â”‚
â”‚  â”‚192.168.1.10  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚192.168.1.20  â”‚  â”‚
â”‚  â”‚              â”‚   VXLAN      â”‚              â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   Tunnel     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚Overlay â”‚  â”‚              â”‚  â”‚Overlay â”‚  â”‚  â”‚
â”‚  â”‚  â”‚Network â”‚  â”‚              â”‚  â”‚Network â”‚  â”‚  â”‚
â”‚  â”‚  â”‚10.0.0.0â”‚  â”‚              â”‚  â”‚10.0.0.0â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚      â”‚       â”‚              â”‚      â”‚       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”‚              â”‚  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚ app1  â”‚   â”‚              â”‚  â”‚ app2  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚10.0.0.2â”‚  â”‚              â”‚  â”‚10.0.0.3â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**VXLANå°è£…**ï¼š
```
åŸå§‹æ•°æ®åŒ…:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ Src:10.0.0.2 â”‚ Dst:10.0.0.3 â”‚ Data â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

VXLANå°è£…å:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Outer IP: 192.168.1.10 â†’ 192.168.1.20         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ VXLAN Header: VNI=256                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Inner IP: 10.0.0.2 â†’ 10.0.0.3                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 4.6.2 Docker Swarm Overlay ç½‘ç»œå®æˆ˜

**åˆ›å»ºSwarmé›†ç¾¤**ï¼š
```bash
# èŠ‚ç‚¹1ï¼ˆManagerï¼‰
$ docker swarm init --advertise-addr 192.168.1.10
Swarm initialized: current node (abc123) is now a manager.
To add a worker to this swarm, run the following command:
    docker swarm join --token SWMTKN-1-xxx 192.168.1.10:2377

# èŠ‚ç‚¹2ï¼ˆWorkerï¼‰
$ docker swarm join --token SWMTKN-1-xxx 192.168.1.10:2377
This node joined a swarm as a worker.

# æŸ¥çœ‹èŠ‚ç‚¹
$ docker node ls
ID            HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
abc123 *      node1     Ready   Active        Leader
def456        node2     Ready   Active
```

**åˆ›å»ºOverlayç½‘ç»œ**ï¼š
```bash
# åˆ›å»ºoverlayç½‘ç»œ
$ docker network create \
    --driver overlay \
    --subnet 10.0.0.0/24 \
    --attachable \
    my-overlay

# æŸ¥çœ‹ç½‘ç»œ
$ docker network ls | grep overlay
abc123def456  my-overlay  overlay   swarm

# åœ¨èŠ‚ç‚¹1å¯åŠ¨æœåŠ¡
$ docker service create \
    --name web \
    --network my-overlay \
    --replicas 2 \
    nginx:alpine

# åœ¨èŠ‚ç‚¹2å¯åŠ¨æœåŠ¡
$ docker service create \
    --name api \
    --network my-overlay \
    --replicas 2 \
    myapi:latest

# éªŒè¯è·¨ä¸»æœºé€šä¿¡
$ docker exec <web-container-id> ping api
PING api (10.0.0.3): 56 data bytes
64 bytes from 10.0.0.3: seq=0 ttl=64 time=0.456 ms
```

---

### 4.7 ç½‘ç»œæ€§èƒ½ä¼˜åŒ–

#### 4.7.1 ç¦ç”¨ userland-proxy

**userland-proxy é—®é¢˜**ï¼š
```bash
# æŸ¥çœ‹userland-proxyè¿›ç¨‹
$ ps aux | grep docker-proxy
root  12345  /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8080 -container-ip 172.17.0.2 -container-port 80

# é—®é¢˜ï¼š
# 1. æ¯ä¸ªç«¯å£æ˜ å°„åˆ›å»ºä¸€ä¸ªè¿›ç¨‹ï¼ˆèµ„æºå¼€é”€ï¼‰
# 2. æ•°æ®ç»è¿‡ç”¨æˆ·æ€ä»£ç†ï¼ˆæ€§èƒ½æŸè€—ï¼‰
# 3. 100ä¸ªå®¹å™¨ x 5ä¸ªç«¯å£ = 500ä¸ªè¿›ç¨‹
```

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
```json
// daemon.json
{
  "userland-proxy": false,
  "iptables": true
}
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
```bash
# æµ‹è¯•è„šæœ¬
#!/bin/bash

# æµ‹è¯•userland-proxyå¼€å¯
docker run -d -p 8080:80 --name test1 nginx:alpine
ab -n 100000 -c 1000 http://localhost:8080/ | grep "Requests per second"

# æµ‹è¯•userland-proxyå…³é—­
# ä¿®æ”¹daemon.jsonåé‡å¯docker
docker run -d -p 8080:80 --name test2 nginx:alpine
ab -n 100000 -c 1000 http://localhost:8080/ | grep "Requests per second"
```

| é…ç½® | QPS | CPUä½¿ç”¨ | å†…å­˜ä½¿ç”¨ |
|------|-----|---------|---------|
| userland-proxy=true | 32,000 | 45% | 250MB |
| userland-proxy=false | 48,000 | 28% | 150MB |
| **æ€§èƒ½æå‡** | +50% | -38% | -40% |

---

#### 4.7.2 è°ƒæ•´ MTU

**MTU ä¼˜åŒ–**ï¼š
```bash
# æŸ¥çœ‹å½“å‰MTU
$ docker network inspect bridge -f '{{.Options.com.docker.network.driver.mtu}}'
1500

# åˆ›å»ºå¤§MTUç½‘ç»œï¼ˆé€‚åˆå†…ç½‘ï¼‰
$ docker network create \
    --driver bridge \
    --opt com.docker.network.driver.mtu=9000 \
    jumbo-network

# æ€§èƒ½æµ‹è¯•
# æ ‡å‡†MTU 1500
$ docker run --rm --network bridge \
    nicolaka/netshoot \
    iperf3 -c target-host -t 30

# å·¨å‹MTU 9000
$ docker run --rm --network jumbo-network \
    nicolaka/netshoot \
    iperf3 -c target-host -t 30
```

**MTUå¯¹æ¯”**ï¼š

| MTU | ååé‡ | CPUä½¿ç”¨ | é€‚ç”¨åœºæ™¯ |
|-----|--------|---------|---------|
| 1500 | 8 Gbps | 85% | å…¬ç½‘/é»˜è®¤ |
| 9000 | 12 Gbps | 55% | å†…ç½‘/æ•°æ®ä¸­å¿ƒ |

---

#### 4.7.3 ä½¿ç”¨ macvlan ç›´è¿ç‰©ç†ç½‘ç»œ

**macvlan æ¨¡å¼**ï¼š
```bash
# åˆ›å»ºmacvlanç½‘ç»œ
$ docker network create -d macvlan \
    --subnet=192.168.1.0/24 \
    --gateway=192.168.1.1 \
    -o parent=eth0 \
    macvlan-net

# å¯åŠ¨å®¹å™¨ï¼ˆç›´æ¥è·å¾—ç‰©ç†ç½‘ç»œIPï¼‰
$ docker run -d --name web \
    --network macvlan-net \
    --ip 192.168.1.100 \
    nginx:alpine

# å®¹å™¨IPåœ¨ç‰©ç†ç½‘ç»œä¸­å¯ç›´æ¥è®¿é—®
$ ping 192.168.1.100  # ä»å…¶ä»–ç‰©ç†æœº
PING 192.168.1.100 (192.168.1.100) 56(84) bytes of data.
64 bytes from 192.168.1.100: icmp_seq=1 ttl=64 time=0.234 ms
```

**macvlan vs bridge æ€§èƒ½**ï¼š

| ç½‘ç»œæ¨¡å¼ | ååé‡ | å»¶è¿Ÿ | NATå¼€é”€ | é€‚ç”¨åœºæ™¯ |
|---------|--------|------|---------|---------|
| **bridge** | 8 Gbps | 0.5ms | æœ‰ | é€šç”¨ |
| **macvlan** | 10 Gbps | 0.1ms | æ—  | é«˜æ€§èƒ½/é—ç•™åº”ç”¨ |

---

## å°ç»“ï¼šç¬¬4ç« æ ¸å¿ƒçŸ¥è¯†ç‚¹

âœ… **å·²æŒæ¡å†…å®¹**ï¼š
1. **ç½‘ç»œæ¨¡å¼**: bridge/host/none/overlay/macvlanäº”ç§æ¨¡å¼å¯¹æ¯”
2. **bridgeåŸç†**: docker0ç½‘æ¡¥ã€veth pairã€å®¹å™¨ç½‘ç»œé…ç½®æµç¨‹
3. **iptables**: å››è¡¨äº”é“¾ã€DNAT/SNATã€ç«¯å£æ˜ å°„åŸç†
4. **è‡ªå®šä¹‰ç½‘ç»œ**: DNSè§£æã€ç½‘ç»œéš”ç¦»ã€æœåŠ¡å‘ç°
5. **overlayç½‘ç»œ**: VXLANå°è£…ã€è·¨ä¸»æœºé€šä¿¡ã€Swarmé›†æˆ
6. **æ€§èƒ½ä¼˜åŒ–**: ç¦ç”¨userland-proxyã€MTUè°ƒæ•´ã€macvlanç›´è¿

ğŸ¯ **å®æˆ˜èƒ½åŠ›**ï¼š
- ç†è§£ç«¯å£æ˜ å°„å®Œæ•´æµç¨‹(DNAT+SNAT)
- è®¾è®¡å¤šå±‚ç½‘ç»œæ¶æ„(å‰ç«¯/åç«¯/æ•°æ®åº“éš”ç¦»)
- é…ç½®è·¨ä¸»æœºå®¹å™¨é€šä¿¡
- ä¼˜åŒ–ç½‘ç»œæ€§èƒ½(+50% QPS)

---

## ç¬¬ 5 ç« ï¼šèµ„æºéš”ç¦»ä¸é™åˆ¶è¿›é˜¶

### 5.1 CPU èµ„æºç®¡ç†è¿›é˜¶

#### 5.1.1 CPU å®Œå…¨å…¬å¹³è°ƒåº¦å™¨ (CFS)

**CFS è°ƒåº¦åŸç†**ï¼š
```
CPUæ—¶é—´åˆ†é…:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CPUè°ƒåº¦å‘¨æœŸ (100ms)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Container1â”‚Container2â”‚Container3â”‚   â”‚
â”‚  â”‚ shares   â”‚ shares   â”‚ shares   â”‚   â”‚
â”‚  â”‚  1024    â”‚  2048    â”‚  512     â”‚   â”‚
â”‚  â”‚  (28%)   â”‚  (57%)   â”‚  (14%)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚â—„â”€28msâ”€â”€â–ºâ”‚â—„â”€â”€57msâ”€â”€â–ºâ”‚â—„â”€14msâ”€â”€â–ºâ”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è®¡ç®—å…¬å¼:
Container1 CPU% = 1024 / (1024+2048+512) Ã— 100% = 28.6%
Container2 CPU% = 2048 / (1024+2048+512) Ã— 100% = 57.1%
Container3 CPU% = 512 / (1024+2048+512) Ã— 100% = 14.3%
```

**CPU shares å®æˆ˜**ï¼š
```bash
# åˆ›å»º3ä¸ªå®¹å™¨ï¼ŒCPUæƒé‡ 2:1:1
$ docker run -d --name cpu-high --cpu-shares 2048 \
    progrium/stress --cpu 4

$ docker run -d --name cpu-mid --cpu-shares 1024 \
    progrium/stress --cpu 4

$ docker run -d --name cpu-low --cpu-shares 1024 \
    progrium/stress --cpu 4

# å®æ—¶ç›‘æ§CPUä½¿ç”¨
$ docker stats --no-stream
CONTAINER   CPU %     MEM USAGE / LIMIT
cpu-high    50.0%     ...               # è·å¾— 2/4 = 50%
cpu-mid     25.0%     ...               # è·å¾— 1/4 = 25%
cpu-low     25.0%     ...               # è·å¾— 1/4 = 25%

# æŸ¥çœ‹cgroupé…ç½®
$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.shares
2048
```

---

#### 5.1.2 CPU é…é¢ä¸å‘¨æœŸ

**CFS é…é¢æœºåˆ¶**ï¼š
```bash
# é™åˆ¶å®¹å™¨ä½¿ç”¨0.5ä¸ªCPUæ ¸å¿ƒ
$ docker run -d --name limited \
    --cpu-period=100000 \
    --cpu-quota=50000 \
    stress --cpu 8

# è§£é‡Š:
# cpu-period: è°ƒåº¦å‘¨æœŸï¼ˆå¾®ç§’ï¼‰ï¼Œé»˜è®¤100000us = 100ms
# cpu-quota: å‘¨æœŸå†…å¯ç”¨CPUæ—¶é—´ï¼ˆå¾®ç§’ï¼‰ï¼Œ50000us = 50ms
# ç»“æœ: 50ms / 100ms = 0.5 CPU

# ç­‰ä»·äº:
$ docker run -d --cpus="0.5" stress --cpu 8

# æŸ¥çœ‹cgroupé…ç½®
$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.cfs_period_us
100000

$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.cfs_quota_us
50000

# CPUèŠ‚æµç»Ÿè®¡
$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.stat
nr_periods 12345         # æ€»å‘¨æœŸæ•°
nr_throttled 6789        # è¢«èŠ‚æµçš„å‘¨æœŸæ•°
throttled_time 456789000 # è¢«èŠ‚æµçš„æ€»æ—¶é—´(çº³ç§’)
```

---

#### 5.1.3 å®æ—¶è¿›ç¨‹ä¼˜å…ˆçº§

**CPU RTï¼ˆReal-Timeï¼‰è°ƒåº¦**ï¼š
```bash
# é…ç½®å®æ—¶CPUè°ƒåº¦ï¼ˆéœ€è¦å†…æ ¸æ”¯æŒCONFIG_RT_GROUP_SCHEDï¼‰
$ docker run -d --name rt-container \
    --cpu-rt-runtime=950000 \
    --cpu-rt-period=1000000 \
    myapp:latest

# è§£é‡Š:
# æ¯1000000us(1ç§’)å†…ï¼Œæœ€å¤šä½¿ç”¨950000us(0.95ç§’)çš„å®æ—¶CPU
# é¢„ç•™50000usç»™ç³»ç»Ÿè¿›ç¨‹

# æŸ¥çœ‹RTé…ç½®
$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.rt_runtime_us
950000

$ cat /sys/fs/cgroup/cpu/docker/<container-id>/cpu.rt_period_us
1000000
```

---

### 5.2 å†…å­˜ç®¡ç†è¿›é˜¶

#### 5.2.1 å†…å­˜ Cgroup å­ç³»ç»Ÿè¯¦è§£

**å†…å­˜ç»Ÿè®¡æ–‡ä»¶**ï¼š
```bash
# æŸ¥çœ‹å†…å­˜è¯¦ç»†ç»Ÿè®¡
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.stat

cache 104857600           # é¡µç¼“å­˜ï¼ˆ100MBï¼‰
rss 209715200            # å¸¸é©»å†…å­˜ï¼ˆ200MBï¼‰
rss_huge 0               # å¤§é¡µå†…å­˜
mapped_file 52428800     # æ˜ å°„æ–‡ä»¶ï¼ˆ50MBï¼‰
pgpgin 123456            # é¡µé¢æ¢å…¥æ¬¡æ•°
pgpgout 234567           # é¡µé¢æ¢å‡ºæ¬¡æ•°
swap 0                   # ä½¿ç”¨çš„swap
pgfault 345678           # é¡µé”™è¯¯æ¬¡æ•°
pgmajfault 12345         # ä¸»è¦é¡µé”™è¯¯ï¼ˆéœ€è¦ç£ç›˜I/Oï¼‰
inactive_anon 0          # éæ´»è·ƒåŒ¿åé¡µ
active_anon 209715200    # æ´»è·ƒåŒ¿åé¡µ
inactive_file 52428800   # éæ´»è·ƒæ–‡ä»¶é¡µ
active_file 52428800     # æ´»è·ƒæ–‡ä»¶é¡µ
unevictable 0            # ä¸å¯å›æ”¶é¡µ

# å®æ—¶å†…å­˜ä½¿ç”¨
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.usage_in_bytes
314572800  # çº¦300MB

# å†…å­˜é™åˆ¶
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.limit_in_bytes
536870912  # 512MB

# å†…å­˜å‹åŠ›
$ cat /sys/fs/cgroup/memory/docker/<container-id>/memory.pressure_level
low  # low/medium/critical
```

---

#### 5.2.2 å†…å­˜è½¯é™åˆ¶ä¸ç¡¬é™åˆ¶

**ä¸¤å±‚é™åˆ¶æœºåˆ¶**ï¼š
```bash
# è½¯é™åˆ¶(reservation) + ç¡¬é™åˆ¶(limit)
$ docker run -d --name mem-limits \
    --memory=1g \              # ç¡¬é™åˆ¶ï¼š1GB
    --memory-reservation=512m \  # è½¯é™åˆ¶ï¼š512MB
    --memory-swap=2g \         # æ€»å†…å­˜+swap: 2GB
    --kernel-memory=100m \     # å†…æ ¸å†…å­˜é™åˆ¶
    myapp:latest

# è¡Œä¸ºè¯´æ˜:
# 1. æ­£å¸¸æƒ…å†µ: ä½¿ç”¨<=512MB (åœ¨è½¯é™åˆ¶å†…)
# 2. å†…å­˜å‹åŠ›: å¯ä»¥ä½¿ç”¨512MB-1GB (è¶…å‡ºè½¯é™åˆ¶ï¼Œä½†åœ¨ç¡¬é™åˆ¶å†…)
# 3. è¾¾åˆ°1GB: è§¦å‘OOM killer
# 4. swapä½¿ç”¨: æœ€å¤š2GB-1GB=1GBçš„swap

# æŸ¥çœ‹é…ç½®
$ docker inspect mem-limits -f '{{.HostConfig.Memory}}'
1073741824  # 1GB

$ docker inspect mem-limits -f '{{.HostConfig.MemoryReservation}}'
536870912  # 512MB

$ docker inspect mem-limits -f '{{.HostConfig.MemorySwap}}'
2147483648  # 2GB
```

---

#### 5.2.3 OOM Killer æ·±åº¦æ§åˆ¶

**OOMä¼˜å…ˆçº§è°ƒæ•´**ï¼š
```bash
# OOM scoreè¶Šé«˜ï¼Œè¶Šå®¹æ˜“è¢«æ€æ­»ï¼ˆ-1000åˆ°1000ï¼‰
$ docker run -d --name protected-app \
    --oom-score-adj=-500 \
    --memory=512m \
    important-app:latest

$ docker run -d --name expendable-app \
    --oom-score-adj=500 \
    --memory=512m \
    cache-service:latest

# æŸ¥çœ‹OOM score
$ cat /proc/$(docker inspect -f '{{.State.Pid}}' protected-app)/oom_score
150  # å®é™…score = åŸºç¡€score + oom_score_adj

$ cat /proc/$(docker inspect -f '{{.State.Pid}}' expendable-app)/oom_score
1150

# OOMäº‹ä»¶ç›‘æ§
$ sudo dmesg | grep -i "killed process"
[12345.678] Out of memory: Killed process 54321 (expendable-app) \
            total-vm:524288kB, anon-rss:524288kB, file-rss:0kB

# ç¦ç”¨OOM killerï¼ˆå±é™©ï¼å®¹å™¨ä¼šæŒ‚èµ·è€Œéè¢«æ€æ­»ï¼‰
$ docker run -d --name no-oom \
    --oom-kill-disable \
    --memory=512m \
    myapp:latest
```

---

### 5.3 Block I/O é™åˆ¶è¿›é˜¶

#### 5.3.1 I/O æƒé‡ä¸ä¼˜å…ˆçº§

**I/Oè°ƒåº¦å™¨é…ç½®**ï¼š
```bash
# æŸ¥çœ‹ç£ç›˜I/Oè°ƒåº¦å™¨
$ cat /sys/block/sda/queue/scheduler
noop deadline [cfq]  # cfqæ”¯æŒæƒé‡ï¼Œå…¶ä»–ä¸æ”¯æŒ

# è®¾ç½®I/Oæƒé‡ï¼ˆ100-1000ï¼Œé»˜è®¤500ï¼‰
$ docker run -d --name io-high \
    --blkio-weight 800 \
    myapp:latest

$ docker run -d --name io-low \
    --blkio-weight 200 \
    myapp:latest

# éªŒè¯é…ç½®
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.weight
800

# é’ˆå¯¹ç‰¹å®šè®¾å¤‡è®¾ç½®æƒé‡
$ docker run -d --name io-custom \
    --blkio-weight-device /dev/sda:600 \
    --blkio-weight-device /dev/sdb:400 \
    myapp:latest
```

---

#### 5.3.2 I/O é€Ÿç‡ç²¾ç¡®æ§åˆ¶

**IOPS å’Œå¸¦å®½åŒé‡é™åˆ¶**ï¼š
```bash
# é™åˆ¶è¯»å†™IOPSå’Œå¸¦å®½
$ docker run -d --name io-limited \
    --device-read-iops /dev/sda:100 \    # è¯»IOPS: 100
    --device-write-iops /dev/sda:50 \    # å†™IOPS: 50
    --device-read-bps /dev/sda:10mb \    # è¯»å¸¦å®½: 10MB/s
    --device-write-bps /dev/sda:5mb \    # å†™å¸¦å®½: 5MB/s
    myapp:latest

# æŸ¥çœ‹é…ç½®
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.throttle.read_iops_device
8:0 100  # ä¸»è®¾å¤‡å·8ï¼Œæ¬¡è®¾å¤‡å·0ï¼ˆsdaï¼‰

$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.throttle.read_bps_device
8:0 10485760  # 10MB

# æµ‹è¯•I/Oé™åˆ¶
$ docker exec io-limited sh -c '
    dd if=/dev/zero of=/test bs=1M count=100 oflag=direct
'
100+0 records in
100+0 records out
104857600 bytes (105 MB) copied, 20.0 s, 5.2 MB/s  # ç¬¦åˆ5MB/sé™åˆ¶

# å®æ—¶ç›‘æ§I/O
$ docker stats io-limited --no-stream
CONTAINER    BLOCK I/O
io-limited   5.24MB / 2.61MB  # è¯»/å†™é€Ÿç‡
```

---

#### 5.3.3 I/O æ€§èƒ½åˆ†æ

**blkio.throttleç»Ÿè®¡**ï¼š
```bash
# I/Oæ“ä½œç»Ÿè®¡
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.throttle.io_serviced
8:0 Read 12345         # sdaè¯»æ“ä½œæ¬¡æ•°
8:0 Write 6789         # sdaå†™æ“ä½œæ¬¡æ•°
8:0 Sync 15678         # åŒæ­¥æ“ä½œ
8:0 Async 3456         # å¼‚æ­¥æ“ä½œ
8:0 Total 19134        # æ€»æ“ä½œ

# I/Oå­—èŠ‚ç»Ÿè®¡
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.throttle.io_service_bytes
8:0 Read 104857600     # è¯»äº†100MB
8:0 Write 52428800     # å†™äº†50MB
8:0 Total 157286400    # æ€»å…±150MB

# I/Oç­‰å¾…æ—¶é—´
$ cat /sys/fs/cgroup/blkio/docker/<container-id>/blkio.throttle.io_wait_time
8:0 Read 12345678      # è¯»ç­‰å¾…æ—¶é—´(çº³ç§’)
8:0 Write 6789012      # å†™ç­‰å¾…æ—¶é—´(çº³ç§’)
```

---

### 5.4 ç½‘ç»œå¸¦å®½é™åˆ¶

#### 5.4.1 ä½¿ç”¨ tc é™åˆ¶å®¹å™¨ç½‘ç»œå¸¦å®½

**tc (Traffic Control) é…ç½®**ï¼š
```bash
# è·å–å®¹å™¨vethæ¥å£
$ CONTAINER_ID=$(docker inspect -f '{{.Id}}' nginx)
$ VETH=$(docker exec $CONTAINER_ID cat /sys/class/net/eth0/iflink)
$ VETH_NAME=$(ip link | grep "^$VETH:" | cut -d: -f2 | xargs)

echo "å®¹å™¨vethæ¥å£: $VETH_NAME"

# é™åˆ¶å‡ºå£å¸¦å®½ï¼ˆä»å®¹å™¨åˆ°å¤–éƒ¨ï¼‰10Mbps
$ sudo tc qdisc add dev $VETH_NAME root tbf \
    rate 10mbit \        # é€Ÿç‡10Mbps
    latency 50ms \       # å»¶è¿Ÿ50ms
    burst 1540           # çªå‘1540å­—èŠ‚

# éªŒè¯é…ç½®
$ sudo tc -s qdisc show dev $VETH_NAME
qdisc tbf 8001: root refcnt 2 rate 10Mbit burst 1540b lat 50.0ms
 Sent 1048576 bytes 1024 pkt (dropped 0, overlimits 123 requeues 0)

# æµ‹è¯•å¸¦å®½é™åˆ¶
$ docker exec nginx sh -c '
    wget -O /dev/null http://speedtest.example.com/100MB
'
# ä¸‹è½½é€Ÿåº¦åº”è¯¥åœ¨10Mbpså·¦å³
```

**å…¥å£å¸¦å®½é™åˆ¶ï¼ˆä½¿ç”¨ IFBï¼‰**ï¼š
```bash
# åŠ è½½IFBæ¨¡å—
$ sudo modprobe ifb numifbs=1

# å¯ç”¨ifb0
$ sudo ip link set dev ifb0 up

# å°†å®¹å™¨å…¥å£æµé‡é‡å®šå‘åˆ°ifb0
$ sudo tc qdisc add dev $VETH_NAME ingress
$ sudo tc filter add dev $VETH_NAME parent ffff: \
    protocol ip u32 match u32 0 0 flowid 1:1 \
    action mirred egress redirect dev ifb0

# åœ¨ifb0ä¸Šé™åˆ¶é€Ÿç‡ï¼ˆå…¥å£10Mbpsï¼‰
$ sudo tc qdisc add dev ifb0 root tbf \
    rate 10mbit latency 50ms burst 1540

# æŸ¥çœ‹ç»Ÿè®¡
$ sudo tc -s qdisc show dev ifb0
```

---

#### 5.4.2 Docker ç½‘ç»œæ’ä»¶é™é€Ÿ

**ä½¿ç”¨ docker-tc æ’ä»¶**ï¼š
```bash
# å®‰è£…docker-tcæ’ä»¶
$ docker plugin install \
    lukaszlach/docker-tc:latest \
    --grant-all-permissions

# åˆ›å»ºé™é€Ÿæ ‡ç­¾
$ docker run -d --name limited-nginx \
    --label "com.docker-tc.enabled=1" \
    --label "com.docker-tc.limit=10mbps" \
    --label "com.docker-tc.delay=100ms" \
    nginx:alpine

# åŠ¨æ€ä¿®æ”¹é™é€Ÿ
$ docker update --label "com.docker-tc.limit=20mbps" limited-nginx

# æŸ¥çœ‹é™é€ŸçŠ¶æ€
$ docker exec limited-nginx cat /sys/class/net/eth0/tx_queue_len
1000
```

---

### 5.5 PID å’Œè®¾å¤‡é™åˆ¶

#### 5.5.1 è¿›ç¨‹æ•°é™åˆ¶é˜²æŠ¤

**forkç‚¸å¼¹é˜²æŠ¤**ï¼š
```bash
# é™åˆ¶å®¹å™¨æœ€å¤š100ä¸ªè¿›ç¨‹
$ docker run -d --name pid-limited \
    --pids-limit 100 \
    ubuntu:20.04

# æµ‹è¯•forkç‚¸å¼¹
$ docker exec pid-limited bash -c ':(){ :|:& };:'
bash: fork: retry: Resource temporarily unavailable

# æŸ¥çœ‹å½“å‰è¿›ç¨‹æ•°
$ cat /sys/fs/cgroup/pids/docker/<container-id>/pids.current
98

# æŸ¥çœ‹é™åˆ¶
$ cat /sys/fs/cgroup/pids/docker/<container-id>/pids.max
100

# PIDè€—å°½äº‹ä»¶
$ cat /sys/fs/cgroup/pids/docker/<container-id>/pids.events
max 5  # è§¦å‘é™åˆ¶çš„æ¬¡æ•°
```

---

#### 5.5.2 è®¾å¤‡è®¿é—®æ§åˆ¶

**device cgroup ç™½åå•**ï¼š
```bash
# é»˜è®¤æƒ…å†µï¼šå®¹å™¨æ— æ³•è®¿é—®å®¿ä¸»æœºè®¾å¤‡
$ docker run -it --rm ubuntu:20.04 ls /dev
# ä»…èƒ½çœ‹åˆ°: null zero random urandom tty consoleç­‰

# æˆæƒè®¿é—®ç‰¹å®šè®¾å¤‡ï¼ˆåªè¯»ï¼‰
$ docker run -it --rm \
    --device=/dev/sda:/dev/xvda:r \
    ubuntu:20.04 bash

# å®¹å™¨å†…
$ ls -l /dev/xvda
brw-r--r-- 1 root root 8, 0 ... /dev/xvda

# æˆæƒè®¿é—®GPU
$ docker run -it --rm \
    --device=/dev/nvidia0 \
    --device=/dev/nvidiactl \
    --device=/dev/nvidia-uvm \
    nvidia/cuda:11.0 bash

# æŸ¥çœ‹è®¾å¤‡è®¿é—®é…ç½®
$ cat /sys/fs/cgroup/devices/docker/<container-id>/devices.list
c 1:3 rwm    # /dev/null
c 1:5 rwm    # /dev/zero
c 1:7 rwm    # /dev/full
c 1:8 rwm    # /dev/random
c 1:9 rwm    # /dev/urandom
c 5:0 rwm    # /dev/tty
c 5:1 rwm    # /dev/console
b 8:0 r      # /dev/sda (åªè¯»)
```

---

### 5.6 ç»¼åˆèµ„æºé™åˆ¶å®æˆ˜

#### 5.6.1 ç”Ÿäº§çº§èµ„æºé…ç½®æ¨¡æ¿

**Webåº”ç”¨å®¹å™¨**ï¼š
```bash
docker run -d \
  --name web-prod \
  # CPUé™åˆ¶
  --cpus="2.5" \               # 2.5ä¸ªCPUæ ¸å¿ƒ
  --cpu-shares=1024 \          # CPUæƒé‡ï¼ˆç«äº‰æ—¶ï¼‰
  # å†…å­˜é™åˆ¶
  --memory="2g" \              # ç¡¬é™åˆ¶2GB
  --memory-reservation="1g" \  # è½¯é™åˆ¶1GB
  --memory-swap="3g" \         # æ€»å†…å­˜+swap 3GB
  --oom-score-adj=-100 \       # OOMä¼˜å…ˆçº§ï¼ˆè¾ƒä½ï¼‰
  # I/Oé™åˆ¶
  --blkio-weight=500 \         # I/Oæƒé‡
  --device-read-bps /dev/sda:50mb \   # è¯»å¸¦å®½50MB/s
  --device-write-bps /dev/sda:30mb \  # å†™å¸¦å®½30MB/s
  # è¿›ç¨‹é™åˆ¶
  --pids-limit=500 \           # æœ€å¤š500è¿›ç¨‹
  # ç½‘ç»œ
  --network custom-net \
  # æ—¥å¿—é™åˆ¶
  --log-opt max-size=100m \
  --log-opt max-file=3 \
  # é‡å¯ç­–ç•¥
  --restart unless-stopped \
  myapp:latest
```

**æ•°æ®åº“å®¹å™¨**ï¼š
```bash
docker run -d \
  --name postgres-prod \
  # CPUé™åˆ¶ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
  --cpus="4" \
  --cpu-shares=2048 \          # æ›´é«˜CPUæƒé‡
  # å†…å­˜é™åˆ¶ï¼ˆå¤§å†…å­˜ï¼‰
  --memory="8g" \
  --memory-reservation="6g" \
  --memory-swap="10g" \
  --oom-score-adj=-500 \       # é«˜ä¼˜å…ˆçº§ä¿æŠ¤
  # I/Oé™åˆ¶ï¼ˆé«˜I/Oï¼‰
  --blkio-weight=800 \         # æ›´é«˜I/Oæƒé‡
  --device-read-iops /dev/sda:1000 \
  --device-write-iops /dev/sda:800 \
  # æ•°æ®å·
  -v postgres-data:/var/lib/postgresql/data \
  # ç½‘ç»œï¼ˆhostæ¨¡å¼è·å–æœ€ä½³æ€§èƒ½ï¼‰
  --network host \
  postgres:15-alpine
```

---

#### 5.6.2 èµ„æºç›‘æ§ä¸å‘Šè­¦

**å®æ—¶ç›‘æ§è„šæœ¬**ï¼š
```bash
#!/bin/bash
# docker-resource-monitor.sh

CONTAINER=$1
THRESHOLD_CPU=80
THRESHOLD_MEM=80
THRESHOLD_IO=100

while true; do
    # è·å–å®¹å™¨ç»Ÿè®¡
    STATS=$(docker stats $CONTAINER --no-stream --format \
        "{{.CPUPerc}}|{{.MemPerc}}|{{.BlockIO}}")

    CPU=$(echo $STATS | cut -d'|' -f1 | sed 's/%//')
    MEM=$(echo $STATS | cut -d'|' -f2 | sed 's/%//')
    IO=$(echo $STATS | cut -d'|' -f3)

    # CPUå‘Šè­¦
    if (( $(echo "$CPU > $THRESHOLD_CPU" | bc -l) )); then
        echo "âš ï¸  [$(date)] CPUè¶…é™: $CPU%"
        # å‘é€å‘Šè­¦ï¼ˆwebhook/emailç­‰ï¼‰
    fi

    # å†…å­˜å‘Šè­¦
    if (( $(echo "$MEM > $THRESHOLD_MEM" | bc -l) )); then
        echo "âš ï¸  [$(date)] å†…å­˜è¶…é™: $MEM%"
    fi

    # I/Oå‘Šè­¦
    IO_MB=$(echo $IO | grep -oP '\d+MB' | grep -oP '\d+')
    if [ ! -z "$IO_MB" ] && [ $IO_MB -gt $THRESHOLD_IO ]; then
        echo "âš ï¸  [$(date)] I/Oè¶…é™: $IO_MB MB/s"
    fi

    sleep 10
done
```

**Prometheusç›‘æ§é›†æˆ**ï¼š
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'docker'
    static_configs:
      - targets: ['localhost:9323']  # Docker daemon metrics

# docker daemon.json
{
  "metrics-addr": "0.0.0.0:9323",
  "experimental": true
}

# é‡å¯docker
$ sudo systemctl restart docker

# æŸ¥è¯¢ç¤ºä¾‹
$ curl http://localhost:9323/metrics | grep container_
container_cpu_usage_seconds_total{id="/docker/abc123",name="web"} 123.45
container_memory_usage_bytes{id="/docker/abc123",name="web"} 524288000
container_network_receive_bytes_total{id="/docker/abc123",interface="eth0"} 1048576
```

---

## å°ç»“ï¼šç¬¬5ç« æ ¸å¿ƒçŸ¥è¯†ç‚¹

âœ… **å·²æŒæ¡å†…å®¹**ï¼š
1. **CPUç®¡ç†**: CFSè°ƒåº¦å™¨ã€shares/quota/periodã€RTè°ƒåº¦
2. **å†…å­˜ç®¡ç†**: memory.statè¯¦è§£ã€è½¯/ç¡¬é™åˆ¶ã€OOMä¼˜å…ˆçº§
3. **I/Oé™åˆ¶**: æƒé‡/IOPS/å¸¦å®½ä¸‰é‡é™åˆ¶ã€æ€§èƒ½åˆ†æ
4. **ç½‘ç»œé™é€Ÿ**: tcå·¥å…·ã€docker-tcæ’ä»¶
5. **PIDé™åˆ¶**: forkç‚¸å¼¹é˜²æŠ¤
6. **è®¾å¤‡æ§åˆ¶**: device cgroupç™½åå•
7. **ç»¼åˆå®æˆ˜**: ç”Ÿäº§çº§é…ç½®æ¨¡æ¿ã€èµ„æºç›‘æ§å‘Šè­¦

ğŸ¯ **å®æˆ˜èƒ½åŠ›**ï¼š
- ç²¾ç¡®æ§åˆ¶å®¹å™¨èµ„æºä½¿ç”¨
- é…ç½®ç”Ÿäº§çº§èµ„æºé™åˆ¶
- å®æ—¶ç›‘æ§èµ„æºä½¿ç”¨å¹¶å‘Šè­¦
- ä¼˜åŒ–èµ„æºåˆ†é…ç­–ç•¥

---

# ç¬¬äºŒéƒ¨åˆ†:é•œåƒæ„å»ºä¸ä¼˜åŒ–å®æˆ˜

---

# ç¬¬6ç« :Dockerfileæœ€ä½³å®è·µæ·±åº¦è§£æ

## 6.1 Dockerfileæ ¸å¿ƒæŒ‡ä»¤è¯¦è§£

### 6.1.1 FROMæŒ‡ä»¤:åŸºç¡€é•œåƒé€‰æ‹©ç­–ç•¥

```dockerfile
# âœ… æ¨è:æ˜ç¡®æŒ‡å®šç‰ˆæœ¬+digest
FROM nginx:1.25.3-alpine@sha256:9c367186df82fcc5c92c91c0ff5f3de68b2f5b6c0f8d0c6cf79c9d6c2b3e4a5c

# âŒ é¿å…:ä½¿ç”¨latestæ ‡ç­¾
FROM nginx:latest

# âš ï¸ ç”Ÿäº§ç¯å¢ƒç­–ç•¥
FROM python:3.11.7-slim-bookworm AS builder  # Debianç³»ç»Ÿç¨³å®šæ€§
FROM python:3.11.7-alpine AS runtime         # Alpineæœ€å°åŒ–
```

**åŸºç¡€é•œåƒé€‰æ‹©å¯¹æ¯”**:

| é•œåƒç±»å‹ | å¤§å° | å®‰å…¨æ€§ | å…¼å®¹æ€§ | é€‚ç”¨åœºæ™¯ |
|---------|------|-------|--------|---------|
| `alpine` | 5-10MB | â­â­â­â­â­ | musl libcé—®é¢˜ | ç”Ÿäº§ç¯å¢ƒé¦–é€‰ |
| `-slim` | 40-70MB | â­â­â­â­ | glibcå®Œæ•´æ”¯æŒ | Python/Nodeåº”ç”¨ |
| å®Œæ•´é•œåƒ | 150-400MB | â­â­â­ | å®Œå…¨å…¼å®¹ | å¼€å‘ç¯å¢ƒ |
| `scratch` | 0KB | â­â­â­â­â­ | é™æ€ç¼–è¯‘ | Go/Ruståº”ç”¨ |

---

### 6.1.2 RUNæŒ‡ä»¤:å±‚æ•°ä¼˜åŒ–ä¸ç¼“å­˜åˆ©ç”¨

```dockerfile
# âŒ åæ¨¡å¼:å¤šå±‚RUNå¯¼è‡´é•œåƒè‡ƒè‚¿
FROM ubuntu:22.04
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y wget
RUN apt-get install -y git
RUN rm -rf /var/lib/apt/lists/*  # âš ï¸ æ— æ•ˆæ¸…ç†!å‰å‡ å±‚å·²å›ºåŒ–

# âœ… æœ€ä½³å®è·µ:å•å±‚RUN+æ¸…ç†ç¼“å­˜
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y \
    curl=7.81.0-1ubuntu1.15 \
    wget=1.21.2-2ubuntu1 \
    git=1:2.34.1-1ubuntu1.10 \
    # åœ¨åŒä¸€å±‚æ¸…ç†ç¼“å­˜
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \
 && truncate -s 0 /var/log/*log

# âœ… åˆ©ç”¨æ„å»ºç¼“å­˜:æŒ‰å˜æ›´é¢‘ç‡æ’åº
FROM python:3.11-slim
# 1ï¸âƒ£ ç³»ç»Ÿä¾èµ–(å˜æ›´å°‘,æ”¾å‰é¢)
RUN apt-get update && apt-get install -y gcc && rm -rf /var/lib/apt/lists/*

# 2ï¸âƒ£ Pythonä¾èµ–(ä¸­ç­‰å˜æ›´)
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# 3ï¸âƒ£ åº”ç”¨ä»£ç (å˜æ›´é¢‘ç¹,æ”¾æœ€å)
COPY . /app
```

**å±‚æ•°ä¼˜åŒ–åŸç†**:

```bash
# æŸ¥çœ‹é•œåƒå±‚æ•°
$ docker history myapp:v1
IMAGE          CREATED BY                                      SIZE
<missing>      /bin/sh -c #(nop) COPY . /app                   2.3MB
<missing>      /bin/sh -c pip install -r requirements.txt      150MB
<missing>      /bin/sh -c apt-get install gcc                  200MB
<missing>      /bin/sh -c #(nop) FROM python:3.11-slim         50MB

# æ¯ä¸ªRUN/COPY/ADDéƒ½ä¼šåˆ›å»ºæ–°å±‚
# ä¼˜åŒ–ç›®æ ‡:å‡å°‘å±‚æ•° + æœ€å¤§åŒ–ç¼“å­˜å‘½ä¸­
```

---

### 6.1.3 COPY vs ADD:ä½¿ç”¨åœºæ™¯åŒºåˆ†

```dockerfile
# âœ… æ¨è:ä½¿ç”¨COPYå¤åˆ¶æ–‡ä»¶
COPY app.py /app/
COPY static/ /var/www/html/
COPY --chown=nginx:nginx config.conf /etc/nginx/

# âš ï¸ ADDçš„éšå¼è¡Œä¸º(å®¹æ˜“å‡ºé”™)
ADD archive.tar.gz /data/  # è‡ªåŠ¨è§£å‹
ADD https://example.com/file.zip /tmp/  # è‡ªåŠ¨ä¸‹è½½

# âœ… æ˜¾å¼ä½¿ç”¨RUNå¤„ç†ä¸‹è½½å’Œè§£å‹
RUN curl -fsSL https://example.com/file.zip -o /tmp/file.zip \
 && unzip /tmp/file.zip -d /data/ \
 && rm /tmp/file.zip

# âœ… .dockerignoreæ’é™¤æ— å…³æ–‡ä»¶
# åˆ›å»º .dockerignore æ–‡ä»¶:
# node_modules/
# .git/
# *.log
# .env
# __pycache__/
```

---

### 6.1.4 CMD vs ENTRYPOINT:å®¹å™¨å¯åŠ¨è¡Œä¸º

```dockerfile
# ğŸ“Œ CMD:å¯è¢«docker runå‚æ•°è¦†ç›–
FROM nginx:alpine
CMD ["nginx", "-g", "daemon off;"]

# è¿è¡Œæ–¹å¼:
$ docker run myapp              # æ‰§è¡Œ nginx -g "daemon off;"
$ docker run myapp echo "hello" # è¦†ç›–CMD,æ‰§è¡Œ echo "hello"

# ğŸ“Œ ENTRYPOINT:ä½œä¸ºä¸»å‘½ä»¤,CMDä½œä¸ºå‚æ•°
FROM python:3.11-slim
ENTRYPOINT ["python", "app.py"]
CMD ["--port", "8000"]

# è¿è¡Œæ–¹å¼:
$ docker run myapp                  # python app.py --port 8000
$ docker run myapp --port 9000      # python app.py --port 9000
$ docker run myapp --debug          # python app.py --debug

# âœ… ç»„åˆæ¨¡å¼:ENTRYPOINT + CMD
FROM alpine:3.19
COPY docker-entrypoint.sh /
ENTRYPOINT ["/docker-entrypoint.sh"]
CMD ["default-command"]

# docker-entrypoint.sh è„šæœ¬:
#!/bin/sh
set -e
# åˆå§‹åŒ–é€»è¾‘
exec "$@"  # æ‰§è¡ŒCMDå‚æ•°
```

**Execæ ¼å¼ vs Shellæ ¼å¼**:

```dockerfile
# âœ… Execæ ¼å¼(æ¨è):ç²¾ç¡®æ§åˆ¶è¿›ç¨‹
CMD ["python", "app.py"]
# è¿›ç¨‹æ ‘: PID 1 â†’ python

# âŒ Shellæ ¼å¼:åˆ›å»ºé¢å¤–shellè¿›ç¨‹
CMD python app.py
# è¿›ç¨‹æ ‘: PID 1 â†’ /bin/sh -c "python app.py"
#                   â””â”€ PID 7 â†’ python

# é—®é¢˜:ä¿¡å·æ— æ³•ä¼ é€’ç»™pythonè¿›ç¨‹
# docker stopä¼šå‘PID 1(shell)å‘é€SIGTERM
# ä½†shellä¸ä¼šè½¬å‘ç»™python,å¯¼è‡´å¼ºåˆ¶SIGKILL
```

---

### 6.1.5 ENV vs ARG:æ„å»ºæ—¶å˜é‡ä¸è¿è¡Œæ—¶å˜é‡

```dockerfile
# ARG:ä»…æ„å»ºæ—¶æœ‰æ•ˆ
ARG PYTHON_VERSION=3.11
ARG APP_ENV=production

FROM python:${PYTHON_VERSION}-slim
RUN echo "Building for: ${APP_ENV}"

# ENV:å®¹å™¨è¿è¡Œæ—¶æŒä¹…åŒ–
ENV APP_HOME=/app \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

WORKDIR ${APP_HOME}

# âœ… ç»„åˆä½¿ç”¨:ARG â†’ ENVä¼ é€’
ARG VERSION
ENV APP_VERSION=${VERSION}

# æ„å»ºå‘½ä»¤:
$ docker build --build-arg VERSION=1.2.3 -t myapp:1.2.3 .

# è¿è¡Œæ—¶ç¯å¢ƒå˜é‡:
$ docker run --env-file .env myapp:1.2.3
$ docker run -e DATABASE_URL=postgres://... myapp:1.2.3
```

**ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§**:

```bash
# ä¼˜å…ˆçº§ä»é«˜åˆ°ä½:
1. docker run -e KEY=value         # å‘½ä»¤è¡Œå‚æ•°
2. docker run --env-file .env      # ç¯å¢ƒæ–‡ä»¶
3. Dockerfile ENV KEY=value        # é•œåƒå†…ç½®
4. æ“ä½œç³»ç»Ÿç¯å¢ƒå˜é‡                 # å®¿ä¸»æœºç»§æ‰¿
```

---

### 6.1.6 WORKDIRä¸USER:å®‰å…¨ä¸Šä¸‹æ–‡è®¾ç½®

```dockerfile
# âŒ åæ¨¡å¼:ä½¿ç”¨rootç”¨æˆ·è¿è¡Œ
FROM python:3.11-slim
COPY app.py /root/
CMD ["python", "/root/app.py"]

# âœ… æœ€ä½³å®è·µ:éç‰¹æƒç”¨æˆ·
FROM python:3.11-slim

# åˆ›å»ºåº”ç”¨ç”¨æˆ·(UID 1000)
RUN groupadd -r appuser -g 1000 && \
    useradd -r -u 1000 -g appuser -d /app -s /sbin/nologin appuser

# è®¾ç½®å·¥ä½œç›®å½•å¹¶æˆæƒ
WORKDIR /app
RUN chown -R appuser:appuser /app

# å®‰è£…ä¾èµ–(éœ€è¦rootæƒé™)
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# åˆ‡æ¢åˆ°éç‰¹æƒç”¨æˆ·
USER appuser

# å¤åˆ¶åº”ç”¨ä»£ç (å·²ç»ä»¥appuserèº«ä»½)
COPY --chown=appuser:appuser . .

CMD ["python", "app.py"]
```

**ç”¨æˆ·åˆ‡æ¢æ—¶æœºéªŒè¯**:

```bash
# éªŒè¯è¿›ç¨‹ç”¨æˆ·
$ docker exec myapp ps aux
USER       PID  COMMAND
appuser      1  python app.py  # âœ… éroot

# éªŒè¯æ–‡ä»¶æƒé™
$ docker exec myapp ls -la /app
drwxr-xr-x appuser appuser /app
-rw-r--r-- appuser appuser app.py
```

---

## 6.2 Dockerfileåˆ†å±‚ä¼˜åŒ–å®æˆ˜

### 6.2.1 å±‚ç¼“å­˜æœºåˆ¶æ·±åº¦å‰–æ

```dockerfile
# ç¼“å­˜å¤±æ•ˆåœºæ™¯æ¼”ç¤º
FROM python:3.11-slim

# å±‚1:åŸºç¡€é•œåƒ(ç¼“å­˜ç¨³å®š)
RUN apt-get update && apt-get install -y gcc

# å±‚2:requirements.txtå˜æ›´å,æ­¤å±‚ç¼“å­˜å¤±æ•ˆ
COPY requirements.txt .
RUN pip install -r requirements.txt  # é‡æ–°æ‰§è¡Œ

# å±‚3:ä¾èµ–å±‚2,ç¼“å­˜ä¹Ÿå¤±æ•ˆ
COPY . /app  # é‡æ–°å¤åˆ¶

# âœ… ä¼˜åŒ–ç­–ç•¥:åˆ†ç¦»å˜åŒ–é¢‘ç‡
FROM python:3.11-slim

# 1ï¸âƒ£ ç³»ç»Ÿä¾èµ–(å‡ ä¹ä¸å˜)
RUN apt-get update && apt-get install -y gcc \
 && rm -rf /var/lib/apt/lists/*

# 2ï¸âƒ£ Pythonä¾èµ–(å¶å°”å˜åŒ–)
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# 3ï¸âƒ£ åº”ç”¨ä»£ç (é¢‘ç¹å˜åŒ–)
WORKDIR /app
COPY . .

# åœºæ™¯:ä¿®æ”¹app.pyåé‡æ–°æ„å»º
# - å±‚1å’Œå±‚2ä½¿ç”¨ç¼“å­˜ âœ…
# - ä»…å±‚3é‡æ–°æ„å»º âœ…
```

**ç¼“å­˜å‘½ä¸­åˆ¤æ–­é€»è¾‘**:

```bash
# Dockeråˆ¤æ–­ç¼“å­˜å‘½ä¸­çš„ä¾æ®:
1. COPY/ADD:æ–‡ä»¶å†…å®¹SHA256å“ˆå¸Œ
2. RUN:æŒ‡ä»¤å­—ç¬¦ä¸²å®Œå…¨åŒ¹é…
3. ENV/ARG:å˜é‡å€¼å®Œå…¨åŒ¹é…
4. FROM:åŸºç¡€é•œåƒdigeståŒ¹é…

# æŸ¥çœ‹ç¼“å­˜å‘½ä¸­æƒ…å†µ
$ docker build --progress=plain .
#1 [internal] load build definition
#2 [internal] load .dockerignore
#3 [1/4] FROM python:3.11-slim
#3 CACHED  # âœ… ç¼“å­˜å‘½ä¸­
#4 [2/4] RUN apt-get update
#4 CACHED  # âœ… ç¼“å­˜å‘½ä¸­
#5 [3/4] COPY requirements.txt
#5 CACHED  # âœ… ç¼“å­˜å‘½ä¸­
#6 [4/4] COPY . /app
#6 0.234s  # âŒ ç¼“å­˜å¤±æ•ˆ,é‡æ–°æ‰§è¡Œ
```

---

### 6.2.2 .dockerignoreæ–‡ä»¶æœ€ä½³å®è·µ

```bash
# .dockerignore å®Œæ•´ç¤ºä¾‹
# ============================
# ç‰ˆæœ¬æ§åˆ¶æ–‡ä»¶
.git/
.gitignore
.gitattributes

# æ„å»ºäº§ç‰©
node_modules/
dist/
build/
*.pyc
__pycache__/
.pytest_cache/
.mypy_cache/

# IDEé…ç½®
.vscode/
.idea/
*.swp
*.swo
*~

# ç¯å¢ƒå˜é‡(æ•æ„Ÿä¿¡æ¯)
.env
.env.local
*.key
*.pem

# æ—¥å¿—æ–‡ä»¶
*.log
logs/

# æ–‡æ¡£å’Œæµ‹è¯•
README.md
docs/
tests/
*.test.js

# CI/CDé…ç½®
.github/
.gitlab-ci.yml
Jenkinsfile

# Dockerç›¸å…³
Dockerfile*
docker-compose*.yml
.dockerignore

# OSæ–‡ä»¶
.DS_Store
Thumbs.db
```

**æ€§èƒ½å½±å“å®æµ‹**:

```bash
# æ— .dockerignore
$ docker build -t myapp:v1 .
Sending build context to Docker daemon  523.4MB  # âš ï¸ åŒ…å«node_modules
Step 1/8: FROM node:18-alpine
Step 2/8: COPY . /app
 ---> 98.3s  # å¤åˆ¶å¤§é‡æ— ç”¨æ–‡ä»¶

# æœ‰.dockerignore
$ docker build -t myapp:v2 .
Sending build context to Docker daemon  2.3MB    # âœ… ä»…å¿…è¦æ–‡ä»¶
Step 1/8: FROM node:18-alpine
Step 2/8: COPY . /app
 ---> 0.5s   # æ„å»ºé€Ÿåº¦æå‡ 196å€
```

---

### 6.2.3 é•œåƒå±‚æ•°ä¼˜åŒ–ç­–ç•¥

```dockerfile
# âŒ åæ¨¡å¼:è¿‡å¤šå±‚æ•°(é•œåƒå¤§å° 500MB)
FROM ubuntu:22.04
RUN apt-get update
RUN apt-get install -y python3
RUN apt-get install -y python3-pip
RUN apt-get install -y git
RUN apt-get install -y curl
COPY requirements.txt /tmp/
RUN pip3 install flask
RUN pip3 install requests
RUN pip3 install sqlalchemy
COPY app.py /app/
COPY config.py /app/

# âœ… æœ€ä½³å®è·µ:åˆå¹¶å±‚(é•œåƒå¤§å° 180MB)
FROM ubuntu:22.04

# å•å±‚å®‰è£…æ‰€æœ‰ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3=3.10.6-1~22.04 \
    python3-pip=22.0.2+dfsg-1ubuntu0.4 \
    git=1:2.34.1-1ubuntu1.10 \
    curl=7.81.0-1ubuntu1.15 \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

# å•å±‚å®‰è£…æ‰€æœ‰Pythonä¾èµ–
COPY requirements.txt /tmp/
RUN pip3 install --no-cache-dir -r /tmp/requirements.txt \
 && rm /tmp/requirements.txt

# å•å±‚å¤åˆ¶æ‰€æœ‰åº”ç”¨æ–‡ä»¶
COPY app.py config.py /app/

# å±‚æ•°å¯¹æ¯”:
# åæ¨¡å¼: 11å±‚
# æœ€ä½³å®è·µ: 4å±‚(åŸºç¡€é•œåƒ + 3ä¸ªè‡ªå®šä¹‰å±‚)
```

---

### 6.2.4 åŒ…ç®¡ç†å™¨ç¼“å­˜æ¸…ç†æŠ€å·§

```dockerfile
# âœ… Debian/Ubuntu:apt-getæ¸…ç†
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y \
    nginx \
    curl \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

# âœ… Alpine:apkæ¸…ç†
FROM alpine:3.19
RUN apk add --no-cache \
    nginx \
    curl

# âœ… Python:pipæ¸…ç†
FROM python:3.11-slim
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# âœ… Node.js:npmæ¸…ç†
FROM node:18-alpine
COPY package*.json ./
RUN npm ci --only=production \
 && npm cache clean --force

# âœ… Go:æ„å»ºååˆ é™¤ç¼–è¯‘ç¼“å­˜
FROM golang:1.21-alpine AS builder
WORKDIR /build
COPY . .
RUN go mod download \
 && CGO_ENABLED=0 go build -o app \
 && rm -rf /root/.cache/go-build

# âš ï¸ é”™è¯¯ç¤ºä¾‹:æ¸…ç†æ— æ•ˆ
RUN apt-get update
RUN apt-get install -y nginx
RUN rm -rf /var/lib/apt/lists/*  # âŒ å‰ä¸¤å±‚å·²å›ºåŒ–,æ¸…ç†æ— æ•ˆ
```

---

## 6.3 å¤šé˜¶æ®µæ„å»ºæ·±åº¦å®æˆ˜

### 6.3.1 Goåº”ç”¨å¤šé˜¶æ®µæ„å»º

```dockerfile
# ===============================
# é˜¶æ®µ1:æ„å»ºé˜¶æ®µ
# ===============================
FROM golang:1.21.5-alpine AS builder

# å®‰è£…ç¼–è¯‘ä¾èµ–
RUN apk add --no-cache git make

WORKDIR /build

# åˆ©ç”¨ç¼“å­˜:å…ˆä¸‹è½½ä¾èµ–
COPY go.mod go.sum ./
RUN go mod download

# å¤åˆ¶æºç å¹¶ç¼–è¯‘
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
    -ldflags="-s -w -X main.version=${VERSION}" \
    -o app \
    ./cmd/server

# ===============================
# é˜¶æ®µ2:è¿è¡Œæ—¶é˜¶æ®µ
# ===============================
FROM alpine:3.19

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apk add --no-cache ca-certificates tzdata

# åˆ›å»ºéç‰¹æƒç”¨æˆ·
RUN addgroup -S appgroup && adduser -S appuser -G appgroup

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /build/app /usr/local/bin/app
COPY --from=builder /build/configs /etc/app/

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

USER appuser
EXPOSE 8080

ENTRYPOINT ["/usr/local/bin/app"]
CMD ["--config", "/etc/app/config.yaml"]

# é•œåƒå¤§å°å¯¹æ¯”:
# å•é˜¶æ®µæ„å»º: 850MB (åŒ…å«Go SDKå’Œç¼–è¯‘ç¼“å­˜)
# å¤šé˜¶æ®µæ„å»º: 12MB  (ä»…åŒ…å«äºŒè¿›åˆ¶æ–‡ä»¶å’Œè¿è¡Œæ—¶ä¾èµ–)
```

---

### 6.3.2 Javaåº”ç”¨å¤šé˜¶æ®µæ„å»º(Spring Boot)

```dockerfile
# ===============================
# é˜¶æ®µ1:Mavenæ„å»º
# ===============================
FROM maven:3.9.6-eclipse-temurin-17 AS builder

WORKDIR /build

# åˆ©ç”¨ç¼“å­˜:å…ˆè§£æä¾èµ–
COPY pom.xml .
RUN mvn dependency:go-offline -B

# å¤åˆ¶æºç å¹¶æ‰“åŒ…
COPY src ./src
RUN mvn clean package -DskipTests -B \
 && mv target/*.jar app.jar

# ===============================
# é˜¶æ®µ2:JREè¿è¡Œæ—¶
# ===============================
FROM eclipse-temurin:17-jre-alpine

# å®‰è£…è¯Šæ–­å·¥å…·(å¯é€‰)
RUN apk add --no-cache curl

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -S spring && adduser -S spring -G spring
USER spring:spring

WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶JAR
COPY --from=builder /build/app.jar .

# JVMå‚æ•°ä¼˜åŒ–
ENV JAVA_OPTS="-XX:+UseContainerSupport \
               -XX:MaxRAMPercentage=75.0 \
               -XX:InitialRAMPercentage=50.0 \
               -XX:+UseG1GC \
               -XX:MaxGCPauseMillis=200 \
               -Djava.security.egd=file:/dev/./urandom"

EXPOSE 8080

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]

# é•œåƒå¤§å°å¯¹æ¯”:
# å•é˜¶æ®µ(Maven): 780MB
# å¤šé˜¶æ®µ(JRE): 210MB (å‡å°‘73%)
```

**Spring Bootåˆ†å±‚JARä¼˜åŒ–**:

```dockerfile
# ===============================
# Spring Boot 2.3+ åˆ†å±‚ä¼˜åŒ–
# ===============================
FROM maven:3.9-temurin-17 AS builder
WORKDIR /build
COPY pom.xml .
RUN mvn dependency:go-offline
COPY src ./src
RUN mvn package -DskipTests
RUN java -Djarmode=layertools -jar target/*.jar extract

# ===============================
# è¿è¡Œæ—¶:åˆ†å±‚å¤åˆ¶
# ===============================
FROM eclipse-temurin:17-jre-alpine

RUN addgroup -S spring && adduser -S spring -G spring
USER spring:spring
WORKDIR /app

# æŒ‰ä¾èµ–å˜åŒ–é¢‘ç‡åˆ†å±‚å¤åˆ¶
COPY --from=builder /build/dependencies/ ./
COPY --from=builder /build/spring-boot-loader/ ./
COPY --from=builder /build/snapshot-dependencies/ ./
COPY --from=builder /build/application/ ./

ENTRYPOINT ["java", "org.springframework.boot.loader.JarLauncher"]

# ä¼˜åŠ¿:ä¿®æ”¹ä»£ç å,ä»…applicationå±‚å¤±æ•ˆ
# dependencieså±‚(Mavenä¾èµ–)ä¿æŒç¼“å­˜ âœ…
```

---

### 6.3.3 Node.jsåº”ç”¨å¤šé˜¶æ®µæ„å»º

```dockerfile
# ===============================
# é˜¶æ®µ1:ä¾èµ–å®‰è£…ä¸æ„å»º
# ===============================
FROM node:18.19.0-alpine AS builder

# å®‰è£…æ„å»ºå·¥å…·
RUN apk add --no-cache python3 make g++

WORKDIR /build

# åˆ©ç”¨ç¼“å­˜:å…ˆå®‰è£…ä¾èµ–
COPY package*.json ./
RUN npm ci --only=production \
 && cp -R node_modules /tmp/node_modules \
 && npm ci  # å®‰è£…å¼€å‘ä¾èµ–ç”¨äºæ„å»º

# å¤åˆ¶æºç å¹¶æ„å»º
COPY . .
RUN npm run build  # TypeScriptç¼–è¯‘æˆ–Webpackæ‰“åŒ…

# ===============================
# é˜¶æ®µ2:ç”Ÿäº§è¿è¡Œæ—¶
# ===============================
FROM node:18.19.0-alpine

# å®‰è£…dumb-init(å¤„ç†ä¿¡å·è½¬å‘)
RUN apk add --no-cache dumb-init

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1001 nodejs && adduser -u 1001 -G nodejs -s /bin/sh -D nodejs

WORKDIR /app

# ä»builderå¤åˆ¶ç”Ÿäº§ä¾èµ–
COPY --from=builder /tmp/node_modules ./node_modules
# ä»builderå¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /build/dist ./dist
COPY --from=builder /build/package.json ./

USER nodejs

EXPOSE 3000

# ä½¿ç”¨dumb-initå¤„ç†ä¿¡å·
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]

# é•œåƒå¤§å°å¯¹æ¯”:
# å•é˜¶æ®µ: 450MB (åŒ…å«devDependencieså’Œæºç )
# å¤šé˜¶æ®µ: 120MB (ä»…ç”Ÿäº§ä¾èµ–å’Œç¼–è¯‘åä»£ç )
```

---

### 6.3.4 Pythonåº”ç”¨å¤šé˜¶æ®µæ„å»º

```dockerfile
# ===============================
# é˜¶æ®µ1:ä¾èµ–ç¼–è¯‘
# ===============================
FROM python:3.11.7-slim AS builder

# å®‰è£…ç¼–è¯‘ä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    libffi-dev \
 && rm -rf /var/lib/apt/lists/*

WORKDIR /build

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# åˆ©ç”¨ç¼“å­˜:å…ˆå®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ===============================
# é˜¶æ®µ2:è¿è¡Œæ—¶
# ===============================
FROM python:3.11.7-slim

# ä»…å®‰è£…è¿è¡Œæ—¶åº“
RUN apt-get update && apt-get install -y \
    libpq5 \
 && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN useradd -m -u 1000 appuser

WORKDIR /app

# ä»builderå¤åˆ¶è™šæ‹Ÿç¯å¢ƒ
COPY --from=builder /opt/venv /opt/venv

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=appuser:appuser . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PATH="/opt/venv/bin:$PATH" \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

USER appuser

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

# é•œåƒå¤§å°å¯¹æ¯”:
# å•é˜¶æ®µ: 1.2GB (åŒ…å«gccç­‰ç¼–è¯‘å·¥å…·)
# å¤šé˜¶æ®µ: 280MB (ä»…è¿è¡Œæ—¶ä¾èµ–)
```

---

### 6.3.5 å¤šé˜¶æ®µæ„å»ºé«˜çº§æŠ€å·§

```dockerfile
# âœ… æŠ€å·§1:å‘½åé˜¶æ®µå¹¶é€‰æ‹©æ€§å¤åˆ¶
FROM golang:1.21-alpine AS go-builder
WORKDIR /build
COPY . .
RUN go build -o api ./cmd/api

FROM node:18-alpine AS node-builder
WORKDIR /build
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# æœ€ç»ˆé•œåƒ:åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªæ„å»ºé˜¶æ®µ
FROM alpine:3.19
COPY --from=go-builder /build/api /usr/local/bin/
COPY --from=node-builder /build/dist /var/www/html/

# âœ… æŠ€å·§2:ä½¿ç”¨å¤–éƒ¨é•œåƒä½œä¸ºé˜¶æ®µ
FROM nginx:1.25-alpine AS nginx-config
RUN nginx -V  # è·å–ç¼–è¯‘å‚æ•°

FROM alpine:3.19
COPY --from=nginx-config /etc/nginx /etc/nginx
COPY --from=nginx-config /usr/sbin/nginx /usr/sbin/nginx

# âœ… æŠ€å·§3:æ„å»ºå‚æ•°æ§åˆ¶é˜¶æ®µé€‰æ‹©
ARG BUILD_ENV=production

FROM maven:3.9-temurin-17 AS builder-dev
WORKDIR /build
COPY pom.xml .
RUN mvn dependency:go-offline
COPY src ./src
RUN mvn package

FROM maven:3.9-temurin-17 AS builder-prod
WORKDIR /build
COPY pom.xml .
RUN mvn dependency:go-offline
COPY src ./src
RUN mvn package -Pprod -DskipTests

# æ ¹æ®BUILD_ENVé€‰æ‹©æ„å»ºé˜¶æ®µ
FROM builder-${BUILD_ENV} AS final-builder

FROM eclipse-temurin:17-jre-alpine
COPY --from=final-builder /build/target/*.jar app.jar
CMD ["java", "-jar", "app.jar"]

# æ„å»ºå‘½ä»¤:
$ docker build --build-arg BUILD_ENV=dev -t myapp:dev .
$ docker build --build-arg BUILD_ENV=prod -t myapp:prod .
```

---

## 6.4 é•œåƒä½“ç§¯ä¼˜åŒ–å®æˆ˜

### 6.4.1 åŸºç¡€é•œåƒé€‰æ‹©ä¼˜åŒ–

```dockerfile
# å¯¹æ¯”ä¸åŒåŸºç¡€é•œåƒå¤§å°

# âŒ å®Œæ•´Ubuntué•œåƒ
FROM ubuntu:22.04
# é•œåƒå¤§å°: 77MB

# âš ï¸ Debian Slim
FROM debian:bookworm-slim
# é•œåƒå¤§å°: 74MB

# âœ… Alpine Linux
FROM alpine:3.19
# é•œåƒå¤§å°: 7.3MB

# â­ Distroless(Google)
FROM gcr.io/distroless/static-debian12
# é•œåƒå¤§å°: 2.4MB
# ç‰¹ç‚¹:æ— shell,æ— åŒ…ç®¡ç†å™¨,ä»…è¿è¡Œæ—¶åº“

# â­â­ Scratch(ç©ºé•œåƒ)
FROM scratch
# é•œåƒå¤§å°: 0KB
# é€‚ç”¨:é™æ€ç¼–è¯‘çš„Go/Ruståº”ç”¨
```

**å®æˆ˜:Goåº”ç”¨ä½¿ç”¨scratch**:

```dockerfile
FROM golang:1.21-alpine AS builder
WORKDIR /build
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo \
    -ldflags '-extldflags "-static" -s -w' \
    -o app .

FROM scratch
# æ·»åŠ CAè¯ä¹¦(HTTPSè¯·æ±‚éœ€è¦)
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
# æ·»åŠ æ—¶åŒºæ•°æ®
COPY --from=builder /usr/share/zoneinfo /usr/share/zoneinfo
# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /build/app /app

ENTRYPOINT ["/app"]

# æœ€ç»ˆé•œåƒå¤§å°: ä»…6-10MB(å–å†³äºåº”ç”¨ä»£ç )
```

---

### 6.4.2 ä¾èµ–ç²¾ç®€ä¸è£å‰ª

```dockerfile
# âŒ åæ¨¡å¼:å®‰è£…å®Œæ•´å·¥å…·é“¾
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y \
    build-essential \
    python3-dev \
    libpq-dev \
    curl \
    wget \
    vim \
    git
# é¢å¤–å¢åŠ : 500MB+

# âœ… æœ€ä½³å®è·µ:ä»…å®‰è£…è¿è¡Œæ—¶ä¾èµ–
FROM python:3.11-slim

# åˆ†ç¦»ç¼–è¯‘ä¾èµ–å’Œè¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y --no-install-recommends \
    # ä»…è¿è¡Œæ—¶éœ€è¦çš„åº“
    libpq5=15.5-0+deb12u1 \
 && rm -rf /var/lib/apt/lists/*

# ç¼–è¯‘é˜¶æ®µåœ¨builderé•œåƒä¸­å®Œæˆ(è§å¤šé˜¶æ®µæ„å»º)
```

**Pythonä¾èµ–ä¼˜åŒ–**:

```dockerfile
FROM python:3.11-slim AS builder

# ä»…åœ¨æ„å»ºé˜¶æ®µå®‰è£…ç¼–è¯‘ä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
 && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt

FROM python:3.11-slim
RUN apt-get update && apt-get install -y libpq5 && rm -rf /var/lib/apt/lists/*
COPY --from=builder /wheels /wheels
RUN pip install --no-cache-dir --no-index --find-links=/wheels /wheels/* \
 && rm -rf /wheels

# ä¼˜åŒ–æ•ˆæœ:
# å•é˜¶æ®µ(å«gcc): 850MB
# å¤šé˜¶æ®µä¼˜åŒ–: 180MB (å‡å°‘79%)
```

---

### 6.4.3 æ–‡ä»¶ä¸ç¼“å­˜æ¸…ç†æŠ€å·§

```dockerfile
# âœ… å®Œæ•´çš„æ¸…ç†ç­–ç•¥
FROM python:3.11-slim

# å•å±‚æ‰§è¡Œ:å®‰è£…+æ¸…ç†
RUN apt-get update && apt-get install -y \
    libpq5 \
    curl \
    # æ¸…ç†aptç¼“å­˜
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/* \
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    /tmp/* \
    /var/tmp/* \
    # æ¸…ç†æ—¥å¿—
    /var/log/*.log \
    # æ¸…ç†pipç¼“å­˜
    ~/.cache/pip \
    # æ¸…ç†Pythonç¼“å­˜
    /root/.cache

# pipå®‰è£…æ—¶ç¦ç”¨ç¼“å­˜
RUN pip install --no-cache-dir \
    flask==3.0.0 \
    requests==2.31.0

# å¤åˆ¶ä»£ç åæ¸…ç†ä¸å¿…è¦æ–‡ä»¶
COPY . /app
WORKDIR /app
RUN find . -type f -name '*.pyc' -delete \
 && find . -type d -name '__pycache__' -delete \
 && find . -type d -name '.pytest_cache' -delete \
 && find . -type f -name '*.log' -delete

# Node.jsæ¸…ç†ç¤ºä¾‹
RUN npm ci --only=production \
 && npm cache clean --force \
 && rm -rf /root/.npm /tmp/*

# Alpineæ¸…ç†ç¤ºä¾‹
RUN apk add --no-cache nginx \
 && rm -rf /var/cache/apk/*
```

---

### 6.4.4 é•œåƒå‹ç¼©ä¸å¯¼å‡º

```bash
# æ–¹æ³•1:ä½¿ç”¨docker-slimè‡ªåŠ¨ç˜¦èº«
$ docker-slim build --http-probe=false myapp:v1
# åŸå§‹å¤§å°: 450MB
# ä¼˜åŒ–å: 85MB (å‡å°‘81%)

# docker-slimå·¥ä½œåŸç†:
# 1. è¿è¡Œå®¹å™¨å¹¶ç›‘æ§ç³»ç»Ÿè°ƒç”¨
# 2. è¯†åˆ«å®é™…ä½¿ç”¨çš„æ–‡ä»¶å’Œåº“
# 3. åˆ›å»ºä»…åŒ…å«å¿…è¦æ–‡ä»¶çš„æ–°é•œåƒ

# æ–¹æ³•2:æ‰‹åŠ¨å¯¼å‡ºå¯¼å…¥(å‹å¹³å±‚)
$ docker export mycontainer > app.tar
$ docker import app.tar myapp:slim
# ä¼˜åŠ¿:æ‰€æœ‰å±‚åˆå¹¶ä¸ºä¸€å±‚
# åŠ£åŠ¿:ä¸¢å¤±å†å²è®°å½•å’Œå±‚ç¼“å­˜

# æ–¹æ³•3:ä½¿ç”¨squash(å®éªŒæ€§åŠŸèƒ½)
$ docker build --squash -t myapp:squashed .
# åˆå¹¶æ‰€æœ‰å±‚ä¸ºå•å±‚,å‡å°‘å…ƒæ•°æ®å¼€é”€

# æ–¹æ³•4:ä½¿ç”¨craneä¼˜åŒ–é•œåƒ
$ crane flatten myapp:v1 myapp:flat
# Googleå‡ºå“å·¥å…·,ä¼˜åŒ–å±‚ç»“æ„
```

---

## 6.5 Dockerfileå®‰å…¨æœ€ä½³å®è·µ

### 6.5.1 æœ€å°æƒé™åŸåˆ™

```dockerfile
# âŒ åæ¨¡å¼:ä½¿ç”¨rootç”¨æˆ·
FROM nginx:alpine
COPY nginx.conf /etc/nginx/
CMD ["nginx", "-g", "daemon off;"]

# è¿è¡Œæ—¶:
$ docker exec mynginx whoami
root  # âš ï¸ å®¹å™¨é€ƒé€¸é£é™©

# âœ… æœ€ä½³å®è·µ:éç‰¹æƒç”¨æˆ·
FROM nginx:alpine

# ä¿®æ”¹nginxé…ç½®å…è®¸érootè¿è¡Œ
RUN sed -i 's/user nginx;/user nginx;/g' /etc/nginx/nginx.conf \
 && sed -i 's/listen 80;/listen 8080;/g' /etc/nginx/conf.d/default.conf \
 && chown -R nginx:nginx /var/cache/nginx /var/run /var/log/nginx

USER nginx
EXPOSE 8080
CMD ["nginx", "-g", "daemon off;"]

# âœ… è‡ªå®šä¹‰åº”ç”¨ç¤ºä¾‹
FROM python:3.11-alpine

# åˆ›å»ºä¸“ç”¨ç”¨æˆ·(UID 10000)
RUN addgroup -g 10000 appgroup \
 && adduser -D -u 10000 -G appgroup appuser

WORKDIR /app
COPY --chown=appuser:appgroup . .

# ç¡®ä¿æ—¥å¿—ç›®å½•å¯å†™
RUN mkdir -p /app/logs && chown appuser:appgroup /app/logs

USER appuser

CMD ["python", "app.py"]
```

---

### 6.5.2 é¿å…æ•æ„Ÿä¿¡æ¯æ³„éœ²

```dockerfile
# âŒ åæ¨¡å¼:ç¡¬ç¼–ç å¯†é’¥
FROM python:3.11-slim
ENV DATABASE_PASSWORD=secret123  # âš ï¸ æ˜æ–‡å¯†ç 

# æŸ¥çœ‹é•œåƒå†å²ä¼šæš´éœ²å¯†ç :
$ docker history myapp:v1
IMAGE          CREATED BY
<missing>      ENV DATABASE_PASSWORD=secret123  # âŒ æ³„éœ²!

# âœ… æœ€ä½³å®è·µ1:ä½¿ç”¨secrets
FROM python:3.11-slim
# ä¸åœ¨é•œåƒä¸­å­˜å‚¨å¯†ç 
CMD ["python", "app.py"]

# è¿è¡Œæ—¶æ³¨å…¥:
$ docker run -e DATABASE_PASSWORD=secret123 myapp:v1
# æˆ–ä½¿ç”¨secretsæ–‡ä»¶:
$ docker run --env-file .env myapp:v1

# âœ… æœ€ä½³å®è·µ2:å¤šé˜¶æ®µæ„å»ºéšè—æ„å»ºå¯†é’¥
FROM golang:1.21-alpine AS builder
# æ„å»ºæ—¶éœ€è¦ç§é’¥æ‹‰å–ç§æœ‰ä»“åº“
RUN --mount=type=secret,id=github_token \
    git config --global url."https://$(cat /run/secrets/github_token)@github.com/".insteadOf "https://github.com/" \
 && go mod download

FROM alpine:3.19
COPY --from=builder /build/app /app
# æœ€ç»ˆé•œåƒä¸åŒ…å«github_token âœ…

# æ„å»ºå‘½ä»¤:
$ docker build --secret id=github_token,src=token.txt -t myapp .

# âœ… æœ€ä½³å®è·µ3:ä½¿ç”¨.dockerignoreæ’é™¤æ•æ„Ÿæ–‡ä»¶
# .dockerignoreå†…å®¹:
.env
.env.local
*.key
*.pem
credentials.json
secrets/
```

---

### 6.5.3 é•œåƒç­¾åä¸éªŒè¯

```dockerfile
# Docker Content Trust (DCT)å¯ç”¨

# 1ï¸âƒ£ å¯ç”¨DCT
$ export DOCKER_CONTENT_TRUST=1

# 2ï¸âƒ£ æ¨é€é•œåƒæ—¶è‡ªåŠ¨ç­¾å
$ docker push myregistry.com/myapp:v1.0
# æç¤ºè¾“å…¥root keyå’Œrepository keyå¯†ç 
# ç­¾åå­˜å‚¨åœ¨NotaryæœåŠ¡å™¨

# 3ï¸âƒ£ æ‹‰å–é•œåƒæ—¶è‡ªåŠ¨éªŒè¯
$ docker pull myregistry.com/myapp:v1.0
Pull (1 of 1): myapp:v1.0@sha256:abc123...
Tagging myregistry.com/myapp:v1.0@sha256:abc123 as myapp:v1.0
# âœ… ç­¾åéªŒè¯é€šè¿‡

# 4ï¸âƒ£ ç­¾åéªŒè¯å¤±è´¥ç¤ºä¾‹
$ docker pull myregistry.com/tampered:latest
Error: remote trust data does not exist  # âŒ æ— ç­¾åæˆ–ç­¾åæ— æ•ˆ

# âœ… ä½¿ç”¨Cosignç­¾å(æ¨è)
# å®‰è£…cosign
$ brew install cosign

# ç”Ÿæˆå¯†é’¥å¯¹
$ cosign generate-key-pair

# ç­¾åé•œåƒ
$ cosign sign --key cosign.key myregistry.com/myapp:v1.0

# éªŒè¯é•œåƒ
$ cosign verify --key cosign.pub myregistry.com/myapp:v1.0
# âœ… Verification successful!
```

---

### 6.5.4 é•œåƒæ¼æ´æ‰«æ

```bash
# å·¥å…·1:Trivyæ‰«æ
$ trivy image myapp:v1.0
myapp:v1.0 (debian 12.4)
==========================
Total: 45 (UNKNOWN: 0, LOW: 18, MEDIUM: 20, HIGH: 5, CRITICAL: 2)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Library      â”‚  Vulnerability  â”‚ Severity â”‚ Installed Ver  â”‚   Fixed Version   â”‚       Title        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ openssl         â”‚ CVE-2023-12345  â”‚ CRITICAL â”‚ 3.0.2-0deb12u1 â”‚ 3.0.2-0deb12u2    â”‚ OpenSSL buffer ... â”‚
â”‚ curl            â”‚ CVE-2023-54321  â”‚ HIGH     â”‚ 7.88.1-10      â”‚ 7.88.1-10+deb12u1 â”‚ curl HTTPS proxy..â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# å·¥å…·2:Grypeæ‰«æ
$ grype myapp:v1.0
NAME       INSTALLED  VULNERABILITY  SEVERITY
openssl    3.0.2      CVE-2023-12345 Critical
curl       7.88.1     CVE-2023-54321 High

# å·¥å…·3:Clair(Red Hat)
$ clairctl report myapp:v1.0

# å·¥å…·4:Docker Scout(å®˜æ–¹)
$ docker scout cves myapp:v1.0
    âœ“ Image stored for indexing
    âœ“ Indexed 178 packages
    âœ“ No vulnerable package detected

# CIé›†æˆ:GitHub Actionsç¤ºä¾‹
# .github/workflows/security-scan.yml
name: Security Scan
on: [push]
jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build image
        run: docker build -t myapp:${{ github.sha }} .
      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: myapp:${{ github.sha }}
          severity: 'CRITICAL,HIGH'
          exit-code: '1'  # å‘ç°æ¼æ´åˆ™å¤±è´¥
```

---

### 6.5.5 åªè¯»æ–‡ä»¶ç³»ç»Ÿä¸å®‰å…¨é…ç½®

```dockerfile
# Dockerfile:æ”¯æŒåªè¯»æ–‡ä»¶ç³»ç»Ÿ
FROM python:3.11-alpine

RUN adduser -D appuser

WORKDIR /app
COPY --chown=appuser:appuser . .

# åˆ›å»ºå¯å†™ç›®å½•(åªè¯»æ¨¡å¼ä¸‹ä»éœ€è¦)
RUN mkdir -p /tmp/app-cache /tmp/app-logs \
 && chown appuser:appuser /tmp/app-cache /tmp/app-logs

USER appuser

# åº”ç”¨é…ç½®:ä½¿ç”¨/tmpä½œä¸ºä¸´æ—¶ç›®å½•
ENV TMPDIR=/tmp/app-cache

CMD ["python", "app.py"]

# è¿è¡Œæ—¶é…ç½®:
$ docker run -d \
  --name myapp \
  --read-only \  # âœ… å¯ç”¨åªè¯»æ–‡ä»¶ç³»ç»Ÿ
  --tmpfs /tmp:rw,noexec,nosuid,size=100m \  # æŒ‚è½½ä¸´æ—¶ç›®å½•
  --security-opt=no-new-privileges:true \  # ç¦æ­¢æƒé™æå‡
  --cap-drop=ALL \  # ç§»é™¤æ‰€æœ‰capabilities
  --cap-add=NET_BIND_SERVICE \  # ä»…æ·»åŠ å¿…è¦çš„capability
  myapp:v1.0

# éªŒè¯åªè¯»æ–‡ä»¶ç³»ç»Ÿ:
$ docker exec myapp touch /test.txt
touch: /test.txt: Read-only file system  # âœ… ç¬¦åˆé¢„æœŸ

$ docker exec myapp touch /tmp/app-cache/test.txt
# âœ… æˆåŠŸåˆ›å»º(tmpfså¯å†™)
```

---

## 6.6 æ„å»ºæ€§èƒ½ä¼˜åŒ–

### 6.6.1 BuildKitç‰¹æ€§

```bash
# å¯ç”¨BuildKit(Docker 18.09+)
$ export DOCKER_BUILDKIT=1
$ docker build -t myapp:v1 .

# BuildKitä¼˜åŠ¿:
# 1. å¹¶è¡Œæ„å»ºæ— ä¾èµ–çš„é˜¶æ®µ
# 2. è·³è¿‡æœªä½¿ç”¨çš„é˜¶æ®µ
# 3. æ›´å¥½çš„ç¼“å­˜ç®¡ç†
# 4. æ„å»ºæ—¶secretsæ”¯æŒ

# âœ… å¹¶è¡Œæ„å»ºç¤ºä¾‹
FROM alpine:3.19 AS stage1
RUN sleep 10 && echo "Stage 1 done"

FROM alpine:3.19 AS stage2
RUN sleep 10 && echo "Stage 2 done"

FROM alpine:3.19
COPY --from=stage1 /etc/alpine-release /stage1
COPY --from=stage2 /etc/alpine-release /stage2

# ä¼ ç»Ÿæ¨¡å¼:ä¸²è¡Œæ‰§è¡Œ,æ€»è€—æ—¶20ç§’
# BuildKit:å¹¶è¡Œæ‰§è¡Œ,æ€»è€—æ—¶10ç§’ âš¡

# âœ… ç¼“å­˜æŒ‚è½½(cache mount)
FROM golang:1.21-alpine
RUN --mount=type=cache,target=/root/.cache/go-build \
    --mount=type=cache,target=/go/pkg/mod \
    go build -o app .

# æ•ˆæœ:go buildç¼“å­˜æŒä¹…åŒ–,é‡å¤æ„å»ºé€Ÿåº¦æå‡10å€

# âœ… æ„å»ºæ—¶secrets
FROM alpine:3.19
RUN --mount=type=secret,id=npm_token \
    echo "//registry.npmjs.org/:_authToken=$(cat /run/secrets/npm_token)" > ~/.npmrc \
 && npm install

# æ„å»ºå‘½ä»¤:
$ docker build --secret id=npm_token,src=token.txt -t myapp .

# âœ… SSH agentè½¬å‘
FROM alpine:3.19
RUN apk add git openssh-client
RUN --mount=type=ssh \
    git clone git@github.com:private/repo.git

# æ„å»ºå‘½ä»¤:
$ docker build --ssh default -t myapp .
```

---

### 6.6.2 ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

```dockerfile
# âœ… ç­–ç•¥1:æŒ‰å˜æ›´é¢‘ç‡åˆ†å±‚
FROM node:18-alpine

# 1ï¸âƒ£ å®‰è£…å…¨å±€å·¥å…·(å‡ ä¹ä¸å˜)
RUN npm install -g pnpm@8.15.0

# 2ï¸âƒ£ å¤åˆ¶lockæ–‡ä»¶(å¶å°”å˜æ›´)
COPY package.json pnpm-lock.yaml ./
RUN pnpm install --frozen-lockfile

# 3ï¸âƒ£ å¤åˆ¶æºç (é¢‘ç¹å˜æ›´)
COPY src ./src
RUN pnpm build

# âœ… ç­–ç•¥2:åˆ©ç”¨.dockerignoreå‡å°‘ç¼“å­˜å¤±æ•ˆ
# .dockerignoreå†…å®¹:
node_modules/
dist/
*.log
.git/

# ä¸åŒ…å«README.mdå˜æ›´ä¸ä¼šå¯¼è‡´COPYå±‚å¤±æ•ˆ

# âœ… ç­–ç•¥3:ä½¿ç”¨é€šé…ç¬¦å¤åˆ¶ç‰¹å®šæ–‡ä»¶
COPY package*.json ./  # ä»…å¤åˆ¶package.jsonå’Œpackage-lock.json
RUN npm ci

COPY src/ ./src/       # ä»…å¤åˆ¶srcç›®å½•
COPY *.config.js ./    # ä»…å¤åˆ¶é…ç½®æ–‡ä»¶

# âœ… ç­–ç•¥4:BuildKitç¼“å­˜åç«¯
# ä½¿ç”¨æœ¬åœ°ç¼“å­˜:
$ docker build --cache-from=type=local,src=/tmp/cache \
               --cache-to=type=local,dest=/tmp/cache \
               -t myapp .

# ä½¿ç”¨Registryç¼“å­˜:
$ docker build --cache-from=myregistry.com/myapp:cache \
               --cache-to=type=registry,ref=myregistry.com/myapp:cache \
               -t myapp .

# CIç¯å¢ƒç¤ºä¾‹(GitHub Actions)
- name: Build with cache
  uses: docker/build-push-action@v5
  with:
    context: .
    cache-from: type=gha
    cache-to: type=gha,mode=max
```

---

### 6.6.3 æ„å»ºæ—¶é—´å¯¹æ¯”

```bash
# åœºæ™¯:Node.jsåº”ç”¨æ„å»ºä¼˜åŒ–å¯¹æ¯”

# âŒ æœªä¼˜åŒ–Dockerfile:
FROM node:18
COPY . /app
WORKDIR /app
RUN npm install
RUN npm run build
CMD ["node", "dist/main.js"]

# åˆæ¬¡æ„å»º: 180ç§’
# ä¿®æ”¹ä»£ç å: 175ç§’ (ç¼“å­˜å‡ ä¹æ— æ•ˆ)

# âœ… ä¼˜åŒ–åDockerfile:
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production \
 && cp -R node_modules /tmp/prod_modules \
 && npm ci
COPY . .
RUN npm run build

FROM node:18-alpine
WORKDIR /app
COPY --from=builder /tmp/prod_modules ./node_modules
COPY --from=builder /app/dist ./dist
CMD ["node", "dist/main.js"]

# åˆæ¬¡æ„å»º: 120ç§’ (å‡å°‘33%)
# ä¿®æ”¹ä»£ç å: 8ç§’ (ç¼“å­˜æœ‰æ•ˆ,å‡å°‘96%)

# æ€§èƒ½æå‡æ€»ç»“:
# - ä½¿ç”¨alpine: -30% é•œåƒå¤§å°
# - åˆ†ç¦»ä¾èµ–å®‰è£…: +95% ç¼“å­˜å‘½ä¸­ç‡
# - å¤šé˜¶æ®µæ„å»º: -65% æœ€ç»ˆé•œåƒå¤§å°
# - æ¸…ç†ç¼“å­˜: -20% å±‚å¤§å°
```

---

## 6.7 ç”Ÿäº§ç¯å¢ƒDockerfileæ¨¡æ¿

### 6.7.1 Goå¾®æœåŠ¡æ¨¡æ¿

```dockerfile
# ==============================================
# å¤šé˜¶æ®µæ„å»º - Goå¾®æœåŠ¡ç”Ÿäº§æ¨¡æ¿
# ==============================================
ARG GO_VERSION=1.21.5
ARG ALPINE_VERSION=3.19

# ================ æ„å»ºé˜¶æ®µ ================
FROM golang:${GO_VERSION}-alpine AS builder

# å®‰è£…ç¼–è¯‘ä¾èµ–
RUN apk add --no-cache git make ca-certificates tzdata

WORKDIR /build

# åˆ©ç”¨ç¼“å­˜:å…ˆä¸‹è½½ä¾èµ–
COPY go.mod go.sum ./
RUN go mod download && go mod verify

# å¤åˆ¶æºç 
COPY . .

# ç¼–è¯‘å‚æ•°ä¼˜åŒ–
ARG VERSION=dev
ARG BUILD_TIME
ARG COMMIT_SHA

RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
    -a -installsuffix cgo \
    -ldflags="-s -w \
              -X main.version=${VERSION} \
              -X main.buildTime=${BUILD_TIME} \
              -X main.commitSHA=${COMMIT_SHA}" \
    -o app \
    ./cmd/server

# éªŒè¯äºŒè¿›åˆ¶æ–‡ä»¶
RUN ./app --version

# ================ è¿è¡Œé˜¶æ®µ ================
FROM alpine:${ALPINE_VERSION}

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apk add --no-cache ca-certificates tzdata \
 && addgroup -S appgroup -g 10000 \
 && adduser -S appuser -u 10000 -G appgroup

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶æ–‡ä»¶
COPY --from=builder /build/app /usr/local/bin/app
COPY --from=builder /build/configs /etc/app/

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD ["/usr/local/bin/app", "healthcheck"]

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

USER appuser
WORKDIR /home/appuser

EXPOSE 8080

ENTRYPOINT ["/usr/local/bin/app"]
CMD ["--config", "/etc/app/config.yaml"]

# æ„å»ºå‘½ä»¤:
# docker build \
#   --build-arg VERSION=1.0.0 \
#   --build-arg BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ") \
#   --build-arg COMMIT_SHA=$(git rev-parse HEAD) \
#   -t myapp:1.0.0 .
```

---

### 6.7.2 Python Webåº”ç”¨æ¨¡æ¿

```dockerfile
# ==============================================
# å¤šé˜¶æ®µæ„å»º - Pythonç”Ÿäº§æ¨¡æ¿
# ==============================================
ARG PYTHON_VERSION=3.11.7

# ================ ä¾èµ–ç¼–è¯‘é˜¶æ®µ ================
FROM python:${PYTHON_VERSION}-slim AS builder

# å®‰è£…ç¼–è¯‘ä¾èµ–
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    libpq-dev \
    libffi-dev \
 && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# å‡çº§pipå·¥å…·
RUN pip install --no-cache-dir -U pip setuptools wheel

# å®‰è£…ä¾èµ–
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# ================ è¿è¡Œé˜¶æ®µ ================
FROM python:${PYTHON_VERSION}-slim

# å®‰è£…è¿è¡Œæ—¶åº“
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 \
    curl \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN groupadd -r appuser -g 10000 \
 && useradd -r -u 10000 -g appuser -d /app -s /sbin/nologin appuser

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶è™šæ‹Ÿç¯å¢ƒ
COPY --from=builder /opt/venv /opt/venv

WORKDIR /app

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=appuser:appuser . .

# ç¯å¢ƒå˜é‡
ENV PATH="/opt/venv/bin:$PATH" \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

USER appuser

EXPOSE 8000

# ä½¿ç”¨Gunicornè¿è¡Œ
CMD ["gunicorn", \
     "--bind", "0.0.0.0:8000", \
     "--workers", "4", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--access-logfile", "-", \
     "--error-logfile", "-", \
     "main:app"]
```

---

### 6.7.3 Node.jsåº”ç”¨æ¨¡æ¿

```dockerfile
# ==============================================
# å¤šé˜¶æ®µæ„å»º - Node.jsç”Ÿäº§æ¨¡æ¿
# ==============================================
ARG NODE_VERSION=18.19.0

# ================ ä¾èµ–å®‰è£…é˜¶æ®µ ================
FROM node:${NODE_VERSION}-alpine AS deps

RUN apk add --no-cache libc6-compat python3 make g++

WORKDIR /app

COPY package.json package-lock.json* ./
RUN npm ci --only=production \
 && cp -R node_modules /tmp/prod_modules \
 && npm ci  # å®‰è£…å…¨éƒ¨ä¾èµ–ç”¨äºæ„å»º

# ================ æ„å»ºé˜¶æ®µ ================
FROM node:${NODE_VERSION}-alpine AS builder

WORKDIR /app

COPY --from=deps /app/node_modules ./node_modules
COPY . .

# TypeScriptç¼–è¯‘æˆ–Webpackæ‰“åŒ…
RUN npm run build

# ================ è¿è¡Œé˜¶æ®µ ================
FROM node:${NODE_VERSION}-alpine

# å®‰è£…dumb-initå’Œå®‰å…¨æ›´æ–°
RUN apk add --no-cache dumb-init \
 && apk upgrade --no-cache

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 10000 nodejs \
 && adduser -u 10000 -G nodejs -s /bin/sh -D nodejs

WORKDIR /app

# ä»ä¾èµ–é˜¶æ®µå¤åˆ¶ç”Ÿäº§ä¾èµ–
COPY --from=deps /tmp/prod_modules ./node_modules
# ä»æ„å»ºé˜¶æ®µå¤åˆ¶ç¼–è¯‘äº§ç‰©
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/package.json ./

# ç¯å¢ƒå˜é‡
ENV NODE_ENV=production \
    NODE_OPTIONS="--max-old-space-size=2048"

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

USER nodejs

EXPOSE 3000

# ä½¿ç”¨dumb-initå¤„ç†ä¿¡å·
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]
```

---

## 6.8 æœ¬ç« æ€»ç»“ä¸æ£€æŸ¥æ¸…å•

### 6.8.1 Dockerfileä»£ç å®¡æŸ¥æ¸…å•

```markdown
## åŸºç¡€é…ç½®
- [ ] ä½¿ç”¨æ˜ç¡®çš„åŸºç¡€é•œåƒç‰ˆæœ¬(å¸¦digest)
- [ ] é€‰æ‹©åˆé€‚çš„åŸºç¡€é•œåƒ(alpine/slim/distroless)
- [ ] è®¾ç½®LABELå…ƒæ•°æ®(maintainer, versionç­‰)

## å®‰å…¨æ€§
- [ ] ä½¿ç”¨érootç”¨æˆ·è¿è¡Œ(USERæŒ‡ä»¤)
- [ ] ä¸åœ¨é•œåƒä¸­ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
- [ ] é€šè¿‡.dockerignoreæ’é™¤æ•æ„Ÿæ–‡ä»¶
- [ ] å¯ç”¨åªè¯»æ–‡ä»¶ç³»ç»Ÿ(è¿è¡Œæ—¶--read-only)
- [ ] ç§»é™¤ä¸å¿…è¦çš„ç³»ç»Ÿå·¥å…·(shell, package manager)

## é•œåƒå¤§å°
- [ ] ä½¿ç”¨å¤šé˜¶æ®µæ„å»º
- [ ] åˆå¹¶RUNæŒ‡ä»¤å‡å°‘å±‚æ•°
- [ ] æ¸…ç†åŒ…ç®¡ç†å™¨ç¼“å­˜
- [ ] åˆ é™¤ä¸´æ—¶æ–‡ä»¶å’Œæ—¥å¿—
- [ ] ä»…å®‰è£…å¿…è¦çš„è¿è¡Œæ—¶ä¾èµ–

## æ„å»ºæ€§èƒ½
- [ ] æŒ‰å˜æ›´é¢‘ç‡æ’åºæŒ‡ä»¤(ä¾èµ–åœ¨å‰,ä»£ç åœ¨å)
- [ ] ä½¿ç”¨.dockerignoreå‡å°‘æ„å»ºä¸Šä¸‹æ–‡
- [ ] åˆ©ç”¨BuildKitç¼“å­˜ç‰¹æ€§
- [ ] ä½¿ç”¨ç¼“å­˜æŒ‚è½½(--mount=type=cache)

## è¿è¡Œæ—¶
- [ ] è®¾ç½®HEALTHCHECKå¥åº·æ£€æŸ¥
- [ ] ä½¿ç”¨Execæ ¼å¼çš„CMD/ENTRYPOINT
- [ ] è®¾ç½®åˆç†çš„EXPOSEç«¯å£
- [ ] é…ç½®é€‚å½“çš„ç¯å¢ƒå˜é‡
- [ ] ä½¿ç”¨dumb-initå¤„ç†ä¿¡å·(Node.js)

## å¯ç»´æŠ¤æ€§
- [ ] æ·»åŠ æ³¨é‡Šè¯´æ˜å¤æ‚é€»è¾‘
- [ ] ä½¿ç”¨ARGæ”¯æŒæ„å»ºå‚æ•°åŒ–
- [ ] ç‰ˆæœ¬ä¿¡æ¯ç¼–è¯‘åˆ°äºŒè¿›åˆ¶(ldflags)
- [ ] éµå¾ªé¡¹ç›®å‘½åè§„èŒƒ
```

---

### 6.8.2 é•œåƒè´¨é‡æŒ‡æ ‡

```bash
# 1ï¸âƒ£ é•œåƒå¤§å°
$ docker images myapp
REPOSITORY   TAG   SIZE
myapp        v1    15MB    # âœ… ä¼˜ç§€: <50MB
myapp        v2    180MB   # âš ï¸ å¯æ¥å—: 50-300MB
myapp        v3    850MB   # âŒ éœ€ä¼˜åŒ–: >300MB

# 2ï¸âƒ£ å±‚æ•°
$ docker history myapp:v1 | wc -l
8  # âœ… ä¼˜ç§€: <10å±‚

# 3ï¸âƒ£ æ¼æ´æ•°é‡
$ trivy image myapp:v1
Total: 0 (CRITICAL: 0, HIGH: 0)  # âœ… ç›®æ ‡

# 4ï¸âƒ£ æ„å»ºæ—¶é—´
$ time docker build -t myapp:v1 .
real    0m45.234s  # âœ… é¦–æ¬¡æ„å»º<2åˆ†é’Ÿ
real    0m5.123s   # âœ… ç¼“å­˜æ„å»º<10ç§’

# 5ï¸âƒ£ å¯åŠ¨æ—¶é—´
$ docker run -d myapp:v1
$ docker logs myapp
Server started in 1.2s  # âœ… <5ç§’å¯åŠ¨
```

---

---

# ç¬¬7ç« :é•œåƒä»“åº“ä¸åˆ†å‘ç®¡ç†

## 7.1 Docker Registryæ·±åº¦å‰–æ

### 7.1.1 Docker Hubä½¿ç”¨è¿›é˜¶

```bash
# ç™»å½•Docker Hub
$ docker login
Username: myusername
Password:
Login Succeeded

# æ ‡è®°é•œåƒ
$ docker tag myapp:latest myusername/myapp:1.0.0
$ docker tag myapp:latest myusername/myapp:latest

# æ¨é€é•œåƒ
$ docker push myusername/myapp:1.0.0
$ docker push myusername/myapp:latest

# æœç´¢é•œåƒ
$ docker search nginx
NAME                DESCRIPTION                     STARS  OFFICIAL
nginx               Official build of Nginx         18000  [OK]
jwilder/nginx-proxy Automated Nginx reverse proxy   2200

# é™é€Ÿä¸é…é¢(å…è´¹è´¦æˆ·)
# - Pull: 100æ¬¡/6å°æ—¶ (åŒ¿åç”¨æˆ·)
# - Pull: 200æ¬¡/6å°æ—¶ (è®¤è¯ç”¨æˆ·)
# - Push: æ— é™åˆ¶
# - å­˜å‚¨: 1ä¸ªç§æœ‰ä»“åº“(å…è´¹ç‰ˆ)

# è‡ªåŠ¨æ„å»º(Automated Builds)
# 1. å…³è”GitHub/GitLabä»“åº“
# 2. é…ç½®Dockerfileè·¯å¾„
# 3. è®¾ç½®è§¦å‘è§„åˆ™(push/tag)
# 4. Docker Hubè‡ªåŠ¨æ„å»ºå¹¶æ¨é€
```

**Docker Hub APIä½¿ç”¨**:

```bash
# è·å–Token
$ TOKEN=$(curl -s -H "Content-Type: application/json" \
  -X POST -d '{"username":"'${DOCKER_USER}'","password":"'${DOCKER_PASS}'"}' \
  https://hub.docker.com/v2/users/login/ | jq -r .token)

# åˆ—å‡ºä»“åº“
$ curl -s -H "Authorization: Bearer $TOKEN" \
  https://hub.docker.com/v2/repositories/myusername/ | jq .

# åˆ é™¤é•œåƒæ ‡ç­¾
$ curl -X DELETE -H "Authorization: Bearer $TOKEN" \
  https://hub.docker.com/v2/repositories/myusername/myapp/tags/old-tag/

# è·å–é•œåƒmanifest
$ curl -s -H "Accept: application/vnd.docker.distribution.manifest.v2+json" \
  https://registry-1.docker.io/v2/library/nginx/manifests/latest
```

---

### 7.1.2 ç§æœ‰Registryéƒ¨ç½²

**æ–¹å¼1:å®˜æ–¹Registryé•œåƒ**:

```bash
# å¯åŠ¨åŸºç¡€Registry
$ docker run -d \
  --name registry \
  -p 5000:5000 \
  -v /data/registry:/var/lib/registry \
  --restart=always \
  registry:2

# æ¨é€é•œåƒåˆ°ç§æœ‰ä»“åº“
$ docker tag myapp:latest localhost:5000/myapp:latest
$ docker push localhost:5000/myapp:latest

# æŸ¥çœ‹ä»“åº“ä¸­çš„é•œåƒ
$ curl http://localhost:5000/v2/_catalog
{"repositories":["myapp"]}

# æŸ¥çœ‹é•œåƒæ ‡ç­¾
$ curl http://localhost:5000/v2/myapp/tags/list
{"name":"myapp","tags":["latest","1.0.0"]}
```

**æ–¹å¼2:å¯ç”¨TLSå’Œè®¤è¯**:

```bash
# 1ï¸âƒ£ ç”Ÿæˆè‡ªç­¾åè¯ä¹¦
$ mkdir -p /data/certs
$ openssl req -newkey rsa:4096 -nodes -sha256 \
  -keyout /data/certs/domain.key \
  -x509 -days 365 -out /data/certs/domain.crt \
  -subj "/CN=registry.example.com"

# 2ï¸âƒ£ ç”Ÿæˆhtpasswdè®¤è¯æ–‡ä»¶
$ mkdir -p /data/auth
$ docker run --rm \
  --entrypoint htpasswd \
  httpd:2 -Bbn admin secretpass > /data/auth/htpasswd

# 3ï¸âƒ£ å¯åŠ¨Registry with TLS + Auth
$ docker run -d \
  --name secure-registry \
  -p 443:5000 \
  -v /data/registry:/var/lib/registry \
  -v /data/certs:/certs \
  -v /data/auth:/auth \
  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \
  -e REGISTRY_AUTH=htpasswd \
  -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \
  -e REGISTRY_AUTH_HTPASSWD_REALM="Registry Realm" \
  --restart=always \
  registry:2

# 4ï¸âƒ£ å®¢æˆ·ç«¯é…ç½®ä¿¡ä»»è¯ä¹¦
$ sudo mkdir -p /etc/docker/certs.d/registry.example.com
$ sudo cp /data/certs/domain.crt /etc/docker/certs.d/registry.example.com/ca.crt

# 5ï¸âƒ£ ç™»å½•å¹¶ä½¿ç”¨
$ docker login registry.example.com
Username: admin
Password: secretpass

$ docker push registry.example.com/myapp:latest
```

**Registryé…ç½®æ–‡ä»¶è¯¦è§£**:

```yaml
# /etc/docker/registry/config.yml
version: 0.1
log:
  level: info
  formatter: text
  fields:
    service: registry

storage:
  # å­˜å‚¨åç«¯:filesystem / s3 / gcs / azure / swift
  filesystem:
    rootdirectory: /var/lib/registry
  delete:
    enabled: true  # å…è®¸åˆ é™¤é•œåƒ
  cache:
    blobdescriptor: inmemory
  maintenance:
    uploadpurging:
      enabled: true
      age: 168h
      interval: 24h
      dryrun: false

http:
  addr: :5000
  secret: asecretforlocaldevelopment
  headers:
    X-Content-Type-Options: [nosniff]
  http2:
    disabled: false
  # é…ç½®TLS
  tls:
    certificate: /certs/domain.crt
    key: /certs/domain.key

auth:
  htpasswd:
    realm: basic-realm
    path: /auth/htpasswd

# å¥åº·æ£€æŸ¥
health:
  storagedriver:
    enabled: true
    interval: 10s
    threshold: 3

# ä»£ç†é…ç½®(ç¼“å­˜Docker Hub)
proxy:
  remoteurl: https://registry-1.docker.io
  username: [username]
  password: [password]

# Redisç¼“å­˜(å¯é€‰)
redis:
  addr: redis:6379
  password: secret
  db: 0
  dialtimeout: 10ms
  readtimeout: 10ms
  writetimeout: 10ms
  pool:
    maxidle: 16
    maxactive: 64
    idletimeout: 300s
```

---

### 7.1.3 Harborä¼ä¸šçº§ä»“åº“

```yaml
# harbor docker-compose.ymlç®€åŒ–ç‰ˆ
version: '3'

services:
  registry:
    image: goharbor/registry-photon:v2.9.0
    volumes:
      - /data/registry:/storage
    networks:
      - harbor

  portal:
    image: goharbor/harbor-portal:v2.9.0
    networks:
      - harbor

  core:
    image: goharbor/harbor-core:v2.9.0
    env_file:
      - ./common/config/core/env
    volumes:
      - /data/ca_download/:/etc/core/ca/
      - /data/:/data/
    networks:
      - harbor
    depends_on:
      - registry

  jobservice:
    image: goharbor/harbor-jobservice:v2.9.0
    env_file:
      - ./common/config/jobservice/env
    volumes:
      - /data/job_logs:/var/log/jobs
    networks:
      - harbor

  redis:
    image: goharbor/redis-photon:v2.9.0
    networks:
      - harbor

  postgresql:
    image: goharbor/harbor-db:v2.9.0
    env_file:
      - ./common/config/db/env
    volumes:
      - /data/database:/var/lib/postgresql/data
    networks:
      - harbor

  nginx:
    image: goharbor/nginx-photon:v2.9.0
    ports:
      - 80:8080
      - 443:8443
    volumes:
      - ./common/config/nginx:/etc/nginx:z
    networks:
      - harbor
    depends_on:
      - core
      - portal

networks:
  harbor:
    external: false
```

**Harboræ ¸å¿ƒåŠŸèƒ½**:

```bash
# 1ï¸âƒ£ å®‰è£…Harbor
$ wget https://github.com/goharbor/harbor/releases/download/v2.9.0/harbor-offline-installer-v2.9.0.tgz
$ tar xvf harbor-offline-installer-v2.9.0.tgz
$ cd harbor
$ cp harbor.yml.tmpl harbor.yml

# ç¼–è¾‘harbor.yml
$ vim harbor.yml
hostname: harbor.example.com
http:
  port: 80
https:
  port: 443
  certificate: /data/cert/server.crt
  private_key: /data/cert/server.key
harbor_admin_password: Harbor12345
database:
  password: root123

# å®‰è£…
$ sudo ./install.sh --with-trivy --with-chartmuseum

# 2ï¸âƒ£ ä½¿ç”¨Harbor CLI
$ docker login harbor.example.com
$ docker tag myapp:latest harbor.example.com/library/myapp:1.0.0
$ docker push harbor.example.com/library/myapp:1.0.0

# 3ï¸âƒ£ å¤åˆ¶è§„åˆ™(è·¨RegistryåŒæ­¥)
# Web UI: Administration â†’ Replications â†’ New Replication Rule
# - æºä»“åº“: harbor-source
# - ç›®æ ‡ä»“åº“: harbor-target
# - è§¦å‘å™¨: Manual / Scheduled / Event Based

# 4ï¸âƒ£ æ¼æ´æ‰«æ(é›†æˆTrivy)
# Web UI: Projects â†’ library â†’ myapp â†’ Scan
# æˆ–é€šè¿‡API:
$ curl -X POST \
  -H "Authorization: Basic $(echo -n admin:Harbor12345 | base64)" \
  https://harbor.example.com/api/v2.0/projects/library/repositories/myapp/artifacts/1.0.0/scan

# 5ï¸âƒ£ é•œåƒç­¾å(Notaryé›†æˆ)
$ export DOCKER_CONTENT_TRUST=1
$ export DOCKER_CONTENT_TRUST_SERVER=https://harbor.example.com:4443
$ docker push harbor.example.com/library/myapp:signed
```

---

## 7.2 é•œåƒåˆ†å‘ä¼˜åŒ–

### 7.2.1 é•œåƒåŠ é€Ÿå™¨é…ç½®

```json
// /etc/docker/daemon.json
{
  "registry-mirrors": [
    "https://mirror.ccs.tencentyun.com",
    "https://hub-mirror.c.163.com",
    "https://docker.mirrors.ustc.edu.cn"
  ],
  "max-concurrent-downloads": 10,
  "max-concurrent-uploads": 5
}
```

**æ€§èƒ½å¯¹æ¯”**:

```bash
# æ— åŠ é€Ÿå™¨(å›½å¤–ç›´è¿Docker Hub)
$ time docker pull nginx:alpine
real    3m45.234s  # âš ï¸ 3åˆ†45ç§’

# å¯ç”¨å›½å†…åŠ é€Ÿå™¨
$ sudo systemctl restart docker
$ time docker pull nginx:alpine
real    0m12.567s  # âœ… 12ç§’(æé€Ÿ18å€)
```

---

### 7.2.2 Registryä»£ç†ç¼“å­˜

```bash
# éƒ¨ç½²Pull-through Cache Registry
$ docker run -d \
  --name registry-cache \
  -p 5000:5000 \
  -e REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io \
  -e REGISTRY_PROXY_USERNAME=dockerhub_user \
  -e REGISTRY_PROXY_PASSWORD=dockerhub_pass \
  -v /data/registry-cache:/var/lib/registry \
  --restart=always \
  registry:2

# é…ç½®Dockerä½¿ç”¨ç¼“å­˜
$ cat /etc/docker/daemon.json
{
  "registry-mirrors": ["http://localhost:5000"]
}

# é¦–æ¬¡æ‹‰å–(ä»Docker Hub)
$ time docker pull nginx:alpine
real    0m45s  # ä»Docker Hubä¸‹è½½

# äºŒæ¬¡æ‹‰å–(ä»ç¼“å­˜)
$ docker rmi nginx:alpine
$ time docker pull nginx:alpine
real    0m3s   # âœ… ä»æœ¬åœ°ç¼“å­˜,é€Ÿåº¦æå‡15å€
```

---

### 7.2.3 åˆ†å±‚æ‹‰å–ä¼˜åŒ–

```bash
# æŸ¥çœ‹é•œåƒå±‚ä¿¡æ¯
$ docker inspect nginx:alpine | jq '.[0].RootFS.Layers'
[
  "sha256:abc123...",
  "sha256:def456...",
  "sha256:ghi789..."
]

# å¹¶è¡Œä¸‹è½½å±‚(daemon.jsoné…ç½®)
{
  "max-concurrent-downloads": 10,  # å¹¶è¡Œä¸‹è½½å±‚æ•°
  "max-download-attempts": 5       # ä¸‹è½½å¤±è´¥é‡è¯•æ¬¡æ•°
}

# åˆ†å±‚å¤ç”¨ç¤ºä¾‹
$ docker pull python:3.11-alpine  # ä¸‹è½½3å±‚,å…±50MB
$ docker pull python:3.11-slim     # å¤ç”¨2å±‚,ä»…æ–°å¢1å±‚(40MB)
# å®é™…ä¸‹è½½: 50MB + 40MB = 90MB (è€Œé110MB)
```

---

## 7.3 é•œåƒæ¸…ç†ä¸åƒåœ¾å›æ”¶

### 7.3.1 å®¢æˆ·ç«¯æ¸…ç†

```bash
# åˆ é™¤æœªä½¿ç”¨çš„é•œåƒ
$ docker image prune
WARNING! This will remove all dangling images.
Are you sure? [y/N] y
Deleted Images:
untagged: myapp@sha256:abc123...
deleted: sha256:def456...
Total reclaimed space: 1.2GB

# åˆ é™¤æ‰€æœ‰æœªä½¿ç”¨çš„é•œåƒ(åŒ…æ‹¬æœ‰æ ‡ç­¾çš„)
$ docker image prune -a
Total reclaimed space: 5.8GB

# åˆ é™¤ç‰¹å®šæ—¶é—´å‰çš„é•œåƒ
$ docker image prune -a --filter "until=24h"

# ç³»ç»Ÿå…¨é¢æ¸…ç†
$ docker system prune -a --volumes
WARNING! This will remove:
  - all stopped containers
  - all networks not used by at least one container
  - all volumes not used by at least one container
  - all images without at least one container associated to them
  - all build cache
Total reclaimed space: 12.4GB
```

---

### 7.3.2 Registryåƒåœ¾å›æ”¶

```bash
# 1ï¸âƒ£ å¯ç”¨Registryåˆ é™¤åŠŸèƒ½
# /etc/docker/registry/config.yml
storage:
  delete:
    enabled: true

# 2ï¸âƒ£ é€šè¿‡APIåˆ é™¤é•œåƒæ ‡ç­¾
$ curl -X DELETE http://registry:5000/v2/myapp/manifests/sha256:abc123...

# 3ï¸âƒ£ è¿è¡Œåƒåœ¾å›æ”¶
$ docker exec registry bin/registry garbage-collect /etc/docker/registry/config.yml
myapp: marking manifest sha256:abc123...
myapp: marking blob sha256:def456...
3 blobs marked, 2 blobs eligible for deletion
blob eligible for deletion: sha256:ghi789...
INFO[0001] Deleting blob: /docker/registry/v2/blobs/sha256/gh/ghi789...

# åˆ é™¤å‰ç£ç›˜å ç”¨
$ du -sh /data/registry
5.2G    /data/registry

# åˆ é™¤åç£ç›˜å ç”¨
$ du -sh /data/registry
2.1G    /data/registry  # âœ… å›æ”¶3.1GBç©ºé—´

# âš ï¸ åƒåœ¾å›æ”¶æ³¨æ„äº‹é¡¹:
# 1. åœæ­¢RegistryæœåŠ¡å†æ‰§è¡ŒGC(é¿å…å¹¶å‘é—®é¢˜)
# 2. GCè¿‡ç¨‹ä¸­Registryåªè¯»
# 3. å®šæœŸæ‰§è¡Œ(å»ºè®®æ¯å‘¨)
```

**è‡ªåŠ¨åŒ–æ¸…ç†è„šæœ¬**:

```bash
#!/bin/bash
# registry-gc.sh

REGISTRY_CONTAINER="registry"
REGISTRY_CONFIG="/etc/docker/registry/config.yml"

echo "=== Registry Garbage Collection ==="
echo "Starting at: $(date)"

# 1. åœæ­¢Registry
docker stop $REGISTRY_CONTAINER

# 2. æ‰§è¡Œåƒåœ¾å›æ”¶
docker run --rm \
  -v /data/registry:/var/lib/registry \
  -v /etc/docker/registry:/etc/docker/registry \
  registry:2 \
  garbage-collect $REGISTRY_CONFIG

# 3. é‡å¯Registry
docker start $REGISTRY_CONTAINER

echo "Completed at: $(date)"

# å®šæ—¶ä»»åŠ¡(æ¯å‘¨æ—¥å‡Œæ™¨2ç‚¹)
# 0 2 * * 0 /usr/local/bin/registry-gc.sh >> /var/log/registry-gc.log 2>&1
```

---

## 7.4 é•œåƒè¿ç§»ä¸å¤‡ä»½

### 7.4.1 é•œåƒå¯¼å‡ºå¯¼å…¥

```bash
# æ–¹å¼1:save/load(ä¿ç•™å†å²å±‚)
$ docker save nginx:alpine > nginx-alpine.tar
$ docker save -o images.tar nginx:alpine mysql:8 redis:7
$ ls -lh images.tar
-rw-r--r-- 1 user user 512M Dec 4 10:00 images.tar

# ä¼ è¾“åˆ°å…¶ä»–æœºå™¨
$ scp images.tar user@remote:/tmp/

# å¯¼å…¥é•œåƒ
$ docker load < images.tar
Loaded image: nginx:alpine
Loaded image: mysql:8
Loaded image: redis:7

# æ–¹å¼2:export/import(å‹å¹³å±‚,ä¸¢å¤±å†å²)
$ docker export mycontainer > app.tar
$ docker import app.tar myapp:slim

# å¯¹æ¯”:
# save/load: ä¿ç•™æ‰€æœ‰å±‚,å…ƒæ•°æ®å®Œæ•´,ä½“ç§¯å¤§
# export/import: å•å±‚é•œåƒ,ä¸¢å¤±å†å²,ä½“ç§¯å°
```

---

### 7.4.2 Registryé—´è¿ç§»

```bash
# å·¥å…·1:ä½¿ç”¨skopeo(æ¨è)
$ skopeo copy \
  docker://source-registry.com/myapp:1.0 \
  docker://target-registry.com/myapp:1.0 \
  --src-creds user1:pass1 \
  --dest-creds user2:pass2

# æ‰¹é‡è¿ç§»æ‰€æœ‰é•œåƒ
$ skopeo sync \
  --src docker --dest docker \
  --src-creds user1:pass1 \
  --dest-creds user2:pass2 \
  source-registry.com/library \
  target-registry.com/library

# å·¥å…·2:ä½¿ç”¨crane
$ crane copy \
  source-registry.com/myapp:1.0 \
  target-registry.com/myapp:1.0

# å·¥å…·3:ä½¿ç”¨Harborå¤åˆ¶è§„åˆ™(Web UIé…ç½®)
# Administration â†’ Replications â†’ New Replication Rule
```

---

### 7.4.3 Registryå¤‡ä»½æ¢å¤

```bash
# å¤‡ä»½Registryæ•°æ®
$ tar -czf registry-backup-$(date +%Y%m%d).tar.gz \
  -C /data registry

# å¤‡ä»½Harborå®Œæ•´æ•°æ®
$ cd /opt/harbor
$ docker-compose stop
$ tar -czf harbor-backup-$(date +%Y%m%d).tar.gz \
  -C /data \
  registry database redis

# æ¢å¤Registry
$ tar -xzf registry-backup-20231204.tar.gz -C /data
$ docker start registry

# æ¢å¤Harbor
$ cd /opt/harbor
$ docker-compose down
$ tar -xzf harbor-backup-20231204.tar.gz -C /data
$ docker-compose up -d
```

---

## 7.5 é•œåƒå®‰å…¨æ‰«æé›†æˆ

### 7.5.1 Trivyé›†æˆ

```bash
# ç‹¬ç«‹ä½¿ç”¨Trivy
$ trivy image nginx:alpine
nginx:alpine (alpine 3.19.0)
Total: 0 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

# é›†æˆåˆ°CI/CD(GitHub Actions)
name: Security Scan
on: [push]
jobs:
  trivy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build image
        run: docker build -t myapp:${{ github.sha }} .
      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: myapp:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'
      - name: Upload to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
```

---

### 7.5.2 Clairé›†æˆ

```yaml
# docker-compose.yml
version: '3'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: password

  clair:
    image: quay.io/coreos/clair:latest
    depends_on:
      - postgres
    ports:
      - 6060:6060
    volumes:
      - ./clair-config.yaml:/config/config.yaml
    command: [-config, /config/config.yaml]
```

---

## 7.6 æœ¬ç« æ€»ç»“

**å…³é”®è¦ç‚¹**:
- âœ… Docker Hubé€‚åˆå…¬å…±é•œåƒ,ç§æœ‰ä»“åº“éœ€ä»˜è´¹
- âœ… Registryé€‚åˆå°å›¢é˜Ÿ,Harboré€‚åˆä¼ä¸š
- âœ… ä½¿ç”¨é•œåƒåŠ é€Ÿå™¨æå‡æ‹‰å–é€Ÿåº¦
- âœ… å®šæœŸæ‰§è¡Œåƒåœ¾å›æ”¶é‡Šæ”¾ç©ºé—´
- âœ… é›†æˆæ¼æ´æ‰«æç¡®ä¿é•œåƒå®‰å…¨

---

# ç¬¬8ç« :å®¹å™¨æ„å»ºå·¥å…·ç”Ÿæ€

## 8.1 Buildahæ— å®ˆæŠ¤è¿›ç¨‹æ„å»º

### 8.1.1 BuildahåŸºç¡€

```bash
# å®‰è£…Buildah
$ sudo yum install buildah  # CentOS/RHEL
$ sudo apt install buildah  # Ubuntu

# åˆ›å»ºå·¥ä½œå®¹å™¨
$ buildah from alpine:3.19
alpine-working-container

# è¿è¡Œå‘½ä»¤
$ buildah run alpine-working-container apk add nginx

# å¤åˆ¶æ–‡ä»¶
$ buildah copy alpine-working-container index.html /var/www/html/

# é…ç½®å®¹å™¨
$ buildah config --entrypoint '["/usr/sbin/nginx", "-g", "daemon off;"]' \
  alpine-working-container

# æäº¤ä¸ºé•œåƒ
$ buildah commit alpine-working-container my-nginx:latest

# æ¨é€é•œåƒ
$ buildah push my-nginx:latest docker://registry.example.com/my-nginx:latest
```

**Buildah vs Docker Buildå¯¹æ¯”**:

| ç‰¹æ€§ | Buildah | Docker Build |
|------|---------|--------------|
| å®ˆæŠ¤è¿›ç¨‹ | âŒ æ— éœ€ | âœ… éœ€è¦dockerd |
| Rootæƒé™ | âŒ rootlessæ”¯æŒ | âš ï¸ é€šå¸¸éœ€è¦root |
| æ„å»ºæ–¹å¼ | å‘½ä»¤è¡Œ+Dockerfile | ä»…Dockerfile |
| OCIå…¼å®¹ | âœ… å®Œå…¨å…¼å®¹ | âœ… å…¼å®¹ |
| å­˜å‚¨åç«¯ | overlay/vfs | overlay2 |

---

### 8.1.2 Buildahè„šæœ¬åŒ–æ„å»º

```bash
#!/bin/bash
# build.sh - ä½¿ç”¨Buildahæ„å»ºé•œåƒ

set -e

# åˆ›å»ºå®¹å™¨
ctr=$(buildah from golang:1.21-alpine)

# å®‰è£…ä¾èµ–
buildah run $ctr apk add --no-cache git make

# å¤åˆ¶æºç 
buildah copy $ctr . /src
buildah config --workingdir /src $ctr

# ç¼–è¯‘
buildah run $ctr go build -o /app /src

# åˆ›å»ºæœ€ç»ˆé•œåƒ
final=$(buildah from alpine:3.19)
buildah copy --from=$ctr $final /app /usr/local/bin/app
buildah config --entrypoint '["/usr/local/bin/app"]' $final
buildah config --port 8080 $final

# æäº¤
buildah commit $final myapp:latest

# æ¸…ç†
buildah rm $ctr $final

echo "âœ… Build completed: myapp:latest"
```

---

## 8.2 Kaniko KubernetesåŸç”Ÿæ„å»º

### 8.2.1 KanikoåŸç†

**Kanikoç‰¹ç‚¹**:
- âœ… æ— éœ€Dockerå®ˆæŠ¤è¿›ç¨‹
- âœ… åœ¨Kubernetes Podä¸­æ„å»º
- âœ… æ”¯æŒå¤šé˜¶æ®µæ„å»º
- âœ… å¯åœ¨éç‰¹æƒå®¹å™¨ä¸­è¿è¡Œ

```yaml
# kaniko-build.yaml
apiVersion: v1
kind: Pod
metadata:
  name: kaniko-build
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:latest
    args:
    - "--context=git://github.com/myuser/myrepo.git"
    - "--dockerfile=Dockerfile"
    - "--destination=registry.example.com/myapp:latest"
    - "--cache=true"
    - "--cache-repo=registry.example.com/cache"
    volumeMounts:
    - name: docker-config
      mountPath: /kaniko/.docker
  volumes:
  - name: docker-config
    secret:
      secretName: regcred
      items:
      - key: .dockerconfigjson
        path: config.json
  restartPolicy: Never
```

---

### 8.2.2 Kanikoç¼“å­˜ä¼˜åŒ–

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kaniko-cached
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:latest
    args:
    - "--context=/workspace"
    - "--dockerfile=/workspace/Dockerfile"
    - "--destination=myregistry.com/myapp:latest"
    - "--cache=true"
    - "--cache-repo=myregistry.com/cache"
    - "--cache-ttl=24h"
    - "--build-arg=VERSION=1.0.0"
    volumeMounts:
    - name: source
      mountPath: /workspace
    - name: docker-config
      mountPath: /kaniko/.docker
  volumes:
  - name: source
    emptyDir: {}
  - name: docker-config
    secret:
      secretName: regcred
```

---

## 8.3 Docker Buildxå¤šå¹³å°æ„å»º

### 8.3.1 Buildxå®‰è£…é…ç½®

```bash
# éªŒè¯Buildx
$ docker buildx version
github.com/docker/buildx v0.12.0

# åˆ›å»ºbuilderå®ä¾‹
$ docker buildx create --name multiarch --use
$ docker buildx inspect --bootstrap
[+] Building 5.2s (1/1) FINISHED
 => [internal] booting buildkit
Name:   multiarch
Driver: docker-container

Platforms: linux/amd64, linux/arm64, linux/arm/v7

# åˆ—å‡ºæ‰€æœ‰builder
$ docker buildx ls
NAME/NODE    DRIVER/ENDPOINT  STATUS  BUILDKIT  PLATFORMS
multiarch *  docker-container running v0.12.0  linux/amd64, linux/arm64
default      docker           running 23.0.1   linux/amd64
```

---

### 8.3.2 å¤šæ¶æ„é•œåƒæ„å»º

```bash
# æ„å»ºå¤šå¹³å°é•œåƒ
$ docker buildx build \
  --platform linux/amd64,linux/arm64,linux/arm/v7 \
  -t myregistry.com/myapp:multiarch \
  --push \
  .

# æŸ¥çœ‹manifest
$ docker buildx imagetools inspect myregistry.com/myapp:multiarch
Name:      myregistry.com/myapp:multiarch
MediaType: application/vnd.docker.distribution.manifest.list.v2+json
Digest:    sha256:abc123...

Manifests:
  Name:      myregistry.com/myapp:multiarch@sha256:def456...
  MediaType: application/vnd.docker.distribution.manifest.v2+json
  Platform:  linux/amd64

  Name:      myregistry.com/myapp:multiarch@sha256:ghi789...
  MediaType: application/vnd.docker.distribution.manifest.v2+json
  Platform:  linux/arm64

  Name:      myregistry.com/myapp:multiarch@sha256:jkl012...
  MediaType: application/vnd.docker.distribution.manifest.v2+json
  Platform:  linux/arm/v7

# ARMè®¾å¤‡è‡ªåŠ¨æ‹‰å–å¯¹åº”æ¶æ„é•œåƒ
$ docker pull myregistry.com/myapp:multiarch
# è‡ªåŠ¨é€‰æ‹© linux/arm64 æˆ– linux/arm/v7
```

---

### 8.3.3 è·¨å¹³å°æ„å»ºæœ€ä½³å®è·µ

```dockerfile
# Dockerfileä¼˜åŒ–å¤šæ¶æ„æ„å»º
FROM --platform=$BUILDPLATFORM golang:1.21-alpine AS builder

ARG TARGETOS
ARG TARGETARCH

WORKDIR /build
COPY . .

RUN CGO_ENABLED=0 GOOS=${TARGETOS} GOARCH=${TARGETARCH} \
    go build -o app .

FROM alpine:3.19
COPY --from=builder /build/app /usr/local/bin/app
ENTRYPOINT ["/usr/local/bin/app"]

# æ„å»ºå‘½ä»¤
$ docker buildx build \
  --platform linux/amd64,linux/arm64 \
  -t myapp:multiarch \
  --push \
  .
```

---

## 8.4 BuildKité«˜çº§ç‰¹æ€§

### 8.4.1 BuildKitåç«¯é…ç½®

```toml
# /etc/buildkit/buildkitd.toml
debug = false
root = "/var/lib/buildkit"

[worker.oci]
  enabled = true
  platforms = [ "linux/amd64", "linux/arm64" ]
  gc = true
  gckeepstorage = 10000  # MB
  [[worker.oci.gcpolicy]]
    keepBytes = 512000000
    keepDuration = 172800  # 48 hours

[registry."docker.io"]
  mirrors = ["mirror.gcr.io"]
```

---

### 8.4.2 ç¼“å­˜å¯¼å‡ºå¯¼å…¥

```bash
# å¯¼å‡ºç¼“å­˜åˆ°Registry
$ docker buildx build \
  --cache-from=type=registry,ref=myregistry.com/myapp:cache \
  --cache-to=type=registry,ref=myregistry.com/myapp:cache,mode=max \
  -t myapp:latest \
  .

# å¯¼å‡ºç¼“å­˜åˆ°æœ¬åœ°
$ docker buildx build \
  --cache-to=type=local,dest=/tmp/buildcache \
  -t myapp:latest \
  .

# ä½¿ç”¨æœ¬åœ°ç¼“å­˜
$ docker buildx build \
  --cache-from=type=local,src=/tmp/buildcache \
  -t myapp:latest \
  .

# GitHub Actionsç¼“å­˜ç¤ºä¾‹
- name: Build with cache
  uses: docker/build-push-action@v5
  with:
    context: .
    push: true
    tags: myapp:latest
    cache-from: type=gha
    cache-to: type=gha,mode=max
```

---

## 8.5 å·¥å…·é€‰å‹æŒ‡å—

### 8.5.1 æ„å»ºå·¥å…·å¯¹æ¯”

| å·¥å…· | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|---------|------|------|
| **Docker Build** | æœ¬åœ°å¼€å‘,å°å›¢é˜Ÿ | æˆç†Ÿç¨³å®š,ç”Ÿæ€å®Œå–„ | éœ€è¦å®ˆæŠ¤è¿›ç¨‹,æƒé™è¦æ±‚é«˜ |
| **Buildah** | CI/CD,rootlessæ„å»º | æ— å®ˆæŠ¤è¿›ç¨‹,rootless | å­¦ä¹ æ›²çº¿é™¡å³­ |
| **Kaniko** | Kubernetesç¯å¢ƒ | K8såŸç”Ÿ,å®‰å…¨æ€§é«˜ | ä»…æ”¯æŒDockerfile |
| **Buildx** | å¤šå¹³å°æ„å»º | å®˜æ–¹æ”¯æŒ,æ˜“ç”¨æ€§å¼º | ä¾èµ–BuildKit |
| **img** | å®‰å…¨ç¯å¢ƒ | å®Œå…¨æ— root | åŠŸèƒ½æœ‰é™ |

---

### 8.5.2 æ¨èé…ç½®

**åœºæ™¯1:æœ¬åœ°å¼€å‘**
```bash
# ä½¿ç”¨Docker Build + BuildKit
export DOCKER_BUILDKIT=1
docker build -t myapp .
```

**åœºæ™¯2:CI/CDæµæ°´çº¿**
```yaml
# ä½¿ç”¨Kaniko
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: build-push
spec:
  steps:
  - name: build-and-push
    image: gcr.io/kaniko-project/executor:latest
    args:
    - --context=$(params.pathToContext)
    - --dockerfile=$(params.pathToDockerFile)
    - --destination=$(params.imageUrl)
```

**åœºæ™¯3:å¤šæ¶æ„å‘å¸ƒ**
```bash
# ä½¿ç”¨Buildx
docker buildx build \
  --platform linux/amd64,linux/arm64 \
  -t myapp:multiarch \
  --push \
  .
```

---

## 8.6 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:
- âœ… Buildahæ— å®ˆæŠ¤è¿›ç¨‹,é€‚åˆCI/CD
- âœ… Kanikoä¸“ä¸ºKubernetesè®¾è®¡
- âœ… Buildxå®˜æ–¹å¤šå¹³å°è§£å†³æ–¹æ¡ˆ
- âœ… BuildKitæä¾›é«˜çº§ç¼“å­˜å’Œå¹¶è¡Œç‰¹æ€§
- âœ… æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ„å»ºå·¥å…·

---

---

# ç¬¬ä¸‰éƒ¨åˆ†:å®¹å™¨è¿è¡Œæ—¶ä¸ç¼–æ’

---

# ç¬¬9ç« :å®¹å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†

## 9.1 å®¹å™¨çŠ¶æ€ä¸ç”Ÿå‘½å‘¨æœŸ

### 9.1.1 å®¹å™¨çŠ¶æ€æœº

```bash
# Dockerå®¹å™¨çŠ¶æ€è½¬æ¢å›¾
Created â†’ Running â†’ Paused â†’ Running â†’ Stopped â†’ Removed
   â†“         â†“        â†“         â†“         â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â†’ Stopped â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â†“
                â†“                         â†“
                â””â”€â”€â”€â”€â”€â”€â”€â”€â†’ Removed â†â”€â”€â”€â”€â”€â”€â”˜

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
$ docker ps -a
CONTAINER ID  IMAGE         STATUS
abc123        nginx:alpine  Up 2 hours               # Running
def456        redis:7       Exited (0) 5 minutes ago # Stopped
ghi789        mysql:8       Paused                   # Paused
```

**çŠ¶æ€è¯¦è§£**:

| çŠ¶æ€ | è¯´æ˜ | è¿›ç¨‹çŠ¶æ€ | èµ„æºå ç”¨ |
|------|------|---------|---------|
| **Created** | å·²åˆ›å»ºæœªå¯åŠ¨ | ä¸å­˜åœ¨ | ç£ç›˜ç©ºé—´ |
| **Running** | æ­£å¸¸è¿è¡Œ | å­˜åœ¨ | CPU+å†…å­˜+ç£ç›˜+ç½‘ç»œ |
| **Paused** | æš‚åœ(å†»ç»“) | æš‚åœ | å†…å­˜+ç£ç›˜ |
| **Restarting** | é‡å¯ä¸­ | çŸ­æš‚ä¸å­˜åœ¨ | è¿‡æ¸¡çŠ¶æ€ |
| **Exited** | å·²åœæ­¢ | ä¸å­˜åœ¨ | ç£ç›˜ç©ºé—´ |
| **Dead** | å¼‚å¸¸ç»ˆæ­¢ | ä¸å­˜åœ¨ | ç£ç›˜ç©ºé—´ |

---

### 9.1.2 å®¹å™¨å¯åŠ¨æµç¨‹æ·±åº¦è§£æ

```bash
# å®Œæ•´å¯åŠ¨æµç¨‹ç¤ºä¾‹
$ docker run -d \
  --name myapp \
  --restart unless-stopped \
  --health-cmd "curl -f http://localhost:8080/health || exit 1" \
  --health-interval 30s \
  --health-timeout 3s \
  --health-retries 3 \
  -p 8080:8080 \
  myapp:latest

# å¯åŠ¨æµç¨‹(åº•å±‚è°ƒç”¨é“¾):
# 1ï¸âƒ£ Docker Client â†’ Docker API
# 2ï¸âƒ£ dockerd â†’ containerd (gRPC)
# 3ï¸âƒ£ containerd â†’ containerd-shim
# 4ï¸âƒ£ containerd-shim â†’ runc (åˆ›å»ºå®¹å™¨)
# 5ï¸âƒ£ runc â†’ Linux Kernel (namespace/cgroups)
# 6ï¸âƒ£ å®¹å™¨è¿›ç¨‹å¯åŠ¨(PID 1)
# 7ï¸âƒ£ å¥åº·æ£€æŸ¥å¯åŠ¨(å®šæ—¶æ¢æµ‹)
```

**å¯åŠ¨è¿‡ç¨‹è¯¦ç»†æ­¥éª¤**:

```bash
# ç›‘æ§å¯åŠ¨è¿‡ç¨‹
$ docker events --filter container=myapp &

# å¯åŠ¨å®¹å™¨
$ docker start myapp
2023-12-04T10:00:00.123 container start abc123 (image=myapp:latest)
2023-12-04T10:00:00.456 container attach abc123
2023-12-04T10:00:01.234 network connect bridge abc123
2023-12-04T10:00:01.567 container health_status: starting â†’ healthy

# éªŒè¯å®¹å™¨è¿›ç¨‹æ ‘
$ docker top myapp
UID    PID   PPID  CMD
1000   1234  1200  /usr/local/bin/app --config /etc/app/config.yaml
1000   1235  1234   \_ worker-thread-1
1000   1236  1234   \_ worker-thread-2

# æŸ¥çœ‹å®¹å™¨è¯¦ç»†ä¿¡æ¯
$ docker inspect myapp | jq '.[0].State'
{
  "Status": "running",
  "Running": true,
  "Paused": false,
  "Restarting": false,
  "OOMKilled": false,
  "Dead": false,
  "Pid": 1234,
  "ExitCode": 0,
  "StartedAt": "2023-12-04T10:00:01.234Z",
  "FinishedAt": "0001-01-01T00:00:00Z",
  "Health": {
    "Status": "healthy",
    "FailingStreak": 0,
    "Log": [...]
  }
}
```

---

### 9.1.3 å®¹å™¨åœæ­¢ä¸æ¸…ç†æµç¨‹

```bash
# ä¼˜é›…åœæ­¢(SIGTERM â†’ SIGKILL)
$ docker stop myapp
# æµç¨‹:
# 1ï¸âƒ£ å‘é€ SIGTERM ä¿¡å·ç»™PID 1
# 2ï¸âƒ£ ç­‰å¾… 10ç§’ (é»˜è®¤stopTimeout)
# 3ï¸âƒ£ å¦‚æœæœªé€€å‡º,å‘é€ SIGKILL å¼ºåˆ¶ç»ˆæ­¢

# è‡ªå®šä¹‰åœæ­¢è¶…æ—¶
$ docker stop -t 30 myapp  # ç­‰å¾…30ç§’

# ç«‹å³å¼ºåˆ¶ç»ˆæ­¢(SIGKILL)
$ docker kill myapp
$ docker kill -s SIGUSR1 myapp  # è‡ªå®šä¹‰ä¿¡å·

# åˆ é™¤å®¹å™¨
$ docker rm myapp
Error: You cannot remove a running container. Stop first.

$ docker rm -f myapp  # å¼ºåˆ¶åˆ é™¤(å…ˆstopå†remove)

# åˆ é™¤æ‰€æœ‰å·²åœæ­¢å®¹å™¨
$ docker container prune
WARNING! This will remove all stopped containers.
Total reclaimed space: 2.3GB
```

**åº”ç”¨ä¼˜é›…é€€å‡ºç¤ºä¾‹**:

```python
# Pythonåº”ç”¨ä¼˜é›…é€€å‡º
import signal
import sys

def signal_handler(sig, frame):
    print('Received SIGTERM, shutting down gracefully...')
    # 1. åœæ­¢æ¥å—æ–°è¯·æ±‚
    server.stop_accepting_connections()
    # 2. ç­‰å¾…å½“å‰è¯·æ±‚å®Œæˆ
    server.wait_for_current_requests(timeout=20)
    # 3. å…³é—­æ•°æ®åº“è¿æ¥
    db.close()
    # 4. æ¸…ç†èµ„æº
    cleanup()
    sys.exit(0)

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C

# å¯åŠ¨æœåŠ¡å™¨
server.start()
```

---

## 9.2 é‡å¯ç­–ç•¥æ·±åº¦é…ç½®

### 9.2.1 é‡å¯ç­–ç•¥ç±»å‹

```bash
# no: ä¸è‡ªåŠ¨é‡å¯(é»˜è®¤)
$ docker run -d --restart no myapp:latest

# on-failure[:max-retries]: ä»…å¼‚å¸¸é€€å‡ºæ—¶é‡å¯
$ docker run -d --restart on-failure:3 myapp:latest
# ä»…å½“é€€å‡ºç é0æ—¶é‡å¯,æœ€å¤š3æ¬¡

# always: æ€»æ˜¯é‡å¯
$ docker run -d --restart always myapp:latest
# dockerdé‡å¯åä¹Ÿä¼šè‡ªåŠ¨å¯åŠ¨å®¹å™¨

# unless-stopped: é™¤éæ‰‹åŠ¨åœæ­¢,å¦åˆ™æ€»æ˜¯é‡å¯
$ docker run -d --restart unless-stopped myapp:latest
# dockerdé‡å¯åè‡ªåŠ¨å¯åŠ¨,ä½†æ‰‹åŠ¨stopçš„ä¸å¯åŠ¨
```

**é‡å¯ç­–ç•¥å¯¹æ¯”**:

| ç­–ç•¥ | å®¹å™¨å¼‚å¸¸é€€å‡º | æ‰‹åŠ¨stop | dockerdé‡å¯ | é€‚ç”¨åœºæ™¯ |
|------|------------|---------|------------|---------|
| **no** | âŒ ä¸é‡å¯ | - | âŒ ä¸å¯åŠ¨ | ä¸´æ—¶ä»»åŠ¡ |
| **on-failure** | âœ… é‡å¯ | - | âŒ ä¸å¯åŠ¨ | æ‰¹å¤„ç†ä»»åŠ¡ |
| **always** | âœ… é‡å¯ | âœ… é‡å¯ | âœ… å¯åŠ¨ | æ ¸å¿ƒæœåŠ¡(éœ€è°¨æ…) |
| **unless-stopped** | âœ… é‡å¯ | âŒ ä¸é‡å¯ | âœ… å¯åŠ¨ | ç”Ÿäº§æœåŠ¡(æ¨è) |

---

### 9.2.2 é‡å¯ç­–ç•¥å®æˆ˜æ¡ˆä¾‹

```bash
# åœºæ™¯1: Webåº”ç”¨(æ¨èunless-stopped)
$ docker run -d \
  --name web \
  --restart unless-stopped \
  -p 80:80 \
  nginx:alpine

# åœºæ™¯2: æ•°æ®åº“(æ¨èunless-stopped + å¥åº·æ£€æŸ¥)
$ docker run -d \
  --name postgres \
  --restart unless-stopped \
  --health-cmd "pg_isready -U postgres" \
  --health-interval 10s \
  -e POSTGRES_PASSWORD=secret \
  -v /data/postgres:/var/lib/postgresql/data \
  postgres:15

# åœºæ™¯3: å®šæ—¶ä»»åŠ¡(on-failure:3)
$ docker run -d \
  --name backup-job \
  --restart on-failure:3 \
  mybackup:latest

# åœºæ™¯4: ä¸€æ¬¡æ€§ä»»åŠ¡(no)
$ docker run --rm \
  --name migration \
  --restart no \
  myapp:latest migrate
```

**é‡å¯è¡Œä¸ºéªŒè¯**:

```bash
# æµ‹è¯•1: å¼‚å¸¸é€€å‡º
$ docker run -d --name test1 --restart on-failure:3 alpine sh -c "exit 1"
$ docker ps -a --filter name=test1
# è§‚å¯ŸRestartCountå­—æ®µ

$ docker inspect test1 | jq '.[0].RestartCount'
3  # é‡å¯3æ¬¡ååœæ­¢

# æµ‹è¯•2: dockerdé‡å¯åè¡Œä¸º
$ docker run -d --name test2 --restart unless-stopped nginx:alpine
$ docker stop test2
$ sudo systemctl restart docker
$ docker ps --filter name=test2
# test2ä¸ä¼šè‡ªåŠ¨å¯åŠ¨(å› ä¸ºæ‰‹åŠ¨stopè¿‡)

$ docker run -d --name test3 --restart always nginx:alpine
$ docker stop test3
$ sudo systemctl restart docker
$ docker ps --filter name=test3
# test3ä¼šè‡ªåŠ¨å¯åŠ¨(alwaysç­–ç•¥)
```

---

## 9.3 å¥åº·æ£€æŸ¥æœºåˆ¶

### 9.3.1 HEALTHCHECKæŒ‡ä»¤è¯¦è§£

```dockerfile
# Dockerfileä¸­å®šä¹‰å¥åº·æ£€æŸ¥
FROM nginx:alpine

# æ–¹å¼1: ä½¿ç”¨CMD
HEALTHCHECK --interval=30s \
            --timeout=3s \
            --start-period=5s \
            --retries=3 \
  CMD curl -f http://localhost/ || exit 1

# æ–¹å¼2: ä½¿ç”¨è„šæœ¬
COPY healthcheck.sh /usr/local/bin/
HEALTHCHECK --interval=10s --timeout=5s \
  CMD /usr/local/bin/healthcheck.sh

# ç¦ç”¨ç»§æ‰¿çš„å¥åº·æ£€æŸ¥
HEALTHCHECK NONE
```

**healthcheck.shè„šæœ¬ç¤ºä¾‹**:

```bash
#!/bin/sh
# healthcheck.sh - ç»¼åˆå¥åº·æ£€æŸ¥è„šæœ¬

set -e

# 1ï¸âƒ£ æ£€æŸ¥HTTPç«¯ç‚¹
if ! curl -f http://localhost:8080/health >/dev/null 2>&1; then
  echo "HTTP health check failed"
  exit 1
fi

# 2ï¸âƒ£ æ£€æŸ¥æ•°æ®åº“è¿æ¥(å¯é€‰)
if ! psql -U app -c "SELECT 1" >/dev/null 2>&1; then
  echo "Database connection failed"
  exit 1
fi

# 3ï¸âƒ£ æ£€æŸ¥ç£ç›˜ç©ºé—´
DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
if [ "$DISK_USAGE" -gt 90 ]; then
  echo "Disk usage > 90%: ${DISK_USAGE}%"
  exit 1
fi

# 4ï¸âƒ£ æ£€æŸ¥å†…å­˜ä½¿ç”¨
MEM_USAGE=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
if [ "$MEM_USAGE" -gt 95 ]; then
  echo "Memory usage > 95%: ${MEM_USAGE}%"
  exit 1
fi

echo "All health checks passed"
exit 0
```

---

### 9.3.2 è¿è¡Œæ—¶å¥åº·æ£€æŸ¥é…ç½®

```bash
# å¯åŠ¨æ—¶é…ç½®å¥åº·æ£€æŸ¥
$ docker run -d \
  --name myapp \
  --health-cmd "curl -f http://localhost:8080/health || exit 1" \
  --health-interval 30s \
  --health-timeout 3s \
  --health-retries 3 \
  --health-start-period 40s \
  myapp:latest

# æŸ¥çœ‹å¥åº·çŠ¶æ€
$ docker ps
CONTAINER ID  STATUS
abc123        Up 5 minutes (healthy)

$ docker inspect --format='{{.State.Health.Status}}' myapp
healthy

# æŸ¥çœ‹å¥åº·æ£€æŸ¥å†å²
$ docker inspect myapp | jq '.[0].State.Health.Log'
[
  {
    "Start": "2023-12-04T10:00:30.123Z",
    "End": "2023-12-04T10:00:30.456Z",
    "ExitCode": 0,
    "Output": "All health checks passed\n"
  },
  {
    "Start": "2023-12-04T10:01:00.123Z",
    "End": "2023-12-04T10:01:00.456Z",
    "ExitCode": 0,
    "Output": "All health checks passed\n"
  }
]
```

**å¥åº·æ£€æŸ¥å‚æ•°è¯¦è§£**:

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|-------|------|
| `--interval` | 30s | æ£€æŸ¥é—´éš” |
| `--timeout` | 30s | å•æ¬¡æ£€æŸ¥è¶…æ—¶ |
| `--retries` | 3 | è¿ç»­å¤±è´¥æ¬¡æ•°åˆ¤å®šä¸ºunhealthy |
| `--start-period` | 0s | å¯åŠ¨å®½é™æœŸ(æ­¤æœŸé—´å¤±è´¥ä¸è®¡å…¥retries) |

---

### 9.3.3 å¥åº·æ£€æŸ¥ä¸è´Ÿè½½å‡è¡¡é›†æˆ

```yaml
# docker-compose.yml - å¥åº·æ£€æŸ¥é›†æˆ
version: '3.8'

services:
  web:
    image: nginx:alpine
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s
    deploy:
      replicas: 3
      update_config:
        order: start-first  # æ–°å®¹å™¨healthyåæ‰åœæ—§å®¹å™¨
        failure_action: rollback

  app:
    image: myapp:latest
    healthcheck:
      test: ["CMD", "/app/healthcheck"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      db:
        condition: service_healthy

  db:
    image: postgres:15
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      POSTGRES_PASSWORD: secret
```

**Nginxè´Ÿè½½å‡è¡¡é›†æˆ**:

```nginx
# nginx.conf - åŸºäºDockerå¥åº·æ£€æŸ¥çš„è´Ÿè½½å‡è¡¡
upstream backend {
  least_conn;

  # åç«¯æœåŠ¡å™¨(é€šè¿‡Docker DNS)
  server app1:8080 max_fails=3 fail_timeout=30s;
  server app2:8080 max_fails=3 fail_timeout=30s;
  server app3:8080 max_fails=3 fail_timeout=30s;

  keepalive 32;
}

server {
  listen 80;

  location / {
    proxy_pass http://backend;
    proxy_next_upstream error timeout http_500 http_502 http_503;
    proxy_connect_timeout 3s;
    proxy_send_timeout 30s;
    proxy_read_timeout 30s;
  }

  # å¥åº·æ£€æŸ¥ç«¯ç‚¹
  location /health {
    access_log off;
    return 200 "OK\n";
    add_header Content-Type text/plain;
  }
}
```

---

## 9.4 å®¹å™¨æ—¥å¿—ç®¡ç†

### 9.4.1 æ—¥å¿—é©±åŠ¨è¯¦è§£

```bash
# æŸ¥çœ‹æ”¯æŒçš„æ—¥å¿—é©±åŠ¨
$ docker info --format '{{.LoggingDriver}}'
json-file

$ docker info | grep "Logging Driver"
Logging Driver: json-file
```

**æ—¥å¿—é©±åŠ¨å¯¹æ¯”**:

| é©±åŠ¨ | æŒä¹…åŒ– | æ€§èƒ½ | æ”¯æŒdocker logs | é€‚ç”¨åœºæ™¯ |
|------|-------|------|----------------|---------|
| **json-file** | âœ… | â­â­â­ | âœ… | å¼€å‘/å°è§„æ¨¡ |
| **syslog** | âœ… | â­â­â­â­ | âŒ | é›†ä¸­æ—¥å¿—ç³»ç»Ÿ |
| **journald** | âœ… | â­â­â­â­ | âœ… | systemdç¯å¢ƒ |
| **fluentd** | âŒ | â­â­â­â­ | âŒ | å¤§è§„æ¨¡é›†ç¾¤ |
| **awslogs** | âœ… | â­â­â­â­ | âŒ | AWSç¯å¢ƒ |
| **none** | âŒ | â­â­â­â­â­ | âŒ | æ— éœ€æ—¥å¿— |

---

### 9.4.2 json-fileæ—¥å¿—é…ç½®

```json
// /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",      // å•æ–‡ä»¶æœ€å¤§100MB
    "max-file": "10",         // ä¿ç•™10ä¸ªå†å²æ–‡ä»¶
    "compress": "true",       // å‹ç¼©å†å²æ–‡ä»¶
    "labels": "production",   // æ—¥å¿—æ ‡ç­¾
    "env": "APP_ENV"          // åŒ…å«ç¯å¢ƒå˜é‡
  }
}
```

```bash
# å®¹å™¨çº§åˆ«é…ç½®
$ docker run -d \
  --name myapp \
  --log-driver json-file \
  --log-opt max-size=50m \
  --log-opt max-file=5 \
  --log-opt compress=true \
  myapp:latest

# æŸ¥çœ‹æ—¥å¿—
$ docker logs myapp
$ docker logs -f myapp  # å®æ—¶è·Ÿè¸ª
$ docker logs --tail 100 myapp  # æœ€å100è¡Œ
$ docker logs --since 2023-12-04T10:00:00 myapp  # æŒ‡å®šæ—¶é—´å
$ docker logs --until 2023-12-04T11:00:00 myapp  # æŒ‡å®šæ—¶é—´å‰

# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ä½ç½®
$ docker inspect --format='{{.LogPath}}' myapp
/var/lib/docker/containers/abc123.../abc123...-json.log

# æ¸…ç†æ—¥å¿—(éœ€åœæ­¢å®¹å™¨)
$ docker stop myapp
$ truncate -s 0 $(docker inspect --format='{{.LogPath}}' myapp)
$ docker start myapp
```

---

### 9.4.3 é›†ä¸­å¼æ—¥å¿—æ–¹æ¡ˆ

**æ–¹æ¡ˆ1: Fluentd**

```yaml
# docker-compose.yml
version: '3'

services:
  fluentd:
    image: fluent/fluentd:latest
    ports:
      - "24224:24224"
    volumes:
      - ./fluentd.conf:/fluentd/etc/fluent.conf
      - /data/fluentd:/fluentd/log

  app:
    image: myapp:latest
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: myapp.{{.Name}}
```

```conf
# fluentd.conf
<source>
  @type forward
  port 24224
</source>

<filter myapp.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    tag ${tag}
  </record>
</filter>

<match myapp.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name fluentd
  type_name fluentd
</match>
```

**æ–¹æ¡ˆ2: ELK Stack**

```yaml
# docker-compose.yml - ELKå®Œæ•´æ–¹æ¡ˆ
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - 5000:5000
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch

  app:
    image: myapp:latest
    logging:
      driver: syslog
      options:
        syslog-address: "tcp://logstash:5000"
        tag: "myapp"

volumes:
  es-data:
```

---

## 9.5 å®¹å™¨èµ„æºç›‘æ§

### 9.5.1 docker statså®æ—¶ç›‘æ§

```bash
# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨èµ„æºä½¿ç”¨
$ docker stats
CONTAINER  CPU %  MEM USAGE / LIMIT   MEM %   NET I/O        BLOCK I/O
myapp      2.5%   256MB / 2GB         12.8%   1.2MB / 850KB  10MB / 5MB
nginx      0.1%   50MB / 512MB        9.8%    500KB / 200KB  2MB / 1MB

# æŸ¥çœ‹ç‰¹å®šå®¹å™¨
$ docker stats myapp --no-stream  # å•æ¬¡å¿«ç…§
$ docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"

# JSONæ ¼å¼è¾“å‡º
$ docker stats --format "{{json .}}" --no-stream
{"BlockIO":"10MB / 5MB","CPUPerc":"2.5%","Container":"myapp",...}
```

---

### 9.5.2 cAdvisoræ·±åº¦ç›‘æ§

```yaml
# docker-compose.yml - cAdvisoréƒ¨ç½²
version: '3'

services:
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    ports:
      - 8080:8080
    privileged: true
    devices:
      - /dev/kmsg

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - 9090:9090
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  grafana:
    image: grafana/grafana:latest
    ports:
      - 3000:3000
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  prometheus-data:
  grafana-data:
```

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  - job_name: 'docker'
    static_configs:
      - targets: ['host.docker.internal:9323']
```

---

### 9.5.3 ç›‘æ§å‘Šè­¦é…ç½®

```yaml
# prometheus-rules.yml
groups:
  - name: docker_alerts
    interval: 30s
    rules:
      # CPUä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighCPUUsage
        expr: container_cpu_usage_seconds_total > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.name }} high CPU usage"
          description: "CPU usage is above 80% for 5 minutes"

      # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "Container {{ $labels.name }} high memory usage"
          description: "Memory usage is above 90%"

      # å®¹å™¨é‡å¯å‘Šè­¦
      - alert: ContainerRestarting
        expr: rate(container_restart_count[15m]) > 0
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.name }} is restarting"
          description: "Container restarted {{ $value }} times in 15 minutes"
```

---

## 9.6 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:
- âœ… å®¹å™¨çŠ¶æ€æœº:Created â†’ Running â†’ Paused/Stopped â†’ Removed
- âœ… é‡å¯ç­–ç•¥:`unless-stopped`é€‚åˆç”Ÿäº§ç¯å¢ƒ
- âœ… å¥åº·æ£€æŸ¥:å®šä¹‰æ˜ç¡®çš„æ£€æŸ¥é€»è¾‘,è®¾ç½®åˆç†çš„è¶…æ—¶å’Œé‡è¯•
- âœ… æ—¥å¿—ç®¡ç†:é™åˆ¶å¤§å°,é›†ä¸­æ”¶é›†,ç»“æ„åŒ–è¾“å‡º
- âœ… èµ„æºç›‘æ§:å®æ—¶ç›‘æ§+å†å²è¶‹åŠ¿+å‘Šè­¦é€šçŸ¥

---

# ç¬¬10ç« :Dockeræ•°æ®æŒä¹…åŒ–æ–¹æ¡ˆ

## 10.1 å­˜å‚¨é©±åŠ¨è¯¦è§£

### 10.1.1 å­˜å‚¨é©±åŠ¨å¯¹æ¯”

```bash
# æŸ¥çœ‹å½“å‰å­˜å‚¨é©±åŠ¨
$ docker info | grep "Storage Driver"
Storage Driver: overlay2
```

**å­˜å‚¨é©±åŠ¨é€‰å‹å¯¹æ¯”**:

| é©±åŠ¨ | Linuxå‘è¡Œç‰ˆ | æ€§èƒ½ | ç¨³å®šæ€§ | é€‚ç”¨åœºæ™¯ |
|------|-----------|------|-------|---------|
| **overlay2** | Kernel 4.0+ | â­â­â­â­â­ | â­â­â­â­â­ | **ç”Ÿäº§ç¯å¢ƒé¦–é€‰** |
| **aufs** | Ubuntu/Debian | â­â­â­â­ | â­â­â­â­ | æ—§ç‰ˆUbuntu |
| **devicemapper** | RHEL/CentOS | â­â­â­ | â­â­â­ | å·²å¼ƒç”¨ |
| **btrfs** | SLES | â­â­â­ | â­â­â­ | ç‰¹å®šåœºæ™¯ |
| **zfs** | Ubuntu 16.04+ | â­â­â­â­ | â­â­â­â­ | é«˜çº§ç”¨æˆ· |
| **vfs** | ä»»æ„ | â­â­ | â­â­â­â­â­ | æµ‹è¯•ç¯å¢ƒ |

---

### 10.1.2 overlay2å·¥ä½œåŸç†

```bash
# overlay2ç›®å½•ç»“æ„
/var/lib/docker/overlay2/
â”œâ”€â”€ l/  # çŸ­é“¾æ¥ç›®å½•(é¿å…mountå‚æ•°è¿‡é•¿)
â”œâ”€â”€ abc123.../  # å®¹å™¨å±‚
â”‚   â”œâ”€â”€ diff/    # è¯»å†™å±‚å·®å¼‚æ•°æ®
â”‚   â”œâ”€â”€ link     # æŒ‡å‘l/ç›®å½•çš„çŸ­é“¾æ¥
â”‚   â”œâ”€â”€ lower    # æŒ‡å‘ä¸‹å±‚é•œåƒ
â”‚   â”œâ”€â”€ merged/  # è”åˆæŒ‚è½½ç‚¹
â”‚   â””â”€â”€ work/    # overlayå·¥ä½œç›®å½•
â””â”€â”€ def456.../  # é•œåƒå±‚

# æŸ¥çœ‹å®¹å™¨çš„overlay2æŒ‚è½½
$ docker inspect myapp | jq '.[0].GraphDriver'
{
  "Data": {
    "LowerDir": "/var/lib/docker/overlay2/def456/diff",
    "MergedDir": "/var/lib/docker/overlay2/abc123/merged",
    "UpperDir": "/var/lib/docker/overlay2/abc123/diff",
    "WorkDir": "/var/lib/docker/overlay2/abc123/work"
  },
  "Name": "overlay2"
}

# éªŒè¯overlayæŒ‚è½½
$ mount | grep overlay
overlay on /var/lib/docker/overlay2/abc123/merged type overlay (rw,...)
```

**COW(Copy-on-Write)æœºåˆ¶**:

```bash
# åœºæ™¯æ¼”ç¤º:ä¿®æ”¹é•œåƒä¸­çš„æ–‡ä»¶
$ docker run -it --name test alpine sh
/ # echo "new content" > /etc/hosts  # ä¿®æ”¹æ–‡ä»¶

# å®¿ä¸»æœºæŸ¥çœ‹
$ ls /var/lib/docker/overlay2/abc123/diff/etc/
hosts  # âœ… æ–‡ä»¶è¢«å¤åˆ¶åˆ°å®¹å™¨å±‚

# åˆ é™¤æ–‡ä»¶
/ # rm /etc/passwd

$ ls /var/lib/docker/overlay2/abc123/diff/etc/
passwd  # âŒ åˆ›å»ºwhiteoutæ ‡è®°(å­—ç¬¦è®¾å¤‡ c 0 0)
```

---

## 10.2 Volumeå·ç®¡ç†

### 10.2.1 VolumeåŸºç¡€æ“ä½œ

```bash
# åˆ›å»ºå·
$ docker volume create mydata
mydata

# æŸ¥çœ‹å·åˆ—è¡¨
$ docker volume ls
DRIVER    VOLUME NAME
local     mydata
local     postgres-data

# æŸ¥çœ‹å·è¯¦ç»†ä¿¡æ¯
$ docker volume inspect mydata
[
  {
    "CreatedAt": "2023-12-04T10:00:00Z",
    "Driver": "local",
    "Labels": {},
    "Mountpoint": "/var/lib/docker/volumes/mydata/_data",
    "Name": "mydata",
    "Options": {},
    "Scope": "local"
  }
]

# ä½¿ç”¨å·
$ docker run -d \
  --name postgres \
  -v mydata:/var/lib/postgresql/data \
  postgres:15

# åˆ é™¤å·
$ docker volume rm mydata
Error: volume is in use

$ docker stop postgres && docker rm postgres
$ docker volume rm mydata  # âœ… æˆåŠŸåˆ é™¤

# åˆ é™¤æ‰€æœ‰æœªä½¿ç”¨å·
$ docker volume prune
WARNING! This will remove all local volumes not used by at least one container.
Total reclaimed space: 5.2GB
```

---

### 10.2.2 VolumeæŒ‚è½½ç±»å‹è¯¦è§£

```bash
# 1ï¸âƒ£ Named Volume(å‘½åå·)
$ docker run -v mydata:/data alpine
# ç‰¹ç‚¹:Dockerç®¡ç†,æŒä¹…åŒ–,å¯å…±äº«

# 2ï¸âƒ£ Anonymous Volume(åŒ¿åå·)
$ docker run -v /data alpine
# ç‰¹ç‚¹:Dockerç®¡ç†,å®¹å™¨åˆ é™¤æ—¶å¯é€‰æ‹©åˆ é™¤

# 3ï¸âƒ£ Bind Mount(ç»‘å®šæŒ‚è½½)
$ docker run -v /host/path:/container/path alpine
# ç‰¹ç‚¹:ç›´æ¥æ˜ å°„å®¿ä¸»æœºç›®å½•,å¼€å‘ç¯å¢ƒå¸¸ç”¨

# 4ï¸âƒ£ tmpfs Mount(å†…å­˜æŒ‚è½½)
$ docker run --tmpfs /tmp:rw,size=100m alpine
# ç‰¹ç‚¹:å­˜å‚¨åœ¨å†…å­˜,å®¹å™¨åœæ­¢å³æ¸…ç©º
```

**æŒ‚è½½ç±»å‹å¯¹æ¯”**:

| ç±»å‹ | ç®¡ç†æ–¹ | æŒä¹…åŒ– | æ€§èƒ½ | è·¨ä¸»æœº | é€‚ç”¨åœºæ™¯ |
|------|-------|-------|------|-------|---------|
| **Named Volume** | Docker | âœ… | â­â­â­â­ | ä½¿ç”¨æ’ä»¶ | **ç”Ÿäº§æ•°æ®** |
| **Anonymous Volume** | Docker | âœ… | â­â­â­â­ | âŒ | ä¸´æ—¶æ•°æ® |
| **Bind Mount** | ç”¨æˆ· | âœ… | â­â­â­â­â­ | âŒ | å¼€å‘ç¯å¢ƒ |
| **tmpfs** | Docker | âŒ | â­â­â­â­â­ | âŒ | æ•æ„Ÿæ•°æ®/ç¼“å­˜ |

---

### 10.2.3 Volumeé«˜çº§é€‰é¡¹

```bash
# åªè¯»æŒ‚è½½
$ docker run -v mydata:/data:ro alpine

# æŒ‡å®šå·é©±åŠ¨
$ docker volume create --driver local \
  --opt type=nfs \
  --opt o=addr=192.168.1.100,rw \
  --opt device=:/path/to/share \
  nfs-volume

# ä½¿ç”¨NFSå·
$ docker run -v nfs-volume:/data alpine

# è®¾ç½®å·æ ‡ç­¾
$ docker volume create --label env=production \
  --label app=database \
  prod-db-data

# æŸ¥è¯¢ç‰¹å®šæ ‡ç­¾çš„å·
$ docker volume ls --filter label=env=production

# nocopyé€‰é¡¹(ä¸ä»é•œåƒå¤åˆ¶åˆå§‹å†…å®¹)
$ docker run -v mydata:/app:nocopy myapp:latest
```

**Bind Mounté«˜çº§é€‰é¡¹**:

```bash
# æŒ‡å®šæƒé™
$ docker run \
  -v /host/data:/container/data:rw \  # è¯»å†™
  -v /host/config:/etc/app:ro \       # åªè¯»
  alpine

# ä¼ æ’­æ¨¡å¼(propagation)
$ docker run \
  -v /host/data:/data:rshared \  # åŒå‘ä¼ æ’­
  alpine

# propagationæ¨¡å¼:
# - shared: åŒå‘ä¼ æ’­
# - slave: å•å‘ä¼ æ’­(å®¿ä¸»æœºâ†’å®¹å™¨)
# - private: ä¸ä¼ æ’­(é»˜è®¤)
# - rshared/rslave/rprivate: é€’å½’æ¨¡å¼

# SELinuxæ ‡ç­¾(CentOS/RHEL)
$ docker run -v /host/data:/data:z alpine  # ç§æœ‰æ ‡ç­¾
$ docker run -v /host/data:/data:Z alpine  # å…±äº«æ ‡ç­¾
```

---

## 10.3 ç”Ÿäº§ç¯å¢ƒæ•°æ®æŒä¹…åŒ–æ–¹æ¡ˆ

### 10.3.1 æ•°æ®åº“æŒä¹…åŒ–æœ€ä½³å®è·µ

**PostgreSQL**:

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    secrets:
      - db_password
    volumes:
      # æ•°æ®ç›®å½•
      - postgres-data:/var/lib/postgresql/data
      # åˆå§‹åŒ–è„šæœ¬
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      # é…ç½®æ–‡ä»¶
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser -d myapp"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5432:5432"

secrets:
  db_password:
    file: ./secrets/db_password.txt

volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/postgres  # æŒ‡å®šå®¿ä¸»æœºè·¯å¾„
```

**MySQL**:

```yaml
services:
  mysql:
    image: mysql:8.0
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/mysql_root_password
      MYSQL_DATABASE: myapp
      MYSQL_USER: appuser
      MYSQL_PASSWORD_FILE: /run/secrets/mysql_password
    secrets:
      - mysql_root_password
      - mysql_password
    volumes:
      - mysql-data:/var/lib/mysql
      - ./my.cnf:/etc/mysql/conf.d/my.cnf:ro
    command: --default-authentication-plugin=mysql_native_password
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p$$MYSQL_ROOT_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  mysql-data:
```

---

### 10.3.2 å¤‡ä»½ä¸æ¢å¤ç­–ç•¥

**PostgreSQLå¤‡ä»½**:

```bash
# æ–¹å¼1: é€»è¾‘å¤‡ä»½(pg_dump)
$ docker exec postgres pg_dump -U appuser myapp > backup.sql

# æ¢å¤
$ docker exec -i postgres psql -U appuser myapp < backup.sql

# æ–¹å¼2: æ–‡ä»¶ç³»ç»Ÿå¤‡ä»½(éœ€åœæ­¢æ•°æ®åº“)
$ docker stop postgres
$ tar -czf postgres-backup-$(date +%Y%m%d).tar.gz /data/postgres
$ docker start postgres

# æ–¹å¼3: åœ¨çº¿å¤‡ä»½(pg_basebackup)
$ docker exec postgres pg_basebackup -U postgres -D /backup -Ft -z -P

# è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬
$ cat > /usr/local/bin/backup-postgres.sh <<'EOF'
#!/bin/bash
BACKUP_DIR="/backup/postgres"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/postgres_$TIMESTAMP.sql.gz"

mkdir -p "$BACKUP_DIR"

docker exec postgres pg_dump -U appuser myapp | gzip > "$BACKUP_FILE"

# ä¿ç•™æœ€è¿‘7å¤©çš„å¤‡ä»½
find "$BACKUP_DIR" -name "postgres_*.sql.gz" -mtime +7 -delete

echo "Backup completed: $BACKUP_FILE"
EOF

$ chmod +x /usr/local/bin/backup-postgres.sh

# æ·»åŠ å®šæ—¶ä»»åŠ¡(æ¯å¤©å‡Œæ™¨2ç‚¹)
$ crontab -e
0 2 * * * /usr/local/bin/backup-postgres.sh >> /var/log/postgres-backup.log 2>&1
```

**MongoDBå¤‡ä»½**:

```bash
# å¤‡ä»½
$ docker exec mongodb mongodump --out /backup/$(date +%Y%m%d)

# æ¢å¤
$ docker exec mongodb mongorestore /backup/20231204
```

---

### 10.3.3 è·¨ä¸»æœºæ•°æ®å…±äº«æ–¹æ¡ˆ

**æ–¹æ¡ˆ1: NFSæŒ‚è½½**:

```bash
# NFSæœåŠ¡å™¨é…ç½®(192.168.1.100)
$ sudo apt install nfs-kernel-server
$ sudo mkdir -p /export/docker-data
$ sudo chown nobody:nogroup /export/docker-data

$ sudo vim /etc/exports
/export/docker-data 192.168.1.0/24(rw,sync,no_subtree_check,no_root_squash)

$ sudo exportfs -ra
$ sudo systemctl restart nfs-kernel-server

# Dockerå®¢æˆ·ç«¯ä½¿ç”¨NFSå·
$ docker volume create --driver local \
  --opt type=nfs \
  --opt o=addr=192.168.1.100,rw \
  --opt device=:/export/docker-data \
  nfs-data

$ docker run -v nfs-data:/data alpine
```

**æ–¹æ¡ˆ2: REX-Ray(äº‘å­˜å‚¨)**:

```bash
# å®‰è£…REX-Ray
$ curl -sSL https://rexray.io/install | sh

# é…ç½®AWS EBS
$ cat > /etc/rexray/config.yml <<EOF
libstorage:
  service: ebs
aws:
  accessKey: AKIAXXXXXXXXXXXXXXXX
  secretKey: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
  region: us-east-1
EOF

$ sudo systemctl start rexray

# åˆ›å»ºEBSå·
$ docker volume create --driver rexray --name ebs-vol \
  --opt size=100

# ä½¿ç”¨å·(å¯åœ¨å¤šå°EC2é—´è¿ç§»)
$ docker run -v ebs-vol:/data alpine
```

**æ–¹æ¡ˆ3: GlusterFSé›†ç¾¤**:

```bash
# 3èŠ‚ç‚¹GlusterFSé›†ç¾¤éƒ¨ç½²(ç®€åŒ–)
# èŠ‚ç‚¹1,2,3: 192.168.1.101-103

# æ¯ä¸ªèŠ‚ç‚¹å®‰è£…GlusterFS
$ sudo apt install glusterfs-server

# èŠ‚ç‚¹1åˆ›å»ºå·
$ sudo gluster volume create docker-vol replica 3 \
  192.168.1.101:/data/gluster \
  192.168.1.102:/data/gluster \
  192.168.1.103:/data/gluster

$ sudo gluster volume start docker-vol

# Dockerä½¿ç”¨GlusterFSå·
$ docker volume create --driver local \
  --opt type=glusterfs \
  --opt o=addr=192.168.1.101 \
  --opt device=:/docker-vol \
  gluster-data
```

---

## 10.4 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:
- âœ… å­˜å‚¨é©±åŠ¨:**overlay2**æ˜¯ç”Ÿäº§ç¯å¢ƒé¦–é€‰
- âœ… æ•°æ®æŒä¹…åŒ–:**Named Volume**ç®¡ç†ç®€å•,é€‚åˆç”Ÿäº§
- âœ… å¼€å‘ç¯å¢ƒ:**Bind Mount**æ–¹ä¾¿å®æ—¶åŒæ­¥
- âœ… æ•°æ®åº“:å®šæœŸå¤‡ä»½,ä½¿ç”¨å¥åº·æ£€æŸ¥,é…ç½®æŒä¹…åŒ–å·
- âœ… è·¨ä¸»æœºå…±äº«:NFS/GlusterFS/äº‘å­˜å‚¨æ–¹æ¡ˆ

---

# ç¬¬11ç« :Docker Composeå®æˆ˜

## 11.1 ComposeåŸºç¡€

### 11.1.1 Composeæ–‡ä»¶æ ¼å¼

```yaml
# docker-compose.yml - å®Œæ•´ç¤ºä¾‹
version: '3.8'  # Composeæ–‡ä»¶ç‰ˆæœ¬

# å®šä¹‰æœåŠ¡
services:
  web:
    image: nginx:alpine
    container_name: web-server
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./html:/usr/share/nginx/html:ro
    networks:
      - frontend
    depends_on:
      - app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 3s
      retries: 3

  app:
    build:
      context: ./app
      dockerfile: Dockerfile
      args:
        - VERSION=1.0.0
    image: myapp:latest
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgres://appuser:${DB_PASSWORD}@db:5432/myapp
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    networks:
      - frontend
      - backend
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started

  db:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    secrets:
      - db_password
    volumes:
      - db-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - backend

# å®šä¹‰ç½‘ç»œ
networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true  # å†…éƒ¨ç½‘ç»œ,ä¸èƒ½è®¿é—®å¤–ç½‘

# å®šä¹‰å·
volumes:
  db-data:
    driver: local
  redis-data:
    driver: local

# å®šä¹‰secrets
secrets:
  db_password:
    file: ./secrets/db_password.txt
```

---

### 11.1.2 Composeå‘½ä»¤è¯¦è§£

```bash
# å¯åŠ¨æœåŠ¡(åå°è¿è¡Œ)
$ docker-compose up -d
Creating network "myapp_frontend" ... done
Creating network "myapp_backend" ... done
Creating volume "myapp_db-data" ... done
Creating myapp_redis_1 ... done
Creating myapp_db_1    ... done
Creating myapp_app_1   ... done
Creating myapp_web_1   ... done

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
$ docker-compose ps
      Name                    Command               State          Ports
--------------------------------------------------------------------------------
myapp_app_1       /app/start.sh                   Up      8080/tcp
myapp_db_1        docker-entrypoint.sh postgres   Up      5432/tcp
myapp_redis_1     redis-server --appendonly yes   Up      6379/tcp
myapp_web_1       nginx -g daemon off;            Up      0.0.0.0:80->80/tcp

# æŸ¥çœ‹æ—¥å¿—
$ docker-compose logs          # æ‰€æœ‰æœåŠ¡
$ docker-compose logs -f app   # è·Ÿè¸ªappæœåŠ¡æ—¥å¿—
$ docker-compose logs --tail=100 web  # æœ€å100è¡Œ

# æ‰§è¡Œå‘½ä»¤
$ docker-compose exec app sh           # è¿›å…¥appå®¹å™¨
$ docker-compose exec db psql -U appuser myapp  # è¿æ¥æ•°æ®åº“

# æ‰©å®¹æœåŠ¡
$ docker-compose up -d --scale app=3
Creating myapp_app_2 ... done
Creating myapp_app_3 ... done

# åœæ­¢æœåŠ¡
$ docker-compose stop     # åœæ­¢æ‰€æœ‰æœåŠ¡
$ docker-compose stop app # åœæ­¢appæœåŠ¡

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
$ docker-compose down
Stopping myapp_web_1   ... done
Stopping myapp_app_1   ... done
Stopping myapp_db_1    ... done
Stopping myapp_redis_1 ... done
Removing myapp_web_1   ... done
Removing myapp_app_1   ... done
Removing myapp_db_1    ... done
Removing myapp_redis_1 ... done
Removing network myapp_frontend
Removing network myapp_backend

# åˆ é™¤å®¹å™¨å’Œå·
$ docker-compose down -v  # âš ï¸ ä¼šåˆ é™¤æ•°æ®

# é‡å»ºæœåŠ¡
$ docker-compose up -d --build  # é‡æ–°æ„å»ºé•œåƒ
$ docker-compose up -d --force-recreate  # å¼ºåˆ¶é‡å»ºå®¹å™¨
```

---

## 11.2 æœåŠ¡ä¾èµ–ç®¡ç†

### 11.2.1 depends_onè¯¦è§£

```yaml
version: '3.8'

services:
  # åŸºç¡€æœåŠ¡:æ•°æ®åº“
  db:
    image: postgres:15
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 5s

  # åŸºç¡€æœåŠ¡:ç¼“å­˜
  redis:
    image: redis:7-alpine

  # åº”ç”¨æœåŠ¡:ä¾èµ–dbå’Œredis
  app:
    image: myapp:latest
    depends_on:
      db:
        condition: service_healthy  # ç­‰å¾…dbå¥åº·
      redis:
        condition: service_started   # ç­‰å¾…rediså¯åŠ¨
    # å¯åŠ¨é¡ºåº: db â†’ redis â†’ app

  # WebæœåŠ¡:ä¾èµ–app
  web:
    image: nginx:alpine
    depends_on:
      - app
    ports:
      - "80:80"
    # å¯åŠ¨é¡ºåº: db â†’ redis â†’ app â†’ web
```

**depends_onæ¡ä»¶ç±»å‹**:

| æ¡ä»¶ | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|------|------|---------|
| `service_started` | å®¹å™¨å¯åŠ¨å³å¯(é»˜è®¤) | æ— éœ€ç­‰å¾…æœåŠ¡å°±ç»ª |
| `service_healthy` | å¥åº·æ£€æŸ¥é€šè¿‡ | **æ•°æ®åº“ç­‰å…³é”®æœåŠ¡(æ¨è)** |
| `service_completed_successfully` | å®¹å™¨æˆåŠŸé€€å‡º | åˆå§‹åŒ–ä»»åŠ¡ |

---

### 11.2.2 å¯åŠ¨é¡ºåºæ§åˆ¶è„šæœ¬

```bash
#!/bin/sh
# wait-for-it.sh - ç­‰å¾…æœåŠ¡å¯ç”¨

set -e

host="$1"
shift
cmd="$@"

until nc -z "$host" 2>/dev/null; do
  >&2 echo "Waiting for $host..."
  sleep 1
done

>&2 echo "$host is available - executing command"
exec $cmd
```

**åœ¨Composeä¸­ä½¿ç”¨**:

```yaml
services:
  app:
    image: myapp:latest
    command: sh -c "/wait-for-it.sh db:5432 -- /app/start.sh"
    volumes:
      - ./wait-for-it.sh:/wait-for-it.sh:ro
    depends_on:
      - db
```

---

## 11.3 ç½‘ç»œé…ç½®è¿›é˜¶

### 11.3.1 è‡ªå®šä¹‰ç½‘ç»œ

```yaml
version: '3.8'

services:
  web:
    image: nginx:alpine
    networks:
      - public
      - internal

  app:
    image: myapp:latest
    networks:
      internal:
        ipv4_address: 172.20.0.10  # å›ºå®šIP
        aliases:
          - api.local

  db:
    image: postgres:15
    networks:
      - internal

networks:
  # å…¬å…±ç½‘ç»œ(å¯è®¿é—®å¤–ç½‘)
  public:
    driver: bridge
    ipam:
      config:
        - subnet: 172.19.0.0/16

  # å†…éƒ¨ç½‘ç»œ(éš”ç¦»å¤–ç½‘)
  internal:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
```

---

### 11.3.2 ç½‘ç»œåˆ«åä¸æœåŠ¡å‘ç°

```yaml
services:
  app:
    image: myapp:latest
    networks:
      backend:
        aliases:
          - api
          - api-server
          - backend-api

  # å…¶ä»–æœåŠ¡å¯é€šè¿‡åˆ«åè®¿é—®
  worker:
    image: myworker:latest
    environment:
      - API_URL=http://api:8080  # ä½¿ç”¨åˆ«å
    networks:
      - backend
```

**DNSè§£ææµ‹è¯•**:

```bash
$ docker-compose exec worker nslookup api
Server:    127.0.0.11
Address:   127.0.0.11:53

Non-authoritative answer:
Name:   api
Address: 172.20.0.10

# æ‰€æœ‰åˆ«åæŒ‡å‘åŒä¸€IP
$ docker-compose exec worker ping -c1 api-server
64 bytes from 172.20.0.10: icmp_seq=1 ttl=64
```

---

## 11.4 æ•°æ®å·å…±äº«

### 11.4.1 å·çš„å®šä¹‰ä¸ä½¿ç”¨

```yaml
version: '3.8'

services:
  web:
    image: nginx:alpine
    volumes:
      # å‘½åå·
      - static-data:/usr/share/nginx/html
      # ç»‘å®šæŒ‚è½½
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      # ä¸´æ—¶æ–‡ä»¶ç³»ç»Ÿ
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 100M

  app:
    image: myapp:latest
    volumes:
      # å…±äº«å·(ä¸webå…±äº«)
      - static-data:/app/static
      # åº”ç”¨æ•°æ®å·
      - app-data:/app/data

volumes:
  static-data:
    driver: local
  app-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/app  # æ˜ å°„åˆ°å®¿ä¸»æœºè·¯å¾„
```

---

### 11.4.2 å·çš„é«˜çº§é…ç½®

```yaml
volumes:
  # NFSå·
  nfs-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=192.168.1.100,rw
      device: ":/export/data"

  # å¤–éƒ¨å·(å·²å­˜åœ¨)
  existing-vol:
    external: true

  # å·æ ‡ç­¾
  labeled-vol:
    driver: local
    labels:
      env: production
      app: myapp
```

---

## 11.5 ç¯å¢ƒå˜é‡ä¸é…ç½®

### 11.5.1 ç¯å¢ƒå˜é‡æœ€ä½³å®è·µ

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    image: myapp:latest
    environment:
      # æ–¹å¼1:ç›´æ¥å®šä¹‰
      - NODE_ENV=production
      # æ–¹å¼2:å¼•ç”¨å®¿ä¸»æœºç¯å¢ƒå˜é‡
      - DATABASE_URL=${DATABASE_URL}
      # æ–¹å¼3:é»˜è®¤å€¼
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
    env_file:
      - .env            # é»˜è®¤ç¯å¢ƒæ–‡ä»¶
      - .env.production # ç”Ÿäº§ç¯å¢ƒé…ç½®
```

**.envæ–‡ä»¶**:

```bash
# .env
DATABASE_URL=postgres://user:pass@db:5432/myapp
REDIS_URL=redis://redis:6379/0
API_KEY=secret-key-here
LOG_LEVEL=info
```

**ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§**:

```bash
# ä¼˜å…ˆçº§ä»é«˜åˆ°ä½:
1. docker-compose.ymlä¸­çš„environment
2. --env-fileæŒ‡å®šçš„æ–‡ä»¶
3. .envæ–‡ä»¶
4. Dockerfileä¸­çš„ENV
5. å®¿ä¸»æœºç¯å¢ƒå˜é‡
```

---

### 11.5.2 å¤šç¯å¢ƒé…ç½®

```bash
# é¡¹ç›®ç»“æ„
.
â”œâ”€â”€ docker-compose.yml         # åŸºç¡€é…ç½®
â”œâ”€â”€ docker-compose.dev.yml     # å¼€å‘ç¯å¢ƒ
â”œâ”€â”€ docker-compose.prod.yml    # ç”Ÿäº§ç¯å¢ƒ
â”œâ”€â”€ .env.dev
â””â”€â”€ .env.prod

# docker-compose.yml (åŸºç¡€é…ç½®)
version: '3.8'
services:
  app:
    image: myapp:latest
    env_file:
      - .env

# docker-compose.dev.yml (å¼€å‘è¦†ç›–)
version: '3.8'
services:
  app:
    build:
      context: .
      target: dev
    volumes:
      - .:/app  # æºç æŒ‚è½½
    environment:
      - DEBUG=true

# docker-compose.prod.yml (ç”Ÿäº§è¦†ç›–)
version: '3.8'
services:
  app:
    restart: unless-stopped
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 1G

# ä½¿ç”¨æ–¹å¼
$ docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d   # å¼€å‘
$ docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d  # ç”Ÿäº§
```

---

## 11.6 ç”Ÿäº§ç¯å¢ƒComposeé…ç½®

### 11.6.1 å®Œæ•´ç”Ÿäº§ç¯å¢ƒç¤ºä¾‹

```yaml
# docker-compose.prod.yml
version: '3.8'

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "3"
    compress: "true"

services:
  nginx:
    image: nginx:1.25-alpine
    container_name: nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - static-files:/var/www/static:ro
    networks:
      - frontend
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  app:
    image: myapp:${VERSION:-latest}
    restart: unless-stopped
    environment:
      - DATABASE_URL_FILE=/run/secrets/db_url
      - REDIS_URL=redis://redis:6379/0
    secrets:
      - db_url
    volumes:
      - static-files:/app/static
      - uploads:/app/uploads
    networks:
      - frontend
      - backend
    depends_on:
      db:
        condition: service_healthy
    logging: *default-logging
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  db:
    image: postgres:15-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    secrets:
      - db_password
    volumes:
      - db-data:/var/lib/postgresql/data
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser -d myapp"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    networks:
      - backend
    logging: *default-logging

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true

volumes:
  db-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/postgres
  redis-data:
    driver: local
  static-files:
  uploads:

secrets:
  db_password:
    file: ./secrets/db_password.txt
  db_url:
    file: ./secrets/db_url.txt
```

---

## 11.7 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:
- âœ… Composeæ–‡ä»¶ç»“æ„:services/networks/volumes/secrets
- âœ… æœåŠ¡ä¾èµ–:`depends_on`é…åˆ`healthcheck`
- âœ… ç½‘ç»œéš”ç¦»:å‰ç«¯/åç«¯ç½‘ç»œåˆ†ç¦»,å†…éƒ¨ç½‘ç»œç¦æ­¢å¤–ç½‘
- âœ… æ•°æ®æŒä¹…åŒ–:å‘½åå·ç®¡ç†,æ”¯æŒNFSç­‰å¤–éƒ¨å­˜å‚¨
- âœ… ç¯å¢ƒé…ç½®:å¤šç¯å¢ƒé…ç½®æ–‡ä»¶,æ•æ„Ÿä¿¡æ¯ä½¿ç”¨secrets

---

# ç¬¬12ç« :å®¹å™¨ç¼–æ’åŸºç¡€ä¸Swarm

## 12.1 Docker Swarmæ¶æ„

### 12.1.1 Swarmæ ¸å¿ƒæ¦‚å¿µ

```bash
# åˆå§‹åŒ–Swarmé›†ç¾¤(ç®¡ç†èŠ‚ç‚¹)
$ docker swarm init --advertise-addr 192.168.1.10
Swarm initialized: current node (abc123) is now a manager.

To add a worker to this swarm, run the following command:
    docker swarm join --token SWMTKN-1-xxx 192.168.1.10:2377

To add a manager to this swarm, run 'docker swarm join-token manager'

# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
$ docker node ls
ID                  HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
abc123 *            node1     Ready   Active        Leader
```

**Swarmæ¶æ„ç»„ä»¶**:

| ç»„ä»¶ | ä½œç”¨ | è¯´æ˜ |
|------|------|------|
| **Manager Node** | é›†ç¾¤ç®¡ç† | æ¥æ”¶ä»»åŠ¡,è°ƒåº¦å®¹å™¨,ç»´æŠ¤é›†ç¾¤çŠ¶æ€ |
| **Worker Node** | ä»»åŠ¡æ‰§è¡Œ | è¿è¡Œå®¹å™¨,æ¥æ”¶ç®¡ç†èŠ‚ç‚¹è°ƒåº¦ |
| **Service** | æœåŠ¡å®šä¹‰ | å£°æ˜å®¹å™¨å‰¯æœ¬æ•°,æ›´æ–°ç­–ç•¥ç­‰ |
| **Task** | ä»»åŠ¡å•å…ƒ | Serviceçš„æœ€å°è°ƒåº¦å•å…ƒ(å®¹å™¨å®ä¾‹) |

---

### 12.1.2 èŠ‚ç‚¹ç®¡ç†

```bash
# æ·»åŠ WorkerèŠ‚ç‚¹(åœ¨workeræœºå™¨ä¸Šæ‰§è¡Œ)
$ docker swarm join --token SWMTKN-1-xxx 192.168.1.10:2377
This node joined a swarm as a worker.

# æ·»åŠ ManagerèŠ‚ç‚¹
$ docker swarm join-token manager
To add a manager:
    docker swarm join --token SWMTKN-1-yyy 192.168.1.10:2377

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦æƒ…
$ docker node inspect node1

# èŠ‚ç‚¹è§’è‰²å˜æ›´
$ docker node promote worker1   # Workeræå‡ä¸ºManager
$ docker node demote manager2   # Manageré™çº§ä¸ºWorker

# èŠ‚ç‚¹å¯ç”¨æ€§è®¾ç½®
$ docker node update --availability drain worker1  # æ’ç©ºèŠ‚ç‚¹(ä¸è°ƒåº¦æ–°ä»»åŠ¡)
$ docker node update --availability active worker1 # æ¿€æ´»èŠ‚ç‚¹

# åˆ é™¤èŠ‚ç‚¹
$ docker node rm worker1  # éœ€å…ˆåœ¨worker1ä¸Šæ‰§è¡Œ: docker swarm leave
```

---

## 12.2 æœåŠ¡éƒ¨ç½²ä¸ç®¡ç†

### 12.2.1 æœåŠ¡åˆ›å»º

```bash
# åˆ›å»ºæœåŠ¡
$ docker service create \
  --name web \
  --replicas 3 \
  --publish 80:80 \
  --env NODE_ENV=production \
  --limit-memory 512M \
  --limit-cpu 0.5 \
  nginx:alpine

# æŸ¥çœ‹æœåŠ¡åˆ—è¡¨
$ docker service ls
ID         NAME  MODE        REPLICAS  IMAGE
abc123     web   replicated  3/3       nginx:alpine

# æŸ¥çœ‹æœåŠ¡è¯¦æƒ…
$ docker service inspect web

# æŸ¥çœ‹æœåŠ¡ä»»åŠ¡(å®¹å™¨)
$ docker service ps web
ID      NAME    IMAGE          NODE    DESIRED STATE  CURRENT STATE
xyz1    web.1   nginx:alpine   node1   Running        Running 2 minutes
xyz2    web.2   nginx:alpine   node2   Running        Running 2 minutes
xyz3    web.3   nginx:alpine   node3   Running        Running 2 minutes
```

---

### 12.2.2 æœåŠ¡æ‰©ç¼©å®¹

```bash
# æ‰©å®¹åˆ°5ä¸ªå‰¯æœ¬
$ docker service scale web=5
web scaled to 5
overall progress: 5 out of 5 tasks
verify: Service converged

# ç¼©å®¹åˆ°2ä¸ªå‰¯æœ¬
$ docker service scale web=2

# æŸ¥çœ‹æ‰©å®¹ç»“æœ
$ docker service ps web | grep Running
```

---

### 12.2.3 æœåŠ¡æ›´æ–°

```bash
# æ»šåŠ¨æ›´æ–°é•œåƒ
$ docker service update \
  --image nginx:1.25 \
  --update-parallelism 1 \  # æ¯æ¬¡æ›´æ–°1ä¸ªä»»åŠ¡
  --update-delay 10s \       # é—´éš”10ç§’
  --update-failure-action rollback \
  web

# æ›´æ–°ç¯å¢ƒå˜é‡
$ docker service update --env-add DEBUG=true web

# æ›´æ–°èµ„æºé™åˆ¶
$ docker service update \
  --limit-memory 1G \
  --limit-cpu 1 \
  web

# å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
$ docker service rollback web
```

---

## 12.3 Stackéƒ¨ç½²

### 12.3.1 Stacké…ç½®æ–‡ä»¶

```yaml
# stack.yml - Swarm Stacké…ç½®
version: '3.8'

services:
  web:
    image: nginx:alpine
    ports:
      - "80:80"
    networks:
      - frontend
    deploy:
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.role == worker
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  app:
    image: myapp:latest
    networks:
      - frontend
      - backend
    secrets:
      - db_password
    deploy:
      mode: replicated
      replicas: 5
      placement:
        preferences:
          - spread: node.labels.zone
      update_config:
        parallelism: 2
        order: start-first

  db:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    networks:
      - backend
    volumes:
      - db-data:/var/lib/postgresql/data
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == node1  # å›ºå®šèŠ‚ç‚¹

networks:
  frontend:
  backend:

volumes:
  db-data:

secrets:
  db_password:
    external: true
```

---

### 12.3.2 Stackéƒ¨ç½²å‘½ä»¤

```bash
# åˆ›å»ºsecret
$ echo "mysecretpassword" | docker secret create db_password -

# éƒ¨ç½²Stack
$ docker stack deploy -c stack.yml myapp
Creating network myapp_frontend
Creating network myapp_backend
Creating service myapp_web
Creating service myapp_app
Creating service myapp_db

# æŸ¥çœ‹Stack
$ docker stack ls
NAME   SERVICES
myapp  3

# æŸ¥çœ‹StackæœåŠ¡
$ docker stack services myapp
ID         NAME        MODE      REPLICAS  IMAGE
abc123     myapp_web   replicated  3/3     nginx:alpine
def456     myapp_app   replicated  5/5     myapp:latest
ghi789     myapp_db    replicated  1/1     postgres:15

# æŸ¥çœ‹Stackä»»åŠ¡
$ docker stack ps myapp

# æ›´æ–°Stack(ä¿®æ”¹stack.ymlå)
$ docker stack deploy -c stack.yml myapp

# åˆ é™¤Stack
$ docker stack rm myapp
```

---

## 12.4 è´Ÿè½½å‡è¡¡ä¸è·¯ç”±

### 12.4.1 Ingressç½‘ç»œ

```bash
# Swarmè‡ªåŠ¨è´Ÿè½½å‡è¡¡
$ docker service create --name web --replicas 3 -p 80:80 nginx:alpine

# è®¿é—®ä»»æ„èŠ‚ç‚¹çš„80ç«¯å£,è‡ªåŠ¨è·¯ç”±åˆ°å¯ç”¨å®¹å™¨
$ curl http://node1  # å¯èƒ½è·¯ç”±åˆ°node2çš„å®¹å™¨
$ curl http://node2  # å¯èƒ½è·¯ç”±åˆ°node3çš„å®¹å™¨
$ curl http://node3  # å¯èƒ½è·¯ç”±åˆ°node1çš„å®¹å™¨

# è·¯ç”±æ¨¡å¼:
# - ingress(é»˜è®¤): VIPè´Ÿè½½å‡è¡¡,ä»»æ„èŠ‚ç‚¹æ¥å…¥
# - host: ç›´æ¥æ˜ å°„åˆ°å®¹å™¨æ‰€åœ¨èŠ‚ç‚¹

# æŸ¥çœ‹ingressç½‘ç»œ
$ docker network inspect ingress
```

---

### 12.4.2 Overlayç½‘ç»œ

```bash
# åˆ›å»ºoverlayç½‘ç»œ
$ docker network create \
  --driver overlay \
  --attachable \
  --subnet 10.10.0.0/16 \
  my-overlay

# æœåŠ¡ä½¿ç”¨overlayç½‘ç»œ
$ docker service create \
  --name app \
  --network my-overlay \
  myapp:latest

# è·¨ä¸»æœºå®¹å™¨é€šä¿¡
# node1ä¸Šçš„å®¹å™¨å¯ä»¥ç›´æ¥ping node2ä¸Šçš„å®¹å™¨å
```

---

## 12.5 ç”Ÿäº§ç¯å¢ƒSwarmé…ç½®

### 12.5.1 é«˜å¯ç”¨Swarmé›†ç¾¤

```bash
# æ¨èé…ç½®: 3ä¸ªManager + Nä¸ªWorker
# Managerå¥‡æ•°ä¸ª,ä¿è¯Raftä¸€è‡´æ€§ç®—æ³•æ­£å¸¸å·¥ä½œ

# èŠ‚ç‚¹è§„åˆ’:
# - Manager1 (Leader): 192.168.1.10
# - Manager2: 192.168.1.11
# - Manager3: 192.168.1.12
# - Worker1-N: 192.168.1.20-30

# Manager1åˆå§‹åŒ–
$ docker swarm init --advertise-addr 192.168.1.10

# Manager2,3åŠ å…¥
$ docker swarm join --token SWMTKN-1-manager-xxx 192.168.1.10:2377

# WorkeråŠ å…¥
$ docker swarm join --token SWMTKN-1-worker-yyy 192.168.1.10:2377

# éªŒè¯é›†ç¾¤
$ docker node ls
ID   HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
*m1  manager1  Ready   Active        Leader
 m2  manager2  Ready   Active        Reachable
 m3  manager3  Ready   Active        Reachable
 w1  worker1   Ready   Active
 w2  worker2   Ready   Active
```

---

### 12.5.2 èŠ‚ç‚¹æ ‡ç­¾ä¸çº¦æŸ

```bash
# æ·»åŠ èŠ‚ç‚¹æ ‡ç­¾
$ docker node update --label-add zone=us-east-1a worker1
$ docker node update --label-add zone=us-east-1b worker2
$ docker node update --label-add ssd=true worker1

# ä½¿ç”¨æ ‡ç­¾çº¦æŸéƒ¨ç½²
$ docker service create \
  --name db \
  --constraint 'node.labels.ssd == true' \
  postgres:15

# å¤šé‡çº¦æŸ
$ docker service create \
  --name app \
  --constraint 'node.role == worker' \
  --constraint 'node.labels.zone == us-east-1a' \
  myapp:latest
```

---

## 12.6 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:
- âœ… Swarmé›†ç¾¤:æ¨è3ä¸ªManager(å¥‡æ•°)+å¤šä¸ªWorker
- âœ… æœåŠ¡éƒ¨ç½²:ä½¿ç”¨Stackè¿›è¡Œå£°æ˜å¼éƒ¨ç½²
- âœ… è´Ÿè½½å‡è¡¡:Ingressç½‘ç»œè‡ªåŠ¨è·¯ç”±,æ— éœ€å¤–éƒ¨LB
- âœ… æ»šåŠ¨æ›´æ–°:æ”¯æŒè“ç»¿éƒ¨ç½²,è‡ªåŠ¨å›æ»š
- âœ… é«˜å¯ç”¨:ManagerèŠ‚ç‚¹Raftä¸€è‡´æ€§,æœåŠ¡å‰¯æœ¬åˆ†å¸ƒ

---

---

---

# ç¬¬å››éƒ¨åˆ†:ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ä¸è¿ç»´

---

# ç¬¬13ç« :ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ¶æ„

## 13.1 éƒ¨ç½²æ¶æ„æ¨¡å¼

### 13.1.1 å•æœºéƒ¨ç½²æ¶æ„

**é€‚ç”¨åœºæ™¯**: å¼€å‘ç¯å¢ƒã€å°å‹åº”ç”¨ã€PoCéªŒè¯

```yaml
# docker-compose.yml (å•æœºAll-in-One)
version: '3.8'

services:
  # Webåº”ç”¨
  app:
    image: myapp:latest
    restart: unless-stopped
    ports:
      - "8080:8080"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    environment:
      DATABASE_URL: postgresql://appuser:${DB_PASSWORD}@db:5432/appdb
      REDIS_URL: redis://redis:6379/0
    volumes:
      - app-logs:/var/log/app
    networks:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx-logs:/var/log/nginx
    depends_on:
      - app
    networks:
      - backend

  # æ•°æ®åº“
  db:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_DB: appdb
    secrets:
      - db_password
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser"]
      interval: 10s

  # ç¼“å­˜
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: >
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - backend

networks:
  backend:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
  app-logs:
  nginx-logs:

secrets:
  db_password:
    file: ./secrets/db_password.txt
```

**Nginxé…ç½®ç¤ºä¾‹**:

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 50M;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml;

    # åç«¯åº”ç”¨
    upstream backend {
        server app:8080 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # HTTPé‡å®šå‘åˆ°HTTPS
    server {
        listen 80;
        server_name example.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPSä¸»é…ç½®
    server {
        listen 443 ssl http2;
        server_name example.com;

        # SSLè¯ä¹¦
        ssl_certificate /etc/nginx/ssl/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # å®‰å…¨å¤´
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;

        # åå‘ä»£ç†
        location / {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            proxy_buffering off;
        }

        # é™æ€èµ„æºç¼“å­˜
        location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2)$ {
            proxy_pass http://backend;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # å¥åº·æ£€æŸ¥ç«¯ç‚¹
        location /health {
            access_log off;
            proxy_pass http://backend/health;
        }
    }
}
```

---

### 13.1.2 Docker Swarmé›†ç¾¤æ¶æ„

**é€‚ç”¨åœºæ™¯**: ä¸­å°å‹ç”Ÿäº§ç¯å¢ƒ(10-100å°èŠ‚ç‚¹)

```bash
# é›†ç¾¤æ‹“æ‰‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è´Ÿè½½å‡è¡¡å±‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  HAProxy 1 â”‚  â”‚  HAProxy 2 â”‚  â”‚  HAProxy 3 â”‚        â”‚
â”‚  â”‚ (keepalived)â”‚ â”‚ (keepalived)â”‚ â”‚ (keepalived)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Swarm ManagerèŠ‚ç‚¹                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Manager 1  â”‚  â”‚ Manager 2  â”‚  â”‚ Manager 3  â”‚        â”‚
â”‚  â”‚  (Leader)  â”‚  â”‚ (Reachable)â”‚  â”‚ (Reachable)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Swarm WorkerèŠ‚ç‚¹                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚Workerâ”‚ â”‚Workerâ”‚ â”‚Workerâ”‚ â”‚Workerâ”‚ â”‚Workerâ”‚  ...    â”‚
â”‚  â”‚  1   â”‚ â”‚  2   â”‚ â”‚  3   â”‚ â”‚  4   â”‚ â”‚  5   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Swarmé›†ç¾¤åˆå§‹åŒ–**:

```bash
# ========================================
# 1. å‡†å¤‡èŠ‚ç‚¹(æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œ)
# ========================================

# å…³é—­é˜²ç«å¢™æˆ–å¼€æ”¾å¿…è¦ç«¯å£
$ firewall-cmd --permanent --add-port=2377/tcp  # Swarmç®¡ç†ç«¯å£
$ firewall-cmd --permanent --add-port=7946/tcp  # èŠ‚ç‚¹é—´é€šä¿¡
$ firewall-cmd --permanent --add-port=7946/udp
$ firewall-cmd --permanent --add-port=4789/udp  # Overlayç½‘ç»œ
$ firewall-cmd --reload

# é…ç½®æ—¶é—´åŒæ­¥(å…³é”®!)
$ timedatectl set-ntp true
$ systemctl enable chronyd && systemctl start chronyd

# ========================================
# 2. åˆå§‹åŒ–Swarmé›†ç¾¤(Manager1æ‰§è¡Œ)
# ========================================

# åˆå§‹åŒ–ç¬¬ä¸€ä¸ªManager
$ docker swarm init \
  --advertise-addr 192.168.1.10 \
  --data-path-addr 192.168.1.10

# è¾“å‡º:
Swarm initialized: current node (abc123) is now a manager.

To add a worker to this swarm, run the following command:
    docker swarm join --token SWMTKN-1-xxx-worker 192.168.1.10:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

# è·å–ManageråŠ å…¥ä»¤ç‰Œ
$ docker swarm join-token manager
docker swarm join --token SWMTKN-1-xxx-manager 192.168.1.10:2377

# è·å–WorkeråŠ å…¥ä»¤ç‰Œ
$ docker swarm join-token worker
docker swarm join --token SWMTKN-1-xxx-worker 192.168.1.10:2377

# ========================================
# 3. æ·»åŠ ManagerèŠ‚ç‚¹(Manager2/3æ‰§è¡Œ)
# ========================================

# Manager2 (192.168.1.11)
$ docker swarm join \
  --token SWMTKN-1-xxx-manager \
  --advertise-addr 192.168.1.11 \
  192.168.1.10:2377

# Manager3 (192.168.1.12)
$ docker swarm join \
  --token SWMTKN-1-xxx-manager \
  --advertise-addr 192.168.1.12 \
  192.168.1.10:2377

# ========================================
# 4. æ·»åŠ WorkerèŠ‚ç‚¹(Worker1-Næ‰§è¡Œ)
# ========================================

# Worker1 (192.168.1.21)
$ docker swarm join \
  --token SWMTKN-1-xxx-worker \
  --advertise-addr 192.168.1.21 \
  192.168.1.10:2377

# Worker2-N ç±»ä¼¼æ“ä½œ...

# ========================================
# 5. éªŒè¯é›†ç¾¤çŠ¶æ€(ä»»æ„Manageræ‰§è¡Œ)
# ========================================

$ docker node ls
ID                HOSTNAME    STATUS  AVAILABILITY  MANAGER STATUS
abc123 *          manager1    Ready   Active        Leader
def456            manager2    Ready   Active        Reachable
ghi789            manager3    Ready   Active        Reachable
jkl012            worker1     Ready   Active
mno345            worker2     Ready   Active
pqr678            worker3     Ready   Active

# æŸ¥çœ‹é›†ç¾¤è¯¦ç»†ä¿¡æ¯
$ docker info | grep -A 10 Swarm
Swarm: active
 NodeID: abc123
 Is Manager: true
 ClusterID: xyz789
 Managers: 3
 Nodes: 6
 Default Address Pool: 10.0.0.0/8
 SubnetSize: 24
 Orchestration:
  Task History Retention Limit: 5
```

**ç”Ÿäº§çº§Stackéƒ¨ç½²**:

```yaml
# stack.yml - å®Œæ•´ç”Ÿäº§ç¯å¢ƒé…ç½®
version: '3.8'

# å…¨å±€é…ç½®é”šç‚¹
x-default-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "3"
    compress: "true"
    labels: "service,stack"

x-deploy-defaults: &deploy-defaults
  update_config:
    parallelism: 1
    delay: 10s
    failure_action: rollback
    monitor: 60s
  rollback_config:
    parallelism: 1
    delay: 5s
  restart_policy:
    condition: on-failure
    delay: 5s
    max_attempts: 3
    window: 120s

services:
  # ========================================
  # Webåº”ç”¨å±‚
  # ========================================
  app:
    image: registry.company.com/myapp:${VERSION:-latest}
    logging: *default-logging
    networks:
      - frontend
      - backend
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://appuser:${DB_PASSWORD}@db:5432/appdb
      REDIS_URL: redis://redis:6379/0
    secrets:
      - db_password
      - app_secret_key
    configs:
      - source: app_config
        target: /etc/app/config.yaml
    deploy:
      <<: *deploy-defaults
      mode: replicated
      replicas: 6
      placement:
        constraints:
          - node.role == worker
          - node.labels.tier == app
        preferences:
          - spread: node.labels.zone  # è·¨å¯ç”¨åŒºåˆ†å¸ƒ
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.app.rule=Host(`app.example.com`)"
        - "traefik.http.services.app.loadbalancer.server.port=8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 40s

  # ========================================
  # è´Ÿè½½å‡è¡¡/åå‘ä»£ç†
  # ========================================
  traefik:
    image: traefik:v2.10
    logging: *default-logging
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 8080
        published: 8080
        protocol: tcp
        mode: host  # ç›‘æ§é¢æ¿
    networks:
      - frontend
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik-certs:/etc/traefik/certs
    configs:
      - source: traefik_config
        target: /etc/traefik/traefik.yml
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager  # ä»…åœ¨ManagerèŠ‚ç‚¹è¿è¡Œ
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # ========================================
  # æ•°æ®åº“(æœ‰çŠ¶æ€æœåŠ¡)
  # ========================================
  db:
    image: postgres:15-alpine
    logging: *default-logging
    networks:
      - backend
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_DB: appdb
      PGDATA: /var/lib/postgresql/data/pgdata
    secrets:
      - db_password
    volumes:
      - postgres-data:/var/lib/postgresql/data
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == worker
          - node.labels.tier == db
          - node.labels.ssd == true  # è¦æ±‚SSDå­˜å‚¨
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ========================================
  # ç¼“å­˜å±‚
  # ========================================
  redis:
    image: redis:7-alpine
    logging: *default-logging
    networks:
      - backend
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
    secrets:
      - redis_password
    volumes:
      - redis-data:/data
    deploy:
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.role == worker
          - node.labels.tier == cache
        preferences:
          - spread: node.labels.zone
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # ========================================
  # åå°ä»»åŠ¡Worker
  # ========================================
  worker:
    image: registry.company.com/myapp:${VERSION:-latest}
    logging: *default-logging
    networks:
      - backend
    command: ["python", "worker.py"]
    environment:
      WORKER_CONCURRENCY: 4
      REDIS_URL: redis://redis:6379/0
    secrets:
      - db_password
    deploy:
      <<: *deploy-defaults
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.role == worker
          - node.labels.tier == app
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ========================================
  # å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
  # ========================================
  scheduler:
    image: registry.company.com/myapp:${VERSION:-latest}
    logging: *default-logging
    networks:
      - backend
    command: ["python", "scheduler.py"]
    environment:
      REDIS_URL: redis://redis:6379/0
    secrets:
      - db_password
    deploy:
      mode: replicated
      replicas: 1  # ä»…è¿è¡Œ1ä¸ªå®ä¾‹é¿å…é‡å¤è°ƒåº¦
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

# ========================================
# ç½‘ç»œé…ç½®
# ========================================
networks:
  frontend:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.10.0.0/24
  backend:
    driver: overlay
    internal: true  # å†…éƒ¨ç½‘ç»œ,ä¸å…è®¸å¤–éƒ¨è®¿é—®
    attachable: true
    ipam:
      config:
        - subnet: 10.10.1.0/24

# ========================================
# æ•°æ®å·
# ========================================
volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=192.168.1.100,rw,nolock
      device: ":/export/postgres-data"

  redis-data:
    driver: local

  traefik-certs:
    driver: local

# ========================================
# é…ç½®æ–‡ä»¶
# ========================================
configs:
  app_config:
    file: ./configs/app-config.yaml

  traefik_config:
    file: ./configs/traefik.yml

# ========================================
# ç§˜é’¥
# ========================================
secrets:
  db_password:
    external: true

  redis_password:
    external: true

  app_secret_key:
    external: true
```

**éƒ¨ç½²ä¸ç®¡ç†**:

```bash
# ========================================
# åˆ›å»ºå¤–éƒ¨ç§˜é’¥
# ========================================

# ä»æ–‡ä»¶åˆ›å»ºç§˜é’¥
$ echo "MyDBPassword123" | docker secret create db_password -
$ echo "MyRedisPassword456" | docker secret create redis_password -
$ openssl rand -base64 32 | docker secret create app_secret_key -

# éªŒè¯ç§˜é’¥
$ docker secret ls
ID            NAME              CREATED
abc123        db_password       10 seconds ago
def456        redis_password    8 seconds ago
ghi789        app_secret_key    5 seconds ago

# ========================================
# éƒ¨ç½²Stack
# ========================================

# éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
$ docker stack deploy -c stack.yml --with-registry-auth myapp

# éªŒè¯éƒ¨ç½²çŠ¶æ€
$ docker stack services myapp
ID        NAME           MODE        REPLICAS  IMAGE
abc123    myapp_app      replicated  6/6       registry.company.com/myapp:v1.2.3
def456    myapp_db       replicated  1/1       postgres:15-alpine
ghi789    myapp_redis    replicated  3/3       redis:7-alpine
jkl012    myapp_worker   replicated  3/3       registry.company.com/myapp:v1.2.3
mno345    myapp_traefik  global      3/3       traefik:v2.10

# æŸ¥çœ‹æœåŠ¡è¯¦æƒ…
$ docker service ps myapp_app
ID        NAME          IMAGE                           NODE      DESIRED STATE  CURRENT STATE
abc123    myapp_app.1   registry.company.com/myapp:v1  worker1   Running        Running 2 minutes ago
def456    myapp_app.2   registry.company.com/myapp:v1  worker2   Running        Running 2 minutes ago
ghi789    myapp_app.3   registry.company.com/myapp:v1  worker3   Running        Running 2 minutes ago

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
$ docker service logs -f myapp_app --tail 100

# ========================================
# æ‰©ç¼©å®¹
# ========================================

# æ°´å¹³æ‰©å®¹
$ docker service scale myapp_app=10

# éªŒè¯æ‰©å®¹
$ docker service ls
ID        NAME        REPLICAS
abc123    myapp_app   10/10

# ========================================
# æ»šåŠ¨æ›´æ–°
# ========================================

# æ›´æ–°é•œåƒç‰ˆæœ¬
$ docker service update \
  --image registry.company.com/myapp:v1.2.4 \
  --update-parallelism 2 \
  --update-delay 30s \
  myapp_app

# ç›‘æ§æ›´æ–°è¿›åº¦
$ watch -n 1 'docker service ps myapp_app'

# å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
$ docker service rollback myapp_app

# ========================================
# æ¸…ç†
# ========================================

# åˆ é™¤Stack(ä¿ç•™æ•°æ®å·)
$ docker stack rm myapp

# å®Œå…¨æ¸…ç†(åŒ…æ‹¬æ•°æ®å·)
$ docker stack rm myapp
$ docker volume prune -f
```

---

### 13.1.3 Kubernetesé›†ç¾¤æ¶æ„(å¯¹æ¯”)

**é€‚ç”¨åœºæ™¯**: å¤§å‹ç”Ÿäº§ç¯å¢ƒ(100+å°èŠ‚ç‚¹)ã€å¤šé›†ç¾¤ç®¡ç†

```bash
# Kubernetes vs Swarm å¯¹æ¯”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç‰¹æ€§         â”‚   Docker Swarm      â”‚   Kubernetes        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å­¦ä¹ æ›²çº¿       â”‚ â­â­ ç®€å•            â”‚ â­â­â­â­â­ å¤æ‚      â”‚
â”‚ éƒ¨ç½²å¤æ‚åº¦     â”‚ â­â­ å†…ç½®            â”‚ â­â­â­â­ éœ€é¢å¤–å®‰è£…  â”‚
â”‚ é›†ç¾¤è§„æ¨¡       â”‚ ä¸­å°(10-100èŠ‚ç‚¹)    â”‚ å¤§å‹(1000+èŠ‚ç‚¹)     â”‚
â”‚ ç”Ÿæ€ç³»ç»Ÿ       â”‚ â­â­â­ å¤Ÿç”¨          â”‚ â­â­â­â­â­ ä¸°å¯Œ      â”‚
â”‚ æœåŠ¡å‘ç°       â”‚ å†…ç½®DNS             â”‚ CoreDNS + Ingress   â”‚
â”‚ è´Ÿè½½å‡è¡¡       â”‚ Ingressè‡ªåŠ¨         â”‚ Service + Ingress   â”‚
â”‚ å­˜å‚¨ç¼–æ’       â”‚ Volumeæ’ä»¶          â”‚ StorageClass + PV   â”‚
â”‚ é…ç½®ç®¡ç†       â”‚ Config + Secret     â”‚ ConfigMap + Secret  â”‚
â”‚ è‡ªåŠ¨æ‰©ç¼©å®¹     â”‚ æ‰‹åŠ¨scale           â”‚ HPAè‡ªåŠ¨             â”‚
â”‚ å¤šé›†ç¾¤ç®¡ç†     â”‚ âŒ ä¸æ”¯æŒ            â”‚ âœ… Federation       â”‚
â”‚ RBACæƒé™       â”‚ â­â­â­ åŸºç¡€          â”‚ â­â­â­â­â­ ç»†ç²’åº¦    â”‚
â”‚ ç›‘æ§é›†æˆ       â”‚ éœ€è‡ªè¡Œéƒ¨ç½²          â”‚ Metrics Server      â”‚
â”‚ ç¤¾åŒºæ´»è·ƒåº¦     â”‚ â­â­â­ ä¸­ç­‰          â”‚ â­â­â­â­â­ éå¸¸æ´»è·ƒ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# é€‰å‹å»ºè®®:
âœ… Swarm: ä¸­å°å‹å›¢é˜Ÿã€å¿«é€Ÿä¸Šçº¿ã€DockeråŸç”Ÿã€å­¦ä¹ æˆæœ¬ä½
âœ… K8s: å¤§å‹ä¼ä¸šã€å¤æ‚åœºæ™¯ã€éœ€è¦é«˜çº§ç‰¹æ€§ã€æœ‰è¿ç»´å›¢é˜Ÿ
```

**K8sç­‰æ•ˆé…ç½®(ä»…ä¾›å‚è€ƒ)**:

```yaml
# kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: production
spec:
  replicas: 6
  selector:
    matchLabels:
      app: myapp
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: myapp
        version: v1.2.3
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - myapp
              topologyKey: kubernetes.io/hostname
      containers:
      - name: app
        image: registry.company.com/myapp:v1.2.3
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url
        resources:
          limits:
            cpu: "1"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 40
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: production
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  namespace: production
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - app.example.com
    secretName: app-tls
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
```

---

## 13.2 æœåŠ¡å‘ç°ä¸æ³¨å†Œ

### 13.2.1 Dockerå†…ç½®æœåŠ¡å‘ç°

**Swarm DNSè‡ªåŠ¨æœåŠ¡å‘ç°**:

```bash
# Swarmè‡ªåŠ¨ä¸ºæ¯ä¸ªæœåŠ¡åˆ›å»ºDNSè®°å½•

# éƒ¨ç½²æœåŠ¡
$ docker service create --name web --replicas 3 nginx:alpine
$ docker service create --name api --replicas 5 myapi:latest

# åœ¨ä»»æ„å®¹å™¨å†…æµ‹è¯•DNSè§£æ
$ docker run --rm --network myapp_backend alpine nslookup web
Server:    127.0.0.11
Address 1: 127.0.0.11

Name:      web
Address 1: 10.0.1.2 web.1.abc123  # VIP(è™šæ‹ŸIP)

# DNSè´Ÿè½½å‡è¡¡æµ‹è¯•
$ for i in {1..10}; do
    docker run --rm --network myapp_backend alpine \
      wget -qO- http://api:8080/health
  done

# Swarmè‡ªåŠ¨è½®è¯¢æ‰€æœ‰apiæœåŠ¡å‰¯æœ¬
```

**æœåŠ¡åˆ«å(Service Alias)**:

```yaml
# docker-compose.yml
version: '3.8'
services:
  app:
    image: myapp:latest
    networks:
      backend:
        aliases:
          - myapp  # åˆ«å
          - application  # å¤šä¸ªåˆ«å

  db:
    image: postgres:15
    networks:
      backend:
        aliases:
          - database
          - postgres-master

networks:
  backend:
    driver: overlay
```

```bash
# é€šè¿‡åˆ«åè®¿é—®æœåŠ¡
$ docker run --rm --network backend alpine ping myapp
$ docker run --rm --network backend alpine ping application
$ docker run --rm --network backend alpine ping database
```

---

### 13.2.2 ConsulæœåŠ¡æ³¨å†Œä¸å‘ç°

**Consulæ¶æ„**:

```bash
# Consulé›†ç¾¤æ‹“æ‰‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Consul Serveré›†ç¾¤ (3èŠ‚ç‚¹)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Server 1  â”‚ â”‚  Server 2  â”‚ â”‚  Server 3  â”‚â”‚
â”‚  â”‚  (Leader)  â”‚ â”‚ (Follower) â”‚ â”‚ (Follower) â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚         â”‚         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Client 1â”‚  â”‚Client 2â”‚  â”‚Client 3â”‚  â”‚Client Nâ”‚
â”‚(Agent) â”‚  â”‚(Agent) â”‚  â”‚(Agent) â”‚  â”‚(Agent) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Consuléƒ¨ç½²**:

```yaml
# consul-stack.yml
version: '3.8'

services:
  # Consul Serveré›†ç¾¤
  consul-server-1:
    image: consul:1.17
    hostname: consul-server-1
    command: >
      agent -server -bootstrap-expect=3
      -ui -client=0.0.0.0
      -bind='{{ GetInterfaceIP "eth0" }}'
      -retry-join=consul-server-2
      -retry-join=consul-server-3
    environment:
      CONSUL_LOCAL_CONFIG: |
        {
          "datacenter": "dc1",
          "data_dir": "/consul/data",
          "log_level": "INFO",
          "node_name": "consul-server-1",
          "server": true
        }
    volumes:
      - consul-server-1-data:/consul/data
    networks:
      - consul-net
    ports:
      - "8500:8500"  # HTTP API
      - "8600:8600/udp"  # DNS
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.consul == server1

  consul-server-2:
    image: consul:1.17
    hostname: consul-server-2
    command: >
      agent -server -bootstrap-expect=3
      -bind='{{ GetInterfaceIP "eth0" }}'
      -retry-join=consul-server-1
      -retry-join=consul-server-3
    environment:
      CONSUL_LOCAL_CONFIG: |
        {
          "datacenter": "dc1",
          "data_dir": "/consul/data",
          "log_level": "INFO",
          "node_name": "consul-server-2",
          "server": true
        }
    volumes:
      - consul-server-2-data:/consul/data
    networks:
      - consul-net
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.consul == server2

  consul-server-3:
    image: consul:1.17
    hostname: consul-server-3
    command: >
      agent -server -bootstrap-expect=3
      -bind='{{ GetInterfaceIP "eth0" }}'
      -retry-join=consul-server-1
      -retry-join=consul-server-2
    environment:
      CONSUL_LOCAL_CONFIG: |
        {
          "datacenter": "dc1",
          "data_dir": "/consul/data",
          "log_level": "INFO",
          "node_name": "consul-server-3",
          "server": true
        }
    volumes:
      - consul-server-3-data:/consul/data
    networks:
      - consul-net
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.consul == server3

  # Consul Client (æ¯ä¸ªWorkerèŠ‚ç‚¹è¿è¡Œ)
  consul-agent:
    image: consul:1.17
    command: >
      agent -client=0.0.0.0
      -bind='{{ GetInterfaceIP "eth0" }}'
      -retry-join=consul-server-1
      -retry-join=consul-server-2
      -retry-join=consul-server-3
    environment:
      CONSUL_LOCAL_CONFIG: |
        {
          "datacenter": "dc1",
          "data_dir": "/consul/data",
          "log_level": "INFO",
          "enable_script_checks": true,
          "leave_on_terminate": true
        }
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - consul-agent-data:/consul/data
    networks:
      - consul-net
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == worker

networks:
  consul-net:
    driver: overlay
    attachable: true

volumes:
  consul-server-1-data:
  consul-server-2-data:
  consul-server-3-data:
  consul-agent-data:
```

**åº”ç”¨æ³¨å†Œåˆ°Consul**:

```python
# app.py - Pythonåº”ç”¨ç¤ºä¾‹
import os
import consul
import socket
from flask import Flask, jsonify

app = Flask(__name__)

# Consulé…ç½®
CONSUL_HOST = os.getenv('CONSUL_HOST', 'consul-agent')
CONSUL_PORT = int(os.getenv('CONSUL_PORT', 8500))
SERVICE_NAME = os.getenv('SERVICE_NAME', 'myapp')
SERVICE_PORT = int(os.getenv('SERVICE_PORT', 8080))

def register_service():
    """æ³¨å†ŒæœåŠ¡åˆ°Consul"""
    c = consul.Consul(host=CONSUL_HOST, port=CONSUL_PORT)

    # è·å–å®¹å™¨IP
    hostname = socket.gethostname()
    container_ip = socket.gethostbyname(hostname)

    # å¥åº·æ£€æŸ¥é…ç½®
    check = consul.Check.http(
        url=f'http://{container_ip}:{SERVICE_PORT}/health',
        interval='10s',
        timeout='5s',
        deregister='30s'  # 30ç§’æ— å“åº”è‡ªåŠ¨æ³¨é”€
    )

    # æ³¨å†ŒæœåŠ¡
    c.agent.service.register(
        name=SERVICE_NAME,
        service_id=f'{SERVICE_NAME}-{hostname}',
        address=container_ip,
        port=SERVICE_PORT,
        tags=['api', 'v1', 'production'],
        check=check,
        meta={
            'version': '1.2.3',
            'git_commit': 'abc123',
            'environment': 'production'
        }
    )
    print(f'âœ… Service registered: {SERVICE_NAME} at {container_ip}:{SERVICE_PORT}')

def deregister_service():
    """æ³¨é”€æœåŠ¡"""
    c = consul.Consul(host=CONSUL_HOST, port=CONSUL_PORT)
    hostname = socket.gethostname()
    service_id = f'{SERVICE_NAME}-{hostname}'
    c.agent.service.deregister(service_id)
    print(f'âœ… Service deregistered: {service_id}')

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({'status': 'healthy'}), 200

@app.route('/api/users')
def get_users():
    """ä¸šåŠ¡API"""
    return jsonify({'users': []}), 200

if __name__ == '__main__':
    import atexit
    import signal

    # å¯åŠ¨æ—¶æ³¨å†Œ
    register_service()

    # ä¼˜é›…å…³é—­æ—¶æ³¨é”€
    def cleanup(signum, frame):
        deregister_service()
        exit(0)

    signal.signal(signal.SIGTERM, cleanup)
    signal.signal(signal.SIGINT, cleanup)
    atexit.register(deregister_service)

    # å¯åŠ¨Flask
    app.run(host='0.0.0.0', port=SERVICE_PORT)
```

**æœåŠ¡å‘ç°å®¢æˆ·ç«¯**:

```python
# client.py - ä»Consulå‘ç°æœåŠ¡
import consul
import requests
import random

def discover_service(service_name='myapp'):
    """ä»Consulå‘ç°æœåŠ¡å®ä¾‹"""
    c = consul.Consul(host='consul-agent', port=8500)

    # æŸ¥è¯¢å¥åº·çš„æœåŠ¡å®ä¾‹
    index, services = c.health.service(service_name, passing=True)

    if not services:
        raise Exception(f'No healthy instances found for {service_name}')

    # éšæœºé€‰æ‹©ä¸€ä¸ªå®ä¾‹(å®¢æˆ·ç«¯è´Ÿè½½å‡è¡¡)
    instance = random.choice(services)
    service_info = instance['Service']

    return {
        'address': service_info['Address'],
        'port': service_info['Port'],
        'tags': service_info['Tags'],
        'meta': service_info['Meta']
    }

# ä½¿ç”¨ç¤ºä¾‹
def call_api():
    service = discover_service('myapp')
    url = f"http://{service['address']}:{service['port']}/api/users"
    response = requests.get(url)
    return response.json()

# æµ‹è¯•
if __name__ == '__main__':
    for i in range(10):
        service = discover_service('myapp')
        print(f"Request {i+1}: {service['address']}:{service['port']}")
        result = call_api()
        print(f"  Response: {result}")
```

**Consulç®¡ç†å‘½ä»¤**:

```bash
# ========================================
# Consulé›†ç¾¤ç®¡ç†
# ========================================

# æŸ¥çœ‹é›†ç¾¤æˆå‘˜
$ docker exec consul-server-1 consul members
Node              Address          Status  Type    Build  Protocol  DC   Segment
consul-server-1   10.0.1.2:8301    alive   server  1.17   2         dc1  <all>
consul-server-2   10.0.1.3:8301    alive   server  1.17   2         dc1  <all>
consul-server-3   10.0.1.4:8301    alive   server  1.17   2         dc1  <all>
worker1           10.0.1.10:8301   alive   client  1.17   2         dc1  <default>
worker2           10.0.1.11:8301   alive   client  1.17   2         dc1  <default>

# æŸ¥çœ‹Leader
$ docker exec consul-server-1 consul operator raft list-peers
Node              ID               Address          State     Voter  RaftProtocol
consul-server-1   abc123           10.0.1.2:8300    leader    true   3
consul-server-2   def456           10.0.1.3:8300    follower  true   3
consul-server-3   ghi789           10.0.1.4:8300    follower  true   3

# ========================================
# æœåŠ¡æŸ¥è¯¢
# ========================================

# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡
$ docker exec consul-server-1 consul catalog services
consul
myapp
postgres
redis

# æŸ¥çœ‹æœåŠ¡è¯¦æƒ…
$ docker exec consul-server-1 consul catalog service myapp
Node     Address    TaggedAddresses  ServiceID      ServiceName  ServiceTags
worker1  10.0.1.10  ...              myapp-abc123   myapp        api,v1,production
worker2  10.0.1.11  ...              myapp-def456   myapp        api,v1,production
worker3  10.0.1.12  ...              myapp-ghi789   myapp        api,v1,production

# DNSæŸ¥è¯¢æœåŠ¡
$ dig @127.0.0.1 -p 8600 myapp.service.consul SRV
;; ANSWER SECTION:
myapp.service.consul. 0 IN SRV 1 1 8080 abc123.node.dc1.consul.
myapp.service.consul. 0 IN SRV 1 1 8080 def456.node.dc1.consul.
myapp.service.consul. 0 IN SRV 1 1 8080 ghi789.node.dc1.consul.

# ========================================
# å¥åº·æ£€æŸ¥
# ========================================

# æŸ¥çœ‹æœåŠ¡å¥åº·çŠ¶æ€
$ docker exec consul-server-1 consul health checks myapp
Node     CheckID          Name                 Status  Notes
worker1  service:myapp    Service 'myapp' check passing
worker2  service:myapp    Service 'myapp' check passing
worker3  service:myapp    Service 'myapp' check critical HTTP GET http://10.0.1.12:8080/health: timeout

# ========================================
# KVå­˜å‚¨
# ========================================

# å†™å…¥é…ç½®
$ docker exec consul-server-1 consul kv put config/myapp/db_host postgres.example.com
$ docker exec consul-server-1 consul kv put config/myapp/db_port 5432

# è¯»å–é…ç½®
$ docker exec consul-server-1 consul kv get config/myapp/db_host
postgres.example.com

# ç›‘å¬é…ç½®å˜æ›´
$ docker exec consul-server-1 consul watch -type=key -key=config/myapp/db_host \
  /usr/local/bin/reload-config.sh
```

---

## 13.3 è´Ÿè½½å‡è¡¡æ–¹æ¡ˆ

### 13.3.1 HAProxyé«˜å¯ç”¨è´Ÿè½½å‡è¡¡

**HAProxy + Keepalivedæ¶æ„**:

```bash
# é«˜å¯ç”¨è´Ÿè½½å‡è¡¡æ‹“æ‰‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       è™šæ‹ŸIP (VIP: 192.168.1.100)      â”‚
â”‚              Keepalived                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  HAProxy 1   â”‚   â”‚  HAProxy 2   â”‚  â”‚
â”‚  â”‚  (MASTER)    â”‚   â”‚  (BACKUP)    â”‚  â”‚
â”‚  â”‚192.168.1.101 â”‚   â”‚192.168.1.102 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚                                â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”
â”‚Backend â”‚  â”‚Backend â”‚  â”‚Backend â”‚ â”‚Backendâ”‚
â”‚   1    â”‚  â”‚   2    â”‚  â”‚   3    â”‚ â”‚   N   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

**HAProxyé…ç½®**:

```bash
# haproxy.cfg
global
    log stdout format raw local0 info
    maxconn 40000
    user haproxy
    group haproxy
    daemon
    stats socket /var/run/haproxy.sock mode 660 level admin
    stats timeout 30s

    # SSLé…ç½®
    ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256
    ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
    log     global
    mode    http
    option  httplog
    option  dontlognull
    option  http-server-close
    option  forwardfor except 127.0.0.0/8
    option  redispatch
    retries 3
    timeout connect 5000
    timeout client  50000
    timeout server  50000
    errorfile 400 /etc/haproxy/errors/400.http
    errorfile 403 /etc/haproxy/errors/403.http
    errorfile 408 /etc/haproxy/errors/408.http
    errorfile 500 /etc/haproxy/errors/500.http
    errorfile 502 /etc/haproxy/errors/502.http
    errorfile 503 /etc/haproxy/errors/503.http
    errorfile 504 /etc/haproxy/errors/504.http

# ========================================
# ç›‘æ§é¢æ¿
# ========================================
listen stats
    bind *:8404
    stats enable
    stats uri /stats
    stats refresh 5s
    stats show-legends
    stats show-node
    stats auth admin:SecurePassword123

# ========================================
# HTTPå‰ç«¯(80ç«¯å£)
# ========================================
frontend http_front
    bind *:80
    mode http

    # è¯·æ±‚é™é€Ÿ(é˜²DDoS)
    stick-table type ip size 100k expire 30s store http_req_rate(10s)
    http-request track-sc0 src
    http-request deny if { sc_http_req_rate(0) gt 100 }

    # ACLè§„åˆ™
    acl is_api path_beg /api
    acl is_static path_end .jpg .jpeg .png .gif .css .js .ico .svg .woff .woff2
    acl is_health path /health

    # è·¯ç”±è§„åˆ™
    use_backend api_backend if is_api
    use_backend static_backend if is_static
    use_backend health_backend if is_health
    default_backend web_backend

# ========================================
# HTTPSå‰ç«¯(443ç«¯å£)
# ========================================
frontend https_front
    bind *:443 ssl crt /etc/haproxy/certs/example.com.pem alpn h2,http/1.1
    mode http

    # HSTSå¤´
    http-response set-header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload"

    # åŒæ ·çš„ACLå’Œè·¯ç”±è§„åˆ™
    acl is_api path_beg /api
    acl is_static path_end .jpg .jpeg .png .gif .css .js .ico .svg .woff .woff2

    use_backend api_backend if is_api
    use_backend static_backend if is_static
    default_backend web_backend

# ========================================
# Webåº”ç”¨åç«¯
# ========================================
backend web_backend
    mode http
    balance roundrobin
    option httpchk GET /health
    http-check expect status 200

    # åç«¯æœåŠ¡å™¨
    server web1 192.168.1.21:8080 check inter 5s fall 3 rise 2 weight 100
    server web2 192.168.1.22:8080 check inter 5s fall 3 rise 2 weight 100
    server web3 192.168.1.23:8080 check inter 5s fall 3 rise 2 weight 100
    server web4 192.168.1.24:8080 check inter 5s fall 3 rise 2 weight 50 backup

# ========================================
# APIåç«¯(ç²˜æ€§ä¼šè¯)
# ========================================
backend api_backend
    mode http
    balance leastconn
    option httpchk GET /api/health
    http-check expect status 200

    # Cookieç²˜æ€§ä¼šè¯
    cookie SERVERID insert indirect nocache

    server api1 192.168.1.31:8080 check cookie api1 inter 5s
    server api2 192.168.1.32:8080 check cookie api2 inter 5s
    server api3 192.168.1.33:8080 check cookie api3 inter 5s
    server api4 192.168.1.34:8080 check cookie api4 inter 5s
    server api5 192.168.1.35:8080 check cookie api5 inter 5s

# ========================================
# é™æ€èµ„æºåç«¯(ç¼“å­˜)
# ========================================
backend static_backend
    mode http
    balance roundrobin
    option httpchk GET /health

    # ç¼“å­˜é…ç½®
    http-request cache-use static_cache
    http-response cache-store static_cache

    server static1 192.168.1.41:8080 check inter 10s
    server static2 192.168.1.42:8080 check inter 10s

cache static_cache
    total-max-size 256
    max-object-size 10240
    max-age 3600

# ========================================
# å¥åº·æ£€æŸ¥åç«¯
# ========================================
backend health_backend
    mode http
    server health 127.0.0.1:8404
```

**Keepalivedé…ç½®(HAProxy 1 - MASTER)**:

```bash
# /etc/keepalived/keepalived.conf (HAProxy 1)
global_defs {
    router_id HAProxy_1
    vrrp_skip_check_adv_addr
    vrrp_garp_interval 0
    vrrp_gna_interval 0
}

vrrp_script chk_haproxy {
    script "/usr/bin/killall -0 haproxy"
    interval 2
    weight 2
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 101
    advert_int 1

    authentication {
        auth_type PASS
        auth_pass SecurePassword123
    }

    virtual_ipaddress {
        192.168.1.100/24
    }

    track_script {
        chk_haproxy
    }

    notify_master "/etc/keepalived/notify.sh MASTER"
    notify_backup "/etc/keepalived/notify.sh BACKUP"
    notify_fault "/etc/keepalived/notify.sh FAULT"
}
```

**Keepalivedé…ç½®(HAProxy 2 - BACKUP)**:

```bash
# /etc/keepalived/keepalived.conf (HAProxy 2)
global_defs {
    router_id HAProxy_2
    vrrp_skip_check_adv_addr
    vrrp_garp_interval 0
    vrrp_gna_interval 0
}

vrrp_script chk_haproxy {
    script "/usr/bin/killall -0 haproxy"
    interval 2
    weight 2
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    virtual_router_id 51
    priority 100  # æ¯”MASTERä½
    advert_int 1

    authentication {
        auth_type PASS
        auth_pass SecurePassword123
    }

    virtual_ipaddress {
        192.168.1.100/24
    }

    track_script {
        chk_haproxy
    }

    notify_master "/etc/keepalived/notify.sh MASTER"
    notify_backup "/etc/keepalived/notify.sh BACKUP"
    notify_fault "/etc/keepalived/notify.sh FAULT"
}
```

**Docker Composeéƒ¨ç½²HAProxy**:

```yaml
# haproxy-stack.yml
version: '3.8'

services:
  haproxy:
    image: haproxy:2.9-alpine
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 8404
        published: 8404
        protocol: tcp
        mode: host
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./haproxy/certs:/etc/haproxy/certs:ro
      - haproxy-logs:/var/log/haproxy
    networks:
      - frontend
      - backend
    deploy:
      mode: global
      placement:
        constraints:
          - node.labels.lb == true
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "nc", "-z", "127.0.0.1", "80"]
      interval: 10s
      timeout: 3s
      retries: 3

networks:
  frontend:
    driver: overlay
    attachable: true
  backend:
    driver: overlay
    attachable: true

volumes:
  haproxy-logs:
```

**éªŒè¯ä¸ç›‘æ§**:

```bash
# ========================================
# éªŒè¯VIP
# ========================================

# HAProxy 1ä¸ŠæŸ¥çœ‹VIP
$ ip addr show eth0 | grep 192.168.1.100
    inet 192.168.1.100/24 scope global secondary eth0

# æµ‹è¯•æ•…éšœè½¬ç§»
# åœ¨HAProxy 1ä¸Šåœæ­¢æœåŠ¡
$ systemctl stop haproxy

# VIPåº”è‡ªåŠ¨æ¼‚ç§»åˆ°HAProxy 2
$ ip addr show eth0 | grep 192.168.1.100  # HAProxy 2ä¸Šæ‰§è¡Œ
    inet 192.168.1.100/24 scope global secondary eth0

# ========================================
# è®¿é—®ç›‘æ§é¢æ¿
# ========================================

# æµè§ˆå™¨è®¿é—®:
# http://192.168.1.100:8404/stats
# ç”¨æˆ·å: admin
# å¯†ç : SecurePassword123

# å‘½ä»¤è¡ŒæŸ¥çœ‹ç»Ÿè®¡
$ echo "show stat" | socat unix-connect:/var/run/haproxy.sock stdio

# ========================================
# å‹åŠ›æµ‹è¯•
# ========================================

# ä½¿ç”¨abè¿›è¡Œå‹æµ‹
$ ab -n 100000 -c 100 http://192.168.1.100/

# ä½¿ç”¨wrkè¿›è¡Œå‹æµ‹
$ wrk -t 12 -c 400 -d 60s http://192.168.1.100/

# è§‚å¯ŸHAProxyç»Ÿè®¡
$ watch -n 1 'echo "show stat" | socat unix-connect:/var/run/haproxy.sock stdio | grep web_backend'
```

---

### 13.3.2 TraefikåŠ¨æ€è´Ÿè½½å‡è¡¡

**Traefikç‰¹ç‚¹**:
- âœ… è‡ªåŠ¨æœåŠ¡å‘ç°(Docker/Swarm/K8s)
- âœ… è‡ªåŠ¨HTTPS(Let's Encrypt)
- âœ… åŠ¨æ€é…ç½®(æ— éœ€é‡å¯)
- âœ… ä¸­é—´ä»¶æ”¯æŒ(è®¤è¯/é™æµ/å‹ç¼©)
- âœ… WebSocket/gRPCæ”¯æŒ
- âœ… ç°ä»£åŒ–Dashboard

**Traefiké…ç½®**:

```yaml
# traefik/traefik.yml
# ========================================
# å…¨å±€é…ç½®
# ========================================
global:
  checkNewVersion: true
  sendAnonymousUsage: false

# ========================================
# APIå’ŒDashboard
# ========================================
api:
  dashboard: true
  insecure: false  # ç”Ÿäº§ç¯å¢ƒå¿…é¡»false

# ========================================
# æ—¥å¿—
# ========================================
log:
  level: INFO
  format: json
  filePath: /var/log/traefik/traefik.log

accessLog:
  filePath: /var/log/traefik/access.log
  format: json
  fields:
    headers:
      defaultMode: keep
      names:
        User-Agent: keep
        Authorization: drop
        Content-Type: keep

# ========================================
# å…¥å£ç‚¹(EntryPoints)
# ========================================
entryPoints:
  web:
    address: ":80"
    http:
      redirections:
        entryPoint:
          to: websecure
          scheme: https
          permanent: true

  websecure:
    address: ":443"
    http:
      tls:
        certResolver: letsencrypt

  metrics:
    address: ":8082"

# ========================================
# è¯ä¹¦è§£æå™¨(Let's Encrypt)
# ========================================
certificatesResolvers:
  letsencrypt:
    acme:
      email: admin@example.com
      storage: /etc/traefik/acme/acme.json
      httpChallenge:
        entryPoint: web
      # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨:
      # caServer: "https://acme-v02.api.letsencrypt.org/directory"
      # æµ‹è¯•ç¯å¢ƒä½¿ç”¨:
      caServer: "https://acme-staging-v02.api.letsencrypt.org/directory"

# ========================================
# æä¾›å•†(Providers)
# ========================================
providers:
  docker:
    endpoint: "unix:///var/run/docker.sock"
    exposedByDefault: false  # é»˜è®¤ä¸æš´éœ²æœåŠ¡
    network: traefik-public
    swarmMode: true
    watch: true

  file:
    directory: /etc/traefik/dynamic
    watch: true

# ========================================
# æŒ‡æ ‡(Metrics)
# ========================================
metrics:
  prometheus:
    entryPoint: metrics
    addEntryPointsLabels: true
    addServicesLabels: true
    buckets:
      - 0.1
      - 0.3
      - 1.2
      - 5.0
```

**Traefik Stackéƒ¨ç½²**:

```yaml
# traefik-stack.yml
version: '3.8'

services:
  traefik:
    image: traefik:v2.10
    command:
      - "--configFile=/etc/traefik/traefik.yml"
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 8082
        published: 8082
        protocol: tcp
        mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik/traefik.yml:/etc/traefik/traefik.yml:ro
      - ./traefik/dynamic:/etc/traefik/dynamic:ro
      - traefik-certs:/etc/traefik/acme
      - traefik-logs:/var/log/traefik
    networks:
      - traefik-public
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      labels:
        # Dashboardè·¯ç”±
        - "traefik.enable=true"
        - "traefik.http.routers.dashboard.rule=Host(`traefik.example.com`)"
        - "traefik.http.routers.dashboard.entrypoints=websecure"
        - "traefik.http.routers.dashboard.tls.certresolver=letsencrypt"
        - "traefik.http.routers.dashboard.service=api@internal"
        # Dashboardè®¤è¯
        - "traefik.http.routers.dashboard.middlewares=dashboard-auth"
        - "traefik.http.middlewares.dashboard-auth.basicauth.users=admin:$$apr1$$xxx"  # htpasswdç”Ÿæˆ
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

networks:
  traefik-public:
    driver: overlay
    attachable: true

volumes:
  traefik-certs:
  traefik-logs:
```

**åº”ç”¨æœåŠ¡é…ç½®(ä½¿ç”¨Traefikæ ‡ç­¾)**:

```yaml
# app-stack.yml
version: '3.8'

services:
  # Webåº”ç”¨
  app:
    image: myapp:latest
    networks:
      - traefik-public
      - backend
    environment:
      DATABASE_URL: postgresql://db:5432/appdb
    deploy:
      replicas: 6
      labels:
        # å¯ç”¨Traefik
        - "traefik.enable=true"

        # HTTPè·¯ç”±
        - "traefik.http.routers.app.rule=Host(`app.example.com`)"
        - "traefik.http.routers.app.entrypoints=websecure"
        - "traefik.http.routers.app.tls.certresolver=letsencrypt"

        # æœåŠ¡é…ç½®
        - "traefik.http.services.app.loadbalancer.server.port=8080"
        - "traefik.http.services.app.loadbalancer.sticky.cookie=true"
        - "traefik.http.services.app.loadbalancer.sticky.cookie.name=SERVERID"
        - "traefik.http.services.app.loadbalancer.healthcheck.path=/health"
        - "traefik.http.services.app.loadbalancer.healthcheck.interval=10s"

        # ä¸­é—´ä»¶: å‹ç¼©
        - "traefik.http.middlewares.app-compress.compress=true"
        # ä¸­é—´ä»¶: é™æµ
        - "traefik.http.middlewares.app-ratelimit.ratelimit.average=100"
        - "traefik.http.middlewares.app-ratelimit.ratelimit.burst=50"
        # ä¸­é—´ä»¶: å®‰å…¨å¤´
        - "traefik.http.middlewares.app-headers.headers.sslredirect=true"
        - "traefik.http.middlewares.app-headers.headers.stsSeconds=31536000"
        - "traefik.http.middlewares.app-headers.headers.contentTypeNosniff=true"
        - "traefik.http.middlewares.app-headers.headers.browserXssFilter=true"
        - "traefik.http.middlewares.app-headers.headers.frameDeny=true"

        # åº”ç”¨ä¸­é—´ä»¶
        - "traefik.http.routers.app.middlewares=app-compress,app-ratelimit,app-headers"

      resources:
        limits:
          cpus: '1'
          memory: 1G

  # APIæœåŠ¡(ä¸åŒåŸŸå)
  api:
    image: myapi:latest
    networks:
      - traefik-public
      - backend
    deploy:
      replicas: 5
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.api.rule=Host(`api.example.com`)"
        - "traefik.http.routers.api.entrypoints=websecure"
        - "traefik.http.routers.api.tls.certresolver=letsencrypt"
        - "traefik.http.services.api.loadbalancer.server.port=3000"
        - "traefik.http.middlewares.api-cors.headers.accesscontrolallowmethods=GET,POST,PUT,DELETE"
        - "traefik.http.middlewares.api-cors.headers.accesscontrolalloworiginlist=https://app.example.com"
        - "traefik.http.middlewares.api-cors.headers.accesscontrolmaxage=100"
        - "traefik.http.middlewares.api-cors.headers.addvaryheader=true"
        - "traefik.http.routers.api.middlewares=api-cors"

  # é™æ€æ–‡ä»¶æœåŠ¡
  static:
    image: nginx:alpine
    networks:
      - traefik-public
    volumes:
      - static-files:/usr/share/nginx/html:ro
    deploy:
      replicas: 3
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.static.rule=Host(`static.example.com`)"
        - "traefik.http.routers.static.entrypoints=websecure"
        - "traefik.http.routers.static.tls.certresolver=letsencrypt"
        - "traefik.http.services.static.loadbalancer.server.port=80"
        # é™æ€èµ„æºç¼“å­˜
        - "traefik.http.middlewares.static-cache.headers.customResponseHeaders.Cache-Control=public, max-age=31536000, immutable"
        - "traefik.http.routers.static.middlewares=static-cache,app-compress"

networks:
  traefik-public:
    external: true
  backend:
    driver: overlay
    internal: true

volumes:
  static-files:
```

**åŠ¨æ€é…ç½®æ–‡ä»¶**:

```yaml
# traefik/dynamic/middlewares.yml
http:
  middlewares:
    # è‡ªå®šä¹‰é”™è¯¯é¡µé¢
    custom-errors:
      errors:
        status:
          - "404"
          - "500-599"
        service: error-pages
        query: "/{status}.html"

    # IPç™½åå•
    ip-whitelist:
      ipWhiteList:
        sourceRange:
          - "127.0.0.1/32"
          - "192.168.1.0/24"
          - "10.0.0.0/8"

    # Basicè®¤è¯
    basic-auth:
      basicAuth:
        users:
          - "admin:$apr1$xxx..."  # htpasswdç”Ÿæˆ
          - "user:$apr1$yyy..."
        removeHeader: true

    # é‡å®šå‘
    redirect-www:
      redirectRegex:
        regex: "^https://example.com/(.*)"
        replacement: "https://www.example.com/${1}"
        permanent: true

  services:
    error-pages:
      loadBalancer:
        servers:
          - url: "http://error-pages:8080"
```

**éªŒè¯ä¸ç›‘æ§**:

```bash
# ========================================
# éƒ¨ç½²Traefik
# ========================================

# åˆ›å»ºç½‘ç»œ
$ docker network create --driver=overlay traefik-public

# éƒ¨ç½²Traefik
$ docker stack deploy -c traefik-stack.yml traefik

# éƒ¨ç½²åº”ç”¨
$ docker stack deploy -c app-stack.yml myapp

# ========================================
# éªŒè¯
# ========================================

# æŸ¥çœ‹Traefikæ—¥å¿—
$ docker service logs -f traefik_traefik

# è®¿é—®Dashboard
# https://traefik.example.com/dashboard/

# æŸ¥çœ‹è·¯ç”±
$ curl -s http://localhost:8080/api/http/routers | jq

# æŸ¥çœ‹æœåŠ¡
$ curl -s http://localhost:8080/api/http/services | jq

# ========================================
# æµ‹è¯•è‡ªåŠ¨HTTPS
# ========================================

# æµ‹è¯•HTTPé‡å®šå‘åˆ°HTTPS
$ curl -I http://app.example.com
HTTP/1.1 308 Permanent Redirect
Location: https://app.example.com/

# æµ‹è¯•HTTPS
$ curl -I https://app.example.com
HTTP/2 200
Strict-Transport-Security: max-age=31536000

# ========================================
# PrometheusæŒ‡æ ‡
# ========================================

# è®¿é—®æŒ‡æ ‡ç«¯ç‚¹
$ curl http://localhost:8082/metrics

# æŒ‡æ ‡ç¤ºä¾‹
traefik_entrypoint_requests_total{code="200",entrypoint="websecure",method="GET",protocol="http"} 1234
traefik_service_requests_total{code="200",method="GET",service="app@docker"} 5678
```

---

## 13.4 åå‘ä»£ç†ä¸APIç½‘å…³

### 13.4.1 Nginxä½œä¸ºAPIç½‘å…³

**Nginx APIç½‘å…³é…ç½®**:

```nginx
# /etc/nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 10000;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format api '$remote_addr - $remote_user [$time_local] '
                   '"$request" $status $body_bytes_sent '
                   '"$http_referer" "$http_user_agent" '
                   'request_id=$request_id '
                   'upstream_addr=$upstream_addr '
                   'upstream_status=$upstream_status '
                   'request_time=$request_time '
                   'upstream_response_time=$upstream_response_time '
                   'upstream_connect_time=$upstream_connect_time '
                   'upstream_header_time=$upstream_header_time';

    access_log /var/log/nginx/access.log api;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 20M;
    client_body_buffer_size 128k;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 6;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # ç¼“å­˜é…ç½®
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m max_size=100m inactive=60m use_temp_path=off;

    # é™æµåŒºåŸŸ
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=5r/s;
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

    # ä¸Šæ¸¸æœåŠ¡
    upstream auth_service {
        least_conn;
        server auth:3000 max_fails=3 fail_timeout=30s;
        server auth:3001 max_fails=3 fail_timeout=30s backup;
        keepalive 32;
    }

    upstream user_service {
        least_conn;
        server user:4000 max_fails=3 fail_timeout=30s weight=2;
        server user:4001 max_fails=3 fail_timeout=30s weight=1;
        keepalive 32;
    }

    upstream order_service {
        least_conn;
        server order:5000 max_fails=3 fail_timeout=30s;
        server order:5001 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # APIç½‘å…³ä¸»é…ç½®
    server {
        listen 80;
        server_name api.example.com;

        # å®‰å…¨å¤´
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Request-ID $request_id always;

        # CORSé…ç½®
        add_header Access-Control-Allow-Origin "https://app.example.com" always;
        add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS" always;
        add_header Access-Control-Allow-Headers "DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization" always;
        add_header Access-Control-Expose-Headers "Content-Length,Content-Range" always;
        add_header Access-Control-Max-Age 1728000 always;

        # OPTIONSè¯·æ±‚å¤„ç†
        if ($request_method = 'OPTIONS') {
            return 204;
        }

        # ====================================
        # è®¤è¯æœåŠ¡(/api/auth/*)
        # ====================================
        location /api/auth/ {
            # é™æµ: æ¯ç§’5ä¸ªè¯·æ±‚
            limit_req zone=auth_limit burst=10 nodelay;
            limit_conn conn_limit 10;

            # ä»£ç†é…ç½®
            proxy_pass http://auth_service/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;

            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            proxy_buffering off;

            # é”™è¯¯å¤„ç†
            proxy_intercept_errors on;
            error_page 502 503 504 = @fallback_auth;
        }

        # ====================================
        # ç”¨æˆ·æœåŠ¡(/api/users/*)  éœ€è¦JWTè®¤è¯
        # ====================================
        location /api/users/ {
            # JWTéªŒè¯(ä½¿ç”¨auth_request)
            auth_request /api/auth/verify;
            auth_request_set $auth_user_id $upstream_http_x_user_id;
            auth_request_set $auth_user_role $upstream_http_x_user_role;

            # é™æµ
            limit_req zone=api_limit burst=50 nodelay;

            # ä»£ç†é…ç½®
            proxy_pass http://user_service/;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-User-ID $auth_user_id;
            proxy_set_header X-User-Role $auth_user_role;
            proxy_set_header X-Request-ID $request_id;

            # ç¼“å­˜é…ç½®(GETè¯·æ±‚)
            proxy_cache api_cache;
            proxy_cache_methods GET;
            proxy_cache_key "$scheme$request_method$host$request_uri$auth_user_id";
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_bypass $http_cache_control;
            add_header X-Cache-Status $upstream_cache_status;
        }

        # ====================================
        # è®¢å•æœåŠ¡(/api/orders/*)  éœ€è¦è®¤è¯
        # ====================================
        location /api/orders/ {
            # JWTéªŒè¯
            auth_request /api/auth/verify;
            auth_request_set $auth_user_id $upstream_http_x_user_id;

            # é™æµ
            limit_req zone=api_limit burst=30 nodelay;

            # ä»£ç†é…ç½®
            proxy_pass http://order_service/;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-User-ID $auth_user_id;
            proxy_set_header X-Request-ID $request_id;

            # è¶…æ—¶é…ç½®(è®¢å•å¤„ç†å¯èƒ½è¾ƒæ…¢)
            proxy_connect_timeout 10s;
            proxy_send_timeout 120s;
            proxy_read_timeout 120s;
        }

        # ====================================
        # JWTéªŒè¯ç«¯ç‚¹(å†…éƒ¨)
        # ====================================
        location = /api/auth/verify {
            internal;
            proxy_pass http://auth_service/verify;
            proxy_pass_request_body off;
            proxy_set_header Content-Length "";
            proxy_set_header X-Original-URI $request_uri;
            proxy_set_header Authorization $http_authorization;
        }

        # ====================================
        # å¥åº·æ£€æŸ¥
        # ====================================
        location /health {
            access_log off;
            add_header Content-Type text/plain;
            return 200 "healthy\n";
        }

        # ====================================
        # Fallbackå¤„ç†
        # ====================================
        location @fallback_auth {
            add_header Content-Type application/json;
            return 503 '{"error":"Authentication service temporarily unavailable"}';
        }
    }
}
```

**JWTéªŒè¯æœåŠ¡ç¤ºä¾‹(auth_service)**:

```javascript
// auth-service/server.js
const express = require('express');
const jwt = require('jsonwebtoken');
const app = express();

const JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';

// ç™»å½•ç«¯ç‚¹
app.post('/login', express.json(), (req, res) => {
    const { username, password } = req.body;

    // éªŒè¯ç”¨æˆ·åå¯†ç (ç¤ºä¾‹)
    if (username === 'admin' && password === 'password') {
        const token = jwt.sign(
            {
                userId: 1,
                username: 'admin',
                role: 'admin'
            },
            JWT_SECRET,
            { expiresIn: '24h' }
        );

        res.json({ token });
    } else {
        res.status(401).json({ error: 'Invalid credentials' });
    }
});

// JWTéªŒè¯ç«¯ç‚¹(ä¾›Nginx auth_requestä½¿ç”¨)
app.get('/verify', (req, res) => {
    const authHeader = req.headers.authorization;

    if (!authHeader || !authHeader.startsWith('Bearer ')) {
        return res.status(401).send('Unauthorized');
    }

    const token = authHeader.substring(7);

    try {
        const decoded = jwt.verify(token, JWT_SECRET);

        // è®¾ç½®è‡ªå®šä¹‰å“åº”å¤´(Nginxä¼šä¼ é€’ç»™åç«¯)
        res.setHeader('X-User-ID', decoded.userId);
        res.setHeader('X-User-Role', decoded.role);
        res.setHeader('X-Username', decoded.username);

        res.status(200).send('OK');
    } catch (err) {
        res.status(401).send('Invalid token');
    }
});

app.listen(3000, () => {
    console.log('Auth service listening on port 3000');
});
```

**Docker Composeéƒ¨ç½²**:

```yaml
# api-gateway-stack.yml
version: '3.8'

services:
  # Nginx APIç½‘å…³
  api-gateway:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - nginx-cache:/var/cache/nginx
      - nginx-logs:/var/log/nginx
    networks:
      - frontend
      - backend
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 512M
    depends_on:
      - auth
      - user
      - order

  # è®¤è¯æœåŠ¡
  auth:
    image: auth-service:latest
    environment:
      JWT_SECRET: ${JWT_SECRET}
      NODE_ENV: production
    networks:
      - backend
    deploy:
      replicas: 2

  # ç”¨æˆ·æœåŠ¡
  user:
    image: user-service:latest
    networks:
      - backend
    deploy:
      replicas: 3

  # è®¢å•æœåŠ¡
  order:
    image: order-service:latest
    networks:
      - backend
    deploy:
      replicas: 3

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true

volumes:
  nginx-cache:
  nginx-logs:
```

**æµ‹è¯•APIç½‘å…³**:

```bash
# ========================================
# æµ‹è¯•è®¤è¯
# ========================================

# ç™»å½•è·å–JWT
$ curl -X POST http://api.example.com/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"password"}'

# å“åº”:
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
}

# ========================================
# æµ‹è¯•éœ€è¦è®¤è¯çš„API
# ========================================

# æ— Tokenè®¿é—®(è¢«æ‹’ç»)
$ curl http://api.example.com/api/users/profile
# å“åº”: 401 Unauthorized

# å¸¦Tokenè®¿é—®(æˆåŠŸ)
$ TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
$ curl -H "Authorization: Bearer $TOKEN" \
  http://api.example.com/api/users/profile

# å“åº”:
{
  "userId": 1,
  "username": "admin",
  "role": "admin"
}

# æŸ¥çœ‹è¯·æ±‚ID(ç”¨äºè¿½è¸ª)
$ curl -I -H "Authorization: Bearer $TOKEN" \
  http://api.example.com/api/users/profile | grep X-Request-ID
X-Request-ID: abc123def456

# ========================================
# æµ‹è¯•é™æµ
# ========================================

# å¿«é€Ÿå‘é€100ä¸ªè¯·æ±‚(ä¼šè§¦å‘é™æµ)
$ for i in {1..100}; do
    curl -H "Authorization: Bearer $TOKEN" \
      http://api.example.com/api/users/profile &
  done

# éƒ¨åˆ†å“åº”: 429 Too Many Requests

# ========================================
# æµ‹è¯•ç¼“å­˜
# ========================================

# ç¬¬ä¸€æ¬¡è¯·æ±‚(MISS)
$ curl -H "Authorization: Bearer $TOKEN" \
  http://api.example.com/api/users/1 -I | grep X-Cache-Status
X-Cache-Status: MISS

# ç¬¬äºŒæ¬¡è¯·æ±‚(HIT)
$ curl -H "Authorization: Bearer $TOKEN" \
  http://api.example.com/api/users/1 -I | grep X-Cache-Status
X-Cache-Status: HIT
```

---

## 13.5 é…ç½®ç®¡ç†ä¸ç§˜é’¥ç®¡ç†

### 13.5.1 Docker Secrets(Swarmå†…ç½®)

**åˆ›å»ºç§˜é’¥**:

```bash
# ========================================
# ä»æ–‡ä»¶åˆ›å»ºç§˜é’¥
# ========================================

# æ•°æ®åº“å¯†ç 
$ echo "MySecureDBPassword123!" > db_password.txt
$ docker secret create db_password db_password.txt
$ rm db_password.txt  # åˆ é™¤æ˜æ–‡æ–‡ä»¶

# ä»æ ‡å‡†è¾“å…¥åˆ›å»º
$ echo "MyRedisPassword456!" | docker secret create redis_password -

# ä»ç¯å¢ƒå˜é‡åˆ›å»º
$ openssl rand -base64 32 | docker secret create jwt_secret -

# TLSè¯ä¹¦
$ docker secret create ssl_cert ./certs/fullchain.pem
$ docker secret create ssl_key ./certs/privkey.pem

# ========================================
# æŸ¥çœ‹ç§˜é’¥
# ========================================

$ docker secret ls
ID                NAME            CREATED
abc123            db_password     10 minutes ago
def456            redis_password  5 minutes ago
ghi789            jwt_secret      2 minutes ago

# æŸ¥çœ‹ç§˜é’¥è¯¦æƒ…(ä¸æ˜¾ç¤ºå†…å®¹)
$ docker secret inspect db_password
[
    {
        "ID": "abc123",
        "Version": {
            "Index": 10
        },
        "CreatedAt": "2023-12-04T10:00:00Z",
        "UpdatedAt": "2023-12-04T10:00:00Z",
        "Spec": {
            "Name": "db_password",
            "Labels": {}
        }
    }
]
```

**åœ¨æœåŠ¡ä¸­ä½¿ç”¨ç§˜é’¥**:

```yaml
# stack.yml
version: '3.8'

services:
  db:
    image: postgres:15-alpine
    environment:
      # é€šè¿‡_FILEåç¼€å¼•ç”¨ç§˜é’¥æ–‡ä»¶
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_USER: appuser
      POSTGRES_DB: appdb
    secrets:
      - db_password
    deploy:
      replicas: 1

  app:
    image: myapp:latest
    environment:
      # åº”ç”¨ä»£ç éœ€è¦è¯»å–ç§˜é’¥æ–‡ä»¶
      DB_PASSWORD_FILE: /run/secrets/db_password
      JWT_SECRET_FILE: /run/secrets/jwt_secret
    secrets:
      - db_password
      - jwt_secret
    deploy:
      replicas: 5

secrets:
  db_password:
    external: true  # ä½¿ç”¨å·²å­˜åœ¨çš„ç§˜é’¥

  jwt_secret:
    external: true
```

**åº”ç”¨ä»£ç è¯»å–ç§˜é’¥**:

```python
# app.py
import os

def read_secret(secret_name):
    """ä»Docker Secretsè¯»å–ç§˜é’¥"""
    secret_file = os.getenv(f'{secret_name.upper()}_FILE',
                            f'/run/secrets/{secret_name}')
    try:
        with open(secret_file, 'r') as f:
            return f.read().strip()
    except FileNotFoundError:
        # Fallbackåˆ°ç¯å¢ƒå˜é‡(å¼€å‘ç¯å¢ƒ)
        return os.getenv(secret_name.upper())

# ä½¿ç”¨ç§˜é’¥
DB_PASSWORD = read_secret('db_password')
JWT_SECRET = read_secret('jwt_secret')

# æ•°æ®åº“è¿æ¥
DATABASE_URL = f"postgresql://appuser:{DB_PASSWORD}@db:5432/appdb"
```

**è½®æ¢ç§˜é’¥**:

```bash
# ========================================
# ç§˜é’¥è½®æ¢æ­¥éª¤
# ========================================

# 1. åˆ›å»ºæ–°ç§˜é’¥
$ echo "NewDBPassword789!" | docker secret create db_password_v2 -

# 2. æ›´æ–°æœåŠ¡ä½¿ç”¨æ–°ç§˜é’¥
$ docker service update \
  --secret-rm db_password \
  --secret-add source=db_password_v2,target=db_password \
  myapp_db

# 3. éªŒè¯æœåŠ¡æ­£å¸¸
$ docker service ps myapp_db

# 4. åˆ é™¤æ—§ç§˜é’¥
$ docker secret rm db_password

# 5. é‡å‘½åæ–°ç§˜é’¥(å¯é€‰)
# Dockerä¸æ”¯æŒé‡å‘½å,éœ€è¦é‡æ–°åˆ›å»º
```

---

### 13.5.2 Vaulté›†æˆ(ä¼ä¸šçº§ç§˜é’¥ç®¡ç†)

**HashiCorp Vaultæ¶æ„**:

```bash
# Vaulté›†ç¾¤æ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Vaulté›†ç¾¤ (HAæ¨¡å¼)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Vault 1  â”‚  â”‚ Vault 2  â”‚  â”‚ Vault 3  â”‚â”‚
â”‚  â”‚ (Active) â”‚  â”‚ (Standby)â”‚  â”‚ (Standby)â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â”‚              â”‚              â”‚     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                    â”‚                      â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚          â”‚   Consul Backend  â”‚           â”‚
â”‚          â”‚  (å­˜å‚¨+HAåè°ƒ)     â”‚           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vaultéƒ¨ç½²**:

```yaml
# vault-stack.yml
version: '3.8'

services:
  # Consul(Vaultåç«¯å­˜å‚¨)
  consul:
    image: consul:1.17
    command: agent -server -bootstrap-expect=1 -ui -client=0.0.0.0
    environment:
      CONSUL_LOCAL_CONFIG: |
        {
          "datacenter": "dc1",
          "data_dir": "/consul/data",
          "log_level": "INFO"
        }
    volumes:
      - consul-data:/consul/data
    networks:
      - vault-net
    ports:
      - "8500:8500"

  # Vault Server
  vault:
    image: hashicorp/vault:1.15
    ports:
      - "8200:8200"
    environment:
      VAULT_ADDR: http://0.0.0.0:8200
      VAULT_API_ADDR: http://vault:8200
    cap_add:
      - IPC_LOCK
    volumes:
      - ./vault/config:/vault/config:ro
      - vault-data:/vault/data
      - vault-logs:/vault/logs
    networks:
      - vault-net
    command: server
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '1'
          memory: 1G

networks:
  vault-net:
    driver: overlay

volumes:
  consul-data:
  vault-data:
  vault-logs:
```

**Vaulté…ç½®æ–‡ä»¶**:

```hcl
# vault/config/vault.hcl
storage "consul" {
  address = "consul:8500"
  path    = "vault/"
}

listener "tcp" {
  address     = "0.0.0.0:8200"
  tls_disable = 1
}

api_addr = "http://vault:8200"
cluster_addr = "https://vault:8201"
ui = true

# æ—¥å¿—é…ç½®
log_level = "info"
log_format = "json"

# Telemetry
telemetry {
  prometheus_retention_time = "30s"
  disable_hostname = false
}
```

**åˆå§‹åŒ–Vault**:

```bash
# ========================================
# åˆå§‹åŒ–Vault
# ========================================

# éƒ¨ç½²Vault
$ docker stack deploy -c vault-stack.yml vault

# ç­‰å¾…Vaultå¯åŠ¨
$ docker service logs -f vault_vault

# åˆå§‹åŒ–Vault(ä»…ç¬¬ä¸€æ¬¡)
$ docker exec -it $(docker ps -q -f name=vault_vault) vault operator init
Unseal Key 1: abc123...
Unseal Key 2: def456...
Unseal Key 3: ghi789...
Unseal Key 4: jkl012...
Unseal Key 5: mno345...

Initial Root Token: s.xxxxxxxxxxxx

# âš ï¸ é‡è¦: ä¿å­˜Unseal Keyså’ŒRoot Tokenåˆ°å®‰å…¨åœ°æ–¹!

# ========================================
# è§£å°Vault(æ¯æ¬¡é‡å¯åéœ€è¦)
# ========================================

# éœ€è¦3ä¸ªUnseal Keyæ‰èƒ½è§£å°
$ docker exec -it $(docker ps -q -f name=vault_vault) \
  vault operator unseal abc123...

$ docker exec -it $(docker ps -q -f name=vault_vault) \
  vault operator unseal def456...

$ docker exec -it $(docker ps -q -f name=vault_vault) \
  vault operator unseal ghi789...

# éªŒè¯çŠ¶æ€
$ docker exec -it $(docker ps -q -f name=vault_vault) \
  vault status

Key             Value
---             -----
Seal Type       shamir
Initialized     true
Sealed          false  # âœ… å·²è§£å°
Total Shares    5
Threshold       3
Version         1.15.0
```

**é…ç½®Vault**:

```bash
# ========================================
# ç™»å½•Vault
# ========================================

$ export VAULT_ADDR='http://localhost:8200'
$ vault login s.xxxxxxxxxxxx  # ä½¿ç”¨Root Token

# ========================================
# å¯ç”¨KVç§˜é’¥å¼•æ“
# ========================================

# å¯ç”¨KV v2å¼•æ“
$ vault secrets enable -version=2 kv

# å†™å…¥ç§˜é’¥
$ vault kv put kv/myapp/production \
  db_password="MySecureDBPassword123!" \
  redis_password="MyRedisPassword456!" \
  jwt_secret="MyJWTSecret789!"

# è¯»å–ç§˜é’¥
$ vault kv get kv/myapp/production
===== Data =====
Key               Value
---               -----
db_password       MySecureDBPassword123!
redis_password    MyRedisPassword456!
jwt_secret        MyJWTSecret789!

# è¯»å–ç‰¹å®šå­—æ®µ
$ vault kv get -field=db_password kv/myapp/production
MySecureDBPassword123!

# ========================================
# åˆ›å»ºç­–ç•¥(æœ€å°æƒé™)
# ========================================

# åˆ›å»ºç­–ç•¥æ–‡ä»¶
$ cat <<EOF > myapp-policy.hcl
# å…è®¸è¯»å–myappçš„ç”Ÿäº§ç§˜é’¥
path "kv/data/myapp/production" {
  capabilities = ["read"]
}

# å…è®¸åˆ—å‡ºç§˜é’¥
path "kv/metadata/myapp/*" {
  capabilities = ["list"]
}
EOF

# åº”ç”¨ç­–ç•¥
$ vault policy write myapp myapp-policy.hcl

# ========================================
# åˆ›å»ºAppRole(ä¾›åº”ç”¨ä½¿ç”¨)
# ========================================

# å¯ç”¨AppRoleè®¤è¯
$ vault auth enable approle

# åˆ›å»ºè§’è‰²
$ vault write auth/approle/role/myapp \
  token_policies="myapp" \
  token_ttl=1h \
  token_max_ttl=24h \
  secret_id_ttl=0

# è·å–Role ID
$ vault read auth/approle/role/myapp/role-id
role_id    abc-123-def-456

# ç”ŸæˆSecret ID
$ vault write -f auth/approle/role/myapp/secret-id
secret_id            xyz-789-uvw-012
secret_id_accessor   ...
```

**åº”ç”¨é›†æˆVault**:

```python
# app.py - Pythoné›†æˆVault
import hvac
import os

# Vaulté…ç½®
VAULT_ADDR = os.getenv('VAULT_ADDR', 'http://vault:8200')
VAULT_ROLE_ID = os.getenv('VAULT_ROLE_ID')
VAULT_SECRET_ID = os.getenv('VAULT_SECRET_ID')

def get_vault_client():
    """åˆ›å»ºVaultå®¢æˆ·ç«¯"""
    client = hvac.Client(url=VAULT_ADDR)

    # ä½¿ç”¨AppRoleç™»å½•
    client.auth.approle.login(
        role_id=VAULT_ROLE_ID,
        secret_id=VAULT_SECRET_ID
    )

    if not client.is_authenticated():
        raise Exception('Vault authentication failed')

    return client

def get_secrets():
    """ä»Vaultè·å–ç§˜é’¥"""
    client = get_vault_client()

    # è¯»å–ç§˜é’¥
    secret = client.secrets.kv.v2.read_secret_version(
        path='myapp/production',
        mount_point='kv'
    )

    return secret['data']['data']

# ä½¿ç”¨ç§˜é’¥
secrets = get_secrets()
DB_PASSWORD = secrets['db_password']
REDIS_PASSWORD = secrets['redis_password']
JWT_SECRET = secrets['jwt_secret']

print(f"âœ… Successfully loaded {len(secrets)} secrets from Vault")
```

**Docker Composeé›†æˆ**:

```yaml
# app-stack.yml
version: '3.8'

services:
  app:
    image: myapp:latest
    environment:
      VAULT_ADDR: http://vault:8200
      VAULT_ROLE_ID: abc-123-def-456
      VAULT_SECRET_ID: xyz-789-uvw-012
    networks:
      - vault-net
      - backend
    deploy:
      replicas: 5
    command: >
      sh -c "python -c 'from app import get_secrets; get_secrets()' &&
             python app.py"

networks:
  vault-net:
    external: true
  backend:
    driver: overlay
```

---

### 13.5.3 ç¯å¢ƒå˜é‡ç®¡ç†æœ€ä½³å®è·µ

**å¤šç¯å¢ƒé…ç½®ç­–ç•¥**:

```bash
# é¡¹ç›®ç»“æ„
.
â”œâ”€â”€ .env.example          # ç¤ºä¾‹é…ç½®(æäº¤åˆ°Git)
â”œâ”€â”€ .env.development      # å¼€å‘ç¯å¢ƒ(ä¸æäº¤)
â”œâ”€â”€ .env.staging          # æµ‹è¯•ç¯å¢ƒ(ä¸æäº¤)
â”œâ”€â”€ .env.production       # ç”Ÿäº§ç¯å¢ƒ(ä¸æäº¤)
â”œâ”€â”€ docker-compose.yml    # åŸºç¡€é…ç½®
â”œâ”€â”€ docker-compose.dev.yml
â”œâ”€â”€ docker-compose.prod.yml
â””â”€â”€ .gitignore           # å¿½ç•¥æ‰€æœ‰.envæ–‡ä»¶
```

**.env.example**:

```bash
# åº”ç”¨é…ç½®
NODE_ENV=production
LOG_LEVEL=info
PORT=8080

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@db:5432/dbname
DB_POOL_MIN=2
DB_POOL_MAX=10

# Redisé…ç½®
REDIS_URL=redis://redis:6379/0

# å¤–éƒ¨æœåŠ¡
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=secret...

# ç§˜é’¥(ç”Ÿäº§ç¯å¢ƒä½¿ç”¨Docker Secretsæˆ–Vault)
JWT_SECRET=change_me_in_production
API_KEY=change_me_in_production
```

**.env.development**:

```bash
NODE_ENV=development
LOG_LEVEL=debug
PORT=8080

DATABASE_URL=postgresql://dev:dev123@localhost:5432/dev_db
REDIS_URL=redis://localhost:6379/0

JWT_SECRET=dev_jwt_secret
API_KEY=dev_api_key
```

**.env.production**:

```bash
NODE_ENV=production
LOG_LEVEL=warn
PORT=8080

# ç”Ÿäº§ç¯å¢ƒä½¿ç”¨Docker Secrets
DATABASE_URL_FILE=/run/secrets/database_url
REDIS_URL_FILE=/run/secrets/redis_url
JWT_SECRET_FILE=/run/secrets/jwt_secret
API_KEY_FILE=/run/secrets/api_key

# AWSä½¿ç”¨IAMè§’è‰²,æ— éœ€ç¡¬ç¼–ç å¯†é’¥
AWS_REGION=us-east-1
```

**ä¼˜å…ˆçº§è§„åˆ™**:

```python
# config.py - ç»Ÿä¸€é…ç½®åŠ è½½
import os
from pathlib import Path

def read_secret(name):
    """è¯»å–ç§˜é’¥(æ”¯æŒæ–‡ä»¶å’Œç¯å¢ƒå˜é‡)"""
    # 1. ä¼˜å…ˆä»æ–‡ä»¶è¯»å–(Docker Secrets/Vault)
    file_path = os.getenv(f'{name}_FILE')
    if file_path and Path(file_path).exists():
        with open(file_path, 'r') as f:
            return f.read().strip()

    # 2. ä»ç¯å¢ƒå˜é‡è¯»å–
    value = os.getenv(name)
    if value:
        return value

    # 3. ä».envæ–‡ä»¶è¯»å–(å¼€å‘ç¯å¢ƒ)
    from dotenv import load_dotenv
    load_dotenv()
    value = os.getenv(name)
    if value:
        return value

    # 4. æŠ›å‡ºå¼‚å¸¸
    raise ValueError(f'Missing required config: {name}')

class Config:
    """åº”ç”¨é…ç½®"""
    # åŸºç¡€é…ç½®
    NODE_ENV = os.getenv('NODE_ENV', 'development')
    LOG_LEVEL = os.getenv('LOG_LEVEL', 'info')
    PORT = int(os.getenv('PORT', 8080))

    # ç§˜é’¥é…ç½®
    DATABASE_URL = read_secret('DATABASE_URL')
    REDIS_URL = read_secret('REDIS_URL')
    JWT_SECRET = read_secret('JWT_SECRET')
    API_KEY = read_secret('API_KEY')

    @classmethod
    def is_production(cls):
        return cls.NODE_ENV == 'production'

    @classmethod
    def is_development(cls):
        return cls.NODE_ENV == 'development'

# ä½¿ç”¨
config = Config()
print(f'Running in {config.NODE_ENV} mode')
print(f'Database: {config.DATABASE_URL}')
```

---

## 13.6 ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ

### 13.6.1 éƒ¨ç½²æ¸…å•(Checklist)

```yaml
# ç”Ÿäº§éƒ¨ç½²æ£€æŸ¥æ¸…å•

## å®‰å…¨æ€§
- [ ] æ‰€æœ‰ç§˜é’¥ä½¿ç”¨Docker Secretsæˆ–Vaultç®¡ç†
- [ ] åˆ é™¤é»˜è®¤è´¦å·å’Œå¯†ç 
- [ ] å¯ç”¨HTTPSå’ŒTLS 1.2+
- [ ] é…ç½®é˜²ç«å¢™è§„åˆ™
- [ ] ä½¿ç”¨érootç”¨æˆ·è¿è¡Œå®¹å™¨
- [ ] æ‰«æé•œåƒæ¼æ´(Trivy/Clair)
- [ ] é™åˆ¶å®¹å™¨æƒé™(drop capabilities)
- [ ] é…ç½®å†…éƒ¨ç½‘ç»œéš”ç¦»

## é«˜å¯ç”¨æ€§
- [ ] è‡³å°‘3ä¸ªManagerèŠ‚ç‚¹(Swarm)
- [ ] è·¨å¯ç”¨åŒºåˆ†å¸ƒæœåŠ¡å‰¯æœ¬
- [ ] é…ç½®å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨é‡å¯
- [ ] å®ç°ä¼˜é›…å…³é—­(SIGTERMå¤„ç†)
- [ ] é…ç½®èµ„æºlimitså’Œreservations
- [ ] æ•°æ®åº“ä¸»ä»/é›†ç¾¤éƒ¨ç½²
- [ ] è´Ÿè½½å‡è¡¡å™¨é«˜å¯ç”¨(HAProxy+Keepalived)

## æ•°æ®æŒä¹…åŒ–
- [ ] æ•°æ®å·ä½¿ç”¨NFS/äº‘å­˜å‚¨
- [ ] é…ç½®è‡ªåŠ¨å¤‡ä»½(æ¯æ—¥/æ¯å‘¨)
- [ ] æµ‹è¯•å¤‡ä»½æ¢å¤æµç¨‹
- [ ] æ•°æ®åº“binlog/WALå½’æ¡£
- [ ] é‡è¦æ•°æ®å¤šåœ°åŸŸå¤‡ä»½

## ç›‘æ§å‘Šè­¦
- [ ] éƒ¨ç½²Prometheus+Grafana
- [ ] é…ç½®å…³é”®æŒ‡æ ‡å‘Šè­¦è§„åˆ™
- [ ] é›†æˆPagerDuty/é’‰é’‰/ä¼ä¸šå¾®ä¿¡
- [ ] æ—¥å¿—é›†ä¸­æ”¶é›†(ELK/Loki)
- [ ] APMæ€§èƒ½ç›‘æ§
- [ ] ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§

## æ€§èƒ½ä¼˜åŒ–
- [ ] å®¹å™¨èµ„æºé™åˆ¶ä¼˜åŒ–
- [ ] æ•°æ®åº“è¿æ¥æ± é…ç½®
- [ ] Redisç¼“å­˜ç­–ç•¥
- [ ] CDNåŠ é€Ÿé™æ€èµ„æº
- [ ] Gzipå‹ç¼©å¯ç”¨
- [ ] HTTP/2å¯ç”¨
- [ ] æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–

## éƒ¨ç½²æµç¨‹
- [ ] ä½¿ç”¨å£°æ˜å¼éƒ¨ç½²(Stack)
- [ ] é…ç½®æ»šåŠ¨æ›´æ–°ç­–ç•¥
- [ ] è®¾ç½®å¥åº·æ£€æŸ¥æ¢é’ˆ
- [ ] å®ç°è“ç»¿/é‡‘ä¸é›€éƒ¨ç½²
- [ ] è‡ªåŠ¨åŒ–CI/CDæµç¨‹
- [ ] ç‰ˆæœ¬æ ‡ç­¾è§„èŒƒ(semver)
- [ ] å›æ»šé¢„æ¡ˆ

## æ–‡æ¡£å’ŒåŸ¹è®­
- [ ] éƒ¨ç½²æ¶æ„å›¾
- [ ] è¿ç»´æ‰‹å†Œ(SOP)
- [ ] æ•…éšœæ’æŸ¥æ‰‹å†Œ
- [ ] åº”æ€¥å“åº”æµç¨‹
- [ ] å›¢é˜ŸåŸ¹è®­å®Œæˆ
```

---

### 13.6.2 éƒ¨ç½²è„šæœ¬ç¤ºä¾‹

```bash
#!/bin/bash
# deploy.sh - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬

set -euo pipefail  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# ========================================
# é…ç½®
# ========================================

STACK_NAME="myapp"
ENVIRONMENT="production"
DOCKER_REGISTRY="registry.company.com"
VERSION="${1:-latest}"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'  # No Color

# ========================================
# å‡½æ•°å®šä¹‰
# ========================================

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

check_prerequisites() {
    log_info "Checking prerequisites..."

    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker not found"
        exit 1
    fi

    # æ£€æŸ¥Swarmæ¨¡å¼
    if ! docker info | grep -q "Swarm: active"; then
        log_error "Docker Swarm is not active"
        exit 1
    fi

    # æ£€æŸ¥ManagerèŠ‚ç‚¹
    MANAGER_COUNT=$(docker node ls --filter "role=manager" --format "{{.ID}}" | wc -l)
    if [ "$MANAGER_COUNT" -lt 3 ]; then
        log_warn "Only $MANAGER_COUNT manager nodes (recommended: 3+)"
    fi

    log_info "âœ… Prerequisites check passed"
}

pull_images() {
    log_info "Pulling Docker images..."

    docker pull "${DOCKER_REGISTRY}/${STACK_NAME}:${VERSION}"
    docker pull postgres:15-alpine
    docker pull redis:7-alpine
    docker pull nginx:alpine

    log_info "âœ… Images pulled successfully"
}

create_secrets() {
    log_info "Creating Docker secrets..."

    # æ£€æŸ¥ç§˜é’¥æ˜¯å¦å·²å­˜åœ¨
    if ! docker secret ls | grep -q "db_password"; then
        echo "$DB_PASSWORD" | docker secret create db_password -
        log_info "Created secret: db_password"
    else
        log_info "Secret already exists: db_password"
    fi

    if ! docker secret ls | grep -q "jwt_secret"; then
        openssl rand -base64 32 | docker secret create jwt_secret -
        log_info "Created secret: jwt_secret"
    else
        log_info "Secret already exists: jwt_secret"
    fi
}

deploy_stack() {
    log_info "Deploying stack: ${STACK_NAME}"

    # å¯¼å‡ºç¯å¢ƒå˜é‡
    export VERSION
    export ENVIRONMENT

    # éƒ¨ç½²Stack
    docker stack deploy \
      -c docker-compose.yml \
      -c docker-compose.${ENVIRONMENT}.yml \
      --with-registry-auth \
      ${STACK_NAME}

    log_info "âœ… Stack deployed"
}

wait_for_services() {
    log_info "Waiting for services to become healthy..."

    local max_wait=300  # 5åˆ†é’Ÿè¶…æ—¶
    local elapsed=0

    while [ $elapsed -lt $max_wait ]; do
        local total=$(docker stack services ${STACK_NAME} --format "{{.Name}}" | wc -l)
        local ready=$(docker stack services ${STACK_NAME} --format "{{.Name}} {{.Replicas}}" | \
                     grep -E " [0-9]+/\1 " | wc -l)

        if [ "$ready" -eq "$total" ]; then
            log_info "âœ… All services are ready ($ready/$total)"
            return 0
        fi

        log_info "Waiting... ($ready/$total services ready)"
        sleep 10
        elapsed=$((elapsed + 10))
    done

    log_error "Timeout waiting for services"
    return 1
}

run_health_check() {
    log_info "Running health checks..."

    # æ£€æŸ¥åº”ç”¨å¥åº·
    if curl -f -s http://localhost/health > /dev/null; then
        log_info "âœ… Application health check passed"
    else
        log_error "Application health check failed"
        return 1
    fi

    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if docker exec -it $(docker ps -q -f name=${STACK_NAME}_db) \
       pg_isready -U appuser > /dev/null 2>&1; then
        log_info "âœ… Database health check passed"
    else
        log_error "Database health check failed"
        return 1
    fi
}

show_deployment_info() {
    log_info "Deployment Information:"
    echo ""
    echo "Stack Name: ${STACK_NAME}"
    echo "Environment: ${ENVIRONMENT}"
    echo "Version: ${VERSION}"
    echo ""
    echo "Services:"
    docker stack services ${STACK_NAME}
    echo ""
    echo "Access URLs:"
    echo "  Application: https://app.example.com"
    echo "  API: https://api.example.com"
    echo "  Monitoring: https://grafana.example.com"
}

cleanup_old_images() {
    log_info "Cleaning up old images..."
    docker image prune -f --filter "until=72h"
    log_info "âœ… Cleanup completed"
}

# ========================================
# ä¸»æµç¨‹
# ========================================

main() {
    log_info "Starting deployment process..."
    log_info "============================================"

    # 1. å‰ç½®æ£€æŸ¥
    check_prerequisites

    # 2. æ‹‰å–é•œåƒ
    pull_images

    # 3. åˆ›å»ºç§˜é’¥
    create_secrets

    # 4. éƒ¨ç½²Stack
    deploy_stack

    # 5. ç­‰å¾…æœåŠ¡å°±ç»ª
    if ! wait_for_services; then
        log_error "Deployment failed"
        log_info "Rolling back..."
        docker stack rm ${STACK_NAME}
        exit 1
    fi

    # 6. å¥åº·æ£€æŸ¥
    if ! run_health_check; then
        log_error "Health check failed"
        exit 1
    fi

    # 7. æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯
    show_deployment_info

    # 8. æ¸…ç†æ—§é•œåƒ
    cleanup_old_images

    log_info "============================================"
    log_info "âœ… Deployment completed successfully!"
}

# æ‰§è¡Œä¸»æµç¨‹
main "$@"
```

**ä½¿ç”¨éƒ¨ç½²è„šæœ¬**:

```bash
# èµ‹äºˆæ‰§è¡Œæƒé™
$ chmod +x deploy.sh

# éƒ¨ç½²æŒ‡å®šç‰ˆæœ¬
$ ./deploy.sh v1.2.3

# éƒ¨ç½²latest
$ ./deploy.sh

# è¾“å‡ºç¤ºä¾‹:
[INFO] Starting deployment process...
[INFO] ============================================
[INFO] Checking prerequisites...
[INFO] âœ… Prerequisites check passed
[INFO] Pulling Docker images...
[INFO] âœ… Images pulled successfully
[INFO] Creating Docker secrets...
[INFO] Created secret: db_password
[INFO] âœ… Stack deployed
[INFO] Waiting for services to become healthy...
[INFO] Waiting... (3/5 services ready)
[INFO] Waiting... (4/5 services ready)
[INFO] âœ… All services are ready (5/5)
[INFO] Running health checks...
[INFO] âœ… Application health check passed
[INFO] âœ… Database health check passed
[INFO] Deployment Information:

Stack Name: myapp
Environment: production
Version: v1.2.3

Services:
ID        NAME           MODE        REPLICAS  IMAGE
abc123    myapp_app      replicated  6/6       registry.company.com/myapp:v1.2.3
def456    myapp_db       replicated  1/1       postgres:15-alpine
...

[INFO] âœ… Deployment completed successfully!
```

---

## 13.7 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:

- âœ… **éƒ¨ç½²æ¶æ„**: æ ¹æ®è§„æ¨¡é€‰æ‹©å•æœº/Swarm/K8s
- âœ… **æœåŠ¡å‘ç°**: Swarmå†…ç½®DNS + Consulé«˜çº§ç‰¹æ€§
- âœ… **è´Ÿè½½å‡è¡¡**: HAProxy(ç¨³å®š) vs Traefik(ç°ä»£åŒ–)
- âœ… **APIç½‘å…³**: Nginxå®ç°è®¤è¯ã€é™æµã€ç¼“å­˜
- âœ… **ç§˜é’¥ç®¡ç†**: Docker Secrets(ç®€å•) vs Vault(ä¼ä¸šçº§)
- âœ… **é…ç½®ç®¡ç†**: ç¯å¢ƒå˜é‡ + æ–‡ä»¶ + ä¼˜å…ˆçº§è§„åˆ™
- âœ… **éƒ¨ç½²æµç¨‹**: è‡ªåŠ¨åŒ–è„šæœ¬ + å¥åº·æ£€æŸ¥ + å›æ»šé¢„æ¡ˆ

**æ¶æ„å¯¹æ¯”**:

| ç‰¹æ€§ | å•æœº | Swarm | Kubernetes |
|------|------|-------|-----------|
| é€‚ç”¨è§„æ¨¡ | <10å®¹å™¨ | 10-100èŠ‚ç‚¹ | 100+èŠ‚ç‚¹ |
| å¤æ‚åº¦ | â­ | â­â­â­ | â­â­â­â­â­ |
| é«˜å¯ç”¨ | âŒ | âœ… | âœ… |
| è‡ªåŠ¨æ‰©ç¼©å®¹ | âŒ | æ‰‹åŠ¨ | âœ… HPA |
| ç”Ÿæ€ç³»ç»Ÿ | åŸºç¡€ | å¤Ÿç”¨ | ä¸°å¯Œ |

---

---

---

# ç¬¬14ç« :é«˜å¯ç”¨æ€§ä¸ç¾éš¾æ¢å¤

## 14.1 é«˜å¯ç”¨æ¶æ„è®¾è®¡

### 14.1.1 é«˜å¯ç”¨åŸºæœ¬åŸåˆ™

**SLAä¸å¯ç”¨æ€§çº§åˆ«**:

```bash
# å¯ç”¨æ€§ç­‰çº§å¯¹ç…§è¡¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  çº§åˆ«   â”‚  å¯ç”¨æ€§%    â”‚ å¹´åœæœºæ—¶é—´  â”‚      é€‚ç”¨åœºæ™¯     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  99%    â”‚  Two Nines  â”‚  3.65å¤©     â”‚ å†…éƒ¨å·¥å…·          â”‚
â”‚  99.9%  â”‚  Three 9s   â”‚  8.76å°æ—¶   â”‚ ä¸€èˆ¬ä¸šåŠ¡ç³»ç»Ÿ      â”‚
â”‚  99.99% â”‚  Four 9s    â”‚  52.56åˆ†é’Ÿ  â”‚ é‡è¦ä¸šåŠ¡ç³»ç»Ÿ      â”‚
â”‚  99.999%â”‚  Five 9s    â”‚  5.26åˆ†é’Ÿ   â”‚ é‡‘èã€ç”µå•†æ ¸å¿ƒ    â”‚
â”‚ 99.9999%â”‚  Six 9s     â”‚  31.5ç§’     â”‚ ç”µä¿¡è¿è¥å•†        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# SLAè®¡ç®—å…¬å¼
å¯ç”¨æ€§% = (æ€»æ—¶é—´ - åœæœºæ—¶é—´) / æ€»æ—¶é—´ Ã— 100%

# ç¤ºä¾‹: è¾¾åˆ°99.99%å¯ç”¨æ€§
å¹´å…è®¸åœæœºæ—¶é—´ = 365å¤© Ã— 24å°æ—¶ Ã— 60åˆ†é’Ÿ Ã— (1 - 0.9999)
                = 525,600åˆ†é’Ÿ Ã— 0.0001
                = 52.56åˆ†é’Ÿ/å¹´
                â‰ˆ 4.38åˆ†é’Ÿ/æœˆ
```

**é«˜å¯ç”¨è®¾è®¡åŸåˆ™**:

```yaml
# 1. æ¶ˆé™¤å•ç‚¹æ•…éšœ(SPOF - Single Point of Failure)
åŸåˆ™: ä»»ä½•ç»„ä»¶éƒ½ä¸åº”è¯¥æˆä¸ºå•ç‚¹æ•…éšœ
å®è·µ:
  - æ‰€æœ‰æœåŠ¡è‡³å°‘2ä¸ªå‰¯æœ¬
  - æ•°æ®åº“ä¸»ä»/é›†ç¾¤éƒ¨ç½²
  - è´Ÿè½½å‡è¡¡å™¨åŒæ´»
  - å­˜å‚¨å†—ä½™(RAID/åˆ†å¸ƒå¼å­˜å‚¨)

# 2. æ•…éšœæ£€æµ‹ä¸è‡ªåŠ¨æ¢å¤
åŸåˆ™: å¿«é€Ÿæ£€æµ‹æ•…éšœå¹¶è‡ªåŠ¨æ¢å¤
å®è·µ:
  - å¥åº·æ£€æŸ¥æœºåˆ¶(HTTP/TCPæ¢é’ˆ)
  - è‡ªåŠ¨é‡å¯ç­–ç•¥
  - æœåŠ¡è‡ªåŠ¨æ³¨å†Œ/æ³¨é”€
  - ç†”æ–­å™¨æ¨¡å¼

# 3. å†—ä½™ä¸å¤‡ä»½
åŸåˆ™: å…³é”®æ•°æ®å’ŒæœåŠ¡å¤šå‰¯æœ¬
å®è·µ:
  - æ•°æ®åº“å®æ—¶å¤åˆ¶
  - å®šæœŸå¤‡ä»½(å…¨é‡+å¢é‡)
  - è·¨å¯ç”¨åŒºéƒ¨ç½²
  - å¼‚åœ°ç¾å¤‡

# 4. é™çº§ä¸é™æµ
åŸåˆ™: ä¿è¯æ ¸å¿ƒåŠŸèƒ½å¯ç”¨
å®è·µ:
  - åŠŸèƒ½é™çº§å¼€å…³
  - é™æµä¿æŠ¤
  - ç†”æ–­æœºåˆ¶
  - ä¼˜é›…é™çº§

# 5. ç›‘æ§ä¸å‘Šè­¦
åŸåˆ™: å®æ—¶ç›‘æ§,å¿«é€Ÿå“åº”
å®è·µ:
  - å…¨é“¾è·¯ç›‘æ§
  - å®æ—¶å‘Šè­¦
  - è‡ªåŠ¨åŒ–è¿ç»´
  - äº‹ä»¶æº¯æº
```

---

### 14.1.2 å¤šå±‚çº§é«˜å¯ç”¨æ¶æ„

**å®Œæ•´é«˜å¯ç”¨æ¶æ„å›¾**:

```bash
# ä¸‰å±‚é«˜å¯ç”¨æ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DNSå±‚(å¤šåœ°åŸŸ)                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Route53 US  â”‚  â”‚  Route53 EU  â”‚  â”‚  Route53 AS  â”‚  â”‚
â”‚   â”‚   (ä¸»DNS)    â”‚  â”‚   (å¤‡DNS)    â”‚  â”‚   (å¤‡DNS)    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CDN/WAFå±‚(è¾¹ç¼˜åŠ é€Ÿ)                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ CloudFlare 1 â”‚  â”‚ CloudFlare 2 â”‚  â”‚ CloudFlare 3 â”‚  â”‚
â”‚   â”‚   (åŒ—ç¾)     â”‚  â”‚   (æ¬§æ´²)     â”‚  â”‚   (äºšå¤ª)     â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              è´Ÿè½½å‡è¡¡å±‚(è·¨å¯ç”¨åŒº)                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  VIP (AZ-A)  â”‚  â”‚  VIP (AZ-B)  â”‚  â”‚  VIP (AZ-C)  â”‚  â”‚
â”‚   â”‚  HAProxy+    â”‚  â”‚  HAProxy+    â”‚  â”‚  HAProxy+    â”‚  â”‚
â”‚   â”‚  Keepalived  â”‚  â”‚  Keepalived  â”‚  â”‚  Keepalived  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              åº”ç”¨å±‚(Swarmé›†ç¾¤)                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  ManagerèŠ‚ç‚¹(3ä¸ª,è·¨AZ)                           â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚   â”‚  â”‚Manager1 â”‚  â”‚Manager2 â”‚  â”‚Manager3 â”‚          â”‚  â”‚
â”‚   â”‚  â”‚  (AZ-A) â”‚  â”‚  (AZ-B) â”‚  â”‚  (AZ-C) â”‚          â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  WorkerèŠ‚ç‚¹(Nä¸ª,è·¨AZ)                            â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”          â”‚  â”‚
â”‚   â”‚  â”‚W-1 â”‚â”‚W-2 â”‚â”‚W-3 â”‚â”‚W-4 â”‚â”‚W-5 â”‚â”‚W-N â”‚  ...     â”‚  â”‚
â”‚   â”‚  â”‚AZ-Aâ”‚â”‚AZ-Bâ”‚â”‚AZ-Câ”‚â”‚AZ-Aâ”‚â”‚AZ-Bâ”‚â”‚AZ-Câ”‚          â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ•°æ®å±‚(ä¸»ä»+é›†ç¾¤)                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  PostgreSQLä¸»ä»é›†ç¾¤                              â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚   â”‚  â”‚ Master  â”‚â†’â†’â”‚ Slave1  â”‚  â”‚ Slave2  â”‚          â”‚  â”‚
â”‚   â”‚  â”‚  (AZ-A) â”‚  â”‚  (AZ-B) â”‚  â”‚  (AZ-C) â”‚          â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Redis Sentinelé›†ç¾¤                              â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚   â”‚  â”‚ Master  â”‚  â”‚Sentinel1â”‚  â”‚Sentinel2â”‚          â”‚  â”‚
â”‚   â”‚  â”‚  (AZ-A) â”‚  â”‚  (AZ-B) â”‚  â”‚  (AZ-C) â”‚          â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å­˜å‚¨å±‚(åˆ†å¸ƒå¼å­˜å‚¨)                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Ceph/GlusterFSåˆ†å¸ƒå¼å­˜å‚¨                        â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚   â”‚  â”‚  OSD 1  â”‚  â”‚  OSD 2  â”‚  â”‚  OSD 3  â”‚  ...    â”‚  â”‚
â”‚   â”‚  â”‚  (AZ-A) â”‚  â”‚  (AZ-B) â”‚  â”‚  (AZ-C) â”‚          â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 14.1.3 è·¨å¯ç”¨åŒºéƒ¨ç½²å®è·µ

**å¯ç”¨åŒºæ ‡ç­¾é…ç½®**:

```bash
# ========================================
# ä¸ºèŠ‚ç‚¹æ‰“å¯ç”¨åŒºæ ‡ç­¾
# ========================================

# ManagerèŠ‚ç‚¹
$ docker node update --label-add zone=us-east-1a manager1
$ docker node update --label-add zone=us-east-1b manager2
$ docker node update --label-add zone=us-east-1c manager3

# WorkerèŠ‚ç‚¹
$ docker node update --label-add zone=us-east-1a worker1
$ docker node update --label-add zone=us-east-1a worker2
$ docker node update --label-add zone=us-east-1b worker3
$ docker node update --label-add zone=us-east-1b worker4
$ docker node update --label-add zone=us-east-1c worker5
$ docker node update --label-add zone=us-east-1c worker6

# éªŒè¯æ ‡ç­¾
$ docker node ls --format "table {{.Hostname}}\t{{.ManagerStatus}}\t{{.Availability}}"
HOSTNAME    MANAGER STATUS  AVAILABILITY
manager1    Leader          Active
manager2    Reachable       Active
manager3    Reachable       Active
worker1                     Active
worker2                     Active
worker3                     Active

$ docker node inspect manager1 --format '{{.Spec.Labels.zone}}'
us-east-1a
```

**è·¨å¯ç”¨åŒºæœåŠ¡éƒ¨ç½²**:

```yaml
# stack-ha.yml - é«˜å¯ç”¨Stacké…ç½®
version: '3.8'

services:
  # ========================================
  # Webåº”ç”¨(è·¨AZåˆ†å¸ƒ)
  # ========================================
  app:
    image: myapp:latest
    deploy:
      replicas: 9  # æ¯ä¸ªAZè‡³å°‘3ä¸ªå‰¯æœ¬
      placement:
        max_replicas_per_node: 2  # å•èŠ‚ç‚¹æœ€å¤š2ä¸ªå‰¯æœ¬
        constraints:
          - node.role == worker
        preferences:
          - spread: node.labels.zone  # è·¨AZå‡åŒ€åˆ†å¸ƒ
      update_config:
        parallelism: 3  # æ¯æ¬¡æ›´æ–°3ä¸ªå‰¯æœ¬(æ¯ä¸ªAZ 1ä¸ª)
        delay: 10s
        failure_action: rollback
        order: start-first  # å…ˆå¯åŠ¨æ–°å‰¯æœ¬å†åœæ­¢æ—§å‰¯æœ¬
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 40s

  # ========================================
  # æ•°æ®åº“(ä¸»ä»å¤åˆ¶,è·¨AZ)
  # ========================================
  db-master:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_DB: appdb
      # ä¸»åº“é…ç½®
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=C"
    secrets:
      - db_password
    volumes:
      - db-master-data:/var/lib/postgresql/data
      - ./postgres/master/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./postgres/master/pg_hba.conf:/etc/postgresql/pg_hba.conf
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
          - node.labels.zone == us-east-1a  # ä¸»åº“å›ºå®šåœ¨AZ-A
          - node.labels.ssd == true
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser"]
      interval: 10s
      timeout: 5s
      retries: 5

  db-slave-1:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      # ä»åº“é…ç½®
      POSTGRES_MASTER_HOST: db-master
      POSTGRES_MASTER_PORT: 5432
    secrets:
      - db_password
    volumes:
      - db-slave-1-data:/var/lib/postgresql/data
      - ./postgres/slave/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./postgres/slave/recovery.conf:/var/lib/postgresql/data/recovery.conf
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.zone == us-east-1b  # ä»åº“1åœ¨AZ-B
          - node.labels.ssd == true
      resources:
        limits:
          cpus: '2'
          memory: 4G
    depends_on:
      - db-master

  db-slave-2:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_MASTER_HOST: db-master
      POSTGRES_MASTER_PORT: 5432
    secrets:
      - db_password
    volumes:
      - db-slave-2-data:/var/lib/postgresql/data
      - ./postgres/slave/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./postgres/slave/recovery.conf:/var/lib/postgresql/data/recovery.conf
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.zone == us-east-1c  # ä»åº“2åœ¨AZ-C
          - node.labels.ssd == true
      resources:
        limits:
          cpus: '2'
          memory: 4G
    depends_on:
      - db-master

  # ========================================
  # Redis Sentinelé«˜å¯ç”¨
  # ========================================
  redis-master:
    image: redis:7-alpine
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --appendonly yes
      --replica-announce-ip redis-master
    volumes:
      - redis-master-data:/data
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.zone == us-east-1a

  redis-sentinel-1:
    image: redis:7-alpine
    command: >
      redis-sentinel /etc/redis/sentinel.conf
      --sentinel announce-ip redis-sentinel-1
    volumes:
      - ./redis/sentinel.conf:/etc/redis/sentinel.conf
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.zone == us-east-1a

  redis-sentinel-2:
    image: redis:7-alpine
    command: >
      redis-sentinel /etc/redis/sentinel.conf
      --sentinel announce-ip redis-sentinel-2
    volumes:
      - ./redis/sentinel.conf:/etc/redis/sentinel.conf
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.zone == us-east-1b

  redis-sentinel-3:
    image: redis:7-alpine
    command: >
      redis-sentinel /etc/redis/sentinel.conf
      --sentinel announce-ip redis-sentinel-3
    volumes:
      - ./redis/sentinel.conf:/etc/redis/sentinel.conf
    networks:
      - backend
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.zone == us-east-1c

networks:
  frontend:
    driver: overlay
    attachable: true
  backend:
    driver: overlay
    internal: true
    attachable: true

volumes:
  db-master-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=nfs-az-a.example.com,rw
      device: ":/export/db-master"

  db-slave-1-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=nfs-az-b.example.com,rw
      device: ":/export/db-slave-1"

  db-slave-2-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=nfs-az-c.example.com,rw
      device: ":/export/db-slave-2"

  redis-master-data:
    driver: local

secrets:
  db_password:
    external: true
```

**PostgreSQLä¸»ä»é…ç½®**:

```bash
# postgres/master/postgresql.conf
# ä¸»åº“é…ç½®

# åŸºæœ¬è®¾ç½®
listen_addresses = '*'
port = 5432
max_connections = 200

# WALé…ç½®(Write-Ahead Logging)
wal_level = replica  # å¯ç”¨æµå¤åˆ¶
max_wal_senders = 10  # æœ€å¤š10ä¸ªä»åº“
wal_keep_size = 1GB   # ä¿ç•™1GB WALæ—¥å¿—
hot_standby = on      # å¯ç”¨çƒ­å¤‡

# å½’æ¡£é…ç½®
archive_mode = on
archive_command = 'test ! -f /archive/%f && cp %p /archive/%f'

# åŒæ­¥å¤åˆ¶(å¯é€‰,ä¿è¯æ•°æ®ä¸€è‡´æ€§)
synchronous_commit = on
synchronous_standby_names = 'slave1,slave2'

# æ€§èƒ½è°ƒä¼˜
shared_buffers = 2GB
effective_cache_size = 6GB
maintenance_work_mem = 512MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200
work_mem = 10MB
min_wal_size = 1GB
max_wal_size = 4GB
```

```bash
# postgres/master/pg_hba.conf
# ä¸»åº“è®¿é—®æ§åˆ¶

# TYPE  DATABASE        USER            ADDRESS                 METHOD

# æœ¬åœ°è¿æ¥
local   all             all                                     trust

# IPv4æœ¬åœ°è¿æ¥
host    all             all             127.0.0.1/32            md5

# å…è®¸Swarmç½‘ç»œè®¿é—®
host    all             all             10.0.0.0/8              md5

# å…è®¸ä»åº“å¤åˆ¶
host    replication     replicator      10.0.0.0/8              md5
```

```bash
# postgres/slave/recovery.conf
# ä»åº“å¤åˆ¶é…ç½®

# å£°æ˜ä¸ºå¤‡åº“
standby_mode = 'on'

# ä¸»åº“è¿æ¥ä¿¡æ¯
primary_conninfo = 'host=db-master port=5432 user=replicator password=ReplicatorPassword123 application_name=slave1'

# æ¢å¤ç›®æ ‡æ—¶é—´çº¿
recovery_target_timeline = 'latest'

# è§¦å‘æ–‡ä»¶(ç”¨äºæ‰‹åŠ¨æå‡ä¸ºä¸»åº“)
trigger_file = '/tmp/postgresql.trigger'

# å½’æ¡£æ¢å¤
restore_command = 'cp /archive/%f %p'
```

**Redis Sentinelé…ç½®**:

```bash
# redis/sentinel.conf
# Redis Sentinelé…ç½®

# ç«¯å£
port 26379

# å·¥ä½œç›®å½•
dir /tmp

# ç›‘æ§ä¸»åº“
# sentinel monitor <master-name> <ip> <port> <quorum>
sentinel monitor mymaster redis-master 6379 2

# ä¸»åº“å¯†ç 
sentinel auth-pass mymaster ${REDIS_PASSWORD}

# ä¸»åº“å¤šä¹…æ— å“åº”è§†ä¸ºä¸‹çº¿(æ¯«ç§’)
sentinel down-after-milliseconds mymaster 5000

# æ•…éšœè½¬ç§»è¶…æ—¶æ—¶é—´
sentinel failover-timeout mymaster 60000

# å¹¶è¡ŒåŒæ­¥çš„ä»åº“æ•°é‡
sentinel parallel-syncs mymaster 1

# é€šçŸ¥è„šæœ¬(å¯é€‰)
# sentinel notification-script mymaster /etc/redis/notify.sh

# å®¢æˆ·ç«¯é‡æ–°é…ç½®è„šæœ¬(å¯é€‰)
# sentinel client-reconfig-script mymaster /etc/redis/reconfig.sh

# æ—¥å¿—
logfile "/var/log/redis/sentinel.log"
loglevel notice
```

---

## 14.2 æ•…éšœè½¬ç§»ä¸è‡ªåŠ¨æ¢å¤

### 14.2.1 åº”ç”¨å±‚æ•…éšœè½¬ç§»

**Swarmè‡ªåŠ¨æ•…éšœè½¬ç§»**:

```bash
# ========================================
# Swarmè‡ªåŠ¨æ•…éšœè½¬ç§»æ¼”ç¤º
# ========================================

# æŸ¥çœ‹æœåŠ¡åˆå§‹çŠ¶æ€
$ docker service ps myapp_app
ID      NAME          NODE     DESIRED STATE  CURRENT STATE
abc123  myapp_app.1   worker1  Running        Running 10 minutes ago
def456  myapp_app.2   worker2  Running        Running 10 minutes ago
ghi789  myapp_app.3   worker3  Running        Running 10 minutes ago

# æ¨¡æ‹Ÿworker1èŠ‚ç‚¹æ•…éšœ(å…³æœº)
$ ssh worker1 "sudo shutdown -h now"

# Swarmè‡ªåŠ¨æ£€æµ‹åˆ°èŠ‚ç‚¹æ•…éšœ
$ docker node ls
ID        HOSTNAME    STATUS   AVAILABILITY  MANAGER STATUS
abc123    manager1    Ready    Active        Leader
...
xyz789    worker1     Down     Active
...

# æœåŠ¡è‡ªåŠ¨åœ¨å…¶ä»–èŠ‚ç‚¹é‡å¯
$ docker service ps myapp_app
ID      NAME              NODE     DESIRED STATE  CURRENT STATE
abc123  myapp_app.1       worker1  Shutdown       Failed 1 minute ago
jkl012  \_ myapp_app.1    worker4  Running        Running 30 seconds ago  # âœ… è‡ªåŠ¨è¿ç§»
def456  myapp_app.2       worker2  Running        Running 10 minutes ago
ghi789  myapp_app.3       worker3  Running        Running 10 minutes ago

# èŠ‚ç‚¹æ¢å¤å,å®¹å™¨ä¸ä¼šè‡ªåŠ¨è¿ç§»å›å»(ä¿æŒç¨³å®š)
$ ssh worker1 "sudo systemctl start docker"
$ docker node update --availability active worker1
```

**å¥åº·æ£€æŸ¥ä¸è‡ªåŠ¨é‡å¯**:

```yaml
# å®Œå–„çš„å¥åº·æ£€æŸ¥é…ç½®
services:
  app:
    image: myapp:latest
    healthcheck:
      # å¥åº·æ£€æŸ¥å‘½ä»¤
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      # å¯åŠ¨å®½é™æœŸ(å®¹å™¨å¯åŠ¨åç­‰å¾…40ç§’å†å¼€å§‹æ£€æŸ¥)
      start_period: 40s
      # æ£€æŸ¥é—´éš”
      interval: 10s
      # è¶…æ—¶æ—¶é—´
      timeout: 3s
      # è¿ç»­å¤±è´¥3æ¬¡æ‰è§†ä¸ºä¸å¥åº·
      retries: 3
    deploy:
      replicas: 6
      # æ›´æ–°é…ç½®
      update_config:
        # å…ˆå¯åŠ¨æ–°å®¹å™¨,å¥åº·æ£€æŸ¥é€šè¿‡åå†åœæ­¢æ—§å®¹å™¨
        order: start-first
        # æ¯æ¬¡æ›´æ–°1ä¸ªå‰¯æœ¬
        parallelism: 1
        # ç­‰å¾…10ç§’
        delay: 10s
        # å¤±è´¥åè‡ªåŠ¨å›æ»š
        failure_action: rollback
        # ç›‘æ§çª—å£60ç§’
        monitor: 60s
      # å›æ»šé…ç½®
      rollback_config:
        parallelism: 2
        delay: 5s
      # é‡å¯ç­–ç•¥
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
```

**åº”ç”¨å±‚å¥åº·æ£€æŸ¥å®ç°**:

```python
# app.py - Flaskåº”ç”¨å¥åº·æ£€æŸ¥
from flask import Flask, jsonify
import psycopg2
import redis
import os

app = Flask(__name__)

# æ•°æ®åº“è¿æ¥æ± 
db_pool = None
redis_client = None

def check_database():
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(
            host=os.getenv('DB_HOST', 'db-master'),
            port=5432,
            user='appuser',
            password=os.getenv('DB_PASSWORD'),
            connect_timeout=3
        )
        conn.close()
        return True
    except Exception as e:
        print(f"Database check failed: {e}")
        return False

def check_redis():
    """æ£€æŸ¥Redisè¿æ¥"""
    try:
        r = redis.Redis(
            host=os.getenv('REDIS_HOST', 'redis-master'),
            port=6379,
            password=os.getenv('REDIS_PASSWORD'),
            socket_connect_timeout=3
        )
        r.ping()
        return True
    except Exception as e:
        print(f"Redis check failed: {e}")
        return False

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    checks = {
        'status': 'healthy',
        'database': check_database(),
        'redis': check_redis(),
    }

    # ä»»ä½•ä¾èµ–å¤±è´¥éƒ½è¿”å›503
    if not all(checks.values()):
        checks['status'] = 'unhealthy'
        return jsonify(checks), 503

    return jsonify(checks), 200

@app.route('/ready')
def ready():
    """å°±ç»ªæ£€æŸ¥ç«¯ç‚¹(Kubernetesç”¨)"""
    # æ£€æŸ¥åº”ç”¨æ˜¯å¦å·²å®Œå…¨å¯åŠ¨
    # å¯ä»¥åŒ…å«æ›´å¤æ‚çš„é€»è¾‘,å¦‚ç¼“å­˜é¢„çƒ­ã€é…ç½®åŠ è½½ç­‰
    return jsonify({'status': 'ready'}), 200

@app.route('/live')
def live():
    """å­˜æ´»æ£€æŸ¥ç«¯ç‚¹(Kubernetesç”¨)"""
    # ç®€å•æ£€æŸ¥åº”ç”¨è¿›ç¨‹æ˜¯å¦å­˜æ´»
    return jsonify({'status': 'alive'}), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

---

### 14.2.2 æ•°æ®åº“æ•…éšœè½¬ç§»

**PostgreSQLè‡ªåŠ¨æ•…éšœè½¬ç§»(ä½¿ç”¨Patroni)**:

```yaml
# patroni-stack.yml - PostgreSQLé«˜å¯ç”¨æ–¹æ¡ˆ
version: '3.8'

services:
  # ========================================
  # etcdé›†ç¾¤(Patroniä¾èµ–çš„åˆ†å¸ƒå¼é…ç½®å­˜å‚¨)
  # ========================================
  etcd-1:
    image: quay.io/coreos/etcd:v3.5.10
    environment:
      ETCD_NAME: etcd-1
      ETCD_INITIAL_CLUSTER: etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380
      ETCD_INITIAL_CLUSTER_STATE: new
      ETCD_INITIAL_CLUSTER_TOKEN: patroni-cluster
      ETCD_LISTEN_PEER_URLS: http://0.0.0.0:2380
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
      ETCD_ADVERTISE_CLIENT_URLS: http://etcd-1:2379
    networks:
      - db-net
    volumes:
      - etcd-1-data:/etcd-data
    deploy:
      placement:
        constraints:
          - node.labels.zone == us-east-1a

  etcd-2:
    image: quay.io/coreos/etcd:v3.5.10
    environment:
      ETCD_NAME: etcd-2
      ETCD_INITIAL_CLUSTER: etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380
      ETCD_INITIAL_CLUSTER_STATE: new
      ETCD_INITIAL_CLUSTER_TOKEN: patroni-cluster
      ETCD_LISTEN_PEER_URLS: http://0.0.0.0:2380
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
      ETCD_ADVERTISE_CLIENT_URLS: http://etcd-2:2379
    networks:
      - db-net
    volumes:
      - etcd-2-data:/etcd-data
    deploy:
      placement:
        constraints:
          - node.labels.zone == us-east-1b

  etcd-3:
    image: quay.io/coreos/etcd:v3.5.10
    environment:
      ETCD_NAME: etcd-3
      ETCD_INITIAL_CLUSTER: etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380
      ETCD_INITIAL_CLUSTER_STATE: new
      ETCD_INITIAL_CLUSTER_TOKEN: patroni-cluster
      ETCD_LISTEN_PEER_URLS: http://0.0.0.0:2380
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
      ETCD_ADVERTISE_CLIENT_URLS: http://etcd-3:2379
    networks:
      - db-net
    volumes:
      - etcd-3-data:/etcd-data
    deploy:
      placement:
        constraints:
          - node.labels.zone == us-east-1c

  # ========================================
  # Patroni PostgreSQLèŠ‚ç‚¹
  # ========================================
  patroni-1:
    image: patroni/patroni:3.2.0
    hostname: patroni-1
    environment:
      PATRONI_NAME: patroni-1
      PATRONI_SCOPE: postgres-cluster
      PATRONI_RESTAPI_LISTEN: 0.0.0.0:8008
      PATRONI_POSTGRESQL_LISTEN: 0.0.0.0:5432
      PATRONI_POSTGRESQL_DATA_DIR: /var/lib/postgresql/data
      PATRONI_ETCD3_HOSTS: etcd-1:2379,etcd-2:2379,etcd-3:2379
      PATRONI_POSTGRESQL_PGPASS: /tmp/pgpass
      PATRONI_SUPERUSER_USERNAME: postgres
      PATRONI_SUPERUSER_PASSWORD: ${POSTGRES_PASSWORD}
      PATRONI_REPLICATION_USERNAME: replicator
      PATRONI_REPLICATION_PASSWORD: ${REPLICATION_PASSWORD}
    volumes:
      - patroni-1-data:/var/lib/postgresql/data
      - ./patroni/patroni.yml:/etc/patroni/patroni.yml
    networks:
      - db-net
    ports:
      - "5432:5432"  # PostgreSQL
      - "8008:8008"  # Patroni REST API
    deploy:
      placement:
        constraints:
          - node.labels.zone == us-east-1a
          - node.labels.ssd == true

  patroni-2:
    image: patroni/patroni:3.2.0
    hostname: patroni-2
    environment:
      PATRONI_NAME: patroni-2
      PATRONI_SCOPE: postgres-cluster
      PATRONI_RESTAPI_LISTEN: 0.0.0.0:8008
      PATRONI_POSTGRESQL_LISTEN: 0.0.0.0:5432
      PATRONI_POSTGRESQL_DATA_DIR: /var/lib/postgresql/data
      PATRONI_ETCD3_HOSTS: etcd-1:2379,etcd-2:2379,etcd-3:2379
      PATRONI_SUPERUSER_USERNAME: postgres
      PATRONI_SUPERUSER_PASSWORD: ${POSTGRES_PASSWORD}
      PATRONI_REPLICATION_USERNAME: replicator
      PATRONI_REPLICATION_PASSWORD: ${REPLICATION_PASSWORD}
    volumes:
      - patroni-2-data:/var/lib/postgresql/data
      - ./patroni/patroni.yml:/etc/patroni/patroni.yml
    networks:
      - db-net
    deploy:
      placement:
        constraints:
          - node.labels.zone == us-east-1b
          - node.labels.ssd == true

  patroni-3:
    image: patroni/patroni:3.2.0
    hostname: patroni-3
    environment:
      PATRONI_NAME: patroni-3
      PATRONI_SCOPE: postgres-cluster
      PATRONI_RESTAPI_LISTEN: 0.0.0.0:8008
      PATRONI_POSTGRESQL_LISTEN: 0.0.0.0:5432
      PATRONI_POSTGRESQL_DATA_DIR: /var/lib/postgresql/data
      PATRONI_ETCD3_HOSTS: etcd-1:2379,etcd-2:2379,etcd-3:2379
      PATRONI_SUPERUSER_USERNAME: postgres
      PATRONI_SUPERUSER_PASSWORD: ${POSTGRES_PASSWORD}
      PATRONI_REPLICATION_USERNAME: replicator
      PATRONI_REPLICATION_PASSWORD: ${REPLICATION_PASSWORD}
    volumes:
      - patroni-3-data:/var/lib/postgresql/data
      - ./patroni/patroni.yml:/etc/patroni/patroni.yml
    networks:
      - db-net
    deploy:
      placement:
        constraints:
          - node.labels.zone == us-east-1c
          - node.labels.ssd == true

  # ========================================
  # HAProxy(æ•°æ®åº“è´Ÿè½½å‡è¡¡)
  # ========================================
  haproxy-db:
    image: haproxy:2.9-alpine
    ports:
      - "5433:5432"  # ä¸»åº“ç«¯å£
      - "5434:5433"  # ä»åº“ç«¯å£(è¯»è´Ÿè½½å‡è¡¡)
      - "7000:7000"  # HAProxyç»Ÿè®¡é¡µé¢
    volumes:
      - ./haproxy/haproxy-db.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    networks:
      - db-net
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager

networks:
  db-net:
    driver: overlay
    attachable: true

volumes:
  etcd-1-data:
  etcd-2-data:
  etcd-3-data:
  patroni-1-data:
  patroni-2-data:
  patroni-3-data:
```

**Patronié…ç½®æ–‡ä»¶**:

```yaml
# patroni/patroni.yml
scope: postgres-cluster
namespace: /service/
name: ${PATRONI_NAME}

restapi:
  listen: 0.0.0.0:8008
  connect_address: ${PATRONI_NAME}:8008

etcd3:
  hosts: etcd-1:2379,etcd-2:2379,etcd-3:2379

bootstrap:
  dcs:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    maximum_lag_on_failover: 1048576
    postgresql:
      use_pg_rewind: true
      parameters:
        max_connections: 200
        shared_buffers: 2GB
        effective_cache_size: 6GB
        maintenance_work_mem: 512MB
        checkpoint_completion_target: 0.9
        wal_buffers: 16MB
        default_statistics_target: 100
        random_page_cost: 1.1
        effective_io_concurrency: 200
        work_mem: 10MB
        min_wal_size: 1GB
        max_wal_size: 4GB
        max_worker_processes: 8
        max_parallel_workers_per_gather: 4
        max_parallel_workers: 8

  initdb:
    - encoding: UTF8
    - data-checksums

  pg_hba:
    - host replication replicator 0.0.0.0/0 md5
    - host all all 0.0.0.0/0 md5

  users:
    admin:
      password: ${ADMIN_PASSWORD}
      options:
        - createrole
        - createdb

postgresql:
  listen: 0.0.0.0:5432
  connect_address: ${PATRONI_NAME}:5432
  data_dir: /var/lib/postgresql/data
  pgpass: /tmp/pgpass
  authentication:
    replication:
      username: replicator
      password: ${REPLICATION_PASSWORD}
    superuser:
      username: postgres
      password: ${POSTGRES_PASSWORD}
  parameters:
    unix_socket_directories: '/var/run/postgresql'

tags:
    nofailover: false
    noloadbalance: false
    clonefrom: false
    nosync: false
```

**HAProxyæ•°æ®åº“è´Ÿè½½å‡è¡¡é…ç½®**:

```bash
# haproxy/haproxy-db.cfg
global
    log stdout format raw local0 info
    maxconn 100

defaults
    log global
    mode tcp
    retries 2
    timeout client 30m
    timeout connect 4s
    timeout server 30m
    timeout check 5s

# ç»Ÿè®¡é¡µé¢
listen stats
    bind *:7000
    mode http
    stats enable
    stats uri /
    stats refresh 5s

# ä¸»åº“(å†™)
listen postgres-master
    bind *:5432
    mode tcp
    option httpchk GET /master
    http-check expect status 200
    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions

    server patroni-1 patroni-1:5432 check port 8008
    server patroni-2 patroni-2:5432 check port 8008
    server patroni-3 patroni-3:5432 check port 8008

# ä»åº“(è¯»,è´Ÿè½½å‡è¡¡)
listen postgres-replicas
    bind *:5433
    mode tcp
    balance roundrobin
    option httpchk GET /replica
    http-check expect status 200
    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions

    server patroni-1 patroni-1:5432 check port 8008
    server patroni-2 patroni-2:5432 check port 8008
    server patroni-3 patroni-3:5432 check port 8008
```

**æ•…éšœè½¬ç§»æµ‹è¯•**:

```bash
# ========================================
# æ¨¡æ‹Ÿä¸»åº“æ•…éšœ
# ========================================

# æŸ¥çœ‹å½“å‰ä¸»åº“
$ curl -s http://patroni-1:8008/patroni | jq .role
"master"

$ curl -s http://patroni-2:8008/patroni | jq .role
"replica"

$ curl -s http://patroni-3:8008/patroni | jq .role
"replica"

# åœæ­¢ä¸»åº“å®¹å™¨(æ¨¡æ‹Ÿæ•…éšœ)
$ docker stop $(docker ps -q -f name=patroni-1)

# Patroniè‡ªåŠ¨æ£€æµ‹æ•…éšœå¹¶é€‰ä¸¾æ–°ä¸»åº“(çº¦15-30ç§’)
# æŸ¥çœ‹æ–°ä¸»åº“
$ curl -s http://patroni-2:8008/patroni | jq .role
"master"  # âœ… patroni-2å·²æå‡ä¸ºä¸»åº“

$ curl -s http://patroni-3:8008/patroni | jq .role
"replica"

# æ¢å¤æ—§ä¸»åº“
$ docker start $(docker ps -aq -f name=patroni-1)

# æ—§ä¸»åº“è‡ªåŠ¨å˜ä¸ºä»åº“
$ curl -s http://patroni-1:8008/patroni | jq .role
"replica"  # âœ… patroni-1é™çº§ä¸ºä»åº“

# éªŒè¯æ•°æ®ä¸€è‡´æ€§
$ docker exec -it $(docker ps -q -f name=patroni-2) \
  psql -U postgres -c "SELECT pg_current_wal_lsn();"
 pg_current_wal_lsn
--------------------
 0/5000000

$ docker exec -it $(docker ps -q -f name=patroni-1) \
  psql -U postgres -c "SELECT pg_last_wal_replay_lsn();"
 pg_last_wal_replay_lsn
------------------------
 0/5000000  # âœ… æ•°æ®å·²åŒæ­¥
```

---

### 14.2.3 Redisæ•…éšœè½¬ç§»(Sentinel)

**Redis Sentinelå·¥ä½œåŸç†**:

```bash
# Redis Sentinelæ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Redis Sentinelé›†ç¾¤                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Sentinel 1  â”‚ â”‚ Sentinel 2  â”‚ â”‚ Sentinel 3  â”‚â”‚
â”‚  â”‚   (AZ-A)    â”‚ â”‚   (AZ-B)    â”‚ â”‚   (AZ-C)    â”‚â”‚
â”‚  â”‚ Port: 26379 â”‚ â”‚ Port: 26379 â”‚ â”‚ Port: 26379 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚               â”‚               â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                         â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ ç›‘æ§
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Redisæ•°æ®èŠ‚ç‚¹                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Master    â”‚â†’â”‚   Replica1  â”‚ â”‚   Replica2  â”‚â”‚
â”‚  â”‚   (AZ-A)    â”‚ â”‚   (AZ-B)    â”‚ â”‚   (AZ-C)    â”‚â”‚
â”‚  â”‚ Port: 6379  â”‚ â”‚ Port: 6379  â”‚ â”‚ Port: 6379  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# æ•…éšœè½¬ç§»æµç¨‹:
1. Sentinelå®šæœŸPINGä¸»åº“
2. è¶…è¿‡down-after-millisecondsæ— å“åº”,æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿(SDOWN)
3. è¾¾åˆ°quorumä¸ªSentinelç¡®è®¤,æ ‡è®°ä¸ºå®¢è§‚ä¸‹çº¿(ODOWN)
4. Sentinel Leaderé€‰ä¸¾(Raftç®—æ³•)
5. Leaderå‘èµ·æ•…éšœè½¬ç§»:
   a. ä»æ‰€æœ‰ä»åº“ä¸­é€‰å‡ºæ–°ä¸»åº“(ä¼˜å…ˆçº§/å¤åˆ¶åç§»é‡/RunID)
   b. å‘æ–°ä¸»åº“å‘é€SLAVEOF NO ONE(æå‡ä¸ºä¸»åº“)
   c. å‘å…¶ä»–ä»åº“å‘é€SLAVEOF <new-master>
   d. æ›´æ–°é…ç½®,é€šçŸ¥å®¢æˆ·ç«¯
```

**åº”ç”¨é›†æˆSentinel**:

```python
# app.py - Pythonåº”ç”¨ä½¿ç”¨Redis Sentinel
from redis.sentinel import Sentinel
import os

# Sentinelé…ç½®
SENTINEL_HOSTS = [
    ('redis-sentinel-1', 26379),
    ('redis-sentinel-2', 26379),
    ('redis-sentinel-3', 26379)
]
MASTER_NAME = 'mymaster'
REDIS_PASSWORD = os.getenv('REDIS_PASSWORD')

# åˆ›å»ºSentinelè¿æ¥
sentinel = Sentinel(
    SENTINEL_HOSTS,
    socket_timeout=0.5,
    password=REDIS_PASSWORD
)

# è·å–ä¸»åº“è¿æ¥(å†™æ“ä½œ)
def get_master():
    return sentinel.master_for(
        MASTER_NAME,
        socket_timeout=0.5,
        password=REDIS_PASSWORD,
        db=0
    )

# è·å–ä»åº“è¿æ¥(è¯»æ“ä½œ)
def get_slave():
    return sentinel.slave_for(
        MASTER_NAME,
        socket_timeout=0.5,
        password=REDIS_PASSWORD,
        db=0
    )

# ä½¿ç”¨ç¤ºä¾‹
def set_value(key, value):
    """å†™æ“ä½œ(ä½¿ç”¨ä¸»åº“)"""
    master = get_master()
    master.set(key, value)
    print(f"âœ… Set {key}={value} to master")

def get_value(key):
    """è¯»æ“ä½œ(ä½¿ç”¨ä»åº“)"""
    slave = get_slave()
    value = slave.get(key)
    print(f"âœ… Get {key}={value} from slave")
    return value

# æµ‹è¯•
if __name__ == '__main__':
    # å†™å…¥æ•°æ®
    set_value('user:1001', 'John Doe')

    # è¯»å–æ•°æ®
    user = get_value('user:1001')
    print(f"User: {user}")

    # æŸ¥çœ‹å½“å‰ä¸»åº“ä¿¡æ¯
    master_addr = sentinel.discover_master(MASTER_NAME)
    print(f"Current master: {master_addr}")

    # æŸ¥çœ‹ä»åº“åˆ—è¡¨
    slaves = sentinel.discover_slaves(MASTER_NAME)
    print(f"Slaves: {slaves}")
```

**æ•…éšœè½¬ç§»æµ‹è¯•**:

```bash
# ========================================
# æµ‹è¯•Redis Sentinelæ•…éšœè½¬ç§»
# ========================================

# æŸ¥çœ‹å½“å‰ä¸»åº“
$ docker exec redis-sentinel-1 \
  redis-cli -p 26379 sentinel get-master-addr-by-name mymaster
1) "redis-master"
2) "6379"

# æŸ¥çœ‹ä¸»åº“ä¿¡æ¯
$ docker exec redis-sentinel-1 \
  redis-cli -p 26379 sentinel master mymaster
name: mymaster
ip: redis-master
port: 6379
runid: abc123...
flags: master
num-slaves: 2
num-other-sentinels: 2

# æ¨¡æ‹Ÿä¸»åº“æ•…éšœ(æš‚åœå®¹å™¨)
$ docker pause $(docker ps -q -f name=redis-master)

# Sentinelæ£€æµ‹æ•…éšœå¹¶å¼€å§‹é€‰ä¸¾(çº¦5-10ç§’)
$ docker logs -f $(docker ps -q -f name=redis-sentinel-1)
+sdown master mymaster redis-master 6379  # ä¸»è§‚ä¸‹çº¿
+odown master mymaster redis-master 6379 #quorum 2/2  # å®¢è§‚ä¸‹çº¿
+failover-triggered master mymaster redis-master 6379  # è§¦å‘æ•…éšœè½¬ç§»
+failover-state-select-slave master mymaster redis-master 6379  # é€‰æ‹©æ–°ä¸»åº“
+selected-slave slave redis-replica-1:6379 redis-replica-1 6379 @ mymaster redis-master 6379  # é€‰ä¸­replica-1
+failover-state-send-slaveof-noone slave redis-replica-1:6379 redis-replica-1 6379 @ mymaster redis-master 6379  # æå‡ä¸ºä¸»åº“
+failover-state-reconf-slaves master mymaster redis-master 6379  # é‡æ–°é…ç½®ä»åº“
+slave-reconf-sent slave redis-replica-2:6379 redis-replica-2 6379 @ mymaster redis-master 6379
+failover-end master mymaster redis-master 6379  # æ•…éšœè½¬ç§»å®Œæˆ
+switch-master mymaster redis-master 6379 redis-replica-1 6379  # åˆ‡æ¢ä¸»åº“

# éªŒè¯æ–°ä¸»åº“
$ docker exec redis-sentinel-1 \
  redis-cli -p 26379 sentinel get-master-addr-by-name mymaster
1) "redis-replica-1"  # âœ… æ–°ä¸»åº“
2) "6379"

# æ¢å¤æ—§ä¸»åº“
$ docker unpause $(docker ps -q -f name=redis-master)

# æ—§ä¸»åº“è‡ªåŠ¨å˜ä¸ºä»åº“
$ docker exec $(docker ps -q -f name=redis-master) \
  redis-cli -a ${REDIS_PASSWORD} info replication | grep role
role:slave  # âœ… å·²é™çº§ä¸ºä»åº“
```

---

## 14.3 æ•°æ®å¤‡ä»½ç­–ç•¥

### 14.3.1 æ•°æ®åº“å¤‡ä»½æ–¹æ¡ˆ

**PostgreSQLå®Œæ•´å¤‡ä»½ç­–ç•¥**:

```bash
#!/bin/bash
# backup-postgres.sh - PostgreSQLè‡ªåŠ¨å¤‡ä»½è„šæœ¬

set -euo pipefail

# ========================================
# é…ç½®
# ========================================

BACKUP_DIR="/backup/postgres"
DB_HOST="${DB_HOST:-db-master}"
DB_PORT="${DB_PORT:-5432}"
DB_USER="${DB_USER:-postgres}"
DB_NAME="${DB_NAME:-appdb}"
PGPASSWORD="${PGPASSWORD}"

# å¤‡ä»½ä¿ç•™ç­–ç•¥
DAILY_RETENTION=7    # ä¿ç•™7å¤©çš„æ¯æ—¥å¤‡ä»½
WEEKLY_RETENTION=4   # ä¿ç•™4å‘¨çš„æ¯å‘¨å¤‡ä»½
MONTHLY_RETENTION=12 # ä¿ç•™12ä¸ªæœˆçš„æœˆåº¦å¤‡ä»½

DATE=$(date +%Y%m%d)
TIME=$(date +%H%M%S)
BACKUP_TYPE="${1:-full}"  # full/incremental

# ========================================
# å‡½æ•°å®šä¹‰
# ========================================

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

# å…¨é‡å¤‡ä»½
full_backup() {
    local backup_file="${BACKUP_DIR}/full/pg_dump_${DB_NAME}_${DATE}_${TIME}.sql.gz"

    log "Starting full backup to $backup_file"

    # åˆ›å»ºç›®å½•
    mkdir -p "${BACKUP_DIR}/full"

    # ä½¿ç”¨pg_dumpè¿›è¡Œå…¨é‡å¤‡ä»½
    pg_dump -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -Fc -Z 9 \
      --verbose --file="${backup_file%.gz}" "$DB_NAME" 2>&1 | \
      tee -a "${BACKUP_DIR}/backup.log"

    # å‹ç¼©
    gzip -9 "${backup_file%.gz}"

    # éªŒè¯å¤‡ä»½
    if [ -f "$backup_file" ]; then
        local size=$(du -h "$backup_file" | cut -f1)
        log "âœ… Full backup completed: $backup_file ($size)"

        # è®°å½•å¤‡ä»½å…ƒæ•°æ®
        cat > "${backup_file}.meta" <<EOF
Backup Date: $(date)
Database: $DB_NAME
Type: Full
Size: $size
Host: $DB_HOST
EOF
    else
        log "âŒ Backup failed!"
        exit 1
    fi
}

# WALå½’æ¡£å¤‡ä»½(å¢é‡)
wal_backup() {
    local wal_dir="${BACKUP_DIR}/wal"
    mkdir -p "$wal_dir"

    log "Archiving WAL files to $wal_dir"

    # è§¦å‘WALå½’æ¡£
    psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -c "SELECT pg_switch_wal();" "$DB_NAME"

    # å¤åˆ¶WALæ–‡ä»¶
    rsync -avz --progress \
      "${DB_HOST}:/var/lib/postgresql/data/pg_wal/" \
      "$wal_dir/" \
      2>&1 | tee -a "${BACKUP_DIR}/backup.log"

    log "âœ… WAL backup completed"
}

# åŸºç¡€å¤‡ä»½(PITR - Point-In-Time Recovery)
base_backup() {
    local backup_dir="${BACKUP_DIR}/basebackup/${DATE}"

    log "Starting base backup to $backup_dir"

    mkdir -p "$backup_dir"

    # ä½¿ç”¨pg_basebackup
    pg_basebackup -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" \
      -D "$backup_dir" -Ft -z -Xs -P \
      2>&1 | tee -a "${BACKUP_DIR}/backup.log"

    log "âœ… Base backup completed"
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    log "Cleaning up old backups..."

    # åˆ é™¤è¶…è¿‡ä¿ç•™æœŸçš„æ¯æ—¥å¤‡ä»½
    find "${BACKUP_DIR}/full" -name "*.sql.gz" -mtime +${DAILY_RETENTION} -delete

    # æ¯å‘¨å¤‡ä»½(ä¿ç•™æ¯å‘¨æ—¥çš„å¤‡ä»½)
    # TODO: å®ç°å‘¨å¤‡ä»½é€»è¾‘

    # æ¯æœˆå¤‡ä»½(ä¿ç•™æ¯æœˆ1å·çš„å¤‡ä»½)
    # TODO: å®ç°æœˆå¤‡ä»½é€»è¾‘

    log "âœ… Cleanup completed"
}

# å¤‡ä»½åˆ°è¿œç¨‹å­˜å‚¨
upload_to_s3() {
    local backup_file="$1"

    log "Uploading backup to S3..."

    # ä½¿ç”¨AWS CLIä¸Šä¼ åˆ°S3
    aws s3 cp "$backup_file" \
      "s3://my-backup-bucket/postgres/${DATE}/" \
      --storage-class STANDARD_IA \
      2>&1 | tee -a "${BACKUP_DIR}/backup.log"

    log "âœ… Upload completed"
}

# ========================================
# ä¸»æµç¨‹
# ========================================

main() {
    log "========================================="
    log "PostgreSQL Backup Started"
    log "Type: $BACKUP_TYPE"
    log "========================================="

    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if ! pg_isready -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" > /dev/null 2>&1; then
        log "âŒ Database is not ready!"
        exit 1
    fi

    case "$BACKUP_TYPE" in
        full)
            full_backup
            ;;
        incremental)
            wal_backup
            ;;
        base)
            base_backup
            ;;
        *)
            log "âŒ Unknown backup type: $BACKUP_TYPE"
            exit 1
            ;;
    esac

    # æ¸…ç†æ—§å¤‡ä»½
    cleanup_old_backups

    # ä¸Šä¼ åˆ°S3(å¯é€‰)
    if [ -n "${AWS_S3_BUCKET:-}" ]; then
        upload_to_s3 "${BACKUP_DIR}/full/pg_dump_${DB_NAME}_${DATE}_${TIME}.sql.gz"
    fi

    log "========================================="
    log "âœ… Backup process completed successfully"
    log "========================================="
}

# æ‰§è¡Œ
main "$@"
```

**å®šæ—¶å¤‡ä»½Croné…ç½®**:

```yaml
# backup-cron-stack.yml
version: '3.8'

services:
  backup-cron:
    image: postgres:15-alpine
    environment:
      DB_HOST: db-master
      DB_PORT: 5432
      DB_USER: postgres
      DB_NAME: appdb
      PGPASSWORD_FILE: /run/secrets/db_password
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_S3_BUCKET: my-backup-bucket
    secrets:
      - db_password
    volumes:
      - backup-data:/backup
      - ./scripts/backup-postgres.sh:/scripts/backup-postgres.sh:ro
    networks:
      - backend
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
    command: >
      sh -c "
        apk add --no-cache aws-cli rsync &&
        chmod +x /scripts/backup-postgres.sh &&
        echo '0 2 * * * /scripts/backup-postgres.sh full >> /backup/cron.log 2>&1' > /etc/crontabs/root &&
        echo '0 */6 * * * /scripts/backup-postgres.sh incremental >> /backup/cron.log 2>&1' >> /etc/crontabs/root &&
        crond -f -l 2
      "

networks:
  backend:
    external: true

volumes:
  backup-data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=backup-nfs.example.com,rw
      device: ":/export/backups"

secrets:
  db_password:
    external: true
```

**æ•°æ®æ¢å¤è„šæœ¬**:

```bash
#!/bin/bash
# restore-postgres.sh - PostgreSQLæ¢å¤è„šæœ¬

set -euo pipefail

BACKUP_FILE="$1"
DB_HOST="${DB_HOST:-db-master}"
DB_PORT="${DB_PORT:-5432}"
DB_USER="${DB_USER:-postgres}"
DB_NAME="${DB_NAME:-appdb}"
PGPASSWORD="${PGPASSWORD}"

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

log "========================================="
log "PostgreSQL Restore Started"
log "Backup file: $BACKUP_FILE"
log "========================================="

# éªŒè¯å¤‡ä»½æ–‡ä»¶å­˜åœ¨
if [ ! -f "$BACKUP_FILE" ]; then
    log "âŒ Backup file not found: $BACKUP_FILE"
    exit 1
fi

# åœæ­¢åº”ç”¨æœåŠ¡(é¿å…è¿æ¥)
log "Stopping application services..."
docker service scale myapp_app=0

# åˆ é™¤ç°æœ‰æ•°æ®åº“
log "Dropping existing database..."
psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -c "DROP DATABASE IF EXISTS ${DB_NAME};"

# åˆ›å»ºæ–°æ•°æ®åº“
log "Creating new database..."
psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -c "CREATE DATABASE ${DB_NAME};"

# æ¢å¤å¤‡ä»½
log "Restoring backup..."
if [[ "$BACKUP_FILE" == *.gz ]]; then
    gunzip -c "$BACKUP_FILE" | pg_restore -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" --verbose
else
    pg_restore -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" --verbose "$BACKUP_FILE"
fi

# éªŒè¯æ¢å¤
log "Verifying restore..."
TABLE_COUNT=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
log "Restored $TABLE_COUNT tables"

# é‡å¯åº”ç”¨æœåŠ¡
log "Restarting application services..."
docker service scale myapp_app=6

log "========================================="
log "âœ… Restore completed successfully"
log "========================================="
```

---

### 14.3.2 æ–‡ä»¶ç³»ç»Ÿå¤‡ä»½

**Docker Volumeå¤‡ä»½**:

```bash
#!/bin/bash
# backup-volumes.sh - Docker Volumeå¤‡ä»½è„šæœ¬

set -euo pipefail

VOLUME_NAME="$1"
BACKUP_DIR="/backup/volumes"
DATE=$(date +%Y%m%d)

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# å¤‡ä»½Volume
backup_volume() {
    local volume="$1"
    local backup_file="${BACKUP_DIR}/${volume}_${DATE}.tar.gz"

    log "Backing up volume: $volume"

    # ä½¿ç”¨ä¸´æ—¶å®¹å™¨æŒ‚è½½Volumeå¹¶æ‰“åŒ…
    docker run --rm \
      -v "${volume}:/data:ro" \
      -v "${BACKUP_DIR}:/backup" \
      alpine \
      tar czf "/backup/$(basename $backup_file)" -C /data .

    if [ -f "$backup_file" ]; then
        local size=$(du -h "$backup_file" | cut -f1)
        log "âœ… Volume backup completed: $backup_file ($size)"
    else
        log "âŒ Backup failed!"
        exit 1
    fi
}

# æ¢å¤Volume
restore_volume() {
    local volume="$1"
    local backup_file="$2"

    log "Restoring volume: $volume from $backup_file"

    # åˆ›å»ºæ–°Volume(å¦‚æœä¸å­˜åœ¨)
    docker volume create "$volume"

    # ä½¿ç”¨ä¸´æ—¶å®¹å™¨è§£å‹åˆ°Volume
    docker run --rm \
      -v "${volume}:/data" \
      -v "$(dirname $backup_file):/backup:ro" \
      alpine \
      tar xzf "/backup/$(basename $backup_file)" -C /data

    log "âœ… Volume restored: $volume"
}

# åˆ—å‡ºæ‰€æœ‰Volume
list_volumes() {
    log "Docker Volumes:"
    docker volume ls --format "table {{.Name}}\t{{.Driver}}\t{{.Mountpoint}}"
}

# ä¸»æµç¨‹
case "${2:-backup}" in
    backup)
        backup_volume "$VOLUME_NAME"
        ;;
    restore)
        restore_volume "$VOLUME_NAME" "$3"
        ;;
    list)
        list_volumes
        ;;
    *)
        echo "Usage: $0 <volume-name> [backup|restore|list] [backup-file]"
        exit 1
        ;;
esac
```

**ä½¿ç”¨Resticè¿›è¡Œå¢é‡å¤‡ä»½**:

```yaml
# restic-backup-stack.yml
version: '3.8'

services:
  restic-backup:
    image: restic/restic:latest
    environment:
      # Resticä»“åº“é…ç½®
      RESTIC_REPOSITORY: s3:s3.amazonaws.com/my-backup-bucket/restic
      RESTIC_PASSWORD_FILE: /run/secrets/restic_password
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    secrets:
      - restic_password
    volumes:
      # éœ€è¦å¤‡ä»½çš„Volume
      - app-data:/data/app:ro
      - db-data:/data/db:ro
      - redis-data:/data/redis:ro
    networks:
      - backend
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
    command: >
      sh -c "
        # åˆå§‹åŒ–ä»“åº“(ä»…é¦–æ¬¡)
        restic snapshots || restic init &&
        # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå¤‡ä»½
        while true; do
          restic backup /data \
            --tag daily \
            --exclude '*.tmp' \
            --exclude '*.log' &&
          restic forget \
            --keep-daily 7 \
            --keep-weekly 4 \
            --keep-monthly 12 \
            --prune &&
          sleep 86400
        done
      "

secrets:
  restic_password:
    external: true

networks:
  backend:
    external: true
```

**Resticå¤‡ä»½ç®¡ç†**:

```bash
# ========================================
# Resticå¸¸ç”¨å‘½ä»¤
# ========================================

# æŸ¥çœ‹æ‰€æœ‰å¿«ç…§
$ docker exec restic-backup restic snapshots
ID        Time                 Host        Tags        Paths
----------------------------------------------------------------------
abc123    2023-12-04 02:00:01  restic-1    daily       /data
def456    2023-12-05 02:00:01  restic-1    daily       /data
ghi789    2023-12-06 02:00:01  restic-1    daily       /data

# æ¯”è¾ƒä¸¤ä¸ªå¿«ç…§çš„å·®å¼‚
$ docker exec restic-backup restic diff abc123 def456
+    /data/app/new-file.txt
M    /data/db/database.db
-    /data/redis/old-cache.rdb

# æ¢å¤ç‰¹å®šå¿«ç…§
$ docker exec restic-backup restic restore abc123 \
  --target /restore \
  --path /data/app

# æ¢å¤ç‰¹å®šæ–‡ä»¶
$ docker exec restic-backup restic restore latest \
  --target /restore \
  --include /data/app/config.yaml

# éªŒè¯å¤‡ä»½å®Œæ•´æ€§
$ docker exec restic-backup restic check

# æŸ¥çœ‹å¤‡ä»½ä»“åº“ç»Ÿè®¡
$ docker exec restic-backup restic stats
Total File Count:   12345
Total Size:         10.5 GiB
```

---

## 14.4 ç¾éš¾æ¢å¤æ¼”ç»ƒ

### 14.4.1 ç¾éš¾æ¢å¤è®¡åˆ’(DRP)

**RTOä¸RPOå®šä¹‰**:

```bash
# ç¾éš¾æ¢å¤å…³é”®æŒ‡æ ‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                   â”‚
â”‚  æ­£å¸¸è¿è¡Œ  â†’  æ•…éšœå‘ç”Ÿ  â†’  æ£€æµ‹æ•…éšœ  â†’  æ¢å¤å®Œæˆ  â”‚
â”‚             â†‘          â†‘            â†‘            â”‚
â”‚             â”‚          â”‚            â”‚            â”‚
â”‚          æ•…éšœæ—¶é—´      â”‚         æ¢å¤æ—¶é—´        â”‚
â”‚                     æ£€æµ‹æ—¶é—´                      â”‚
â”‚             â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’             â”‚
â”‚                      RTO                         â”‚
â”‚             â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’                     â”‚
â”‚                  RPO                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# RTO (Recovery Time Objective) - æ¢å¤æ—¶é—´ç›®æ ‡
å®šä¹‰: ä»æ•…éšœå‘ç”Ÿåˆ°ç³»ç»Ÿæ¢å¤æ­£å¸¸çš„æœ€å¤§å¯æ¥å—æ—¶é—´
ç¤ºä¾‹:
  - Tier 1: RTO < 5åˆ†é’Ÿ   (å…³é”®ä¸šåŠ¡)
  - Tier 2: RTO < 1å°æ—¶   (é‡è¦ä¸šåŠ¡)
  - Tier 3: RTO < 24å°æ—¶  (ä¸€èˆ¬ä¸šåŠ¡)

# RPO (Recovery Point Objective) - æ¢å¤ç‚¹ç›®æ ‡
å®šä¹‰: ç³»ç»Ÿå¯æ¥å—çš„æœ€å¤§æ•°æ®ä¸¢å¤±é‡
ç¤ºä¾‹:
  - Tier 1: RPO = 0       (å®æ—¶åŒæ­¥,é›¶æ•°æ®ä¸¢å¤±)
  - Tier 2: RPO < 15åˆ†é’Ÿ  (5åˆ†é’Ÿä¸€æ¬¡å¢é‡å¤‡ä»½)
  - Tier 3: RPO < 24å°æ—¶  (æ¯æ—¥å…¨é‡å¤‡ä»½)
```

**ç¾éš¾æ¢å¤ç­‰çº§**:

```yaml
# ç¾éš¾æ¢å¤ç­‰çº§åˆ’åˆ†
Tier 0: æ— ç¾å¤‡
  - RTO: æ— é™åˆ¶
  - RPO: æœ€åä¸€æ¬¡å¤‡ä»½
  - æˆæœ¬: æœ€ä½
  - é€‚ç”¨: éå…³é”®ç³»ç»Ÿ

Tier 1: å†·å¤‡ä»½
  - RTO: 24-72å°æ—¶
  - RPO: 24å°æ—¶
  - æ–¹æ¡ˆ: å®šæœŸç¦»çº¿å¤‡ä»½
  - æˆæœ¬: ä½
  - é€‚ç”¨: å†…éƒ¨å·¥å…·

Tier 2: æ¸©å¤‡ä»½
  - RTO: 4-12å°æ—¶
  - RPO: 1-4å°æ—¶
  - æ–¹æ¡ˆ: å®šæœŸåœ¨çº¿å¤‡ä»½ + å¼‚åœ°å­˜å‚¨
  - æˆæœ¬: ä¸­ç­‰
  - é€‚ç”¨: ä¸€èˆ¬ä¸šåŠ¡ç³»ç»Ÿ

Tier 3: çƒ­å¤‡ä»½
  - RTO: 1-4å°æ—¶
  - RPO: 15åˆ†é’Ÿ-1å°æ—¶
  - æ–¹æ¡ˆ: å®æ—¶å¤åˆ¶ + å¼‚åœ°å¤‡æœº
  - æˆæœ¬: è¾ƒé«˜
  - é€‚ç”¨: é‡è¦ä¸šåŠ¡ç³»ç»Ÿ

Tier 4: åŒæ´»(ä¸»å¤‡)
  - RTO: 10-30åˆ†é’Ÿ
  - RPO: å‡ åˆ†é’Ÿ
  - æ–¹æ¡ˆ: ä¸»å¤‡æ•°æ®åº“ + è‡ªåŠ¨æ•…éšœè½¬ç§»
  - æˆæœ¬: é«˜
  - é€‚ç”¨: æ ¸å¿ƒä¸šåŠ¡

Tier 5: å¤šæ´»(å¼‚åœ°å¤šæ´»)
  - RTO: < 5åˆ†é’Ÿ
  - RPO: å‡ ç§’(å‡†å®æ—¶)
  - æ–¹æ¡ˆ: å¤šæ•°æ®ä¸­å¿ƒåŒæ—¶æä¾›æœåŠ¡
  - æˆæœ¬: éå¸¸é«˜
  - é€‚ç”¨: é‡‘èã€ç”µå•†æ ¸å¿ƒ
```

---

### 14.4.2 ç¾éš¾åœºæ™¯æ¼”ç»ƒ

**åœºæ™¯1: å•èŠ‚ç‚¹æ•…éšœ**:

```bash
# ========================================
# æ¼”ç»ƒæ­¥éª¤
# ========================================

# 1. è®°å½•åˆå§‹çŠ¶æ€
$ docker service ps myapp_app
ID      NAME          NODE     DESIRED STATE  CURRENT STATE
abc123  myapp_app.1   worker1  Running        Running 1 hour ago
def456  myapp_app.2   worker2  Running        Running 1 hour ago
ghi789  myapp_app.3   worker3  Running        Running 1 hour ago

# 2. æ¨¡æ‹Ÿworker1èŠ‚ç‚¹æ•…éšœ
$ ssh worker1 "sudo systemctl stop docker"

# 3. è§‚å¯ŸSwarmè‡ªåŠ¨æ¢å¤
$ watch -n 1 'docker service ps myapp_app'
# çº¦30ç§’å,å®¹å™¨è‡ªåŠ¨åœ¨worker4å¯åŠ¨

# 4. éªŒè¯æœåŠ¡å¯ç”¨æ€§
$ for i in {1..100}; do
    curl -s http://app.example.com/health || echo "FAIL"
  done | grep -c FAIL
0  # âœ… æ— å¤±è´¥è¯·æ±‚

# 5. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
$ curl http://app.example.com/api/users/count
{"count": 10000}  # âœ… æ•°æ®æ— ä¸¢å¤±

# 6. æ¢å¤èŠ‚ç‚¹
$ ssh worker1 "sudo systemctl start docker"

# 7. è®°å½•æ¢å¤æ—¶é—´
RTOå®é™…: çº¦35ç§’
RPOå®é™…: 0(æ— æ•°æ®ä¸¢å¤±)
```

**åœºæ™¯2: æ•°æ®åº“ä¸»åº“æ•…éšœ**:

```bash
# ========================================
# æ¼”ç»ƒæ­¥éª¤
# ========================================

# 1. è®°å½•å½“å‰ä¸»åº“
$ curl http://patroni-1:8008/patroni | jq .role
"master"

# 2. è®°å½•æœ€åä¸€ç¬”äº¤æ˜“
$ psql -h db-master -U postgres -d appdb -c \
  "SELECT MAX(id) FROM transactions;"
 max
-------
 100000

# 3. æ¨¡æ‹Ÿä¸»åº“æ•…éšœ
$ docker stop patroni-1

# 4. è§‚å¯Ÿè‡ªåŠ¨æ•…éšœè½¬ç§»
$ watch -n 1 'curl -s http://patroni-2:8008/patroni | jq .role'
# çº¦15ç§’åå˜ä¸º"master"

# 5. éªŒè¯æ•°æ®ä¸€è‡´æ€§
$ psql -h patroni-2 -U postgres -d appdb -c \
  "SELECT MAX(id) FROM transactions;"
 max
-------
 100000  # âœ… æ•°æ®ä¸€è‡´

# 6. éªŒè¯åº”ç”¨ä»å¯å†™å…¥
$ curl -X POST http://app.example.com/api/transactions \
  -d '{"amount": 100}'
{"id": 100001, "status": "success"}  # âœ… å†™å…¥æˆåŠŸ

# 7. æ¢å¤æ—§ä¸»åº“
$ docker start patroni-1

# 8. éªŒè¯æ—§ä¸»åº“é™çº§ä¸ºä»åº“
$ curl -s http://patroni-1:8008/patroni | jq .role
"replica"  # âœ… å·²é™çº§

# 9. è®°å½•æ¢å¤æ—¶é—´
æ£€æµ‹æ—¶é—´: çº¦5ç§’
æ•…éšœè½¬ç§»æ—¶é—´: çº¦15ç§’
RTOå®é™…: çº¦20ç§’
RPOå®é™…: 0(åŒæ­¥å¤åˆ¶,æ— æ•°æ®ä¸¢å¤±)
```

**åœºæ™¯3: å¯ç”¨åŒºæ•…éšœ(AZ-Aå®Œå…¨ä¸å¯ç”¨)**:

```bash
# ========================================
# æ¼”ç»ƒæ­¥éª¤
# ========================================

# 1. è®°å½•AZ-Açš„èµ„æº
$ docker node ls --filter "node.labels.zone=us-east-1a"
ID        HOSTNAME    STATUS  AVAILABILITY
abc123    manager1    Ready   Active
def456    worker1     Ready   Active
ghi789    worker2     Ready   Active

# 2. æ¨¡æ‹ŸAZ-Aå®Œå…¨æ•…éšœ(ç½‘ç»œéš”ç¦»)
$ for node in manager1 worker1 worker2; do
    ssh $node "sudo iptables -A INPUT -j DROP"
    ssh $node "sudo iptables -A OUTPUT -j DROP"
  done

# 3. è§‚å¯ŸManager Leaderåˆ‡æ¢
$ docker node ls
ID        HOSTNAME    STATUS   AVAILABILITY  MANAGER STATUS
abc123    manager1    Unknown  Active        Unreachable
xyz789    manager2    Ready    Active        Leader  # âœ… æ–°Leader
...

# 4. è§‚å¯ŸæœåŠ¡è‡ªåŠ¨é‡æ–°è°ƒåº¦
$ docker service ps myapp_app
# AZ-Açš„å®¹å™¨å…¨éƒ¨è¿ç§»åˆ°AZ-Bå’ŒAZ-C

# 5. éªŒè¯æ•°æ®åº“ä¸»åº“çŠ¶æ€
# å¦‚æœä¸»åº“åœ¨AZ-A,Patroniä¼šè‡ªåŠ¨é€‰ä¸¾AZ-Bæˆ–AZ-Cçš„ä»åº“ä¸ºä¸»åº“

# 6. éªŒè¯æœåŠ¡å¯ç”¨æ€§
$ for i in {1..1000}; do
    curl -s -o /dev/null -w "%{http_code}\n" http://app.example.com/
  done | grep -v 200 | wc -l
5  # âœ… ä»…5ä¸ªè¯·æ±‚å¤±è´¥(0.5%é”™è¯¯ç‡)

# 7. æ¢å¤AZ-A
$ for node in manager1 worker1 worker2; do
    ssh $node "sudo iptables -F"
  done

# 8. è®°å½•æ¢å¤æ—¶é—´
æ£€æµ‹æ—¶é—´: çº¦10ç§’
æœåŠ¡è¿ç§»æ—¶é—´: çº¦60ç§’
RTOå®é™…: çº¦70ç§’
RPOå®é™…: 0(æ•°æ®åº“ä¸»ä»åŒæ­¥)
å—å½±å“è¯·æ±‚: 5/1000 (0.5%)
```

**åœºæ™¯4: å®Œæ•´ç¾éš¾æ¢å¤(ä»å¤‡ä»½æ¢å¤)**:

```bash
# ========================================
# æ¼”ç»ƒæ­¥éª¤
# ========================================

# 1. æ¨¡æ‹Ÿç¾éš¾(åˆ é™¤æ‰€æœ‰æ•°æ®)
$ docker stack rm myapp
$ docker volume rm postgres-data redis-data

# 2. ä»æœ€æ–°å¤‡ä»½æ¢å¤
LATEST_BACKUP=$(ls -t /backup/postgres/full/*.sql.gz | head -1)
echo "Restoring from: $LATEST_BACKUP"

# 3. é‡æ–°éƒ¨ç½²åŸºç¡€è®¾æ–½
$ docker stack deploy -c stack.yml myapp

# 4. ç­‰å¾…æ•°æ®åº“å°±ç»ª
$ docker exec -it $(docker ps -q -f name=myapp_db) \
  pg_isready -U appuser
/var/run/postgresql:5432 - accepting connections

# 5. æ¢å¤æ•°æ®åº“
$ ./restore-postgres.sh "$LATEST_BACKUP"

# 6. æ¢å¤Redisæ•°æ®
$ docker run --rm \
  -v redis-data:/data \
  -v /backup/redis:/backup:ro \
  redis:7-alpine \
  sh -c "redis-cli --rdb /backup/dump.rdb > /data/dump.rdb"

# 7. éªŒè¯æ•°æ®å®Œæ•´æ€§
$ psql -h db-master -U postgres -d appdb -c \
  "SELECT COUNT(*) FROM users;"
 count
--------
 10000  # âœ… æ•°æ®æ¢å¤æˆåŠŸ

# 8. é‡å¯åº”ç”¨æœåŠ¡
$ docker service scale myapp_app=6

# 9. éªŒè¯æœåŠ¡å¯ç”¨
$ curl http://app.example.com/health
{"status": "healthy"}  # âœ… æœåŠ¡æ­£å¸¸

# 10. è®°å½•æ¢å¤æ—¶é—´
åŸºç¡€è®¾æ–½éƒ¨ç½²: çº¦5åˆ†é’Ÿ
æ•°æ®åº“æ¢å¤: çº¦10åˆ†é’Ÿ
æœåŠ¡å¯åŠ¨: çº¦2åˆ†é’Ÿ
RTOå®é™…: çº¦17åˆ†é’Ÿ
RPOå®é™…: çº¦6å°æ—¶(æœ€åä¸€æ¬¡å¤‡ä»½)
```

---

## 14.5 æœ¬ç« æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:

- âœ… **é«˜å¯ç”¨åŸåˆ™**: æ¶ˆé™¤SPOFã€è‡ªåŠ¨æ¢å¤ã€è·¨AZéƒ¨ç½²ã€é™çº§é™æµ
- âœ… **æ•…éšœè½¬ç§»**: Swarmè‡ªåŠ¨è°ƒåº¦ã€Patroniæ•°æ®åº“HAã€Redis Sentinel
- âœ… **å¤‡ä»½ç­–ç•¥**: å…¨é‡+å¢é‡ã€å®šæœŸ+å®æ—¶ã€æœ¬åœ°+å¼‚åœ°ã€è‡ªåŠ¨åŒ–å¤‡ä»½
- âœ… **ç¾éš¾æ¢å¤**: RTO/RPOç›®æ ‡ã€å®šæœŸæ¼”ç»ƒã€è‡ªåŠ¨åŒ–æ¢å¤ã€å¤šçº§å®¹ç¾

**é«˜å¯ç”¨æ£€æŸ¥æ¸…å•**:

```yaml
åº”ç”¨å±‚:
  - [x] æœåŠ¡è‡³å°‘3ä¸ªå‰¯æœ¬
  - [x] è·¨å¯ç”¨åŒºåˆ†å¸ƒ
  - [x] å¥åº·æ£€æŸ¥é…ç½®
  - [x] è‡ªåŠ¨é‡å¯ç­–ç•¥
  - [x] æ»šåŠ¨æ›´æ–°é…ç½®

è´Ÿè½½å‡è¡¡å±‚:
  - [x] HAProxy/Traefiké«˜å¯ç”¨
  - [x] Keepalived VIPæ¼‚ç§»
  - [x] å¥åº·æ£€æŸ¥æ¢é’ˆ
  - [x] ä¼šè¯ä¿æŒ(å¦‚éœ€è¦)

æ•°æ®åº“å±‚:
  - [x] ä¸»ä»å¤åˆ¶/Patronié›†ç¾¤
  - [x] è‡ªåŠ¨æ•…éšœè½¬ç§»
  - [x] æ•°æ®åŒæ­¥å¤åˆ¶
  - [x] å®šæœŸå¤‡ä»½
  - [x] PITRèƒ½åŠ›

å­˜å‚¨å±‚:
  - [x] åˆ†å¸ƒå¼å­˜å‚¨(NFS/Ceph)
  - [x] æ•°æ®å†—ä½™(RAID/å‰¯æœ¬)
  - [x] å¿«ç…§å¤‡ä»½
  - [x] å¼‚åœ°å¤‡ä»½

ç›‘æ§å‘Šè­¦:
  - [x] å…¨é“¾è·¯ç›‘æ§
  - [x] å®æ—¶å‘Šè­¦
  - [x] æ•…éšœè‡ªæ„ˆ
  - [x] äº‹ä»¶æº¯æº
```

**SLAè¾¾æˆç­–ç•¥**:

| ç›®æ ‡SLA | æ¶æ„è¦æ±‚ | å¤‡ä»½ç­–ç•¥ | é¢„è®¡æˆæœ¬ |
|---------|---------|---------|---------|
| 99.9%   | å•AZ,ä¸»ä» | æ¯æ—¥å¤‡ä»½ | åŸºå‡† |
| 99.99%  | è·¨AZ,é›†ç¾¤ | æ¯å°æ—¶å¤‡ä»½ | 2-3x |
| 99.999% | å¤šæ•°æ®ä¸­å¿ƒ | å®æ—¶åŒæ­¥ | 5-10x |

---

ğŸ“ **ä¸‹ä¸€ç« é¢„å‘Š**: Prometheusç›‘æ§éƒ¨ç½²ã€Grafanaå¯è§†åŒ–ã€AlertManagerå‘Šè­¦ã€APMæ€§èƒ½ç›‘æ§

---

*ï¼ˆç¬¬14ç« å®Œæˆ,çº¦2100è¡Œã€‚å·²å®Œæˆ14ç« ,å‰©ä½™5ç« ...ï¼‰*

---

# ç¬¬åäº”ç« : ç›‘æ§å‘Šè­¦ä½“ç³»

> **æœ¬ç« ç›®æ ‡**: æŒæ¡Dockerç”Ÿäº§ç¯å¢ƒå®Œæ•´ç›‘æ§æ–¹æ¡ˆ,åŒ…æ‹¬Prometheus+Grafana+AlertManagerçš„ä¼ä¸šçº§éƒ¨ç½²ã€è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™è®¾è®¡ã€åˆ†å¸ƒå¼è¿½è¸ªç³»ç»Ÿé›†æˆ,ä»¥åŠAPMæ€§èƒ½ç›‘æ§å®è·µã€‚

---

## 15.1 ç›‘æ§ä½“ç³»æ¶æ„è®¾è®¡

### 15.1.1 ç›‘æ§å±‚æ¬¡æ¨¡å‹

**å®Œæ•´ç›‘æ§é‡‘å­—å¡”**:

```yaml
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ä¸šåŠ¡ç›‘æ§ (Business Metrics)          â”‚  â† æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡
â”‚  - è®¢å•æˆåŠŸç‡ã€ç”¨æˆ·æ´»è·ƒåº¦ã€è½¬åŒ–ç‡            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         åº”ç”¨ç›‘æ§ (Application Metrics)       â”‚  â† APMã€æ…¢æŸ¥è¯¢ã€å¼‚å¸¸
â”‚  - QPSã€å»¶è¿Ÿã€é”™è¯¯ç‡ã€è°ƒç”¨é“¾                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         ä¸­é—´ä»¶ç›‘æ§ (Middleware Metrics)      â”‚  â† Redisã€MySQLã€MQ
â”‚  - è¿æ¥æ•°ã€ç¼“å­˜å‘½ä¸­ç‡ã€é˜Ÿåˆ—æ·±åº¦              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         å®¹å™¨ç›‘æ§ (Container Metrics)         â”‚  â† Dockerè¿è¡Œæ—¶
â”‚  - CPUã€å†…å­˜ã€ç½‘ç»œIOã€ç£ç›˜IO                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         ä¸»æœºç›‘æ§ (Host Metrics)              â”‚  â† æ“ä½œç³»ç»Ÿå±‚
â”‚  - ç³»ç»Ÿè´Ÿè½½ã€ç£ç›˜ç©ºé—´ã€ç½‘å¡æµé‡              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç›‘æ§æ•°æ®æµæ¶æ„**:

```yaml
[åº”ç”¨æœåŠ¡] â”€â”€metricsâ”€â”€> [Prometheus Exporter]
    â”‚                          â”‚
    â”‚                          â”œâ”€â”€> [Prometheus Server] â”€â”€> [Grafana]
    â”‚                          â”‚           â”‚
    â”‚                          â”‚           â””â”€â”€> [AlertManager] â”€â”€> [é’‰é’‰/é‚®ä»¶/PagerDuty]
    â”‚                          â”‚
    â”œâ”€â”€tracesâ”€â”€> [Jaeger Collector] â”€â”€> [Jaeger Query UI]
    â”‚
    â””â”€â”€logsâ”€â”€â”€â”€> [Fluentd] â”€â”€> [Elasticsearch] â”€â”€> [Kibana]

[Grafana] â†â”€â”€æŸ¥è¯¢â”€â”€â”
                   â”œâ”€â”€ [Prometheus]
                   â”œâ”€â”€ [Jaeger]
                   â””â”€â”€ [Elasticsearch]
```

### 15.1.2 ç›‘æ§æŒ‡æ ‡åˆ†ç±»(å››å¤§é»„é‡‘ä¿¡å·)

**Google SREå››å¤§é»„é‡‘ä¿¡å·**:

| ä¿¡å·ç±»å‹ | æŒ‡æ ‡åç§° | é‡‡é›†æ–¹å¼ | å‘Šè­¦é˜ˆå€¼ç¤ºä¾‹ |
|---------|---------|---------|-------------|
| **Latency(å»¶è¿Ÿ)** | http_request_duration_seconds | Histogram | P95 > 1s |
| **Traffic(æµé‡)** | http_requests_total | Counter | QPS < 100(æµé‡éª¤é™) |
| **Errors(é”™è¯¯ç‡)** | http_requests_failed_total | Counter | é”™è¯¯ç‡ > 1% |
| **Saturation(é¥±å’Œåº¦)** | container_memory_usage_percent | Gauge | å†…å­˜ > 80% |

**å®é™…æ¡ˆä¾‹: WebæœåŠ¡ç›‘æ§æŒ‡æ ‡**:

```python
# app.py - åº”ç”¨åŸ‹ç‚¹ç¤ºä¾‹
from prometheus_client import Counter, Histogram, Gauge
import time

# 1. Traffic: è¯·æ±‚æ€»æ•°
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# 2. Latency: è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ
http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]  # è‡ªå®šä¹‰åˆ†ä½æ¡¶
)

# 3. Errors: é”™è¯¯è®¡æ•°
http_requests_failed_total = Counter(
    'http_requests_failed_total',
    'Total failed HTTP requests',
    ['method', 'endpoint', 'error_type']
)

# 4. Saturation: å½“å‰å¹¶å‘è¿æ¥æ•°
active_connections = Gauge(
    'active_connections',
    'Number of active connections'
)

# ä¸šåŠ¡æŒ‡æ ‡
order_total = Counter('order_total', 'Total orders', ['status'])
order_amount = Histogram('order_amount', 'Order amount distribution')

@app.route('/api/order', methods=['POST'])
def create_order():
    start_time = time.time()
    active_connections.inc()

    try:
        # ä¸šåŠ¡é€»è¾‘
        order = process_order(request.json)

        # è®°å½•æŒ‡æ ‡
        order_total.labels(status='success').inc()
        order_amount.observe(order['amount'])
        http_requests_total.labels(
            method='POST',
            endpoint='/api/order',
            status='200'
        ).inc()

        return jsonify(order), 200

    except Exception as e:
        http_requests_failed_total.labels(
            method='POST',
            endpoint='/api/order',
            error_type=type(e).__name__
        ).inc()
        http_requests_total.labels(
            method='POST',
            endpoint='/api/order',
            status='500'
        ).inc()
        raise

    finally:
        # è®°å½•å»¶è¿Ÿ
        duration = time.time() - start_time
        http_request_duration_seconds.labels(
            method='POST',
            endpoint='/api/order'
        ).observe(duration)
        active_connections.dec()
```

---

## 15.2 Prometheuså®Œæ•´éƒ¨ç½²

### 15.2.1 Prometheusé«˜å¯ç”¨æ¶æ„

**ç”Ÿäº§ç¯å¢ƒæ¶æ„å›¾**:

```yaml
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Grafana       â”‚
                    â”‚   (è¯»å–æ•°æ®)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚Prometheus1â”‚      â”‚Prometheus2â”‚      â”‚Prometheus3â”‚
    â”‚  (ä¸»)     â”‚      â”‚  (ä¸»)     â”‚      â”‚  (ä¸»)     â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Thanos Sidecar â”‚ â† é•¿æœŸå­˜å‚¨æ–¹æ¡ˆ
                    â”‚  (å¯¹è±¡å­˜å‚¨)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   S3/MinIO      â”‚
                    â”‚  (å†å²æ•°æ®)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹ç‚¹:
- å¤šä¸ªPrometheuså¹¶è¡ŒæŠ“å–(é¿å…å•ç‚¹)
- Thanosæä¾›å…¨å±€è§†å›¾å’Œé•¿æœŸå­˜å‚¨
- æ•°æ®ä¿ç•™ç­–ç•¥: æœ¬åœ°15å¤© + å¯¹è±¡å­˜å‚¨æ°¸ä¹…
```

### 15.2.2 Prometheus Stackéƒ¨ç½²

**ç›®å½•ç»“æ„**:

```bash
monitoring/
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yml          # ä¸»é…ç½®
â”‚   â”œâ”€â”€ rules/
â”‚   â”‚   â”œâ”€â”€ alerts.yml         # å‘Šè­¦è§„åˆ™
â”‚   â”‚   â”œâ”€â”€ recording.yml      # é¢„èšåˆè§„åˆ™
â”‚   â”‚   â””â”€â”€ docker.yml         # Dockerä¸“ç”¨è§„åˆ™
â”‚   â””â”€â”€ targets/
â”‚       â”œâ”€â”€ nodes.yml          # èŠ‚ç‚¹å‘ç°
â”‚       â””â”€â”€ containers.yml     # å®¹å™¨å‘ç°
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/       # æ•°æ®æºé…ç½®
â”‚   â”‚   â””â”€â”€ dashboards/        # çœ‹æ¿é…ç½®
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ docker.json
â”‚       â”œâ”€â”€ postgres.json
â”‚       â””â”€â”€ app.json
â”œâ”€â”€ alertmanager/
â”‚   â””â”€â”€ alertmanager.yml       # å‘Šè­¦è·¯ç”±é…ç½®
â””â”€â”€ stack.yml                  # Docker Composeé…ç½®
```

**1. Prometheusä¸»é…ç½®æ–‡ä»¶**:

```yaml
# prometheus/prometheus.yml
global:
  scrape_interval: 15s          # é»˜è®¤æŠ“å–é—´éš”
  scrape_timeout: 10s
  evaluation_interval: 15s      # è§„åˆ™è¯„ä¼°é—´éš”

  external_labels:
    cluster: 'docker-swarm-prod'
    region: 'us-west-2'
    environment: 'production'

# å‘Šè­¦ç®¡ç†å™¨é…ç½®
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093
      timeout: 10s
      api_version: v2

# åŠ è½½å‘Šè­¦è§„åˆ™
rule_files:
  - '/etc/prometheus/rules/*.yml'

# æŠ“å–é…ç½®
scrape_configs:
  # ========================================
  # 1. Prometheusè‡ªèº«ç›‘æ§
  # ========================================
  - job_name: 'prometheus'
    static_configs:
      - targets:
          - localhost:9090
        labels:
          service: 'prometheus'

  # ========================================
  # 2. Node Exporter(ä¸»æœºç›‘æ§)
  # ========================================
  - job_name: 'node-exporter'
    file_sd_configs:
      - files:
          - '/etc/prometheus/targets/nodes.yml'
        refresh_interval: 30s
    relabel_configs:
      # ä»__meta_æ ‡ç­¾æå–å®ä¾‹å
      - source_labels: [__meta_instance]
        target_label: instance
      - source_labels: [__meta_datacenter]
        target_label: datacenter

  # ========================================
  # 3. cAdvisor(å®¹å™¨ç›‘æ§)
  # ========================================
  - job_name: 'cadvisor'
    dns_sd_configs:
      - names:
          - 'tasks.cadvisor'  # SwarmæœåŠ¡å‘ç°
        type: 'A'
        port: 8080
        refresh_interval: 30s
    relabel_configs:
      # ä»…ä¿ç•™Dockerå®¹å™¨æŒ‡æ ‡
      - source_labels: [container_label_com_docker_swarm_service_name]
        action: keep
        regex: .+
      # æ·»åŠ æœåŠ¡åæ ‡ç­¾
      - source_labels: [container_label_com_docker_swarm_service_name]
        target_label: service
      - source_labels: [container_label_com_docker_swarm_task_name]
        target_label: task

  # ========================================
  # 4. Docker Engine Metrics
  # ========================================
  - job_name: 'docker-engine'
    static_configs:
      - targets:
          - 'node1:9323'
          - 'node2:9323'
          - 'node3:9323'
    metrics_path: '/metrics'

  # ========================================
  # 5. PostgreSQL Exporter
  # ========================================
  - job_name: 'postgres'
    static_configs:
      - targets:
          - 'postgres-exporter:9187'
        labels:
          database: 'appdb'
          role: 'master'

  # ========================================
  # 6. Redis Exporter
  # ========================================
  - job_name: 'redis'
    static_configs:
      - targets:
          - 'redis-exporter:9121'
        labels:
          cache: 'main'

  # ========================================
  # 7. åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡
  # ========================================
  - job_name: 'app-metrics'
    dns_sd_configs:
      - names:
          - 'tasks.myapp'
        type: 'A'
        port: 8000
        refresh_interval: 15s
    metrics_path: '/metrics'
    relabel_configs:
      - source_labels: [__meta_dockerswarm_service_label_app]
        target_label: app
      - source_labels: [__meta_dockerswarm_service_label_version]
        target_label: version

  # ========================================
  # 8. Blackbox Exporter(é»‘ç›’æ¢æµ‹)
  # ========================================
  - job_name: 'blackbox-http'
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
          - https://api.example.com/health
          - https://app.example.com
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115

  # ========================================
  # 9. NGINX Exporter
  # ========================================
  - job_name: 'nginx'
    static_configs:
      - targets:
          - 'nginx-exporter:9113'
        labels:
          proxy: 'main'

# å­˜å‚¨é…ç½®
storage:
  tsdb:
    path: /prometheus
    retention:
      time: 15d              # æœ¬åœ°ä¿ç•™15å¤©
      size: 50GB             # æœ€å¤§ç£ç›˜ç”¨é‡
    wal_compression: true    # WALå‹ç¼©(èŠ‚çœ30%ç©ºé—´)

# è¿œç¨‹å†™å…¥(å¯é€‰,ç”¨äºé•¿æœŸå­˜å‚¨)
remote_write:
  - url: http://thanos-receiver:19291/api/v1/receive
    queue_config:
      max_samples_per_send: 10000
      batch_send_deadline: 10s
      max_retries: 3
```

**2. èŠ‚ç‚¹å‘ç°é…ç½®**:

```yaml
# prometheus/targets/nodes.yml
- targets:
    - '192.168.1.10:9100'
  labels:
    instance: 'swarm-manager-1'
    datacenter: 'dc1'
    zone: 'us-west-2a'

- targets:
    - '192.168.1.11:9100'
  labels:
    instance: 'swarm-manager-2'
    datacenter: 'dc1'
    zone: 'us-west-2b'

- targets:
    - '192.168.1.12:9100'
  labels:
    instance: 'swarm-manager-3'
    datacenter: 'dc1'
    zone: 'us-west-2c'

- targets:
    - '192.168.1.21:9100'
    - '192.168.1.22:9100'
    - '192.168.1.23:9100'
  labels:
    datacenter: 'dc1'
    role: 'worker'
```

**3. Docker Compose Stacké…ç½®**:

```yaml
# monitoring/stack.yml
version: '3.8'

services:
  # ========================================
  # Prometheus Server
  # ========================================
  prometheus:
    image: prom/prometheus:v2.47.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=50GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'              # å…è®¸çƒ­é‡è½½
      - '--web.enable-admin-api'              # å¯ç”¨ç®¡ç†API
      - '--query.max-concurrency=50'          # æœ€å¤§å¹¶å‘æŸ¥è¯¢
      - '--query.timeout=2m'                  # æŸ¥è¯¢è¶…æ—¶
    volumes:
      - prometheus-data:/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/rules:/etc/prometheus/rules:ro
      - ./prometheus/targets:/etc/prometheus/targets:ro
    networks:
      - monitoring
    ports:
      - "9090:9090"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ========================================
  # AlertManager
  # ========================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--cluster.advertise-address=0.0.0.0:9093'
      - '--web.external-url=http://alertmanager.example.com'
    volumes:
      - alertmanager-data:/alertmanager
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    networks:
      - monitoring
    ports:
      - "9093:9093"
    deploy:
      mode: replicated
      replicas: 3  # é«˜å¯ç”¨éƒ¨ç½²
      placement:
        max_replicas_per_node: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # ========================================
  # Node Exporter(æ¯ä¸ªèŠ‚ç‚¹)
  # ========================================
  node-exporter:
    image: prom/node-exporter:v1.6.1
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netclass.ignored-devices=^(veth.*|br-.*|docker.*)$$'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - monitoring
    ports:
      - "9100:9100"
    deploy:
      mode: global  # æ¯ä¸ªèŠ‚ç‚¹ä¸€ä¸ªå®ä¾‹
      resources:
        limits:
          cpus: '0.2'
          memory: 128M

  # ========================================
  # cAdvisor(å®¹å™¨ç›‘æ§)
  # ========================================
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    command:
      - '--docker_only=true'
      - '--housekeeping_interval=30s'
      - '--disable_metrics=disk,network,tcp,udp,percpu,sched,process'
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /dev/disk:/dev/disk:ro
    networks:
      - monitoring
    ports:
      - "8080:8080"
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.3'
          memory: 256M

  # ========================================
  # Postgres Exporter
  # ========================================
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.13.2
    environment:
      DATA_SOURCE_NAME: "postgresql://exporter:${POSTGRES_EXPORTER_PASSWORD}@postgres:5432/appdb?sslmode=disable"
    networks:
      - monitoring
      - backend
    deploy:
      mode: replicated
      replicas: 1

  # ========================================
  # Redis Exporter
  # ========================================
  redis-exporter:
    image: oliver006/redis_exporter:v1.52.0
    environment:
      REDIS_ADDR: "redis:6379"
      REDIS_PASSWORD: "${REDIS_PASSWORD}"
    networks:
      - monitoring
      - backend
    deploy:
      mode: replicated
      replicas: 1

  # ========================================
  # Blackbox Exporter(æ¢æµ‹)
  # ========================================
  blackbox-exporter:
    image: prom/blackbox-exporter:v0.24.0
    volumes:
      - ./blackbox/blackbox.yml:/etc/blackbox/blackbox.yml:ro
    networks:
      - monitoring
    ports:
      - "9115:9115"
    deploy:
      mode: replicated
      replicas: 2

networks:
  monitoring:
    driver: overlay
    attachable: true
  backend:
    external: true

volumes:
  prometheus-data:
  alertmanager-data:
```

**4. å¯ç”¨Docker Engine Metrics**:

```bash
# /etc/docker/daemon.json - æ‰€æœ‰èŠ‚ç‚¹
{
  "metrics-addr": "0.0.0.0:9323",
  "experimental": true
}

# é‡å¯Docker
$ sudo systemctl restart docker

# éªŒè¯
$ curl http://localhost:9323/metrics | grep engine_daemon
# engine_daemon_container_actions_seconds_count{action="start"} 1234
```

### 15.2.3 å‘Šè­¦è§„åˆ™é…ç½®

**1. Dockerå®¹å™¨å‘Šè­¦è§„åˆ™**:

```yaml
# prometheus/rules/docker.yml
groups:
  - name: docker_containers
    interval: 30s
    rules:
      # ========================================
      # å®¹å™¨çŠ¶æ€å‘Šè­¦
      # ========================================
      - alert: ContainerDown
        expr: |
          up{job="cadvisor"} == 0
        for: 1m
        labels:
          severity: critical
          category: availability
        annotations:
          summary: "å®¹å™¨ {{ $labels.instance }} å·²ä¸‹çº¿"
          description: "å®¹å™¨ {{ $labels.container_label_com_docker_swarm_service_name }} åœ¨èŠ‚ç‚¹ {{ $labels.instance }} ä¸Šæ— æ³•è®¿é—®è¶…è¿‡1åˆ†é’Ÿ"

      - alert: ContainerRestarting
        expr: |
          rate(container_last_seen{name!=""}[5m]) > 0
        for: 5m
        labels:
          severity: warning
          category: stability
        annotations:
          summary: "å®¹å™¨é¢‘ç¹é‡å¯"
          description: "å®¹å™¨ {{ $labels.name }} åœ¨è¿‡å»5åˆ†é’Ÿå†…é‡å¯äº† {{ $value | humanize }} æ¬¡"

      # ========================================
      # CPUå‘Šè­¦
      # ========================================
      - alert: ContainerCpuUsageHigh
        expr: |
          (sum(rate(container_cpu_usage_seconds_total{name!=""}[5m])) by (name, instance)
          /
          sum(container_spec_cpu_quota{name!=""}/container_spec_cpu_period{name!=""}) by (name, instance))
          * 100 > 80
        for: 10m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "å®¹å™¨CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®¹å™¨ {{ $labels.name }} åœ¨èŠ‚ç‚¹ {{ $labels.instance }} ä¸ŠCPUä½¿ç”¨ç‡ä¸º {{ $value | humanizePercentage }},å·²æŒç»­10åˆ†é’Ÿ"

      - alert: ContainerCpuThrottling
        expr: |
          rate(container_cpu_cfs_throttled_seconds_total{name!=""}[5m]) > 0.3
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "å®¹å™¨CPUè¢«é™æµ"
          description: "å®¹å™¨ {{ $labels.name }} CPUè¢«é™æµæ—¶é—´å æ¯” {{ $value | humanizePercentage }},å»ºè®®å¢åŠ CPUé…é¢"

      # ========================================
      # å†…å­˜å‘Šè­¦
      # ========================================
      - alert: ContainerMemoryUsageHigh
        expr: |
          (container_memory_usage_bytes{name!=""}
          /
          container_spec_memory_limit_bytes{name!=""})
          * 100 > 85
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "å®¹å™¨å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®¹å™¨ {{ $labels.name }} å†…å­˜ä½¿ç”¨ç‡ä¸º {{ $value | humanizePercentage }}"

      - alert: ContainerMemoryOOM
        expr: |
          container_memory_failcnt{name!=""} > 0
        for: 1m
        labels:
          severity: critical
          category: availability
        annotations:
          summary: "å®¹å™¨å‘ç”ŸOOM"
          description: "å®¹å™¨ {{ $labels.name }} å‘ç”Ÿå†…å­˜æº¢å‡º,failcnt={{ $value }}"

      # ========================================
      # ç½‘ç»œå‘Šè­¦
      # ========================================
      - alert: ContainerNetworkReceiveErrors
        expr: |
          rate(container_network_receive_errors_total{name!=""}[5m]) > 100
        for: 5m
        labels:
          severity: warning
          category: network
        annotations:
          summary: "å®¹å™¨ç½‘ç»œæ¥æ”¶é”™è¯¯ç‡é«˜"
          description: "å®¹å™¨ {{ $labels.name }} ç½‘ç»œæ¥æ”¶é”™è¯¯ç‡ {{ $value | humanize }} errors/s"

      # ========================================
      # ç£ç›˜å‘Šè­¦
      # ========================================
      - alert: ContainerDiskUsageHigh
        expr: |
          (container_fs_usage_bytes{name!=""}
          /
          container_fs_limit_bytes{name!=""})
          * 100 > 85
        for: 10m
        labels:
          severity: warning
          category: storage
        annotations:
          summary: "å®¹å™¨ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®¹å™¨ {{ $labels.name }} ç£ç›˜ä½¿ç”¨ç‡ {{ $value | humanizePercentage }}"

  # ========================================
  # Swarmé›†ç¾¤å‘Šè­¦
  # ========================================
  - name: docker_swarm
    interval: 60s
    rules:
      - alert: SwarmNodeDown
        expr: |
          swarm_node_status{state="ready"} == 0
        for: 2m
        labels:
          severity: critical
          category: infrastructure
        annotations:
          summary: "SwarmèŠ‚ç‚¹ä¸‹çº¿"
          description: "èŠ‚ç‚¹ {{ $labels.node_name }} çŠ¶æ€å¼‚å¸¸"

      - alert: SwarmManagerQuorumLost
        expr: |
          count(swarm_manager_is_leader) < 2
        for: 1m
        labels:
          severity: critical
          category: infrastructure
        annotations:
          summary: "Swarm Managerä»²è£ä¸¢å¤±"
          description: "å½“å‰ä»…æœ‰ {{ $value }} ä¸ªManagerèŠ‚ç‚¹,é›†ç¾¤æ— æ³•æ­£å¸¸å·¥ä½œ"

      - alert: SwarmServiceReplicasDown
        expr: |
          (swarm_service_replicas_desired - swarm_service_replicas_running) > 0
        for: 5m
        labels:
          severity: warning
          category: availability
        annotations:
          summary: "æœåŠ¡å‰¯æœ¬æ•°ä¸è¶³"
          description: "æœåŠ¡ {{ $labels.service_name }} æœŸæœ›å‰¯æœ¬æ•° {{ $labels.desired }},å®é™…è¿è¡Œ {{ $labels.running }}"
```

**2. ä¸»æœºç›‘æ§å‘Šè­¦è§„åˆ™**:

```yaml
# prometheus/rules/alerts.yml
groups:
  - name: host_alerts
    interval: 30s
    rules:
      # CPUå‘Šè­¦
      - alert: HostCpuUsageHigh
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ä¸»æœºCPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "ä¸»æœº {{ $labels.instance }} CPUä½¿ç”¨ç‡ {{ $value | humanizePercentage }}"

      # å†…å­˜å‘Šè­¦
      - alert: HostMemoryUsageHigh
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ä¸»æœºå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "ä¸»æœº {{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡ {{ $value | humanizePercentage }}"

      # ç£ç›˜ç©ºé—´å‘Šè­¦
      - alert: HostDiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes{fstype=~"ext4|xfs"}
          /
          node_filesystem_size_bytes{fstype=~"ext4|xfs"})
          * 100 < 15
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ä¸»æœºç£ç›˜ç©ºé—´ä¸è¶³"
          description: "ä¸»æœº {{ $labels.instance }} æŒ‚è½½ç‚¹ {{ $labels.mountpoint }} å‰©ä½™ç©ºé—´ä»… {{ $value | humanizePercentage }}"

      # ç£ç›˜IOå‘Šè­¦
      - alert: HostDiskIOUtilizationHigh
        expr: |
          rate(node_disk_io_time_seconds_total[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ä¸»æœºç£ç›˜IOåˆ©ç”¨ç‡é«˜"
          description: "ä¸»æœº {{ $labels.instance }} ç£ç›˜ {{ $labels.device }} IOåˆ©ç”¨ç‡ {{ $value | humanizePercentage }}"

      # ç½‘ç»œå¸¦å®½å‘Šè­¦(å‡è®¾åƒå…†ç½‘å¡)
      - alert: HostNetworkBandwidthSaturated
        expr: |
          rate(node_network_receive_bytes_total{device!~"lo|veth.*|br-.*"}[5m]) * 8 / 1000000000 > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ä¸»æœºç½‘ç»œå¸¦å®½æ¥è¿‘é¥±å’Œ"
          description: "ä¸»æœº {{ $labels.instance }} ç½‘å¡ {{ $labels.device }} æ¥æ”¶å¸¦å®½ {{ $value | humanize }} Gbps"
```

**3. åº”ç”¨å±‚å‘Šè­¦è§„åˆ™**:

```yaml
# prometheus/rules/app.yml
groups:
  - name: application_alerts
    interval: 15s
    rules:
      # ========================================
      # å››å¤§é»„é‡‘ä¿¡å·
      # ========================================

      # 1. Latency: å»¶è¿Ÿå‘Šè­¦
      - alert: ApiLatencyHigh
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
          ) > 1
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "APIå»¶è¿Ÿè¿‡é«˜"
          description: "æ¥å£ {{ $labels.endpoint }} P95å»¶è¿Ÿä¸º {{ $value | humanizeDuration }}"

      # 2. Traffic: æµé‡å¼‚å¸¸
      - alert: ApiTrafficDrop
        expr: |
          (rate(http_requests_total[5m])
          /
          rate(http_requests_total[5m] offset 1h)) < 0.5
        for: 10m
        labels:
          severity: warning
          category: business
        annotations:
          summary: "APIæµé‡éª¤é™"
          description: "æ¥å£ {{ $labels.endpoint }} æµé‡ç›¸æ¯”1å°æ—¶å‰ä¸‹é™ {{ $value | humanizePercentage }}"

      # 3. Errors: é”™è¯¯ç‡å‘Šè­¦
      - alert: ApiErrorRateHigh
        expr: |
          (sum(rate(http_requests_total{status=~"5.."}[5m])) by (endpoint)
          /
          sum(rate(http_requests_total[5m])) by (endpoint))
          * 100 > 1
        for: 5m
        labels:
          severity: critical
          category: availability
        annotations:
          summary: "APIé”™è¯¯ç‡è¿‡é«˜"
          description: "æ¥å£ {{ $labels.endpoint }} 5xxé”™è¯¯ç‡ {{ $value | humanizePercentage }}"

      # 4. Saturation: é¥±å’Œåº¦å‘Šè­¦
      - alert: ApiConcurrencyHigh
        expr: |
          active_connections > 1000
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "APIå¹¶å‘è¿æ¥æ•°è¿‡é«˜"
          description: "å½“å‰å¹¶å‘è¿æ¥æ•° {{ $value }},æ¥è¿‘ç³»ç»Ÿä¸Šé™"

      # ========================================
      # æ•°æ®åº“å‘Šè­¦
      # ========================================
      - alert: PostgresConnectionPoolExhausted
        expr: |
          (pg_stat_database_numbackends / pg_settings_max_connections) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQLè¿æ¥æ± æ¥è¿‘è€—å°½"
          description: "æ•°æ®åº“ {{ $labels.datname }} è¿æ¥ä½¿ç”¨ç‡ {{ $value | humanizePercentage }}"

      - alert: PostgresSlowQueries
        expr: |
          rate(pg_stat_statements_mean_time_seconds[5m]) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQLæ…¢æŸ¥è¯¢å¢å¤š"
          description: "å¹³å‡æŸ¥è¯¢æ—¶é—´ {{ $value | humanizeDuration }}"

      # ========================================
      # Rediså‘Šè­¦
      # ========================================
      - alert: RedisCacheHitRateLow
        expr: |
          (redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total)) * 100 < 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Redisç¼“å­˜å‘½ä¸­ç‡ä½"
          description: "å½“å‰å‘½ä¸­ç‡ {{ $value | humanizePercentage }},å»ºè®®æ£€æŸ¥ç¼“å­˜ç­–ç•¥"

      - alert: RedisMemoryUsageHigh
        expr: |
          (redis_memory_used_bytes / redis_memory_max_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Rediså†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡ {{ $value | humanizePercentage }}"
```

**4. Recording Rules(é¢„èšåˆè§„åˆ™)**:

```yaml
# prometheus/rules/recording.yml
groups:
  - name: recording_rules
    interval: 30s
    rules:
      # é¢„èšåˆå¸¸ç”¨æŸ¥è¯¢(æé«˜æŸ¥è¯¢æ€§èƒ½)

      # å®¹å™¨CPUä½¿ç”¨ç‡(æŒ‰æœåŠ¡èšåˆ)
      - record: service:container_cpu_usage:rate5m
        expr: |
          sum(rate(container_cpu_usage_seconds_total{name!=""}[5m])) by (
            container_label_com_docker_swarm_service_name
          )

      # å®¹å™¨å†…å­˜ä½¿ç”¨ç‡(æŒ‰æœåŠ¡èšåˆ)
      - record: service:container_memory_usage:percent
        expr: |
          sum(container_memory_usage_bytes{name!=""}) by (
            container_label_com_docker_swarm_service_name
          )
          /
          sum(container_spec_memory_limit_bytes{name!=""}) by (
            container_label_com_docker_swarm_service_name
          )
          * 100

      # APIè¯·æ±‚QPS(æŒ‰endpointèšåˆ)
      - record: endpoint:http_requests:rate1m
        expr: |
          sum(rate(http_requests_total[1m])) by (endpoint, method)

      # API P95å»¶è¿Ÿ(æŒ‰endpointèšåˆ)
      - record: endpoint:http_request_duration:p95
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
          )

      # APIé”™è¯¯ç‡(æŒ‰endpointèšåˆ)
      - record: endpoint:http_errors:rate5m
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (endpoint)
          /
          sum(rate(http_requests_total[5m])) by (endpoint)
```

### 15.2.4 éƒ¨ç½²ä¸éªŒè¯

```bash
# ========================================
# 1. å‡†å¤‡é…ç½®æ–‡ä»¶
# ========================================
$ cd monitoring

# éªŒè¯Prometheusé…ç½®è¯­æ³•
$ docker run --rm \
  -v $(pwd)/prometheus:/etc/prometheus \
  prom/prometheus:v2.47.0 \
  promtool check config /etc/prometheus/prometheus.yml
# âœ… SUCCESS: /etc/prometheus/prometheus.yml is valid prometheus config file syntax

# éªŒè¯å‘Šè­¦è§„åˆ™è¯­æ³•
$ docker run --rm \
  -v $(pwd)/prometheus:/etc/prometheus \
  prom/prometheus:v2.47.0 \
  promtool check rules /etc/prometheus/rules/*.yml
# âœ… SUCCESS: 45 rules found

# ========================================
# 2. éƒ¨ç½²Stack
# ========================================
$ docker stack deploy -c stack.yml monitoring

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
$ docker stack services monitoring
ID         NAME                      MODE      REPLICAS   IMAGE
abc123     monitoring_prometheus     replicated   1/1     prom/prometheus:v2.47.0
def456     monitoring_alertmanager   replicated   3/3     prom/alertmanager:v0.26.0
ghi789     monitoring_node-exporter  global       6/6     prom/node-exporter:v1.6.1
jkl012     monitoring_cadvisor       global       6/6     gcr.io/cadvisor/cadvisor:v0.47.0

# ========================================
# 3. è®¿é—®Prometheus UI
# ========================================
$ open http://prometheus.example.com:9090

# éªŒè¯TargetçŠ¶æ€
# è®¿é—®: http://prometheus.example.com:9090/targets
# ç¡®è®¤æ‰€æœ‰TargetçŠ¶æ€ä¸ºUP

# ========================================
# 4. æµ‹è¯•PromQLæŸ¥è¯¢
# ========================================

# æŸ¥è¯¢å®¹å™¨CPUä½¿ç”¨ç‡TOP 10
$ curl -G 'http://localhost:9090/api/v1/query' \
  --data-urlencode 'query=topk(10, service:container_cpu_usage:rate5m)'

# æŸ¥è¯¢APIé”™è¯¯ç‡
$ curl -G 'http://localhost:9090/api/v1/query' \
  --data-urlencode 'query=endpoint:http_errors:rate5m > 0.01'

# ========================================
# 5. çƒ­é‡è½½é…ç½®(æ— éœ€é‡å¯)
# ========================================
$ curl -X POST http://localhost:9090/-/reload
# âœ… é…ç½®å·²é‡è½½

# ========================================
# 6. éªŒè¯å‘Šè­¦è§„åˆ™
# ========================================
$ curl http://localhost:9090/api/v1/rules | jq '.data.groups[] | .name'
"docker_containers"
"docker_swarm"
"host_alerts"
"application_alerts"

# æŸ¥çœ‹å½“å‰è§¦å‘çš„å‘Šè­¦
$ curl http://localhost:9090/api/v1/alerts | jq '.data.alerts[] | select(.state=="firing")'
```

---

## 15.3 Grafanaå¯è§†åŒ–çœ‹æ¿

### 15.3.1 Grafanaéƒ¨ç½²ä¸é…ç½®

**1. Grafana Stacké…ç½®**:

```yaml
# monitoring/stack.yml (æ·»åŠ åˆ°ç°æœ‰é…ç½®)
services:
  grafana:
    image: grafana/grafana:10.1.0
    environment:
      # åŸºç¡€é…ç½®
      GF_SERVER_ROOT_URL: "http://grafana.example.com"
      GF_SERVER_DOMAIN: "grafana.example.com"

      # å®‰å…¨é…ç½®
      GF_SECURITY_ADMIN_USER: "admin"
      GF_SECURITY_ADMIN_PASSWORD__FILE: /run/secrets/grafana_admin_password
      GF_SECURITY_SECRET_KEY__FILE: /run/secrets/grafana_secret_key

      # æ•°æ®åº“é…ç½®(ä½¿ç”¨PostgreSQLè€Œéé»˜è®¤SQLite)
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: postgres:5432
      GF_DATABASE_NAME: grafana
      GF_DATABASE_USER: grafana
      GF_DATABASE_PASSWORD__FILE: /run/secrets/grafana_db_password

      # ç”¨æˆ·è®¤è¯
      GF_AUTH_ANONYMOUS_ENABLED: "false"
      GF_AUTH_BASIC_ENABLED: "true"
      GF_AUTH_DISABLE_LOGIN_FORM: "false"

      # SMTPé‚®ä»¶å‘Šè­¦(å¯é€‰)
      GF_SMTP_ENABLED: "true"
      GF_SMTP_HOST: "smtp.example.com:587"
      GF_SMTP_USER: "alerts@example.com"
      GF_SMTP_PASSWORD__FILE: /run/secrets/smtp_password
      GF_SMTP_FROM_ADDRESS: "alerts@example.com"
      GF_SMTP_FROM_NAME: "Grafana Alerts"

      # æ€§èƒ½ä¼˜åŒ–
      GF_DATAPROXY_TIMEOUT: "300"
      GF_DATAPROXY_MAX_IDLE_CONNS: "100"

    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    secrets:
      - grafana_admin_password
      - grafana_db_password
      - grafana_secret_key
      - smtp_password
    networks:
      - monitoring
      - backend
    ports:
      - "3000:3000"
    deploy:
      mode: replicated
      replicas: 2  # é«˜å¯ç”¨éƒ¨ç½²
      placement:
        max_replicas_per_node: 1
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

secrets:
  grafana_admin_password:
    external: true
  grafana_db_password:
    external: true
  grafana_secret_key:
    external: true
  smtp_password:
    external: true

volumes:
  grafana-data:
```

**2. åˆ›å»ºSecrets**:

```bash
# åˆ›å»ºGrafanaç®¡ç†å‘˜å¯†ç 
$ echo "YourStrongPassword123!" | docker secret create grafana_admin_password -

# åˆ›å»ºæ•°æ®åº“å¯†ç 
$ echo "GrafanaDBPass456" | docker secret create grafana_db_password -

# åˆ›å»ºå¯†é’¥(ç”¨äºCookieåŠ å¯†)
$ openssl rand -base64 32 | docker secret create grafana_secret_key -

# åˆ›å»ºSMTPå¯†ç 
$ echo "smtp-password" | docker secret create smtp_password -
```

**3. æ•°æ®æºè‡ªåŠ¨é…ç½®**:

```yaml
# grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  # Prometheusä¸»æ•°æ®æº
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false
    jsonData:
      timeInterval: "30s"
      queryTimeout: "300s"
      httpMethod: POST  # ä½¿ç”¨POSTå‘é€é•¿æŸ¥è¯¢
      customQueryParameters: ""
      manageAlerts: true
      prometheusType: Prometheus
      prometheusVersion: 2.47.0
      cacheLevel: 'High'
      incrementalQuerying: true
      incrementalQueryOverlapWindow: "10m"
      disableRecordingRules: false

  # Alertmanageræ•°æ®æº
  - name: Alertmanager
    type: alertmanager
    access: proxy
    url: http://alertmanager:9093
    editable: false
    jsonData:
      implementation: prometheus
```

**4. çœ‹æ¿è‡ªåŠ¨åŠ è½½é…ç½®**:

```yaml
# grafana/provisioning/dashboards/default.yml
apiVersion: 1

providers:
  - name: 'Default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 30
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards
      foldersFromFilesStructure: true
```

### 15.3.2 ç”Ÿäº§çº§Dashboardè®¾è®¡

**1. Docker Swarmé›†ç¾¤ç›‘æ§é¢æ¿**:

```json
{
  "dashboard": {
    "title": "Docker Swarm Cluster Overview",
    "tags": ["docker", "swarm", "infrastructure"],
    "timezone": "browser",
    "refresh": "30s",
    "time": {
      "from": "now-6h",
      "to": "now"
    },
    "panels": [
      {
        "id": 1,
        "title": "é›†ç¾¤å¥åº·çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "count(swarm_node_status{state=\"ready\"})",
            "legendFormat": "åœ¨çº¿èŠ‚ç‚¹"
          },
          {
            "expr": "count(swarm_node_status) - count(swarm_node_status{state=\"ready\"})",
            "legendFormat": "ç¦»çº¿èŠ‚ç‚¹"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": 0, "color": "red"},
                {"value": 3, "color": "green"}
              ]
            },
            "unit": "short"
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "æœåŠ¡è¿è¡ŒçŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "count(swarm_service_replicas_running == swarm_service_replicas_desired)",
            "legendFormat": "å¥åº·æœåŠ¡"
          },
          {
            "expr": "count(swarm_service_replicas_running != swarm_service_replicas_desired)",
            "legendFormat": "å¼‚å¸¸æœåŠ¡"
          }
        ],
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "é›†ç¾¤CPUä½¿ç”¨ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "å¹³å‡CPUä½¿ç”¨ç‡"
          },
          {
            "expr": "100 - (rate(node_cpu_seconds_total{mode=\"idle\"}[5m]) * 100)",
            "legendFormat": "{{ instance }}"
          }
        ],
        "yaxes": [
          {"format": "percent", "max": 100, "min": 0}
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4}
      },
      {
        "id": 4,
        "title": "é›†ç¾¤å†…å­˜ä½¿ç”¨ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "legendFormat": "{{ instance }}"
          }
        ],
        "yaxes": [
          {"format": "percent", "max": 100, "min": 0}
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4}
      },
      {
        "id": 5,
        "title": "å®¹å™¨è¿è¡Œæ•°é‡",
        "type": "graph",
        "targets": [
          {
            "expr": "count(container_last_seen{name!=\"\"}) by (instance)",
            "legendFormat": "{{ instance }}"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 12}
      },
      {
        "id": 6,
        "title": "ç½‘ç»œæµé‡",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(container_network_receive_bytes_total[5m])) by (instance)",
            "legendFormat": "{{ instance }} æ¥æ”¶"
          },
          {
            "expr": "sum(rate(container_network_transmit_bytes_total[5m])) by (instance) * -1",
            "legendFormat": "{{ instance }} å‘é€"
          }
        ],
        "yaxes": [
          {"format": "Bps"}
        ],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 12}
      },
      {
        "id": 7,
        "title": "ç£ç›˜IO",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(node_disk_read_bytes_total[5m])) by (instance)",
            "legendFormat": "{{ instance }} è¯»"
          },
          {
            "expr": "sum(rate(node_disk_written_bytes_total[5m])) by (instance) * -1",
            "legendFormat": "{{ instance }} å†™"
          }
        ],
        "yaxes": [
          {"format": "Bps"}
        ],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 12}
      }
    ]
  }
}
```

**å°†ä¸Šè¿°JSONä¿å­˜ä¸º**: `grafana/dashboards/docker-swarm.json`

**2. åº”ç”¨æ€§èƒ½ç›‘æ§é¢æ¿(APM)**:

```json
{
  "dashboard": {
    "title": "Application Performance Monitoring",
    "tags": ["apm", "application", "performance"],
    "panels": [
      {
        "id": 1,
        "title": "è¯·æ±‚é€Ÿç‡(QPS)",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[1m])) by (endpoint)",
            "legendFormat": "{{ endpoint }}"
          }
        ],
        "yaxes": [{"format": "reqps"}],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum(rate(http_request_duration_seconds_bucket[5m])) by (le)",
            "format": "heatmap",
            "legendFormat": "{{ le }}"
          }
        ],
        "dataFormat": "tsbuckets",
        "yAxis": {"format": "s"},
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "é”™è¯¯ç‡(%)",
        "type": "graph",
        "targets": [
          {
            "expr": "(sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (endpoint) / sum(rate(http_requests_total[5m])) by (endpoint)) * 100",
            "legendFormat": "{{ endpoint }}"
          }
        ],
        "alert": {
          "conditions": [
            {
              "evaluator": {"params": [1], "type": "gt"},
              "operator": {"type": "and"},
              "query": {"params": ["A", "5m", "now"]},
              "reducer": {"params": [], "type": "avg"},
              "type": "query"
            }
          ],
          "executionErrorState": "alerting",
          "frequency": "60s",
          "handler": 1,
          "name": "APIé”™è¯¯ç‡å‘Šè­¦",
          "noDataState": "no_data",
          "notifications": [
            {"uid": "alertmanager"}
          ]
        },
        "yaxes": [{"format": "percent"}],
        "gridPos": {"h": 6, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 4,
        "title": "P95/P99å»¶è¿Ÿ",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint))",
            "legendFormat": "P95 - {{ endpoint }}"
          },
          {
            "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint))",
            "legendFormat": "P99 - {{ endpoint }}"
          }
        ],
        "yaxes": [{"format": "s"}],
        "gridPos": {"h": 6, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 5,
        "title": "å¹¶å‘è¿æ¥æ•°",
        "type": "graph",
        "targets": [
          {
            "expr": "active_connections",
            "legendFormat": "å½“å‰è¿æ¥"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 14}
      },
      {
        "id": 6,
        "title": "æ•°æ®åº“è¿æ¥æ± ",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_database_numbackends",
            "legendFormat": "{{ datname }}"
          },
          {
            "expr": "pg_settings_max_connections",
            "legendFormat": "æœ€å¤§è¿æ¥æ•°"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 14}
      },
      {
        "id": 7,
        "title": "Rediså‘½ä¸­ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "(redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total)) * 100"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "steps": [
                {"value": 0, "color": "red"},
                {"value": 80, "color": "yellow"},
                {"value": 95, "color": "green"}
              ]
            },
            "unit": "percent"
          }
        },
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 14}
      }
    ]
  }
}
```

**ä¿å­˜ä¸º**: `grafana/dashboards/apm.json`

**3. å¯¼å…¥ç¤¾åŒºä¼˜è´¨Dashboard**:

```bash
# æ¨èçš„ç¤¾åŒºDashboard IDåˆ—è¡¨:

# Docker & Containerç›‘æ§
- 893   # Docker & System Monitoring
- 179   # Docker Prometheus Monitoring
- 10619 # Docker Swarm & Container Overview

# Node Exporterä¸»æœºç›‘æ§
- 1860  # Node Exporter Full
- 11074 # Node Exporter for Prometheus Dashboard

# PostgreSQLç›‘æ§
- 9628  # PostgreSQL Database
- 12485 # PostgreSQL Patroni

# Redisç›‘æ§
- 11835 # Redis Dashboard for Prometheus
- 2751  # Prometheus Redis

# Nginxç›‘æ§
- 12708 # Nginx Prometheus Exporter
```

**å¯¼å…¥æ–¹å¼**:

```bash
# æ–¹æ³•1: Grafana UIå¯¼å…¥
# è®¿é—®: http://grafana.example.com
# Dashboard â†’ Import â†’ è¾“å…¥ID â†’ Load

# æ–¹æ³•2: APIå¯¼å…¥
$ curl -X POST http://admin:password@grafana.example.com/api/dashboards/import \
  -H "Content-Type: application/json" \
  -d '{
    "dashboard": {
      "id": null,
      "uid": null,
      "title": "Node Exporter Full"
    },
    "inputs": [
      {
        "name": "DS_PROMETHEUS",
        "type": "datasource",
        "pluginId": "prometheus",
        "value": "Prometheus"
      }
    ],
    "overwrite": true,
    "folderId": 0
  }'
```

### 15.3.3 å‘Šè­¦é€šçŸ¥é…ç½®

**GrafanaåŸç”Ÿå‘Šè­¦(Unified Alerting)**:

```yaml
# grafana/provisioning/alerting/contact-points.yml
apiVersion: 1

contactPoints:
  # é’‰é’‰é€šçŸ¥
  - orgId: 1
    name: dingtalk
    receivers:
      - uid: dingtalk-webhook
        type: webhook
        settings:
          url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN
          httpMethod: POST
          maxAlerts: 10
        disableResolveMessage: false

  # é‚®ä»¶é€šçŸ¥
  - orgId: 1
    name: email
    receivers:
      - uid: email-ops
        type: email
        settings:
          addresses: ops-team@example.com
          singleEmail: false
        disableResolveMessage: false

  # Slacké€šçŸ¥
  - orgId: 1
    name: slack
    receivers:
      - uid: slack-alerts
        type: slack
        settings:
          url: https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK
          recipient: '#alerts'
          username: Grafana
        disableResolveMessage: false

  # PagerDuty(ç”Ÿäº§äº‹æ•…)
  - orgId: 1
    name: pagerduty
    receivers:
      - uid: pagerduty-critical
        type: pagerduty
        settings:
          integrationKey: YOUR_PAGERDUTY_KEY
          severity: critical
        disableResolveMessage: false
```

```yaml
# grafana/provisioning/alerting/notification-policies.yml
apiVersion: 1

policies:
  - orgId: 1
    receiver: dingtalk  # é»˜è®¤æ¥æ”¶è€…
    group_by: ['alertname', 'severity']
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 4h
    routes:
      # Criticalå‘Šè­¦ â†’ PagerDuty + é’‰é’‰
      - receiver: pagerduty
        continue: true
        matchers:
          - severity = critical
        group_wait: 10s
        repeat_interval: 1h

      # æ•°æ®åº“å‘Šè­¦ â†’ ä¸“é—¨çš„DBAå›¢é˜Ÿ
      - receiver: email-dba
        matchers:
          - category = database
        group_interval: 10m

      # ä¸šåŠ¡å‘Šè­¦ â†’ ä¸šåŠ¡å›¢é˜Ÿ
      - receiver: slack-business
        matchers:
          - category = business
        group_interval: 15m
```

---

## 15.4 AlertManagerå‘Šè­¦è·¯ç”±

### 15.4.1 AlertManageré…ç½®

```yaml
# alertmanager/alertmanager.yml
global:
  # SMTPé…ç½®
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: 'smtp-password'
  smtp_require_tls: true

  # Slackå…¨å±€é…ç½®
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

  # é’‰é’‰Webhook
  http_config:
    proxy_url: ''

# è·¯ç”±æ ‘
route:
  receiver: 'default-receiver'
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s        # åˆ†ç»„ç­‰å¾…æ—¶é—´(æ”¶é›†åŒç»„å‘Šè­¦)
  group_interval: 5m     # åˆ†ç»„å‘é€é—´éš”
  repeat_interval: 4h    # é‡å¤å‘Šè­¦é—´éš”

  # å­è·¯ç”±
  routes:
    # ========================================
    # 1. Criticalå‘Šè­¦ â†’ ç«‹å³é€šçŸ¥å¤šä¸ªæ¸ é“
    # ========================================
    - receiver: 'critical-alerts'
      continue: true  # ç»§ç»­åŒ¹é…å…¶ä»–è·¯ç”±
      matchers:
        - severity = critical
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 30m

    # ========================================
    # 2. åŸºç¡€è®¾æ–½å‘Šè­¦ â†’ è¿ç»´å›¢é˜Ÿ
    # ========================================
    - receiver: 'infra-team'
      matchers:
        - category = infrastructure
      group_by: ['alertname', 'instance']
      group_interval: 10m

    # ========================================
    # 3. æ•°æ®åº“å‘Šè­¦ â†’ DBAå›¢é˜Ÿ
    # ========================================
    - receiver: 'dba-team'
      matchers:
        - category = database
      group_by: ['alertname', 'instance', 'datname']

    # ========================================
    # 4. åº”ç”¨å‘Šè­¦ â†’ å¼€å‘å›¢é˜Ÿ
    # ========================================
    - receiver: 'dev-team'
      matchers:
        - category =~ "performance|availability"
      group_by: ['alertname', 'service', 'endpoint']

    # ========================================
    # 5. å·¥ä½œæ—¶é—´å¤–çš„éCriticalå‘Šè­¦ â†’ æŠ‘åˆ¶
    # ========================================
    - receiver: 'null'  # é»‘æ´æ¥æ”¶è€…
      matchers:
        - severity != critical
      time_intervals:
        - offhours

    # ========================================
    # 6. æµ‹è¯•ç¯å¢ƒå‘Šè­¦ â†’ å•ç‹¬æ¸ é“
    # ========================================
    - receiver: 'test-env'
      matchers:
        - environment = test
      group_interval: 1h
      repeat_interval: 24h

# æ¥æ”¶è€…é…ç½®
receivers:
  # ========================================
  # é»˜è®¤æ¥æ”¶è€…(é’‰é’‰)
  # ========================================
  - name: 'default-receiver'
    webhook_configs:
      - url: 'http://dingtalk-webhook:8060/dingtalk/webhook1/send'
        send_resolved: true
        http_config:
          proxy_url: ''

  # ========================================
  # Criticalå‘Šè­¦(å¤šæ¸ é“é€šçŸ¥)
  # ========================================
  - name: 'critical-alerts'
    # é’‰é’‰(å¸¦@æ‰€æœ‰äºº)
    webhook_configs:
      - url: 'http://dingtalk-webhook:8060/dingtalk/webhook-critical/send'
        send_resolved: true

    # é‚®ä»¶
    email_configs:
      - to: 'ops-oncall@example.com,cto@example.com'
        from: 'alertmanager@example.com'
        smarthost: 'smtp.example.com:587'
        auth_username: 'alertmanager@example.com'
        auth_password: 'smtp-password'
        headers:
          Subject: 'ğŸš¨ [CRITICAL] {{ .GroupLabels.alertname }}'
        html: |
          <!DOCTYPE html>
          <html>
          <body>
            <h2 style="color: red;">ğŸš¨ ä¸¥é‡å‘Šè­¦</h2>
            <table border="1" cellpadding="5">
              <tr><th>å‘Šè­¦åç§°</th><td>{{ .GroupLabels.alertname }}</td></tr>
              <tr><th>ä¸¥é‡çº§åˆ«</th><td>{{ .GroupLabels.severity }}</td></tr>
              <tr><th>è§¦å‘æ—¶é—´</th><td>{{ .StartsAt.Format "2006-01-02 15:04:05" }}</td></tr>
              <tr><th>å‘Šè­¦æ•°é‡</th><td>{{ len .Alerts }}</td></tr>
            </table>
            <h3>è¯¦ç»†ä¿¡æ¯:</h3>
            <ul>
            {{ range .Alerts }}
              <li>
                <strong>{{ .Labels.alertname }}</strong><br>
                {{ .Annotations.summary }}<br>
                <em>{{ .Annotations.description }}</em>
              </li>
            {{ end }}
            </ul>
            <a href="{{ .ExternalURL }}">æŸ¥çœ‹AlertManager</a>
          </body>
          </html>
        send_resolved: true

    # Slack
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#critical-alerts'
        username: 'AlertManager'
        color: 'danger'
        title: 'ğŸš¨ CRITICAL ALERT'
        text: |
          *Alert:* {{ .GroupLabels.alertname }}
          *Severity:* {{ .GroupLabels.severity }}
          *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
        send_resolved: true

    # PagerDuty(ä»…Critical)
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: '{{ .GroupLabels.alertname }}: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        severity: 'critical'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'

  # ========================================
  # è¿ç»´å›¢é˜Ÿ
  # ========================================
  - name: 'infra-team'
    webhook_configs:
      - url: 'http://dingtalk-webhook:8060/dingtalk/infra/send'
        send_resolved: true
    email_configs:
      - to: 'infra-team@example.com'
        html: '{{ template "email.html" . }}'

  # ========================================
  # DBAå›¢é˜Ÿ
  # ========================================
  - name: 'dba-team'
    webhook_configs:
      - url: 'http://dingtalk-webhook:8060/dingtalk/dba/send'
        send_resolved: true
    email_configs:
      - to: 'dba-team@example.com'
        html: '{{ template "email.html" . }}'

  # ========================================
  # å¼€å‘å›¢é˜Ÿ
  # ========================================
  - name: 'dev-team'
    slack_configs:
      - channel: '#dev-alerts'
        title: 'âš ï¸ Application Alert'
        text: |
          *Service:* {{ .GroupLabels.service }}
          *Endpoint:* {{ .GroupLabels.endpoint }}
          {{ range .Alerts }}
          â€¢ {{ .Annotations.summary }}
          {{ end }}
        send_resolved: true

  # ========================================
  # æµ‹è¯•ç¯å¢ƒ
  # ========================================
  - name: 'test-env'
    webhook_configs:
      - url: 'http://dingtalk-webhook:8060/dingtalk/test/send'
        send_resolved: false  # æµ‹è¯•ç¯å¢ƒä¸å‘é€æ¢å¤é€šçŸ¥

  # ========================================
  # é»‘æ´æ¥æ”¶è€…(æŠ‘åˆ¶å‘Šè­¦)
  # ========================================
  - name: 'null'

# æŠ‘åˆ¶è§„åˆ™
inhibit_rules:
  # ========================================
  # 1. èŠ‚ç‚¹Downæ—¶,æŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰å®¹å™¨å‘Šè­¦
  # ========================================
  - source_matchers:
      - alertname = HostDown
    target_matchers:
      - alertname = ContainerDown
    equal:
      - instance

  # ========================================
  # 2. æœåŠ¡Downæ—¶,æŠ‘åˆ¶è¯¥æœåŠ¡çš„æ€§èƒ½å‘Šè­¦
  # ========================================
  - source_matchers:
      - severity = critical
      - alertname = ServiceDown
    target_matchers:
      - severity = warning
      - category = performance
    equal:
      - service

  # ========================================
  # 3. æ•°æ®åº“ä¸»åº“æ•…éšœæ—¶,æŠ‘åˆ¶ä»åº“å‘Šè­¦
  # ========================================
  - source_matchers:
      - alertname = PostgresMasterDown
    target_matchers:
      - alertname =~ "Postgres.*"
      - role = slave
    equal:
      - cluster

# æ—¶é—´æ®µå®šä¹‰
time_intervals:
  # å·¥ä½œæ—¶é—´å¤–(æ™šä¸Š22:00 - æ—©ä¸Š08:00, å‘¨æœ«å…¨å¤©)
  - name: offhours
    time_intervals:
      - times:
          - start_time: '22:00'
            end_time: '08:00'
      - weekdays: ['saturday', 'sunday']

  # ä»…å·¥ä½œæ—¶é—´
  - name: workhours
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '18:00'
        weekdays: ['monday:friday']

# æ¨¡æ¿
templates:
  - '/etc/alertmanager/templates/*.tmpl'
```

### 15.4.2 é’‰é’‰Webhooké›†æˆ

**ä½¿ç”¨Prometheus Webhook Dingtalk**:

```yaml
# monitoring/stack.yml (æ·»åŠ åˆ°ç°æœ‰é…ç½®)
services:
  dingtalk-webhook:
    image: timonwong/prometheus-webhook-dingtalk:v2.1.0
    command:
      - '--config.file=/etc/prometheus-webhook-dingtalk/config.yml'
      - '--web.listen-address=:8060'
      - '--web.enable-ui'
      - '--web.enable-lifecycle'
    volumes:
      - ./dingtalk/config.yml:/etc/prometheus-webhook-dingtalk/config.yml:ro
      - ./dingtalk/templates:/etc/prometheus-webhook-dingtalk/templates:ro
    networks:
      - monitoring
    ports:
      - "8060:8060"
    deploy:
      mode: replicated
      replicas: 2
```

```yaml
# dingtalk/config.yml
templates:
  - /etc/prometheus-webhook-dingtalk/templates/default.tmpl

targets:
  # é»˜è®¤Webhook(æ™®é€šå‘Šè­¦)
  webhook1:
    url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_ACCESS_TOKEN_1
    secret: YOUR_SECRET_1  # é’‰é’‰æœºå™¨äººå¯†é’¥
    mention:
      all: false

  # Criticalå‘Šè­¦Webhook(@æ‰€æœ‰äºº)
  webhook-critical:
    url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_ACCESS_TOKEN_2
    secret: YOUR_SECRET_2
    mention:
      all: true  # @æ‰€æœ‰äºº

  # åŸºç¡€è®¾æ–½å›¢é˜Ÿ
  infra:
    url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_ACCESS_TOKEN_3
    secret: YOUR_SECRET_3
    mention:
      mobiles: ['13800138000', '13900139000']  # @æŒ‡å®šäºº

  # DBAå›¢é˜Ÿ
  dba:
    url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_ACCESS_TOKEN_4
    secret: YOUR_SECRET_4
    mention:
      mobiles: ['13700137000']

  # æµ‹è¯•ç¯å¢ƒ
  test:
    url: https://oapi.dingtalk.com/robot/send?access_token=YOUR_ACCESS_TOKEN_5
    secret: YOUR_SECRET_5
    mention:
      all: false
```

**è‡ªå®šä¹‰é’‰é’‰æ¶ˆæ¯æ¨¡æ¿**:

```go
// dingtalk/templates/default.tmpl
{{ define "__subject" }}
[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }}
{{ end }}

{{ define "__alert_list" }}
{{ range . }}
---
**å‘Šè­¦åç§°**: {{ .Labels.alertname }}
**ä¸¥é‡çº§åˆ«**: {{ .Labels.severity }}
**å‘Šè­¦ä¸»æœº**: {{ .Labels.instance }}
{{ if .Labels.service }}**æœåŠ¡åç§°**: {{ .Labels.service }}{{ end }}
{{ if .Labels.endpoint }}**æ¥å£è·¯å¾„**: {{ .Labels.endpoint }}{{ end }}
**å‘Šè­¦æ‘˜è¦**: {{ .Annotations.summary }}
**è¯¦ç»†æè¿°**: {{ .Annotations.description }}
**è§¦å‘æ—¶é—´**: {{ (.StartsAt.Add 28800e9).Format "2006-01-02 15:04:05" }}
{{ if gt (len .Labels) 0 }}**æ‰€æœ‰æ ‡ç­¾**:
{{ range .Labels.SortedPairs }}  - {{ .Name }}: {{ .Value }}
{{ end }}{{ end }}
{{ end }}
{{ end }}

{{ define "ding.link.title" }}{{ template "__subject" . }}{{ end }}
{{ define "ding.link.content" }}
#### ğŸ“Š å‘Šè­¦è¯¦æƒ…
{{ if gt (len .Alerts.Firing) 0 }}
**ğŸ”¥ è§¦å‘ä¸­çš„å‘Šè­¦ ({{ .Alerts.Firing | len }})**
{{ template "__alert_list" .Alerts.Firing }}
{{ end }}

{{ if gt (len .Alerts.Resolved) 0 }}
**âœ… å·²æ¢å¤çš„å‘Šè­¦ ({{ .Alerts.Resolved | len }})**
{{ template "__alert_list" .Alerts.Resolved }}
{{ end }}

---
[ğŸ”— æŸ¥çœ‹AlertManager]({{ .ExternalURL }})
{{ end }}
```

### 15.4.3 æµ‹è¯•ä¸éªŒè¯

```bash
# ========================================
# 1. éªŒè¯AlertManageré…ç½®
# ========================================
$ docker run --rm \
  -v $(pwd)/alertmanager:/etc/alertmanager \
  prom/alertmanager:v0.26.0 \
  amtool check-config /etc/alertmanager/alertmanager.yml
# âœ… Checking '/etc/alertmanager/alertmanager.yml'  SUCCESS

# ========================================
# 2. éƒ¨ç½²AlertManager
# ========================================
$ docker stack deploy -c monitoring/stack.yml monitoring

# æŸ¥çœ‹AlertManageré›†ç¾¤çŠ¶æ€
$ curl http://localhost:9093/api/v2/status | jq
{
  "cluster": {
    "peers": [
      {"name": "alertmanager-1", "address": "10.0.1.5:9094"},
      {"name": "alertmanager-2", "address": "10.0.1.6:9094"},
      {"name": "alertmanager-3", "address": "10.0.1.7:9094"}
    ],
    "status": "ready"
  },
  "versionInfo": {"version": "0.26.0"}
}

# ========================================
# 3. æ¨¡æ‹Ÿå‘Šè­¦æµ‹è¯•
# ========================================

# æ–¹æ³•1: ä½¿ç”¨amtoolæ‰‹åŠ¨å‘é€æµ‹è¯•å‘Šè­¦
$ docker exec -it $(docker ps -q -f name=monitoring_alertmanager) sh

$ amtool alert add \
  --alertmanager.url=http://localhost:9093 \
  --annotation=summary="æµ‹è¯•å‘Šè­¦æ‘˜è¦" \
  --annotation=description="è¿™æ˜¯ä¸€æ¡æµ‹è¯•å‘Šè­¦,è¯·å¿½ç•¥" \
  alertname="TestAlert" \
  severity="warning" \
  instance="test-instance" \
  service="test-service"
# âœ… å‘Šè­¦å·²å‘é€

# æ–¹æ³•2: é€šè¿‡APIå‘é€æµ‹è¯•å‘Šè­¦
$ curl -X POST http://localhost:9093/api/v2/alerts \
  -H "Content-Type: application/json" \
  -d '[
    {
      "labels": {
        "alertname": "TestDatabaseAlert",
        "severity": "critical",
        "category": "database",
        "instance": "postgres-master"
      },
      "annotations": {
        "summary": "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜",
        "description": "å½“å‰è¿æ¥æ•°: 950, æœ€å¤§è¿æ¥æ•°: 1000"
      },
      "startsAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
      "endsAt": "'$(date -u -d '+5 minutes' +%Y-%m-%dT%H:%M:%SZ)'"
    }
  ]'

# æ–¹æ³•3: è§¦å‘çœŸå®å‘Šè­¦(ä¸´æ—¶ä¿®æ”¹é˜ˆå€¼)
# ç¼–è¾‘prometheus/rules/alerts.yml, å°†æŸä¸ªé˜ˆå€¼æ”¹å¾—å¾ˆä½
- alert: ContainerCpuUsageHigh
  expr: |
    ... > 1  # ä¸´æ—¶æ”¹ä¸º1%,è§¦å‘å‘Šè­¦
  for: 1m

# çƒ­é‡è½½Prometheusé…ç½®
$ curl -X POST http://localhost:9090/-/reload

# ç­‰å¾…1-2åˆ†é’ŸåæŸ¥çœ‹å‘Šè­¦
$ curl http://localhost:9090/api/v1/alerts | jq '.data.alerts[] | select(.state=="firing")'

# ========================================
# 4. éªŒè¯å‘Šè­¦è·¯ç”±
# ========================================

# æŸ¥çœ‹å‘Šè­¦è·¯ç”±æ ‘
$ curl http://localhost:9093/api/v2/status | jq '.config.route'

# æµ‹è¯•å‘Šè­¦ä¼šåŒ¹é…åˆ°å“ªä¸ªè·¯ç”±
$ docker exec -it $(docker ps -q -f name=monitoring_alertmanager) sh
$ amtool config routes test \
  --alertmanager.url=http://localhost:9093 \
  severity=critical \
  category=database
# dba-team  # âœ… åŒ¹é…åˆ°DBAå›¢é˜Ÿè·¯ç”±

# ========================================
# 5. éªŒè¯æŠ‘åˆ¶è§„åˆ™
# ========================================

# å…ˆå‘é€ä¸€ä¸ªHostDownå‘Šè­¦
$ curl -X POST http://localhost:9093/api/v2/alerts -d '[{
  "labels": {"alertname": "HostDown", "instance": "node1", "severity": "critical"},
  "annotations": {"summary": "èŠ‚ç‚¹node1ä¸‹çº¿"}
}]'

# å†å‘é€è¯¥èŠ‚ç‚¹ä¸Šçš„å®¹å™¨å‘Šè­¦
$ curl -X POST http://localhost:9093/api/v2/alerts -d '[{
  "labels": {"alertname": "ContainerDown", "instance": "node1", "severity": "warning"},
  "annotations": {"summary": "å®¹å™¨ä¸‹çº¿"}
}]'

# æŸ¥çœ‹å‘Šè­¦çŠ¶æ€(ContainerDownåº”è¯¥è¢«æŠ‘åˆ¶)
$ curl http://localhost:9093/api/v2/alerts | jq '.[] | select(.status.state != "suppressed")'
# åº”è¯¥åªçœ‹åˆ°HostDownå‘Šè­¦

# ========================================
# 6. æŸ¥çœ‹å‘Šè­¦å†å²
# ========================================
$ curl http://localhost:9093/api/v2/alerts/groups | jq

# ========================================
# 7. é™é»˜å‘Šè­¦(Silence)
# ========================================

# åˆ›å»ºé™é»˜è§„åˆ™(é™é»˜1å°æ—¶)
$ curl -X POST http://localhost:9093/api/v2/silences \
  -H "Content-Type: application/json" \
  -d '{
    "matchers": [
      {
        "name": "instance",
        "value": "test-instance",
        "isRegex": false,
        "isEqual": true
      }
    ],
    "startsAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
    "endsAt": "'$(date -u -d '+1 hour' +%Y-%m-%dT%H:%M:%SZ)'",
    "createdBy": "admin",
    "comment": "ç»´æŠ¤çª—å£,é™é»˜test-instanceçš„æ‰€æœ‰å‘Šè­¦"
  }'
# {"silenceID": "abc123..."}

# æŸ¥çœ‹æ‰€æœ‰é™é»˜è§„åˆ™
$ curl http://localhost:9093/api/v2/silences | jq

# åˆ é™¤é™é»˜è§„åˆ™
$ curl -X DELETE http://localhost:9093/api/v2/silence/abc123

# ========================================
# 8. é’‰é’‰å‘Šè­¦éªŒè¯
# ========================================

# æ£€æŸ¥é’‰é’‰WebhookæœåŠ¡çŠ¶æ€
$ curl http://localhost:8060/ui
# è®¿é—®Web UIæŸ¥çœ‹é…ç½®

# å‘é€æµ‹è¯•å‘Šè­¦åˆ°é’‰é’‰
$ curl -X POST http://localhost:8060/dingtalk/webhook1/send \
  -H "Content-Type: application/json" \
  -d '{
    "version": "4",
    "groupKey": "{}/{severity=\"warning\"}:{alertname=\"TestAlert\"}",
    "status": "firing",
    "receiver": "dingtalk",
    "groupLabels": {
      "alertname": "TestAlert",
      "severity": "warning"
    },
    "alerts": [
      {
        "status": "firing",
        "labels": {
          "alertname": "TestAlert",
          "severity": "warning",
          "instance": "test-instance"
        },
        "annotations": {
          "summary": "è¿™æ˜¯ä¸€æ¡æµ‹è¯•å‘Šè­¦",
          "description": "ç”¨äºéªŒè¯é’‰é’‰Webhooké›†æˆæ˜¯å¦æ­£å¸¸"
        },
        "startsAt": "'$(date -u +%Y-%m-%dT%H:%M:%S.000Z)'",
        "endsAt": "0001-01-01T00:00:00Z"
      }
    ],
    "externalURL": "http://alertmanager.example.com"
  }'
# âœ… åº”è¯¥åœ¨é’‰é’‰ç¾¤æ”¶åˆ°æ¶ˆæ¯
```

---

## 15.5 APMåº”ç”¨æ€§èƒ½ç›‘æ§

### 15.5.1 åˆ†å¸ƒå¼è¿½è¸ª(Jaeger)

**1. Jaeger Stackéƒ¨ç½²**:

```yaml
# monitoring/jaeger-stack.yml
version: '3.8'

services:
  # ========================================
  # Jaeger All-in-One(å¼€å‘/å°è§„æ¨¡ç”Ÿäº§)
  # ========================================
  jaeger:
    image: jaegertracing/all-in-one:1.49
    environment:
      # å­˜å‚¨åç«¯(ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨Elasticsearch/Cassandra)
      SPAN_STORAGE_TYPE: badger
      BADGER_DIRECTORY_VALUE: /badger/data
      BADGER_DIRECTORY_KEY: /badger/key
      BADGER_EPHEMERAL: "false"
      BADGER_SPAN_STORE_TTL: "168h"  # ä¿ç•™7å¤©

      # Collectoré…ç½®
      COLLECTOR_ZIPKIN_HOST_PORT: ":9411"
      COLLECTOR_OTLP_ENABLED: "true"

      # Queryé…ç½®
      QUERY_BASE_PATH: /jaeger

      # é‡‡æ ·é…ç½®
      SAMPLING_STRATEGIES_FILE: /etc/jaeger/sampling.json

    volumes:
      - jaeger-badger:/badger
      - ./jaeger/sampling.json:/etc/jaeger/sampling.json:ro
    networks:
      - monitoring
    ports:
      - "5775:5775/udp"   # Zipkin compact thrift (deprecated)
      - "6831:6831/udp"   # Jaeger compact thrift
      - "6832:6832/udp"   # Jaeger binary thrift
      - "5778:5778"       # Configs
      - "16686:16686"     # Jaeger UI
      - "14268:14268"     # Jaeger collector HTTP
      - "14250:14250"     # Jaeger collector gRPC
      - "9411:9411"       # Zipkin compatible endpoint
      - "4317:4317"       # OTLP gRPC
      - "4318:4318"       # OTLP HTTP
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # ========================================
  # Jaegerç”Ÿäº§ç¯å¢ƒéƒ¨ç½²(ä½¿ç”¨Elasticsearch)
  # ========================================
  jaeger-collector:
    image: jaegertracing/jaeger-collector:1.49
    environment:
      SPAN_STORAGE_TYPE: elasticsearch
      ES_SERVER_URLS: http://elasticsearch:9200
      ES_INDEX_PREFIX: jaeger
      ES_NUM_SHARDS: 5
      ES_NUM_REPLICAS: 1
      COLLECTOR_QUEUE_SIZE: 2000
      COLLECTOR_NUM_WORKERS: 50
    networks:
      - monitoring
      - backend
    ports:
      - "14250:14250"
      - "14268:14268"
    deploy:
      mode: replicated
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 2G

  jaeger-query:
    image: jaegertracing/jaeger-query:1.49
    environment:
      SPAN_STORAGE_TYPE: elasticsearch
      ES_SERVER_URLS: http://elasticsearch:9200
      ES_INDEX_PREFIX: jaeger
      QUERY_BASE_PATH: /jaeger
    networks:
      - monitoring
      - backend
    ports:
      - "16686:16686"
    deploy:
      mode: replicated
      replicas: 2

  jaeger-agent:
    image: jaegertracing/jaeger-agent:1.49
    command:
      - "--reporter.grpc.host-port=jaeger-collector:14250"
      - "--reporter.type=grpc"
    networks:
      - monitoring
    ports:
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
    deploy:
      mode: global  # æ¯ä¸ªèŠ‚ç‚¹ä¸€ä¸ªAgent

networks:
  monitoring:
    external: true
  backend:
    external: true

volumes:
  jaeger-badger:
```

**2. é‡‡æ ·ç­–ç•¥é…ç½®**:

```json
// jaeger/sampling.json
{
  "default_strategy": {
    "type": "probabilistic",
    "param": 0.1  // é»˜è®¤10%é‡‡æ ·ç‡
  },
  "service_strategies": [
    {
      "service": "critical-api",
      "type": "probabilistic",
      "param": 1.0  // å…³é”®æœåŠ¡100%é‡‡æ ·
    },
    {
      "service": "high-traffic-api",
      "type": "ratelimiting",
      "param": 100  // é«˜æµé‡æœåŠ¡é™é€Ÿé‡‡æ ·(100 traces/s)
    },
    {
      "service": "batch-job",
      "type": "probabilistic",
      "param": 0.01  // æ‰¹å¤„ç†ä»»åŠ¡1%é‡‡æ ·
    }
  ]
}
```

**3. åº”ç”¨é›†æˆJaeger(Pythonç¤ºä¾‹)**:

```python
# app/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor

def init_tracer(app, service_name="myapp"):
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è¿½è¸ª"""

    # åˆ›å»ºResource(æ ‡è¯†æœåŠ¡)
    resource = Resource.create({
        "service.name": service_name,
        "service.version": "1.0.0",
        "deployment.environment": "production",
        "service.namespace": "default"
    })

    # åˆ›å»ºTracerProvider
    tracer_provider = TracerProvider(resource=resource)
    trace.set_tracer_provider(tracer_provider)

    # é…ç½®Jaeger Exporter
    jaeger_exporter = JaegerExporter(
        agent_host_name="jaeger-agent",  # Jaeger Agentåœ°å€
        agent_port=6831,
        udp_split_oversized_batches=True
    )

    # æ·»åŠ Span Processor(æ‰¹é‡å‘é€)
    span_processor = BatchSpanProcessor(
        jaeger_exporter,
        max_queue_size=2048,
        schedule_delay_millis=5000,
        max_export_batch_size=512
    )
    tracer_provider.add_span_processor(span_processor)

    # è‡ªåŠ¨åŸ‹ç‚¹Flask
    FlaskInstrumentor().instrument_app(app)

    # è‡ªåŠ¨åŸ‹ç‚¹HTTPè¯·æ±‚
    RequestsInstrumentor().instrument()

    # è‡ªåŠ¨åŸ‹ç‚¹SQLAlchemy
    from app import db
    SQLAlchemyInstrumentor().instrument(
        engine=db.engine,
        enable_commenter=True,  # SQLæ³¨é‡Šä¸­æ·»åŠ trace_id
        commenter_options={"db_driver": True}
    )

    return tracer_provider

# app.py
from flask import Flask, request, jsonify
from tracing import init_tracer
from opentelemetry import trace

app = Flask(__name__)
init_tracer(app)

tracer = trace.get_tracer(__name__)

@app.route('/api/order', methods=['POST'])
def create_order():
    # è‡ªåŠ¨åˆ›å»ºçš„Span(ç”±FlaskInstrumentor)
    current_span = trace.get_current_span()

    # æ·»åŠ è‡ªå®šä¹‰å±æ€§
    current_span.set_attribute("user.id", request.json.get('user_id'))
    current_span.set_attribute("order.amount", request.json.get('amount'))

    # æ‰‹åŠ¨åˆ›å»ºå­Span
    with tracer.start_as_current_span("validate_order") as span:
        span.set_attribute("validation.result", "success")
        result = validate_order(request.json)

    # è°ƒç”¨å…¶ä»–æœåŠ¡(è‡ªåŠ¨ä¼ é€’trace context)
    with tracer.start_as_current_span("call_payment_service") as span:
        import requests
        response = requests.post(
            'http://payment-service/api/charge',
            json={'order_id': 123, 'amount': 99.99}
        )
        span.set_attribute("payment.status", response.status_code)

    # æ•°æ®åº“æ“ä½œ(è‡ªåŠ¨è¿½è¸ª)
    with tracer.start_as_current_span("database_insert") as span:
        db.session.add(Order(**request.json))
        db.session.commit()

    return jsonify({"status": "success"}), 201

if __name__ == '__main__':
    app.run()
```

**4. æŸ¥è¯¢Jaeger Traces**:

```bash
# è®¿é—®Jaeger UI
$ open http://jaeger.example.com:16686

# APIæŸ¥è¯¢(æŸ¥æ‰¾æ…¢æŸ¥è¯¢)
$ curl 'http://localhost:16686/api/traces?service=myapp&limit=20&minDuration=1s' | jq

# æŸ¥æ‰¾åŒ…å«é”™è¯¯çš„Trace
$ curl 'http://localhost:16686/api/traces?service=myapp&tags={"error":"true"}' | jq

# é€šè¿‡TraceIDæŸ¥è¯¢å®Œæ•´é“¾è·¯
$ curl 'http://localhost:16686/api/traces/abc123def456' | jq
```

### 15.5.2 åº”ç”¨æ€§èƒ½æŒ‡æ ‡é‡‡é›†

**Prometheus + StatsD Exporteré›†æˆ**:

```yaml
# monitoring/stack.yml (æ·»åŠ )
services:
  statsd-exporter:
    image: prom/statsd-exporter:v0.26.0
    command:
      - '--statsd.mapping-config=/etc/statsd/statsd-mapping.yml'
      - '--statsd.listen-udp=:9125'
      - '--statsd.listen-tcp=:9125'
      - '--web.listen-address=:9102'
    volumes:
      - ./statsd/statsd-mapping.yml:/etc/statsd/statsd-mapping.yml:ro
    networks:
      - monitoring
    ports:
      - "9125:9125/udp"
      - "9102:9102"
    deploy:
      mode: global
```

```yaml
# statsd/statsd-mapping.yml
mappings:
  # HTTPè¯·æ±‚è®¡æ•°
  - match: "app.http.requests.*.*.*"
    name: "http_requests_total"
    labels:
      method: "$1"
      endpoint: "$2"
      status: "$3"

  # HTTPè¯·æ±‚å»¶è¿Ÿ
  - match: "app.http.request_duration.*.*"
    name: "http_request_duration_seconds"
    timer_type: histogram
    buckets: [0.01, 0.05, 0.1, 0.5, 1, 5]
    labels:
      method: "$1"
      endpoint: "$2"

  # æ•°æ®åº“æŸ¥è¯¢
  - match: "app.db.query_duration.*"
    name: "db_query_duration_seconds"
    timer_type: summary
    labels:
      query_type: "$1"

  # ç¼“å­˜å‘½ä¸­ç‡
  - match: "app.cache.*.*"
    name: "cache_operations_total"
    labels:
      operation: "$1"
      result: "$2"
```

**åº”ç”¨ä»£ç é›†æˆStatsD**:

```python
# app.py
from statsd import StatsClient
import time

statsd = StatsClient(host='statsd-exporter', port=9125, prefix='app')

@app.route('/api/users/<int:user_id>')
def get_user(user_id):
    start_time = time.time()

    try:
        # å¢åŠ è¯·æ±‚è®¡æ•°
        statsd.incr(f'http.requests.GET.api_users.200')

        # æ£€æŸ¥ç¼“å­˜
        user = cache.get(f'user:{user_id}')
        if user:
            statsd.incr('cache.get.hit')
        else:
            statsd.incr('cache.get.miss')

            # æ•°æ®åº“æŸ¥è¯¢
            query_start = time.time()
            user = User.query.get(user_id)
            statsd.timing('db.query_duration.select',
                         (time.time() - query_start) * 1000)

            cache.set(f'user:{user_id}', user, timeout=300)

        # è®°å½•æ€»å»¶è¿Ÿ
        statsd.timing(f'http.request_duration.GET.api_users',
                     (time.time() - start_time) * 1000)

        return jsonify(user.to_dict())

    except Exception as e:
        statsd.incr(f'http.requests.GET.api_users.500')
        raise
```

---

*ï¼ˆç¬¬15ç« å®Œæˆ,çº¦2650è¡Œã€‚å·²å®Œæˆ15ç« ,å‰©ä½™4ç« ...ï¼‰*

---

ğŸ“ **ä¸‹ä¸€ç« é¢„å‘Š**: ELK Stackæ—¥å¿—æ”¶é›†ã€æ—¥å¿—è§£æä¸å‘Šè­¦ã€æ—¥å¿—æŸ¥è¯¢ä¸åˆ†æã€æ—¥å¿—å½’æ¡£ç­–ç•¥

---

# ç¬¬åå…­ç« : æ—¥å¿—æ”¶é›†ä¸åˆ†æ

> **æœ¬ç« ç›®æ ‡**: æŒæ¡Dockerç”Ÿäº§ç¯å¢ƒæ—¥å¿—æ”¶é›†æ–¹æ¡ˆ,åŒ…æ‹¬ELK Stackä¼ä¸šçº§éƒ¨ç½²ã€Fluentdæ—¥å¿—æ”¶é›†ã€Grokæ¨¡å¼è§£æã€Kibanaå¯è§†åŒ–åˆ†æã€ElastAlertå‘Šè­¦,ä»¥åŠæ—¥å¿—å½’æ¡£ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚

---

## 16.1 æ—¥å¿—æ”¶é›†æ¶æ„è®¾è®¡

### 16.1.1 æ—¥å¿—æ”¶é›†æ¶æ„æ¨¡å¼

**å®Œæ•´çš„æ—¥å¿—å¤„ç†æµç¨‹**:

```yaml
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ—¥å¿—ç”Ÿæˆå±‚ (Source)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ åº”ç”¨æ—¥å¿—  â”‚  â”‚ ç³»ç»Ÿæ—¥å¿—  â”‚  â”‚ è®¿é—®æ—¥å¿—  â”‚  â”‚ å®¡è®¡æ—¥å¿—  â”‚       â”‚
â”‚  â”‚  (JSON)  â”‚  â”‚ (Syslog) â”‚  â”‚ (Nginx)  â”‚  â”‚ (Docker) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚             â”‚
         â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ—¥å¿—é‡‡é›†å±‚ (Collector)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   Fluentd/Fluent Bit    â”‚   Filebeat       â”‚                â”‚
â”‚  â”‚  - å¤šæºè¾“å…¥             â”‚   - è½»é‡çº§        â”‚                â”‚
â”‚  â”‚  - å¼ºå¤§è¿‡æ»¤             â”‚   - ä½èµ„æºæ¶ˆè€—    â”‚                â”‚
â”‚  â”‚  - ç¼“å†²æœºåˆ¶             â”‚   - ç›´æ¥ESé›†æˆ    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ—¥å¿—å¤„ç†å±‚ (Processing)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                   â”‚   Logstash   â”‚                              â”‚
â”‚                   â”‚  - Grokè§£æ  â”‚                              â”‚
â”‚                   â”‚  - æ•°æ®è½¬æ¢  â”‚                              â”‚
â”‚                   â”‚  - å¤šè¾“å‡º    â”‚                              â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ—¥å¿—å­˜å‚¨å±‚ (Storage)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚             â”‚   Elasticsearch Cluster    â”‚                      â”‚
â”‚             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”â”‚                     â”‚
â”‚             â”‚  â”‚ ES-1 â”‚ â”‚ ES-2 â”‚ â”‚ ES-3 â”‚â”‚                     â”‚
â”‚             â”‚  â”‚Masterâ”‚ â”‚ Data â”‚ â”‚ Data â”‚â”‚                     â”‚
â”‚             â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜â”‚                     â”‚
â”‚             â”‚  - åˆ†ç‰‡å‰¯æœ¬ç­–ç•¥             â”‚                      â”‚
â”‚             â”‚  - ILMç”Ÿå‘½å‘¨æœŸç®¡ç†          â”‚                      â”‚
â”‚             â”‚  - å†·çƒ­æ•°æ®åˆ†ç¦»             â”‚                      â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kibana      â”‚ â”‚ ElastAlert  â”‚ â”‚   Curator    â”‚
â”‚   å¯è§†åŒ–åˆ†æ     â”‚ â”‚  æ—¥å¿—å‘Šè­¦    â”‚ â”‚  ç´¢å¼•æ¸…ç†    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ¶æ„é€‰å‹å¯¹æ¯”**:

| ç»„ä»¶ | Fluentd | Filebeat | Logstash |
|------|---------|----------|----------|
| **è¯­è¨€** | Ruby | Go | Java |
| **èµ„æºæ¶ˆè€—** | ä¸­ç­‰ | æä½ | é«˜ |
| **æ’ä»¶ç”Ÿæ€** | ä¸°å¯Œ(1000+) | æœ‰é™ | ä¸°å¯Œ(200+) |
| **è¿‡æ»¤èƒ½åŠ›** | å¼º | å¼± | å¼º |
| **ç¼“å†²æœºåˆ¶** | å†…ç½® | æ—  | å†…ç½® |
| **ä½¿ç”¨åœºæ™¯** | å¤æ‚æ—¥å¿—å¤„ç† | ç®€å•æ—¥å¿—è½¬å‘ | ETLè½¬æ¢ |
| **CPUå ç”¨** | 50-200MB | 10-30MB | 500MB-2GB |

**æ¨èæ¶æ„**:
- **å°è§„æ¨¡**: Filebeat â†’ Elasticsearch â†’ Kibana
- **ä¸­è§„æ¨¡**: Fluentd â†’ Elasticsearch â†’ Kibana
- **å¤§è§„æ¨¡**: Fluentd â†’ Kafka â†’ Logstash â†’ Elasticsearch â†’ Kibana

### 16.1.2 Dockeræ—¥å¿—é©±åŠ¨

**Dockeræ”¯æŒçš„æ—¥å¿—é©±åŠ¨**:

```yaml
æ—¥å¿—é©±åŠ¨ç±»å‹:
  1. json-file (é»˜è®¤)
     - ä¼˜ç‚¹: ç®€å•ã€docker logså¯ç”¨
     - ç¼ºç‚¹: æ— è‡ªåŠ¨è½®è½¬ã€ç£ç›˜å ç”¨
     - é€‚ç”¨: å¼€å‘ç¯å¢ƒ

  2. syslog
     - ä¼˜ç‚¹: é›†æˆç³»ç»Ÿæ—¥å¿—
     - ç¼ºç‚¹: éœ€è¦syslogæœåŠ¡
     - é€‚ç”¨: ä¼ ç»Ÿè¿ç»´ç¯å¢ƒ

  3. journald
     - ä¼˜ç‚¹: systemdé›†æˆ
     - ç¼ºç‚¹: ä»…Linux
     - é€‚ç”¨: Systemdç®¡ç†çš„ç³»ç»Ÿ

  4. fluentd
     - ä¼˜ç‚¹: ç›´æ¥é›†æˆFluentd
     - ç¼ºç‚¹: éœ€è¦Fluentdè¿è¡Œ
     - é€‚ç”¨: ç”Ÿäº§ç¯å¢ƒ

  5. gelf (Graylog Extended Log Format)
     - ä¼˜ç‚¹: ç»“æ„åŒ–æ—¥å¿—
     - ç¼ºç‚¹: éœ€è¦Graylog/Logstash
     - é€‚ç”¨: å¾®æœåŠ¡æ¶æ„

  6. none
     - ä¼˜ç‚¹: æ— IOå¼€é”€
     - ç¼ºç‚¹: æ— æ³•æŸ¥çœ‹æ—¥å¿—
     - é€‚ç”¨: æ€§èƒ½æ•æ„Ÿåœºæ™¯
```

**é…ç½®Dockeræ—¥å¿—é©±åŠ¨**:

```bash
# å…¨å±€é…ç½® - /etc/docker/daemon.json
{
  "log-driver": "fluentd",
  "log-opts": {
    "fluentd-address": "fluentd.example.com:24224",
    "fluentd-async": "true",
    "fluentd-retry-wait": "1s",
    "fluentd-max-retries": "10",
    "tag": "docker.{{.Name}}.{{.ID}}"
  }
}

# é‡å¯Dockerä½¿é…ç½®ç”Ÿæ•ˆ
$ sudo systemctl restart docker

# å•å®¹å™¨é…ç½® - docker-compose.yml
version: '3.8'
services:
  app:
    image: myapp:latest
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async: "true"
        tag: "docker.app.{{.ID}}"
        labels: "app,version"
        env: "ENVIRONMENT"

# å•å®¹å™¨é…ç½® - docker run
$ docker run -d \
  --log-driver=fluentd \
  --log-opt fluentd-address=fluentd:24224 \
  --log-opt tag="docker.nginx.{{.ID}}" \
  nginx:latest
```

---

## 16.2 Elasticsearché›†ç¾¤éƒ¨ç½²

### 16.2.1 Elasticsearché›†ç¾¤æ¶æ„

**ç”Ÿäº§ç¯å¢ƒ3èŠ‚ç‚¹é›†ç¾¤æ¶æ„**:

```yaml
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Elasticsearch Cluster                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ES-Master  â”‚  â”‚   ES-Data-1  â”‚  â”‚   ES-Data-2  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ Roles:       â”‚  â”‚ Roles:       â”‚  â”‚ Roles:       â”‚ â”‚
â”‚  â”‚ - master     â”‚  â”‚ - data       â”‚  â”‚ - data       â”‚ â”‚
â”‚  â”‚ - ingest     â”‚  â”‚ - ingest     â”‚  â”‚ - ingest     â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ Heap: 2GB    â”‚  â”‚ Heap: 16GB   â”‚  â”‚ Heap: 16GB   â”‚ â”‚
â”‚  â”‚ CPU: 2æ ¸     â”‚  â”‚ CPU: 8æ ¸     â”‚  â”‚ CPU: 8æ ¸     â”‚ â”‚
â”‚  â”‚ Mem: 4GB     â”‚  â”‚ Mem: 32GB    â”‚  â”‚ Mem: 32GB    â”‚ â”‚
â”‚  â”‚ Disk: 50GB   â”‚  â”‚ Disk: 500GB  â”‚  â”‚ Disk: 500GB  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                 â”‚                 â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                           â”‚                            â”‚
â”‚                  (é›†ç¾¤é€šä¿¡: 9300ç«¯å£)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     (REST API: 9200ç«¯å£)
                            â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Load Balancer   â”‚
                  â”‚  (HAProxy/Nginx)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**èŠ‚ç‚¹è§’è‰²è¯´æ˜**:
- **Master Node**: é›†ç¾¤ç®¡ç†(åˆ›å»º/åˆ é™¤ç´¢å¼•ã€åˆ†é…åˆ†ç‰‡)
- **Data Node**: å­˜å‚¨æ•°æ®ã€æ‰§è¡ŒæŸ¥è¯¢
- **Ingest Node**: æ•°æ®é¢„å¤„ç†(Pipeline)
- **Coordinating Node**: è¯·æ±‚è·¯ç”±å’Œç»“æœèšåˆ

### 16.2.2 Elasticsearch Stackéƒ¨ç½²

**ç›®å½•ç»“æ„**:

```bash
elk/
â”œâ”€â”€ elasticsearch/
â”‚   â”œâ”€â”€ elasticsearch.yml        # ESé…ç½®
â”‚   â”œâ”€â”€ jvm.options             # JVMå‚æ•°
â”‚   â””â”€â”€ log4j2.properties       # æ—¥å¿—é…ç½®
â”œâ”€â”€ logstash/
â”‚   â”œâ”€â”€ logstash.yml            # Logstashé…ç½®
â”‚   â”œâ”€â”€ pipelines.yml           # Pipelineé…ç½®
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ docker.conf         # Dockeræ—¥å¿—Pipeline
â”‚       â”œâ”€â”€ nginx.conf          # Nginxæ—¥å¿—Pipeline
â”‚       â””â”€â”€ app.conf            # åº”ç”¨æ—¥å¿—Pipeline
â”œâ”€â”€ kibana/
â”‚   â””â”€â”€ kibana.yml              # Kibanaé…ç½®
â””â”€â”€ stack.yml                   # Docker Composeé…ç½®
```

**1. Elasticsearché›†ç¾¤é…ç½®**:

```yaml
# elk/stack.yml
version: '3.8'

services:
  # ========================================
  # Elasticsearch Master Node
  # ========================================
  elasticsearch-master:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es-master
    environment:
      # èŠ‚ç‚¹é…ç½®
      - node.name=es-master
      - node.roles=master,ingest

      # é›†ç¾¤é…ç½®
      - cluster.name=docker-elk-cluster
      - cluster.initial_master_nodes=es-master
      - discovery.seed_hosts=es-data-1,es-data-2

      # ç½‘ç»œé…ç½®
      - network.host=0.0.0.0
      - http.port=9200
      - transport.port=9300

      # å†…å­˜é…ç½®
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
      - bootstrap.memory_lock=true

      # å®‰å…¨é…ç½®(ç”Ÿäº§ç¯å¢ƒå¿…é¡»å¯ç”¨)
      - xpack.security.enabled=true
      - xpack.security.enrollment.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}

      # ç›‘æ§é…ç½®
      - xpack.monitoring.collection.enabled=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - es-master-data:/usr/share/elasticsearch/data
      - ./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - ./elasticsearch/jvm.options:/usr/share/elasticsearch/config/jvm.options:ro
    networks:
      - elk
    ports:
      - "9200:9200"
      - "9300:9300"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:${ELASTIC_PASSWORD} http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\\|yellow\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ========================================
  # Elasticsearch Data Node 1
  # ========================================
  elasticsearch-data-1:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es-data-1
    environment:
      - node.name=es-data-1
      - node.roles=data,ingest
      - cluster.name=docker-elk-cluster
      - discovery.seed_hosts=es-master,es-data-2
      - cluster.initial_master_nodes=es-master
      - ES_JAVA_OPTS=-Xms16g -Xmx16g
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - es-data-1-data:/usr/share/elasticsearch/data
    networks:
      - elk
    depends_on:
      - elasticsearch-master
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '8'
          memory: 32G
        reservations:
          cpus: '4'
          memory: 16G
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ========================================
  # Elasticsearch Data Node 2
  # ========================================
  elasticsearch-data-2:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es-data-2
    environment:
      - node.name=es-data-2
      - node.roles=data,ingest
      - cluster.name=docker-elk-cluster
      - discovery.seed_hosts=es-master,es-data-1
      - cluster.initial_master_nodes=es-master
      - ES_JAVA_OPTS=-Xms16g -Xmx16g
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - es-data-2-data:/usr/share/elasticsearch/data
    networks:
      - elk
    depends_on:
      - elasticsearch-master
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '8'
          memory: 32G
        reservations:
          cpus: '4'
          memory: 16G

  # ========================================
  # Kibana
  # ========================================
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    environment:
      # Elasticsearchè¿æ¥
      - ELASTICSEARCH_HOSTS=http://elasticsearch-master:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}

      # Kibanaé…ç½®
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=5601

      # ä¸­æ–‡æ”¯æŒ
      - I18N_LOCALE=zh-CN

      # ç›‘æ§é…ç½®
      - MONITORING_ENABLED=true
      - XPACK_MONITORING_UI_CONTAINER_ELASTICSEARCH_ENABLED=true
    volumes:
      - kibana-data:/usr/share/kibana/data
      - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    networks:
      - elk
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch-master
    deploy:
      mode: replicated
      replicas: 2
      placement:
        max_replicas_per_node: 1
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:5601/api/status | grep -q '\"state\":\"green\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ========================================
  # Logstash
  # ========================================
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch-master:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - LS_JAVA_OPTS=-Xms2g -Xmx2g
      - XPACK_MONITORING_ENABLED=true
      - XPACK_MONITORING_ELASTICSEARCH_HOSTS=http://elasticsearch-master:9200
    volumes:
      - ./logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    networks:
      - elk
    ports:
      - "5044:5044"  # Beats input
      - "9600:9600"  # Logstash monitoring API
    depends_on:
      - elasticsearch-master
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9600/_node/stats"]
      interval: 30s
      timeout: 10s
      retries: 5

networks:
  elk:
    driver: overlay
    attachable: true

volumes:
  es-master-data:
  es-data-1-data:
  es-data-2-data:
  kibana-data:
```

**2. Elasticsearché…ç½®æ–‡ä»¶**:

```yaml
# elk/elasticsearch/elasticsearch.yml
# ========================================
# é›†ç¾¤é…ç½®
# ========================================
cluster.name: docker-elk-cluster

# ========================================
# èŠ‚ç‚¹é…ç½®
# ========================================
node.name: ${HOSTNAME}
node.roles: [ master, data, ingest ]

# ========================================
# è·¯å¾„é…ç½®
# ========================================
path.data: /usr/share/elasticsearch/data
path.logs: /usr/share/elasticsearch/logs

# ========================================
# ç½‘ç»œé…ç½®
# ========================================
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300

# ========================================
# å‘ç°é…ç½®
# ========================================
discovery.seed_hosts:
  - es-master
  - es-data-1
  - es-data-2

cluster.initial_master_nodes:
  - es-master

# ========================================
# å†…å­˜é…ç½®
# ========================================
bootstrap.memory_lock: true

# ========================================
# å®‰å…¨é…ç½®
# ========================================
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: false  # ç”Ÿäº§ç¯å¢ƒå»ºè®®å¯ç”¨
xpack.security.http.ssl.enabled: false       # ç”Ÿäº§ç¯å¢ƒå»ºè®®å¯ç”¨

# ========================================
# ç´¢å¼•é…ç½®
# ========================================
# é»˜è®¤åˆ†ç‰‡å’Œå‰¯æœ¬
index.number_of_shards: 3
index.number_of_replicas: 1

# æ…¢æŸ¥è¯¢æ—¥å¿—
index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.indexing.slowlog.threshold.index.warn: 10s

# ========================================
# çº¿ç¨‹æ± é…ç½®
# ========================================
thread_pool.write.queue_size: 1000
thread_pool.search.queue_size: 1000

# ========================================
# ç¼“å­˜é…ç½®
# ========================================
indices.queries.cache.size: 10%
indices.fielddata.cache.size: 20%
indices.requests.cache.size: 2%

# ========================================
# ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ========================================
xpack.ilm.enabled: true
```

**3. JVMé…ç½®**:

```bash
# elk/elasticsearch/jvm.options
# ========================================
# Heap Size (æ ¹æ®èŠ‚ç‚¹ç±»å‹è°ƒæ•´)
# ========================================
# MasterèŠ‚ç‚¹
-Xms2g
-Xmx2g

# DataèŠ‚ç‚¹(å»ºè®®ç‰©ç†å†…å­˜çš„50%, æœ€å¤§32GB)
# -Xms16g
# -Xmx16g

# ========================================
# GCé…ç½® (ä½¿ç”¨G1 GC)
# ========================================
-XX:+UseG1GC
-XX:G1ReservePercent=25
-XX:InitiatingHeapOccupancyPercent=30

# ========================================
# GCæ—¥å¿—
# ========================================
-Xlog:gc*,gc+age=trace,safepoint:file=/usr/share/elasticsearch/logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m

# ========================================
# å †è½¬å‚¨
# ========================================
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=/usr/share/elasticsearch/logs/heapdump.hprof

# ========================================
# é”™è¯¯æ—¥å¿—
# ========================================
-XX:ErrorFile=/usr/share/elasticsearch/logs/hs_err_pid%p.log
```

### 16.2.3 ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†(ILM)

**ILMç­–ç•¥é…ç½®**:

```bash
# åˆ›å»ºæ—¥å¿—ç´¢å¼•ILMç­–ç•¥
PUT _ilm/policy/logs-policy
{
  "policy": {
    "phases": {
      # ========================================
      # Hoté˜¶æ®µ: æ´»è·ƒå†™å…¥(0-3å¤©)
      # ========================================
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50GB",       # ç´¢å¼•å¤§å°è¶…è¿‡50GBåˆ™æ»šåŠ¨
            "max_age": "1d",          # ç´¢å¼•åˆ›å»º1å¤©åæ»šåŠ¨
            "max_docs": 100000000     # ç´¢å¼•æ–‡æ¡£æ•°è¶…è¿‡1äº¿åˆ™æ»šåŠ¨
          },
          "set_priority": {
            "priority": 100           # é«˜ä¼˜å…ˆçº§
          }
        }
      },

      # ========================================
      # Warmé˜¶æ®µ: åªè¯»,å¯æŸ¥è¯¢(3-7å¤©)
      # ========================================
      "warm": {
        "min_age": "3d",
        "actions": {
          "readonly": {},             # è®¾ç½®ä¸ºåªè¯»
          "forcemerge": {
            "max_num_segments": 1     # å¼ºåˆ¶åˆå¹¶ä¸º1ä¸ªæ®µ(æé«˜æŸ¥è¯¢æ€§èƒ½)
          },
          "shrink": {
            "number_of_shards": 1     # ç¼©å‡åˆ†ç‰‡æ•°(èŠ‚çœèµ„æº)
          },
          "allocate": {
            "number_of_replicas": 1   # ä¿ç•™1ä¸ªå‰¯æœ¬
          },
          "set_priority": {
            "priority": 50            # ä¸­ç­‰ä¼˜å…ˆçº§
          }
        }
      },

      # ========================================
      # Coldé˜¶æ®µ: å½’æ¡£å­˜å‚¨(7-30å¤©)
      # ========================================
      "cold": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "require": {
              "data": "cold"          # è¿ç§»åˆ°å†·æ•°æ®èŠ‚ç‚¹
            },
            "number_of_replicas": 0   # ä¸ä¿ç•™å‰¯æœ¬(èŠ‚çœç©ºé—´)
          },
          "freeze": {},               # å†»ç»“ç´¢å¼•(æå°‘æŸ¥è¯¢)
          "set_priority": {
            "priority": 0             # ä½ä¼˜å…ˆçº§
          }
        }
      },

      # ========================================
      # Deleteé˜¶æ®µ: åˆ é™¤(30å¤©å)
      # ========================================
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}                # åˆ é™¤ç´¢å¼•
        }
      }
    }
  }
}

# åˆ›å»ºç´¢å¼•æ¨¡æ¿å¹¶åº”ç”¨ILMç­–ç•¥
PUT _index_template/logs-template
{
  "index_patterns": ["logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "index.lifecycle.name": "logs-policy",
      "index.lifecycle.rollover_alias": "logs"
    },
    "mappings": {
      "properties": {
        "@timestamp": {
          "type": "date"
        },
        "level": {
          "type": "keyword"
        },
        "message": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "container_name": {
          "type": "keyword"
        },
        "service_name": {
          "type": "keyword"
        },
        "host": {
          "type": "keyword"
        }
      }
    }
  }
}

# åˆ›å»ºåˆå§‹ç´¢å¼•
PUT logs-000001
{
  "aliases": {
    "logs": {
      "is_write_index": true
    }
  }
}
```

**éªŒè¯ILMç­–ç•¥**:

```bash
# æŸ¥çœ‹ILMç­–ç•¥
GET _ilm/policy/logs-policy

# æŸ¥çœ‹ç´¢å¼•çš„ILMçŠ¶æ€
GET logs-*/_ilm/explain

# æ‰‹åŠ¨è§¦å‘rollover(æµ‹è¯•ç”¨)
POST logs/_rollover

# æŸ¥çœ‹ILMç»Ÿè®¡ä¿¡æ¯
GET _ilm/status
```

---

## 16.3 Fluentdæ—¥å¿—æ”¶é›†

### 16.3.1 Fluentdéƒ¨ç½²é…ç½®

**Fluentd Stacké…ç½®**:

```yaml
# elk/stack.yml (æ·»åŠ åˆ°ç°æœ‰é…ç½®)
services:
  # ========================================
  # Fluentd Aggregator(æ±‡èšèŠ‚ç‚¹)
  # ========================================
  fluentd:
    image: fluent/fluentd:v1.16-1
    container_name: fluentd
    volumes:
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - ./fluentd/plugins:/fluentd/plugins:ro
      - fluentd-buffer:/fluentd/buffer
    networks:
      - elk
    ports:
      - "24224:24224"   # Forward input
      - "24224:24224/udp"
      - "9880:9880"     # HTTP input
    environment:
      - FLUENTD_CONF=fluent.conf
      - ELASTICSEARCH_HOST=elasticsearch-master
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_USER=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
    depends_on:
      - elasticsearch-master
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9880/api/plugins.json"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ========================================
  # Fluent Bit (è½»é‡çº§é‡‡é›†å™¨,æ¯ä¸ªèŠ‚ç‚¹)
  # ========================================
  fluent-bit:
    image: fluent/fluent-bit:2.2
    volumes:
      - ./fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
    networks:
      - elk
    deploy:
      mode: global  # æ¯ä¸ªèŠ‚ç‚¹ä¸€ä¸ªå®ä¾‹
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

volumes:
  fluentd-buffer:
```

**Fluentdé…ç½®æ–‡ä»¶**:

```ruby
# elk/fluentd/fluent.conf
# ========================================
# Source: æ¥æ”¶Dockeræ—¥å¿—
# ========================================
<source>
  @type forward
  @id docker_forward
  @label @docker
  port 24224
  bind 0.0.0.0

  # å®‰å…¨é…ç½®
  <security>
    self_hostname fluentd
    shared_key ${FLUENTD_SHARED_KEY}
  </security>

  # ç¼“å†²é…ç½®
  <transport tls>
    cert_path /fluentd/certs/fluentd.crt
    private_key_path /fluentd/certs/fluentd.key
  </transport>
</source>

# ========================================
# Source: HTTPè¾“å…¥(åº”ç”¨ç›´æ¥å‘é€æ—¥å¿—)
# ========================================
<source>
  @type http
  @id http_input
  @label @app
  port 9880
  bind 0.0.0.0

  # è§£æJSON
  <parse>
    @type json
    time_key timestamp
    time_format %iso8601
  </parse>
</source>

# ========================================
# Source: Syslogè¾“å…¥
# ========================================
<source>
  @type syslog
  @id syslog_input
  @label @syslog
  port 5140
  bind 0.0.0.0
  tag system

  <parse>
    message_format rfc5424
  </parse>
</source>

# ========================================
# Label: Dockeræ—¥å¿—å¤„ç†
# ========================================
<label @docker>
  # Filter: è§£æDockeræ—¥å¿—
  <filter docker.**>
    @type parser
    key_name log
    reserve_data true
    remove_key_name_field false

    <parse>
      @type json
      time_key timestamp
      time_format %iso8601
      keep_time_key true
    </parse>
  </filter>

  # Filter: æ·»åŠ Kuberneteså…ƒæ•°æ®(å¦‚æœä½¿ç”¨K8s)
  <filter docker.**>
    @type record_transformer
    enable_ruby true

    <record>
      # æå–å®¹å™¨åç§°
      container_name ${record["container_name"] || "unknown"}

      # æå–å®¹å™¨ID
      container_id ${record["container_id"] || "unknown"}

      # æ·»åŠ ä¸»æœºå
      hostname "#{Socket.gethostname}"

      # æ·»åŠ æ—¶é—´æˆ³(å¦‚æœä¸å­˜åœ¨)
      timestamp ${record["timestamp"] || Time.now.iso8601}
    </record>
  </filter>

  # Filter: åˆ é™¤æ•æ„Ÿä¿¡æ¯
  <filter docker.**>
    @type grep
    <exclude>
      key message
      pattern /(password|secret|token|key)=/i
    </exclude>
  </filter>

  # Filter: å¤šè¡Œæ—¥å¿—åˆå¹¶(Javaå †æ ˆè·Ÿè¸ª)
  <filter docker.app.**>
    @type concat
    key message
    multiline_start_regexp /^(\d{4}-\d{2}-\d{2}|Exception|Error)/
    multiline_end_regexp /^\s*at\s+/
    flush_interval 5s
    timeout_label @output
  </filter>

  # Match: è¾“å‡ºåˆ°Elasticsearch
  <match docker.**>
    @type elasticsearch
    @id elasticsearch_docker
    @log_level info

    # Elasticsearchè¿æ¥
    host "#{ENV['ELASTICSEARCH_HOST']}"
    port "#{ENV['ELASTICSEARCH_PORT']}"
    user "#{ENV['ELASTICSEARCH_USER']}"
    password "#{ENV['ELASTICSEARCH_PASSWORD']}"
    scheme http

    # ç´¢å¼•é…ç½®
    index_name logs-docker-%Y.%m.%d
    logstash_format true
    logstash_prefix logs-docker
    logstash_dateformat %Y.%m.%d

    # ç±»å‹æ˜ å°„
    type_name _doc

    # ç¼“å†²é…ç½®
    <buffer tag, time>
      @type file
      path /fluentd/buffer/docker

      # ç¼“å†²å—é…ç½®
      chunk_limit_size 16MB
      chunk_limit_records 10000

      # åˆ·æ–°é…ç½®
      flush_mode interval
      flush_interval 10s
      flush_at_shutdown true

      # é‡è¯•é…ç½®
      retry_type exponential_backoff
      retry_wait 1s
      retry_max_interval 60s
      retry_timeout 1h
      retry_max_times 10

      # æº¢å‡ºé…ç½®
      overflow_action drop_oldest_chunk

      # é˜Ÿåˆ—é…ç½®
      total_limit_size 1GB
    </buffer>

    # æ‰¹é‡å†™å…¥é…ç½®
    bulk_message_request_threshold 20MB

    # å¥åº·æ£€æŸ¥
    health_check_uri /
    health_check_interval 30s

    # æ¨¡æ¿é…ç½®
    template_name logs-docker
    template_file /fluentd/etc/docker-template.json
    template_overwrite true

    # é”™è¯¯å¤„ç†
    <secondary>
      @type file
      path /fluentd/buffer/failed/docker
      compress gzip
    </secondary>
  </match>
</label>

# ========================================
# Label: åº”ç”¨æ—¥å¿—å¤„ç†
# ========================================
<label @app>
  # Filter: æ·»åŠ æ ‡å‡†å­—æ®µ
  <filter app.**>
    @type record_transformer
    <record>
      source application
      environment production
      timestamp ${time.iso8601}
    </record>
  </filter>

  # Match: æ ¹æ®æ—¥å¿—çº§åˆ«è·¯ç”±
  <match app.**>
    @type rewrite_tag_filter

    <rule>
      key level
      pattern /^(ERROR|FATAL)$/
      tag app.error.${tag}
    </rule>

    <rule>
      key level
      pattern /^WARN$/
      tag app.warn.${tag}
    </rule>

    <rule>
      key level
      pattern /.*/
      tag app.info.${tag}
    </rule>
  </match>

  # Match: Errorçº§åˆ«æ—¥å¿—
  <match app.error.**>
    @type copy

    # å‘é€åˆ°Elasticsearch
    <store>
      @type elasticsearch
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      user "#{ENV['ELASTICSEARCH_USER']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      index_name logs-app-error-%Y.%m.%d

      <buffer>
        @type file
        path /fluentd/buffer/app-error
        flush_interval 5s
      </buffer>
    </store>

    # å‘é€å‘Šè­¦
    <store>
      @type http
      endpoint http://alertmanager:9093/api/v1/alerts
      open_timeout 2
      json_array true

      <format>
        @type json
      </format>

      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>

  # Match: å…¶ä»–çº§åˆ«æ—¥å¿—
  <match app.**>
    @type elasticsearch
    host "#{ENV['ELASTICSEARCH_HOST']}"
    port "#{ENV['ELASTICSEARCH_PORT']}"
    user "#{ENV['ELASTICSEARCH_USER']}"
    password "#{ENV['ELASTICSEARCH_PASSWORD']}"
    index_name logs-app-%Y.%m.%d

    <buffer>
      @type file
      path /fluentd/buffer/app
      flush_interval 10s
    </buffer>
  </match>
</label>

# ========================================
# ç³»ç»Ÿç›‘æ§
# ========================================
<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

# ========================================
# Prometheusç›‘æ§æŒ‡æ ‡
# ========================================
<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>

<source>
  @type prometheus_monitor
  <labels>
    host #{Socket.gethostname}
  </labels>
</source>

<source>
  @type prometheus_output_monitor
  <labels>
    host #{Socket.gethostname}
  </labels>
</source>
```

**Elasticsearchç´¢å¼•æ¨¡æ¿**:

```json
// elk/fluentd/docker-template.json
{
  "index_patterns": ["logs-docker-*"],
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index.lifecycle.name": "logs-policy",
    "index.lifecycle.rollover_alias": "logs-docker",
    "index.refresh_interval": "5s",
    "index.translog.durability": "async",
    "index.translog.sync_interval": "30s"
  },
  "mappings": {
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "container_name": {
        "type": "keyword"
      },
      "container_id": {
        "type": "keyword"
      },
      "source": {
        "type": "keyword"
      },
      "level": {
        "type": "keyword"
      },
      "message": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 512
          }
        },
        "norms": false
      },
      "hostname": {
        "type": "keyword"
      },
      "tags": {
        "type": "keyword"
      }
    }
  }
}
```

### 16.3.2 Fluent Bité…ç½®(è½»é‡çº§é‡‡é›†)

```ini
# elk/fluent-bit/fluent-bit.conf
[SERVICE]
    Flush        5
    Daemon       Off
    Log_Level    info
    Parsers_File parsers.conf

# ========================================
# Input: Dockerå®¹å™¨æ—¥å¿—
# ========================================
[INPUT]
    Name              tail
    Path              /var/lib/docker/containers/*/*.log
    Parser            docker
    Tag               docker.*
    Refresh_Interval  5
    Mem_Buf_Limit     50MB
    Skip_Long_Lines   On
    DB                /fluent-bit/tail-docker.db

# ========================================
# Input: ç³»ç»Ÿæ—¥å¿—
# ========================================
[INPUT]
    Name   systemd
    Tag    systemd.*
    Read_From_Tail On

# ========================================
# Filter: è§£æDocker JSON
# ========================================
[FILTER]
    Name                parser
    Match               docker.*
    Key_Name            log
    Parser              docker-json
    Reserve_Data        True
    Preserve_Key        True

# ========================================
# Filter: æ·»åŠ Kuberneteså…ƒæ•°æ®(å¯é€‰)
# ========================================
[FILTER]
    Name                kubernetes
    Match               docker.*
    Kube_URL            https://kubernetes.default.svc:443
    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
    Kube_Tag_Prefix     docker.var.log.containers.
    Merge_Log           On
    Keep_Log            Off

# ========================================
# Output: è½¬å‘åˆ°Fluentd
# ========================================
[OUTPUT]
    Name          forward
    Match         *
    Host          fluentd
    Port          24224
    Retry_Limit   10

    # TLSé…ç½®
    tls           on
    tls_verify    off

    # å…±äº«å¯†é’¥
    Shared_Key    ${FLUENTD_SHARED_KEY}
```

**Parseré…ç½®**:

```ini
# elk/fluent-bit/parsers.conf
[PARSER]
    Name   docker
    Format json
    Time_Key time
    Time_Format %Y-%m-%dT%H:%M:%S.%LZ
    Time_Keep On

[PARSER]
    Name   docker-json
    Format json
    Time_Key timestamp
    Time_Format %Y-%m-%dT%H:%M:%S.%LZ

[PARSER]
    Name   nginx
    Format regex
    Regex ^(?<remote>[^ ]*) - (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z

[PARSER]
    Name   syslog
    Format regex
    Regex ^\<(?<pri>[0-9]+)\>(?<time>[^ ]* {1,2}[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[a-zA-Z0-9_\/\.\-]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? *(?<message>.*)$
    Time_Key time
    Time_Format %b %d %H:%M:%S
```

---

*ï¼ˆç¬¬16ç« å®Œæˆ,çº¦2500è¡Œã€‚å·²å®Œæˆ16ç« ,å‰©ä½™3ç« ...ï¼‰*

---

# ç¬¬17ç« : æ€§èƒ½ä¼˜åŒ–

## 17.1 å®¹å™¨æ€§èƒ½åˆ†æåŸºç¡€

### 17.1.1 æ€§èƒ½åˆ†ææ–¹æ³•è®º

**USEæ–¹æ³•ï¼ˆUtilization, Saturation, Errorsï¼‰**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           å®¹å™¨æ€§èƒ½åˆ†æUSEæ–¹æ³•                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  [1] Utilization (åˆ©ç”¨ç‡)                                â”‚
â”‚      â”œâ”€ CPUåˆ©ç”¨ç‡                                         â”‚
â”‚      â”œâ”€ å†…å­˜åˆ©ç”¨ç‡                                         â”‚
â”‚      â”œâ”€ ç½‘ç»œå¸¦å®½åˆ©ç”¨ç‡                                      â”‚
â”‚      â””â”€ ç£ç›˜IOåˆ©ç”¨ç‡                                       â”‚
â”‚                                                         â”‚
â”‚  [2] Saturation (é¥±å’Œåº¦)                                 â”‚
â”‚      â”œâ”€ CPUè¿è¡Œé˜Ÿåˆ—é•¿åº¦                                    â”‚
â”‚      â”œâ”€ å†…å­˜é¡µé¢äº¤æ¢                                       â”‚
â”‚      â”œâ”€ ç½‘ç»œæ•°æ®åŒ…é˜Ÿåˆ—                                      â”‚
â”‚      â””â”€ ç£ç›˜IOç­‰å¾…é˜Ÿåˆ—                                     â”‚
â”‚                                                         â”‚
â”‚  [3] Errors (é”™è¯¯ç‡)                                     â”‚
â”‚      â”œâ”€ ç½‘ç»œä¸¢åŒ…ç‡                                         â”‚
â”‚      â”œâ”€ ç£ç›˜è¯»å†™é”™è¯¯                                       â”‚
â”‚      â”œâ”€ OOM Killeräº‹ä»¶                                   â”‚
â”‚      â””â”€ å®¹å™¨é‡å¯æ¬¡æ•°                                       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**REDæ–¹æ³•ï¼ˆRate, Errors, Durationï¼‰- åº”ç”¨å±‚**
```yaml
# æœåŠ¡çº§åˆ«æ€§èƒ½æŒ‡æ ‡
REDæ–¹æ³•:
  Rate (è¯·æ±‚ç‡):
    - æ¯ç§’è¯·æ±‚æ•° (RPS)
    - æ¯åˆ†é’Ÿäº‹åŠ¡æ•° (TPM)

  Errors (é”™è¯¯ç‡):
    - HTTP 5xxé”™è¯¯ç‡
    - è¶…æ—¶é”™è¯¯ç‡
    - ä¸šåŠ¡é€»è¾‘é”™è¯¯ç‡

  Duration (å“åº”æ—¶é—´):
    - P50å»¶è¿Ÿ (ä¸­ä½æ•°)
    - P95å»¶è¿Ÿ
    - P99å»¶è¿Ÿ
    - æœ€å¤§å»¶è¿Ÿ
```

### 17.1.2 æ€§èƒ½åˆ†æå·¥å…·æ ˆ

**å·¥å…·é€‰æ‹©çŸ©é˜µ**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   åˆ†æå±‚æ¬¡     â”‚   ä¸»è¦å·¥å…·   â”‚   é€‚ç”¨åœºæ™¯    â”‚   å¼€é”€ç­‰çº§   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç³»ç»Ÿçº§       â”‚ top/htop    â”‚ å®æ—¶ç›‘æ§      â”‚ ä½          â”‚
â”‚ ç³»ç»Ÿçº§       â”‚ vmstat      â”‚ å†…å­˜/CPUåˆ†æ  â”‚ ä½          â”‚
â”‚ ç³»ç»Ÿçº§       â”‚ iostat      â”‚ ç£ç›˜IOåˆ†æ    â”‚ ä½          â”‚
â”‚ ç³»ç»Ÿçº§       â”‚ netstat     â”‚ ç½‘ç»œè¿æ¥åˆ†æ  â”‚ ä½          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å®¹å™¨çº§       â”‚ docker statsâ”‚ å®¹å™¨èµ„æºç›‘æ§  â”‚ ä½          â”‚
â”‚ å®¹å™¨çº§       â”‚ cAdvisor    â”‚ è¯¦ç»†æŒ‡æ ‡é‡‡é›†  â”‚ ä¸­          â”‚
â”‚ å®¹å™¨çº§       â”‚ ctop        â”‚ äº¤äº’å¼ç›‘æ§    â”‚ ä½          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¿›ç¨‹çº§       â”‚ strace      â”‚ ç³»ç»Ÿè°ƒç”¨è¿½è¸ª  â”‚ é«˜          â”‚
â”‚ è¿›ç¨‹çº§       â”‚ lsof        â”‚ æ–‡ä»¶å¥æŸ„åˆ†æ  â”‚ ä½          â”‚
â”‚ è¿›ç¨‹çº§       â”‚ pmap        â”‚ å†…å­˜æ˜ å°„åˆ†æ  â”‚ ä½          â”‚
â”‚ è¿›ç¨‹çº§       â”‚ perf        â”‚ CPUæ€§èƒ½åˆ†æ   â”‚ ä¸­-é«˜       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ åº”ç”¨çº§       â”‚ JProfiler   â”‚ Javaæ€§èƒ½åˆ†æ  â”‚ é«˜          â”‚
â”‚ åº”ç”¨çº§       â”‚ py-spy      â”‚ Pythonæ€§èƒ½åˆ†æâ”‚ ä¸­          â”‚
â”‚ åº”ç”¨çº§       â”‚ pprof       â”‚ Goæ€§èƒ½åˆ†æ    â”‚ ä¸­          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**cAdvisorå®¹å™¨ç›‘æ§éƒ¨ç½²**
```yaml
# docker-stack-cadvisor.yml
version: '3.8'

services:
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    hostname: '{{.Node.Hostname}}'
    command:
      - '--housekeeping_interval=10s'
      - '--docker_only=true'
      - '--storage_duration=1m0s'
      - '--disable_metrics=disk,network,tcp,udp,percpu,sched,process'
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    deploy:
      mode: global  # æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œä¸€ä¸ªå®ä¾‹
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
```

**éƒ¨ç½²cAdvisor**
```bash
# éƒ¨ç½²cAdvisoråˆ°æ‰€æœ‰èŠ‚ç‚¹
docker stack deploy -c docker-stack-cadvisor.yml monitoring

# éªŒè¯éƒ¨ç½²
docker service ls | grep cadvisor

# æŸ¥çœ‹æŒ‡æ ‡ï¼ˆé€‰æ‹©ä»»ä¸€èŠ‚ç‚¹ï¼‰
curl http://localhost:8080/metrics | grep container_cpu

# ç¤ºä¾‹è¾“å‡º
container_cpu_usage_seconds_total{id="/docker/abc123"} 124.5
container_memory_usage_bytes{id="/docker/abc123"} 524288000
```

### 17.1.3 æ€§èƒ½åŸºå‡†æµ‹è¯•

**å®¹å™¨å¯åŠ¨æ€§èƒ½æµ‹è¯•**
```bash
#!/bin/bash
# benchmark-container-startup.sh - å®¹å™¨å¯åŠ¨æ€§èƒ½åŸºå‡†æµ‹è¯•

IMAGE="nginx:alpine"
ITERATIONS=100

echo "å®¹å™¨å¯åŠ¨æ€§èƒ½æµ‹è¯• - è¿­ä»£æ¬¡æ•°: $ITERATIONS"
echo "é•œåƒ: $IMAGE"
echo "----------------------------------------"

# æµ‹è¯•1: å†·å¯åŠ¨ï¼ˆæ¯æ¬¡åˆ é™¤å®¹å™¨ï¼‰
total_time=0
for i in $(seq 1 $ITERATIONS); do
    start=$(date +%s%N)

    docker run -d --name test-$i $IMAGE >/dev/null
    docker wait test-$i >/dev/null 2>&1 &
    sleep 0.1
    docker rm -f test-$i >/dev/null

    end=$(date +%s%N)
    elapsed=$(( (end - start) / 1000000 ))  # è½¬æ¢ä¸ºæ¯«ç§’
    total_time=$(( total_time + elapsed ))

    if [ $(( i % 10 )) -eq 0 ]; then
        echo "è¿›åº¦: $i/$ITERATIONS"
    fi
done

avg_time=$(( total_time / ITERATIONS ))
echo ""
echo "å†·å¯åŠ¨å¹³å‡æ—¶é—´: ${avg_time}ms"

# æµ‹è¯•2: çƒ­å¯åŠ¨ï¼ˆå¤ç”¨å®¹å™¨ï¼‰
echo ""
echo "æµ‹è¯•çƒ­å¯åŠ¨ï¼ˆstart/stopï¼‰..."

docker run -d --name test-hot $IMAGE >/dev/null
sleep 1

total_time=0
for i in $(seq 1 $ITERATIONS); do
    docker stop test-hot >/dev/null

    start=$(date +%s%N)
    docker start test-hot >/dev/null
    end=$(date +%s%N)

    elapsed=$(( (end - start) / 1000000 ))
    total_time=$(( total_time + elapsed ))
done

docker rm -f test-hot >/dev/null

avg_hot_time=$(( total_time / ITERATIONS ))
echo "çƒ­å¯åŠ¨å¹³å‡æ—¶é—´: ${avg_hot_time}ms"
echo ""
echo "æ€§èƒ½æå‡: $(( (avg_time - avg_hot_time) * 100 / avg_time ))%"
```

**æ‰§è¡ŒåŸºå‡†æµ‹è¯•**
```bash
chmod +x benchmark-container-startup.sh
./benchmark-container-startup.sh

# é¢„æœŸè¾“å‡º
å®¹å™¨å¯åŠ¨æ€§èƒ½æµ‹è¯• - è¿­ä»£æ¬¡æ•°: 100
é•œåƒ: nginx:alpine
----------------------------------------
è¿›åº¦: 10/100
è¿›åº¦: 20/100
...
å†·å¯åŠ¨å¹³å‡æ—¶é—´: 523ms

æµ‹è¯•çƒ­å¯åŠ¨ï¼ˆstart/stopï¼‰...
çƒ­å¯åŠ¨å¹³å‡æ—¶é—´: 145ms

æ€§èƒ½æå‡: 72%
```

## 17.2 CPUæ€§èƒ½ä¼˜åŒ–

### 17.2.1 CPUé™åˆ¶ä¸é…é¢

**CPUèµ„æºé™åˆ¶ç­–ç•¥**
```yaml
# CPUé™åˆ¶é…ç½®ç¤ºä¾‹
services:
  web:
    image: myapp:latest
    deploy:
      resources:
        limits:
          cpus: '2.0'        # æœ€å¤šä½¿ç”¨2ä¸ªCPUæ ¸å¿ƒ
        reservations:
          cpus: '0.5'        # ä¿è¯è‡³å°‘0.5ä¸ªæ ¸å¿ƒ

  # å®æ—¶åº”ç”¨ - ä¸¥æ ¼CPUé…é¢
  realtime-processor:
    image: processor:latest
    deploy:
      resources:
        limits:
          cpus: '4.0'
        reservations:
          cpus: '4.0'        # é¢„ç•™ç­‰äºé™åˆ¶ - ç¡®ä¿ç‹¬å èµ„æº

  # æ‰¹å¤„ç†ä»»åŠ¡ - å¼¹æ€§CPUé…é¢
  batch-job:
    image: batch:latest
    deploy:
      resources:
        limits:
          cpus: '8.0'        # å³°å€¼å¯ç”¨8æ ¸
        reservations:
          cpus: '1.0'        # åŸºç¡€ä¿è¯1æ ¸
```

**CPUäº²å’Œæ€§ï¼ˆCPU Pinningï¼‰**
```yaml
# docker-compose-cpu-pinning.yml
version: '3.8'

services:
  # åœºæ™¯1: ç»‘å®šåˆ°ç‰¹å®šCPUæ ¸å¿ƒ
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    cpuset: "0,1"  # ä»…ä½¿ç”¨CPU 0å’Œ1
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
    volumes:
      - redis-data:/data

  # åœºæ™¯2: NUMAèŠ‚ç‚¹ä¼˜åŒ–
  database:
    image: postgres:15-alpine
    cpuset: "0-7"   # ä½¿ç”¨NUMAèŠ‚ç‚¹0çš„CPU (å‡è®¾0-7æ˜¯èŠ‚ç‚¹0)
    mem_limit: 16G
    environment:
      - POSTGRES_SHARED_BUFFERS=4GB
    deploy:
      placement:
        constraints:
          - node.labels.numa_node == 0

  # åœºæ™¯3: é¿å…CPU0ï¼ˆç³»ç»Ÿä¸­æ–­å¤„ç†ï¼‰
  app:
    image: myapp:latest
    cpuset: "2-15"  # é¿å¼€CPU 0-1,ç•™ç»™ç³»ç»Ÿå’Œå…³é”®æœåŠ¡
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '2.0'

volumes:
  redis-data:
```

**æŸ¥çœ‹NUMAæ‹“æ‰‘**
```bash
# å®‰è£…numactlå·¥å…·
apt-get update && apt-get install -y numactl

# æŸ¥çœ‹NUMAèŠ‚ç‚¹ä¿¡æ¯
numactl --hardware

# ç¤ºä¾‹è¾“å‡º
available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23
node 0 size: 65536 MB
node 0 free: 32768 MB
node 1 cpus: 8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31
node 1 size: 65536 MB
node 1 free: 45678 MB

# æŸ¥çœ‹è¿›ç¨‹NUMAåˆ†é…
numastat -p $(docker inspect -f '{{.State.Pid}}' container_name)
```

**è¿è¡Œæ—¶ä¿®æ”¹CPUé…é¢**
```bash
# åŠ¨æ€è°ƒæ•´CPUé™åˆ¶ï¼ˆæ— éœ€é‡å¯å®¹å™¨ï¼‰
docker update --cpus="4.0" --cpuset-cpus="0-3" my-container

# æŸ¥çœ‹å½“å‰CPUé…ç½®
docker inspect my-container | jq '.[0].HostConfig.CpuQuota'
docker inspect my-container | jq '.[0].HostConfig.CpusetCpus'

# éªŒè¯ç”Ÿæ•ˆ
docker stats my-container --no-stream
```

### 17.2.2 CPUæ€§èƒ½åˆ†æä¸è°ƒä¼˜

**ä½¿ç”¨perfè¿›è¡ŒCPUæ€§èƒ½åˆ†æ**
```bash
# å®‰è£…perfå·¥å…·
apt-get install -y linux-tools-common linux-tools-$(uname -r)

# è·å–å®¹å™¨PID
CONTAINER_PID=$(docker inspect -f '{{.State.Pid}}' my-app)

# æ–¹æ³•1: è®°å½•30ç§’çš„CPUæ€§èƒ½æ•°æ®
perf record -F 99 -p $CONTAINER_PID -g -- sleep 30

# ç”Ÿæˆç«ç„°å›¾å¯è§†åŒ–æ•°æ®
perf script | ./FlameGraph/stackcollapse-perf.pl | \
  ./FlameGraph/flamegraph.pl > cpu-flamegraph.svg

# æ–¹æ³•2: å®æ—¶æŸ¥çœ‹çƒ­ç‚¹å‡½æ•°
perf top -p $CONTAINER_PID

# æ–¹æ³•3: ç»Ÿè®¡CPUäº‹ä»¶
perf stat -p $CONTAINER_PID sleep 10

# ç¤ºä¾‹è¾“å‡º
 Performance counter stats for process id '12345':

      8,234.56 msec task-clock                #    0.823 CPUs utilized
         1,234      context-switches          #    0.150 K/sec
            12      cpu-migrations            #    0.001 K/sec
         5,678      page-faults               #    0.689 K/sec
23,456,789,012      cycles                    #    2.848 GHz
15,678,901,234      instructions              #    0.67  insn per cycle
 3,456,789,012      branches                  #  419.876 M/sec
    12,345,678      branch-misses             #    0.36% of all branches
```

**CPUä¸Šä¸‹æ–‡åˆ‡æ¢åˆ†æ**
```bash
# ç›‘æ§å®¹å™¨çš„ä¸Šä¸‹æ–‡åˆ‡æ¢
docker stats --format "table {{.Container}}\t{{.CPUPerc}}" --no-stream

# ä½¿ç”¨pidstatæŸ¥çœ‹è¯¦ç»†ä¸Šä¸‹æ–‡åˆ‡æ¢
apt-get install -y sysstat

# æ¯ç§’é‡‡æ ·ä¸€æ¬¡,æ˜¾ç¤º5æ¬¡
pidstat -w -p $CONTAINER_PID 1 5

# ç¤ºä¾‹è¾“å‡º - é«˜ä¸Šä¸‹æ–‡åˆ‡æ¢ç¤ºä¾‹
12:00:01      PID   cswch/s nvcswch/s  Command
12:00:02    12345    523.00   1234.00  java
12:00:03    12345    567.00   1456.00  java
# cswch/s: è‡ªæ„¿ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ˆIOç­‰å¾…ï¼‰
# nvcswch/s: éè‡ªæ„¿ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ˆæ—¶é—´ç‰‡ç”¨å®Œï¼‰

# å¦‚æœnvcswch/så¾ˆé«˜,è¯´æ˜CPUç«äº‰ä¸¥é‡,éœ€è¦:
# 1. å¢åŠ CPUé…é¢
# 2. å‡å°‘çº¿ç¨‹æ•°
# 3. ä¼˜åŒ–åº”ç”¨é€»è¾‘
```

**CPUä¸­æ–­åˆ†æ**
```bash
# æŸ¥çœ‹ä¸­æ–­åˆ†å¸ƒ
watch -n 1 'cat /proc/interrupts | head -20'

# æŸ¥çœ‹è½¯ä¸­æ–­
watch -n 1 'cat /proc/softirqs'

# å°†ç½‘ç»œä¸­æ–­ç»‘å®šåˆ°ç‰¹å®šCPUï¼ˆé¿å…å¹²æ‰°åº”ç”¨ï¼‰
# æŸ¥æ‰¾ç½‘å¡ä¸­æ–­å·
grep eth0 /proc/interrupts

# è®¾ç½®CPUäº²å’Œæ€§ï¼ˆç¤ºä¾‹ï¼šç»‘å®šåˆ°CPU 0ï¼‰
echo 1 > /proc/irq/123/smp_affinity_list  # 123æ˜¯ä¸­æ–­å·
```

### 17.2.3 CPUè°ƒåº¦ä¼˜åŒ–

**CFSè°ƒåº¦å™¨å‚æ•°è°ƒä¼˜**
```bash
# è°ƒæ•´å®¹å™¨CPUæƒé‡ï¼ˆsharesï¼‰
# é»˜è®¤å€¼1024,å€¼è¶Šå¤§è·å¾—çš„CPUæ—¶é—´è¶Šå¤š

# ç¤ºä¾‹:å…³é”®æœåŠ¡è·å¾—æ›´å¤šCPUæ—¶é—´
docker run -d \
  --name critical-service \
  --cpu-shares 2048 \    # 2å€æƒé‡
  myapp:latest

docker run -d \
  --name background-task \
  --cpu-shares 512 \     # 0.5å€æƒé‡
  batch:latest

# éªŒè¯:åœ¨CPUç«äº‰æ—¶,critical-serviceè·å¾—çš„CPUæ—¶é—´æ˜¯background-taskçš„4å€
```

**å®æ—¶è°ƒåº¦ç­–ç•¥ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰**
```yaml
# docker-compose-realtime.yml
version: '3.8'

services:
  realtime-app:
    image: realtime:latest
    # éœ€è¦å®¿ä¸»æœºå†…æ ¸æ”¯æŒCONFIG_RT_GROUP_SCHED
    cap_add:
      - SYS_NICE      # å…è®¸ä¿®æ”¹è¿›ç¨‹ä¼˜å…ˆçº§
    security_opt:
      - apparmor=unconfined
    deploy:
      resources:
        limits:
          cpus: '2.0'
        reservations:
          cpus: '2.0'  # ç¡®ä¿ç‹¬å CPU
```

**è¿›ç¨‹ä¼˜å…ˆçº§è°ƒæ•´**
```bash
# åœ¨å®¹å™¨å†…è°ƒæ•´è¿›ç¨‹ä¼˜å…ˆçº§
docker exec my-container bash -c '
  # æŸ¥çœ‹å½“å‰niceå€¼
  ps -eo pid,ni,comm | grep myapp

  # é™ä½ä¼˜å…ˆçº§ï¼ˆæé«˜niceå€¼:0åˆ°19ï¼‰
  renice +10 -p $(pgrep myapp)

  # æé«˜ä¼˜å…ˆçº§ï¼ˆé™ä½niceå€¼:-20åˆ°0,éœ€è¦rootï¼‰
  renice -5 -p $(pgrep myapp)
'

# ä½¿ç”¨chrtè®¾ç½®å®æ—¶ä¼˜å…ˆçº§ï¼ˆéœ€è¦CAP_SYS_NICEï¼‰
docker exec my-container chrt -f -p 50 $(pgrep myapp)
# -f: FIFOè°ƒåº¦ç­–ç•¥
# -p 50: å®æ—¶ä¼˜å…ˆçº§50ï¼ˆ1-99ï¼‰
```

## 17.3 å†…å­˜æ€§èƒ½ä¼˜åŒ–

### 17.3.1 å†…å­˜é™åˆ¶ä¸é¢„ç•™

**å†…å­˜é™åˆ¶æœ€ä½³å®è·µ**
```yaml
version: '3.8'

services:
  # åœºæ™¯1: Javaåº”ç”¨ - å †å†…å­˜+å…ƒç©ºé—´+å †å¤–å†…å­˜
  java-app:
    image: openjdk:17-slim
    environment:
      # JVMå †å†…å­˜=å®¹å™¨å†…å­˜çš„75%
      - JAVA_OPTS=-Xms2g -Xmx2g -XX:MaxMetaspaceSize=256m
    deploy:
      resources:
        limits:
          memory: 3G      # 2Gå †+256Må…ƒç©ºé—´+768Må †å¤–+OSå¼€é”€
        reservations:
          memory: 2G

  # åœºæ™¯2: Redis - å†…å­˜+æŒä¹…åŒ–ç¼“å†²
  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 7gb --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          memory: 8G      # 7Gæ•°æ®+1GæŒä¹…åŒ–ç¼“å†²
        reservations:
          memory: 4G

  # åœºæ™¯3: Nginx - æœ€å°å†…å­˜å ç”¨
  nginx:
    image: nginx:alpine
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # åœºæ™¯4: æ•°æ®åº“ - å¤§å†…å­˜+Swap
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_SHARED_BUFFERS=8GB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=24GB
    deploy:
      resources:
        limits:
          memory: 32G
        reservations:
          memory: 16G
    # å…è®¸ä½¿ç”¨Swapä½œä¸ºç¼“å†²
    mem_swappiness: 10
```

**å†…å­˜é¢„ç•™ä¸OOMä¼˜å…ˆçº§**
```yaml
services:
  # å…³é”®æœåŠ¡ - æœ€ä½OOMä¼˜å…ˆçº§
  critical-db:
    image: postgres:15
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 16G    # é¢„ç•™ç­‰äºé™åˆ¶
    # OOM Score Adj: -1000åˆ°1000
    # è¶Šä½è¶Šä¸å®¹æ˜“è¢«OOM Killeræ€æ­»
    oom_score_adj: -500

  # æ™®é€šæœåŠ¡ - é»˜è®¤OOMä¼˜å…ˆçº§
  web-app:
    image: webapp:latest
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    # é»˜è®¤oom_score_adj: 0

  # æ‰¹å¤„ç†ä»»åŠ¡ - é«˜OOMä¼˜å…ˆçº§ï¼ˆä¼˜å…ˆç‰ºç‰²ï¼‰
  batch-worker:
    image: worker:latest
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 2G
    oom_score_adj: 500
```

### 17.3.2 å†…å­˜æ€§èƒ½åˆ†æ

**å†…å­˜ä½¿ç”¨åˆ†æè„šæœ¬**
```bash
#!/bin/bash
# analyze-memory.sh - å®¹å™¨å†…å­˜è¯¦ç»†åˆ†æ

CONTAINER=$1

if [ -z "$CONTAINER" ]; then
    echo "ç”¨æ³•: $0 <å®¹å™¨åç§°>"
    exit 1
fi

echo "=========================================="
echo "å®¹å™¨å†…å­˜åˆ†æ: $CONTAINER"
echo "=========================================="

# 1. Docker Statså†…å­˜ç»Ÿè®¡
echo -e "\n[1] Docker Statså†…å­˜ä½¿ç”¨:"
docker stats $CONTAINER --no-stream --format \
  "table {{.MemUsage}}\t{{.MemPerc}}"

# 2. Cgroupå†…å­˜è¯¦ç»†ä¿¡æ¯
CONTAINER_ID=$(docker inspect -f '{{.Id}}' $CONTAINER)
CGROUP_PATH="/sys/fs/cgroup/memory/docker/$CONTAINER_ID"

if [ -d "$CGROUP_PATH" ]; then
    echo -e "\n[2] Cgroupå†…å­˜è¯¦ç»†:"
    echo "å†…å­˜é™åˆ¶: $(cat $CGROUP_PATH/memory.limit_in_bytes | \
      awk '{print $1/1024/1024 " MB"}')"
    echo "å½“å‰ä½¿ç”¨: $(cat $CGROUP_PATH/memory.usage_in_bytes | \
      awk '{print $1/1024/1024 " MB"}')"
    echo "ç¼“å­˜å†…å­˜: $(cat $CGROUP_PATH/memory.stat | \
      grep ^cache | awk '{print $2/1024/1024 " MB"}')"
    echo "RSSå†…å­˜: $(cat $CGROUP_PATH/memory.stat | \
      grep ^rss | head -1 | awk '{print $2/1024/1024 " MB"}')"
    echo "Swapä½¿ç”¨: $(cat $CGROUP_PATH/memory.memsw.usage_in_bytes | \
      awk '{print $1/1024/1024 " MB"}')"
fi

# 3. å®¹å™¨å†…è¿›ç¨‹å†…å­˜æ’è¡Œ
echo -e "\n[3] å®¹å™¨å†…TOP 5è¿›ç¨‹å†…å­˜ä½¿ç”¨:"
docker exec $CONTAINER sh -c '
  ps aux --sort=-%mem | head -6 | \
  awk "{printf \"%-15s %6s %6s %s\n\", \$1, \$3, \$4, \$11}"
'

# 4. æ£€æŸ¥OOMäº‹ä»¶
echo -e "\n[4] OOM Killeräº‹ä»¶:"
docker inspect $CONTAINER | \
  jq '.[0].State.OOMKilled'

# 5. å†…å­˜ç»Ÿè®¡å†å²ï¼ˆå¦‚æœæœ‰cAdvisorï¼‰
echo -e "\n[5] å†…å­˜è¶‹åŠ¿ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰:"
if command -v curl &> /dev/null; then
    curl -s "http://localhost:8080/api/v1.3/docker/$CONTAINER" | \
      jq -r '.stats[-60:] | .[] |
        "\(.timestamp) \(.memory_stats.usage / 1024 / 1024 | floor) MB"' | \
      tail -10 2>/dev/null || echo "cAdvisoræœªè¿è¡Œ"
fi

echo -e "\n=========================================="
```

**æ‰§è¡Œå†…å­˜åˆ†æ**
```bash
chmod +x analyze-memory.sh
./analyze-memory.sh my-app

# ç¤ºä¾‹è¾“å‡º
==========================================
å®¹å™¨å†…å­˜åˆ†æ: my-app
==========================================

[1] Docker Statså†…å­˜ä½¿ç”¨:
MEM USAGE / LIMIT   MEM %
1.234GiB / 2GiB     61.7%

[2] Cgroupå†…å­˜è¯¦ç»†:
å†…å­˜é™åˆ¶: 2048 MB
å½“å‰ä½¿ç”¨: 1264 MB
ç¼“å­˜å†…å­˜: 234 MB
RSSå†…å­˜: 1030 MB
Swapä½¿ç”¨: 0 MB

[3] å®¹å™¨å†…TOP 5è¿›ç¨‹å†…å­˜ä½¿ç”¨:
USER            CPU%   MEM%  COMMAND
app             45.2   58.3  /usr/bin/java
app             2.1    3.2   node
root            0.1    0.5   nginx
```

**Javaå †å†…å­˜åˆ†æ**
```bash
# å®¹å™¨å†…æ‰§è¡Œjmapåˆ†æ
docker exec my-java-app jmap -heap 1

# ç¤ºä¾‹è¾“å‡º
Heap Configuration:
   MinHeapFreeRatio         = 40
   MaxHeapFreeRatio         = 70
   MaxHeapSize              = 2147483648 (2048.0MB)
   NewSize                  = 715653120 (682.5MB)
   MaxNewSize               = 715653120 (682.5MB)
   OldSize                  = 1431830528 (1365.5MB)

Heap Usage:
New Generation (Eden + 1 Survivor Space):
   capacity = 644349952 (614.5MB)
   used     = 523678432 (499.3MB)    # 81.2%ä½¿ç”¨ç‡
   free     = 120671520 (115.2MB)

Eden Space:
   capacity = 572653568 (546.0MB)
   used     = 512345678 (488.6MB)    # 89.5%ä½¿ç”¨ç‡

Old Generation:
   capacity = 1431830528 (1365.5MB)
   used     = 834567890 (796.2MB)    # 58.3%ä½¿ç”¨ç‡

# ç”Ÿæˆå †è½¬å‚¨æ–‡ä»¶
docker exec my-java-app jmap -dump:format=b,file=/tmp/heap.hprof 1

# å¤åˆ¶åˆ°å®¿ä¸»æœºåˆ†æ
docker cp my-java-app:/tmp/heap.hprof ./
# ä½¿ç”¨MAT (Memory Analyzer Tool)åˆ†æ
```

### 17.3.3 Huge Pagesä¼˜åŒ–

**Huge Pagesé…ç½®**
```bash
# å®¿ä¸»æœºé…ç½®Huge Pages
# æŸ¥çœ‹å½“å‰é…ç½®
cat /proc/meminfo | grep Huge

# ç¤ºä¾‹è¾“å‡º
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB

# åˆ†é…1024ä¸ª2MBçš„Huge Pages (å…±2GB)
echo 1024 > /proc/sys/vm/nr_hugepages

# æŒä¹…åŒ–é…ç½®
cat >> /etc/sysctl.conf <<EOF
vm.nr_hugepages = 1024
vm.hugetlb_shm_group = 0
EOF

sysctl -p

# éªŒè¯
cat /proc/meminfo | grep HugePages_Total
# HugePages_Total:    1024
```

**Dockerå®¹å™¨ä½¿ç”¨Huge Pages**
```yaml
# docker-compose-hugepages.yml
version: '3.8'

services:
  # æ•°æ®åº“ä½¿ç”¨Huge Pages
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_SHARED_BUFFERS=1GB
      # PostgreSQLä½¿ç”¨Huge Pages
      - POSTGRES_HUGE_PAGES=try
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - type: tmpfs
        target: /dev/hugepages
        tmpfs:
          size: 2G
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
          hugepages-2MB: 1GB  # é¢„ç•™1GB Huge Pages

  # Redisä½¿ç”¨Huge Pages
  redis:
    image: redis:7-alpine
    command: >
      sh -c "
        echo never > /sys/kernel/mm/transparent_hugepage/enabled &&
        redis-server
          --maxmemory 2gb
          --maxmemory-policy allkeys-lru
      "
    privileged: true  # éœ€è¦ä¿®æ”¹THPè®¾ç½®
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          hugepages-2MB: 512M

volumes:
  postgres-data:
```

**éªŒè¯Huge Pagesä½¿ç”¨**
```bash
# æŸ¥çœ‹å®¹å™¨Huge Pagesä½¿ç”¨æƒ…å†µ
docker exec postgres grep Huge /proc/meminfo

# ç¤ºä¾‹è¾“å‡º
HugePages_Total:    1024
HugePages_Free:      512  # å·²ä½¿ç”¨512ä¸ª(1GB)
HugePages_Rsvd:      256
Hugepagesize:       2048 kB

# ç›‘æ§Huge Pagesæ•ˆæœ
# å¯¹æ¯”ä½¿ç”¨å‰åçš„æ€§èƒ½æŒ‡æ ‡:
# 1. å†…å­˜è®¿é—®å»¶è¿Ÿé™ä½
# 2. TLBç¼“å­˜å‘½ä¸­ç‡æå‡
# 3. CPUåˆ©ç”¨ç‡å¯èƒ½ç•¥å¾®ä¸‹é™
```

## 17.4 ç½‘ç»œæ€§èƒ½ä¼˜åŒ–

### 17.4.1 ç½‘ç»œæ¨¡å¼é€‰æ‹©

**ç½‘ç»œæ¨¡å¼æ€§èƒ½å¯¹æ¯”**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç½‘ç»œæ¨¡å¼    â”‚ ååé‡    â”‚ å»¶è¿Ÿ     â”‚ éš”ç¦»æ€§    â”‚ é€‚ç”¨åœºæ™¯  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ host         â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ â˜†â˜†â˜†â˜†â˜†   â”‚ é«˜æ€§èƒ½    â”‚
â”‚ bridge       â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ é€šç”¨      â”‚
â”‚ overlay      â”‚ â˜…â˜…â˜†â˜†â˜†   â”‚ â˜…â˜…â˜†â˜†â˜†   â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ å¤šä¸»æœº    â”‚
â”‚ macvlan      â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ ç‰©ç†ç½‘ç»œ  â”‚
â”‚ ipvlan       â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ è™šæ‹Ÿç½‘ç»œ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é«˜æ€§èƒ½ç½‘ç»œé…ç½® - Hostæ¨¡å¼**
```yaml
# é€‚ç”¨äºé«˜ååé‡åº”ç”¨ï¼ˆå¦‚è´Ÿè½½å‡è¡¡å™¨ã€ç¼“å­˜ï¼‰
version: '3.8'

services:
  haproxy:
    image: haproxy:2.8-alpine
    network_mode: host  # ç›´æ¥ä½¿ç”¨å®¿ä¸»æœºç½‘ç»œ
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    deploy:
      placement:
        constraints:
          - node.role == worker
          - node.labels.network == high-performance
```

**é«˜æ€§èƒ½ç½‘ç»œé…ç½® - Macvlan**
```bash
# åˆ›å»ºmacvlanç½‘ç»œ
docker network create -d macvlan \
  --subnet=192.168.1.0/24 \
  --gateway=192.168.1.1 \
  --ip-range=192.168.1.192/27 \
  -o parent=eth0 \
  macvlan-net

# ä½¿ç”¨macvlanç½‘ç»œ
docker run -d \
  --name high-perf-app \
  --network macvlan-net \
  --ip 192.168.1.200 \
  myapp:latest

# éªŒè¯ç½‘ç»œæ€§èƒ½
docker exec high-perf-app iperf3 -c 192.168.1.1 -t 30

# é¢„æœŸç»“æœ:æ¥è¿‘ç‰©ç†ç½‘å¡æ€§èƒ½
# [ ID] Interval           Transfer     Bandwidth
# [  4]   0.00-30.00  sec  33.2 GBytes  9.50 Gbits/sec
```

### 17.4.2 ç½‘ç»œå†…æ ¸å‚æ•°è°ƒä¼˜

**ç³»ç»Ÿçº§ç½‘ç»œä¼˜åŒ–**
```bash
# /etc/sysctl.d/99-docker-network.conf

# ============ TCPè¿æ¥ä¼˜åŒ– ============
# å¢å¤§è¿æ¥é˜Ÿåˆ—
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 8192

# å¿«é€Ÿå›æ”¶TIME_WAITè¿æ¥
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 15

# ============ TCPç¼“å†²ä¼˜åŒ– ============
# å¢å¤§TCPæ¥æ”¶/å‘é€ç¼“å†²åŒº
net.core.rmem_max = 134217728        # 128MB
net.core.wmem_max = 134217728
net.core.rmem_default = 16777216     # 16MB
net.core.wmem_default = 16777216

# TCPè‡ªåŠ¨è°ƒä¼˜
net.ipv4.tcp_rmem = 4096 87380 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.ipv4.tcp_mem = 786432 1048576 26777216

# ============ ç½‘ç»œè®¾å¤‡é˜Ÿåˆ— ============
# å¢å¤§ç½‘ç»œè®¾å¤‡æ¥æ”¶é˜Ÿåˆ—
net.core.netdev_max_backlog = 30000

# ============ TCPæ‹¥å¡æ§åˆ¶ ============
# ä½¿ç”¨BBRæ‹¥å¡æ§åˆ¶ç®—æ³•
net.core.default_qdisc = fq
net.ipv4.tcp_congestion_control = bbr

# ============ è¿æ¥è¿½è¸ªä¼˜åŒ– ============
# å¢å¤§conntrackè¡¨å¤§å°
net.netfilter.nf_conntrack_max = 1048576
net.netfilter.nf_conntrack_tcp_timeout_established = 600

# ============ å…¶ä»–ä¼˜åŒ– ============
# å¯ç”¨TCP Fast Open
net.ipv4.tcp_fastopen = 3

# ç¦ç”¨TCPæ—¶é—´æˆ³ï¼ˆå‡å°‘å¼€é”€ï¼‰
net.ipv4.tcp_timestamps = 0

# MTUæ¢æµ‹
net.ipv4.tcp_mtu_probing = 1
```

**åº”ç”¨é…ç½®**
```bash
# åº”ç”¨åˆ°ç³»ç»Ÿ
sysctl -p /etc/sysctl.d/99-docker-network.conf

# éªŒè¯é…ç½®
sysctl net.ipv4.tcp_congestion_control
# net.ipv4.tcp_congestion_control = bbr

sysctl net.core.somaxconn
# net.core.somaxconn = 65535

# æŸ¥çœ‹TCPè¿æ¥çŠ¶æ€ç»Ÿè®¡
ss -s

# ç¤ºä¾‹è¾“å‡º
Total: 234
TCP:   180 (estab 95, closed 45, orphaned 2, timewait 40)
```

### 17.4.3 å®¹å™¨ç½‘ç»œæ€§èƒ½æµ‹è¯•

**iperf3ç½‘ç»œæ€§èƒ½æµ‹è¯•**
```bash
# éƒ¨ç½²iperf3æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯
cat > docker-compose-iperf3.yml <<'EOF'
version: '3.8'

services:
  iperf3-server:
    image: networkstatic/iperf3
    command: -s
    networks:
      - perf-test
    ports:
      - "5201:5201"
    deploy:
      replicas: 1

  iperf3-client:
    image: networkstatic/iperf3
    depends_on:
      - iperf3-server
    networks:
      - perf-test
    deploy:
      replicas: 0  # æ‰‹åŠ¨è¿è¡Œ

networks:
  perf-test:
    driver: bridge
EOF

docker stack deploy -c docker-compose-iperf3.yml perftest

# æµ‹è¯•1: TCPååé‡ï¼ˆå•çº¿ç¨‹ï¼‰
docker run --rm --network perftest_perf-test \
  networkstatic/iperf3 -c iperf3-server -t 30

# ç¤ºä¾‹è¾“å‡º
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-30.00  sec  10.2 GBytes  2.92 Gbits/sec

# æµ‹è¯•2: TCPååé‡ï¼ˆ10å¹¶å‘æµï¼‰
docker run --rm --network perftest_perf-test \
  networkstatic/iperf3 -c iperf3-server -P 10 -t 30

# æµ‹è¯•3: UDPååé‡
docker run --rm --network perftest_perf-test \
  networkstatic/iperf3 -c iperf3-server -u -b 10G -t 30

# æµ‹è¯•4: æµ‹è¯•å»¶è¿Ÿ
docker run --rm --network perftest_perf-test \
  alpine ping -c 100 iperf3-server

# è®¡ç®—å¹³å‡å»¶è¿Ÿ
# rtt min/avg/max/mdev = 0.123/0.156/0.234/0.023 ms
```

**ä¸åŒç½‘ç»œæ¨¡å¼æ€§èƒ½å¯¹æ¯”è„šæœ¬**
```bash
#!/bin/bash
# network-benchmark.sh - å¯¹æ¯”ä¸åŒç½‘ç»œæ¨¡å¼æ€§èƒ½

echo "Dockerç½‘ç»œæ¨¡å¼æ€§èƒ½å¯¹æ¯”æµ‹è¯•"
echo "======================================"

# æµ‹è¯•å‡½æ•°
test_network() {
    local mode=$1
    local server_name="iperf-server-$mode"
    local client_cmd="docker run --rm --name iperf-client-$mode"

    echo ""
    echo "æµ‹è¯•æ¨¡å¼: $mode"
    echo "--------------------------------------"

    # å¯åŠ¨æœåŠ¡ç«¯
    case $mode in
        "host")
            docker run -d --name $server_name --network host \
              networkstatic/iperf3 -s
            sleep 2
            $client_cmd --network host \
              networkstatic/iperf3 -c localhost -t 10 | grep receiver
            ;;
        "bridge")
            docker run -d --name $server_name \
              networkstatic/iperf3 -s
            sleep 2
            SERVER_IP=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $server_name)
            $client_cmd --link $server_name \
              networkstatic/iperf3 -c $SERVER_IP -t 10 | grep receiver
            ;;
        "overlay")
            docker network create -d overlay test-overlay
            docker service create --name $server_name \
              --network test-overlay networkstatic/iperf3 -s
            sleep 5
            docker run --rm --network test-overlay \
              networkstatic/iperf3 -c $server_name -t 10 | grep receiver
            docker service rm $server_name
            docker network rm test-overlay
            return
            ;;
    esac

    # æ¸…ç†
    docker rm -f $server_name >/dev/null 2>&1
}

# æ‰§è¡Œæµ‹è¯•
test_network "host"
test_network "bridge"
test_network "overlay"

echo ""
echo "======================================"
echo "æµ‹è¯•å®Œæˆ"
```

**æ‰§è¡Œå¯¹æ¯”æµ‹è¯•**
```bash
chmod +x network-benchmark.sh
./network-benchmark.sh

# é¢„æœŸè¾“å‡ºç¤ºä¾‹
Dockerç½‘ç»œæ¨¡å¼æ€§èƒ½å¯¹æ¯”æµ‹è¯•
======================================

æµ‹è¯•æ¨¡å¼: host
--------------------------------------
[  4]   0.00-10.00  sec  11.2 GBytes  9.62 Gbits/sec    receiver

æµ‹è¯•æ¨¡å¼: bridge
--------------------------------------
[  4]   0.00-10.00  sec   3.5 GBytes  3.01 Gbits/sec    receiver

æµ‹è¯•æ¨¡å¼: overlay
--------------------------------------
[  4]   0.00-10.00  sec   2.1 GBytes  1.80 Gbits/sec    receiver

======================================
ç»“è®º:
- hostæ¨¡å¼:    9.62 Gbps (åŸºå‡†)
- bridgeæ¨¡å¼:  3.01 Gbps (31%æ€§èƒ½)
- overlayæ¨¡å¼: 1.80 Gbps (19%æ€§èƒ½)
```

### 17.4.4 è¿æ¥æ± ä¸Keep-Aliveä¼˜åŒ–

**Nginxè¿æ¥ä¼˜åŒ–**
```nginx
# nginx.conf - é«˜æ€§èƒ½é…ç½®

user nginx;
worker_processes auto;  # è‡ªåŠ¨åŒ¹é…CPUæ ¸å¿ƒæ•°
worker_rlimit_nofile 65535;

events {
    worker_connections 16384;  # æ¯ä¸ªworkeræœ€å¤§è¿æ¥æ•°
    use epoll;                 # ä½¿ç”¨epolläº‹ä»¶æ¨¡å‹
    multi_accept on;           # ä¸€æ¬¡æ¥å—å¤šä¸ªè¿æ¥
}

http {
    # ============ è¿æ¥ä¼˜åŒ– ============
    keepalive_timeout 65;
    keepalive_requests 1000;   # å•ä¸ªkeep-aliveè¿æ¥æœ€å¤§è¯·æ±‚æ•°

    # ============ ä¸Šæ¸¸è¿æ¥æ±  ============
    upstream backend {
        server backend1:8080 max_fails=3 fail_timeout=30s;
        server backend2:8080 max_fails=3 fail_timeout=30s;

        # è¿æ¥æ± é…ç½®
        keepalive 256;          # ä¿æŒ256ä¸ªç©ºé—²è¿æ¥
        keepalive_requests 1000;
        keepalive_timeout 60s;
    }

    server {
        listen 80 reuseport;    # ç«¯å£å¤ç”¨

        location / {
            proxy_pass http://backend;

            # å¯ç”¨HTTP/1.1å’ŒKeep-Alive
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # è¿æ¥è¶…æ—¶
            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;

            # ç¼“å†²ä¼˜åŒ–
            proxy_buffering on;
            proxy_buffer_size 8k;
            proxy_buffers 32 8k;
        }
    }
}
```

**æ•°æ®åº“è¿æ¥æ± é…ç½®**
```python
# Python - SQLAlchemyè¿æ¥æ± ä¼˜åŒ–

from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

# é«˜å¹¶å‘åœºæ™¯è¿æ¥æ± é…ç½®
engine = create_engine(
    'postgresql://user:pass@db:5432/mydb',

    # è¿æ¥æ± å‚æ•°
    poolclass=QueuePool,
    pool_size=20,              # å¸¸é©»è¿æ¥æ•°
    max_overflow=40,           # å³°å€¼é¢å¤–è¿æ¥æ•°ï¼ˆæ€»å…±60ï¼‰
    pool_pre_ping=True,        # è¿æ¥å¥åº·æ£€æŸ¥
    pool_recycle=3600,         # 1å°æ—¶å›æ”¶è¿æ¥
    pool_timeout=30,           # è·å–è¿æ¥è¶…æ—¶

    # è¿æ¥å‚æ•°
    connect_args={
        'connect_timeout': 10,
        'application_name': 'myapp',
        'options': '-c statement_timeout=30000'  # 30ç§’æŸ¥è¯¢è¶…æ—¶
    }
)

# ç›‘æ§è¿æ¥æ± çŠ¶æ€
from sqlalchemy import event

@event.listens_for(engine, "connect")
def receive_connect(dbapi_conn, connection_record):
    print(f"æ–°è¿æ¥å»ºç«‹: {id(dbapi_conn)}")

@event.listens_for(engine, "checkout")
def receive_checkout(dbapi_conn, connection_record, connection_proxy):
    pool = engine.pool
    print(f"è¿æ¥æ± çŠ¶æ€ - ä½¿ç”¨:{pool.checkedout()} ç©ºé—²:{pool.size() - pool.checkedout()}")
```

**Redisè¿æ¥æ± é…ç½®**
```python
# Python - Redisè¿æ¥æ± ä¼˜åŒ–

import redis
from redis import ConnectionPool

# é«˜æ€§èƒ½è¿æ¥æ± é…ç½®
pool = ConnectionPool(
    host='redis',
    port=6379,
    db=0,

    # è¿æ¥æ± å‚æ•°
    max_connections=100,       # æœ€å¤§è¿æ¥æ•°
    socket_timeout=5,          # Socketè¶…æ—¶
    socket_connect_timeout=5,  # è¿æ¥è¶…æ—¶
    socket_keepalive=True,     # å¯ç”¨TCP Keep-Alive
    socket_keepalive_options={
        socket.TCP_KEEPIDLE: 60,    # 60ç§’åå‘é€keepaliveæ¢æµ‹
        socket.TCP_KEEPINTVL: 10,   # æ¢æµ‹é—´éš”10ç§’
        socket.TCP_KEEPCNT: 3       # æ¢æµ‹3æ¬¡å¤±è´¥åæ–­å¼€
    },

    # é‡è¯•é…ç½®
    retry_on_timeout=True,
    health_check_interval=30,  # 30ç§’å¥åº·æ£€æŸ¥
)

redis_client = redis.Redis(connection_pool=pool)

# ç›‘æ§è¿æ¥æ± 
def monitor_redis_pool():
    pool_info = pool.get_connection('_').pool._available_connections
    print(f"Redisè¿æ¥æ±  - å¯ç”¨è¿æ¥: {len(pool_info)}/{pool.max_connections}")
```

## 17.5 å­˜å‚¨æ€§èƒ½ä¼˜åŒ–

### 17.5.1 å­˜å‚¨é©±åŠ¨é€‰æ‹©

**å­˜å‚¨é©±åŠ¨æ€§èƒ½å¯¹æ¯”**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å­˜å‚¨é©±åŠ¨     â”‚ è¯»æ€§èƒ½    â”‚ å†™æ€§èƒ½    â”‚ ç¨³å®šæ€§    â”‚ æ¨èåœºæ™¯  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ overlay2     â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ é€šç”¨      â”‚
â”‚ aufs         â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ â˜…â˜…â˜†â˜†â˜†   â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ æ—§å†…æ ¸    â”‚
â”‚ btrfs        â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ â˜…â˜…â˜…â˜†â˜†   â”‚ å¿«ç…§      â”‚
â”‚ zfs          â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜…   â”‚ ä¼ä¸šçº§    â”‚
â”‚ devicemapper â”‚ â˜…â˜…â˜†â˜†â˜†   â”‚ â˜…â˜…â˜†â˜†â˜†   â”‚ â˜…â˜…â˜†â˜†â˜†   â”‚ ä¸æ¨è    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**overlay2ä¼˜åŒ–é…ç½®**
```json
// /etc/docker/daemon.json

{
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true",
    "overlay2.size=20G"  // é™åˆ¶å•ä¸ªå®¹å™¨rootfså¤§å°
  ],

  // æ•°æ®æ ¹ç›®å½•(é€‰æ‹©é«˜æ€§èƒ½SSD)
  "data-root": "/mnt/ssd/docker",

  // æ—¥å¿—ä¼˜åŒ–
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}
```

**éªŒè¯å­˜å‚¨é©±åŠ¨**
```bash
# æŸ¥çœ‹å½“å‰å­˜å‚¨é©±åŠ¨
docker info | grep "Storage Driver"

# æŸ¥çœ‹overlay2è¯¦ç»†ä¿¡æ¯
docker info | grep -A 10 "Storage Driver"

# ç¤ºä¾‹è¾“å‡º
Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
  userxattr: false
```

### 17.5.2 å·æ€§èƒ½ä¼˜åŒ–

**å·ç±»å‹æ€§èƒ½å¯¹æ¯”**
```yaml
version: '3.8'

services:
  # åœºæ™¯1: é«˜æ€§èƒ½è¯»å†™ - æœ¬åœ°å·
  database:
    image: postgres:15
    volumes:
      # ç›´æ¥æŒ‚è½½å®¿ä¸»æœºç›®å½•(æ€§èƒ½æœ€ä¼˜)
      - type: bind
        source: /mnt/nvme/postgres
        target: /var/lib/postgresql/data
        bind:
          propagation: rprivate
    deploy:
      placement:
        constraints:
          - node.labels.storage == nvme

  # åœºæ™¯2: æŒä¹…åŒ–å­˜å‚¨ - Dockerå·
  app-data:
    image: myapp:latest
    volumes:
      # Dockerç®¡ç†çš„å·(å¹³è¡¡æ€§èƒ½å’Œç®¡ç†)
      - type: volume
        source: app-data
        target: /data
        volume:
          nocopy: false

  # åœºæ™¯3: ä¸´æ—¶é«˜æ€§èƒ½ - tmpfs
  cache:
    image: redis:7-alpine
    volumes:
      # å†…å­˜æ–‡ä»¶ç³»ç»Ÿ(æœ€å¿«,ä½†é‡å¯ä¸¢å¤±)
      - type: tmpfs
        target: /data
        tmpfs:
          size: 4G
          mode: 1777

volumes:
  app-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/ssd/app-data
```

**å·æ€§èƒ½æµ‹è¯•è„šæœ¬**
```bash
#!/bin/bash
# benchmark-storage.sh - å­˜å‚¨æ€§èƒ½åŸºå‡†æµ‹è¯•

IMAGE="alpine:latest"

echo "Dockerå­˜å‚¨æ€§èƒ½æµ‹è¯•"
echo "=========================================="

# æµ‹è¯•å‡½æ•°
test_storage() {
    local mount_type=$1
    local mount_opts=$2
    local test_name=$3

    echo ""
    echo "æµ‹è¯•: $test_name"
    echo "----------------------------------------"

    # åˆ›å»ºæµ‹è¯•å®¹å™¨
    docker run --rm $mount_opts $IMAGE sh -c '
        # æµ‹è¯•1: é¡ºåºå†™å…¥
        echo "é¡ºåºå†™å…¥ 1GB..."
        time dd if=/dev/zero of=/data/test.img bs=1M count=1024 conv=fdatasync

        # æµ‹è¯•2: éšæœºå†™å…¥
        echo "éšæœºå†™å…¥..."
        time dd if=/dev/urandom of=/data/random.img bs=4K count=10000 conv=fdatasync

        # æµ‹è¯•3: é¡ºåºè¯»å–
        echo "é¡ºåºè¯»å–..."
        time dd if=/data/test.img of=/dev/null bs=1M

        # æ¸…ç†
        rm -f /data/*.img
    ' 2>&1 | grep -E "copied|real"
}

# æµ‹è¯•1: tmpfs (å†…å­˜)
test_storage "tmpfs" \
  "--tmpfs /data:rw,size=2G,mode=1777" \
  "tmpfs (å†…å­˜æ–‡ä»¶ç³»ç»Ÿ)"

# æµ‹è¯•2: Dockerå·
docker volume create test-vol
test_storage "volume" \
  "-v test-vol:/data" \
  "Docker Volume"
docker volume rm test-vol

# æµ‹è¯•3: BindæŒ‚è½½
mkdir -p /tmp/docker-bench
test_storage "bind" \
  "-v /tmp/docker-bench:/data" \
  "Bind Mount"
rm -rf /tmp/docker-bench

echo ""
echo "=========================================="
echo "æµ‹è¯•å®Œæˆ"
```

**æ‰§è¡Œå­˜å‚¨åŸºå‡†æµ‹è¯•**
```bash
chmod +x benchmark-storage.sh
./benchmark-storage.sh

# é¢„æœŸè¾“å‡ºç¤ºä¾‹
Dockerå­˜å‚¨æ€§èƒ½æµ‹è¯•
==========================================

æµ‹è¯•: tmpfs (å†…å­˜æ–‡ä»¶ç³»ç»Ÿ)
----------------------------------------
é¡ºåºå†™å…¥ 1GB...
1073741824 bytes (1.1 GB) copied, 0.523 s, 2.1 GB/s
éšæœºå†™å…¥...
40960000 bytes (41 MB) copied, 0.156 s, 263 MB/s
é¡ºåºè¯»å–...
1073741824 bytes (1.1 GB) copied, 0.234 s, 4.6 GB/s

æµ‹è¯•: Docker Volume
----------------------------------------
é¡ºåºå†™å…¥ 1GB...
1073741824 bytes (1.1 GB) copied, 2.345 s, 458 MB/s
éšæœºå†™å…¥...
40960000 bytes (41 MB) copied, 0.678 s, 60.4 MB/s
é¡ºåºè¯»å–...
1073741824 bytes (1.1 GB) copied, 1.234 s, 870 MB/s

æµ‹è¯•: Bind Mount
----------------------------------------
é¡ºåºå†™å…¥ 1GB...
1073741824 bytes (1.1 GB) copied, 2.123 s, 506 MB/s
éšæœºå†™å…¥...
40960000 bytes (41 MB) copied, 0.589 s, 69.5 MB/s
é¡ºåºè¯»å–...
1073741824 bytes (1.1 GB) copied, 1.123 s, 956 MB/s
```

### 17.5.3 I/Oè°ƒåº¦å™¨ä¼˜åŒ–

**æŸ¥çœ‹å’Œè®¾ç½®I/Oè°ƒåº¦å™¨**
```bash
# æŸ¥çœ‹å½“å‰I/Oè°ƒåº¦å™¨
cat /sys/block/sda/queue/scheduler
# è¾“å‡º: [mq-deadline] kyber bfq none

# ä¸åŒè°ƒåº¦å™¨ç‰¹ç‚¹:
# - mq-deadline: é»˜è®¤,å¹³è¡¡æ€§èƒ½å’Œå»¶è¿Ÿ
# - kyber: ä¼˜åŒ–å»¶è¿Ÿ,é€‚åˆSSD
# - bfq: å…¬å¹³é˜Ÿåˆ—,é€‚åˆæ¡Œé¢
# - none: æ— è°ƒåº¦,é€‚åˆNVMe SSD

# ä¸ºNVMe SSDè®¾ç½®noneè°ƒåº¦å™¨
echo none > /sys/block/nvme0n1/queue/scheduler

# ä¸ºSATA SSDè®¾ç½®kyberè°ƒåº¦å™¨
echo kyber > /sys/block/sda/queue/scheduler

# æŒä¹…åŒ–é…ç½®
cat > /etc/udev/rules.d/60-scheduler.rules <<'EOF'
# NVMeè®¾å¤‡ä½¿ç”¨noneè°ƒåº¦å™¨
ACTION=="add|change", KERNEL=="nvme[0-9]n[0-9]", ATTR{queue/scheduler}="none"

# SSDè®¾å¤‡ä½¿ç”¨kyberè°ƒåº¦å™¨
ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/rotational}=="0", ATTR{queue/scheduler}="kyber"

# HDDè®¾å¤‡ä½¿ç”¨mq-deadlineè°ƒåº¦å™¨
ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/rotational}=="1", ATTR{queue/scheduler}="mq-deadline"
EOF

# åº”ç”¨udevè§„åˆ™
udevadm control --reload-rules
udevadm trigger
```

**I/Oé˜Ÿåˆ—æ·±åº¦ä¼˜åŒ–**
```bash
# æŸ¥çœ‹å½“å‰é˜Ÿåˆ—æ·±åº¦
cat /sys/block/nvme0n1/queue/nr_requests
# é»˜è®¤: 128

# å¢å¤§é˜Ÿåˆ—æ·±åº¦(æé«˜ååé‡,ç•¥å¢å»¶è¿Ÿ)
echo 1024 > /sys/block/nvme0n1/queue/nr_requests

# å‡å°é˜Ÿåˆ—æ·±åº¦(é™ä½å»¶è¿Ÿ,ç•¥é™ååé‡)
echo 64 > /sys/block/nvme0n1/queue/nr_requests

# æŸ¥çœ‹è®¾å¤‡é˜Ÿåˆ—ç»Ÿè®¡
cat /sys/block/nvme0n1/queue/iostats
```

### 17.5.4 æ•°æ®åº“å­˜å‚¨ä¼˜åŒ–æ¡ˆä¾‹

**PostgreSQLå­˜å‚¨ä¼˜åŒ–**
```yaml
# docker-stack-postgres-optimized.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine

    environment:
      # ============ å†…å­˜é…ç½® ============
      POSTGRES_SHARED_BUFFERS: 8GB          # 25%çš„ç³»ç»Ÿå†…å­˜
      POSTGRES_EFFECTIVE_CACHE_SIZE: 24GB  # 75%çš„ç³»ç»Ÿå†…å­˜
      POSTGRES_WORK_MEM: 64MB               # æ¯ä¸ªæŸ¥è¯¢æ“ä½œå†…å­˜
      POSTGRES_MAINTENANCE_WORK_MEM: 2GB   # ç»´æŠ¤æ“ä½œå†…å­˜

      # ============ WALé…ç½® ============
      POSTGRES_WAL_BUFFERS: 16MB
      POSTGRES_MAX_WAL_SIZE: 4GB
      POSTGRES_MIN_WAL_SIZE: 1GB
      POSTGRES_WAL_COMPRESSION: on

      # ============ æ£€æŸ¥ç‚¹é…ç½® ============
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9
      POSTGRES_CHECKPOINT_TIMEOUT: 15min

      # ============ I/Oä¼˜åŒ– ============
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: 200  # SSDæ¨èå€¼
      POSTGRES_RANDOM_PAGE_COST: 1.1          # SSDæ¨è1.1

    volumes:
      # æ•°æ®ç›®å½• - NVMe SSD
      - type: bind
        source: /mnt/nvme/postgres/data
        target: /var/lib/postgresql/data

      # WALç›®å½• - å•ç‹¬çš„é«˜é€Ÿç£ç›˜
      - type: bind
        source: /mnt/ssd/postgres/wal
        target: /var/lib/postgresql/wal

      # ä¸´æ—¶æ–‡ä»¶ - tmpfs
      - type: tmpfs
        target: /var/lib/postgresql/tmp
        tmpfs:
          size: 4G

    deploy:
      resources:
        limits:
          cpus: '16'
          memory: 32G
        reservations:
          cpus: '8'
          memory: 16G

      placement:
        constraints:
          - node.labels.storage == nvme
          - node.labels.role == database
```

**PostgreSQLè‡ªå®šä¹‰é…ç½®**
```bash
# custom-postgres.conf - è¿›ä¸€æ­¥ä¼˜åŒ–

# ============ æŸ¥è¯¢è§„åˆ’å™¨ ============
effective_cache_size = '24GB'
random_page_cost = 1.1              # SSD
seq_page_cost = 1.0
cpu_tuple_cost = 0.01
cpu_index_tuple_cost = 0.005
cpu_operator_cost = 0.0025

# ============ å¹¶å‘é…ç½® ============
max_connections = 200
max_worker_processes = 16
max_parallel_workers_per_gather = 4
max_parallel_workers = 16
max_parallel_maintenance_workers = 4

# ============ WALæ€§èƒ½ ============
wal_level = replica
synchronous_commit = off            # å¼‚æ­¥æäº¤,æé«˜æ€§èƒ½(å¯èƒ½ä¸¢å¤±å°‘é‡æ•°æ®)
wal_writer_delay = 200ms
commit_delay = 100
commit_siblings = 5

# ============ è‡ªåŠ¨æ¸…ç† ============
autovacuum = on
autovacuum_max_workers = 4
autovacuum_naptime = 10s
autovacuum_vacuum_cost_limit = 1000

# ============ æ—¥å¿—é…ç½® ============
logging_collector = on
log_destination = 'csvlog'
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d.log'
log_min_duration_statement = 100    # è®°å½•>100msçš„æŸ¥è¯¢
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
log_temp_files = 0
```

**æŒ‚è½½é…ç½®æ–‡ä»¶**
```yaml
services:
  postgres:
    volumes:
      - ./custom-postgres.conf:/etc/postgresql/postgresql.conf:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
```

## 17.6 åº”ç”¨å±‚ä¼˜åŒ–

### 17.6.1 åº”ç”¨å®¹å™¨åŒ–æœ€ä½³å®è·µ

**å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–**
```dockerfile
# Dockerfile.optimized - Python Flaskåº”ç”¨ä¼˜åŒ–ç¤ºä¾‹

# ============ é˜¶æ®µ1: æ„å»ºä¾èµ– ============
FROM python:3.11-slim AS builder

WORKDIR /build

# å®‰è£…æ„å»ºä¾èµ–
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶(åˆ©ç”¨ç¼“å­˜)
COPY requirements.txt .

# å®‰è£…PythonåŒ…åˆ°ç‹¬ç«‹ç›®å½•
RUN pip install --user --no-cache-dir --no-warn-script-location \
    -r requirements.txt

# ============ é˜¶æ®µ2: è¿è¡Œæ—¶é•œåƒ ============
FROM python:3.11-slim

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r app && useradd -r -g app app

WORKDIR /app

# ä»…å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶PythonåŒ…
COPY --from=builder /root/.local /home/app/.local

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=app:app . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PATH=/home/app/.local/bin:$PATH \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER app

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health', timeout=2)"

# å¯åŠ¨åº”ç”¨
CMD ["gunicorn", "--config", "gunicorn_config.py", "app:app"]
```

**Gunicorné«˜æ€§èƒ½é…ç½®**
```python
# gunicorn_config.py

import multiprocessing
import os

# ============ Server Socket ============
bind = "0.0.0.0:8000"
backlog = 2048

# ============ Workerè¿›ç¨‹ ============
# CPUå¯†é›†å‹: workers = CPUæ ¸å¿ƒæ•°
# I/Oå¯†é›†å‹: workers = 2-4 * CPUæ ¸å¿ƒæ•°
workers = int(os.getenv("GUNICORN_WORKERS", multiprocessing.cpu_count() * 2 + 1))

# Workerç±»å‹
worker_class = "gevent"  # æˆ– "sync" / "gthread" / "eventlet"
worker_connections = 1000

# ============ Workerè¶…æ—¶ ============
timeout = 30
graceful_timeout = 30
keepalive = 5

# ============ è¿›ç¨‹ç®¡ç† ============
max_requests = 10000        # å¤„ç†Nä¸ªè¯·æ±‚åé‡å¯worker(é˜²æ­¢å†…å­˜æ³„æ¼)
max_requests_jitter = 1000  # éšæœºæŠ–åŠ¨
worker_tmp_dir = "/dev/shm" # ä½¿ç”¨å…±äº«å†…å­˜

# ============ æ—¥å¿— ============
accesslog = "-"  # stdout
errorlog = "-"   # stderr
loglevel = "info"
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# ============ æ€§èƒ½ä¼˜åŒ– ============
preload_app = True  # é¢„åŠ è½½åº”ç”¨(å‡å°‘å†…å­˜,åŠ å¿«å¯åŠ¨)

def on_starting(server):
    """æœåŠ¡å™¨å¯åŠ¨æ—¶"""
    print("Gunicornæ­£åœ¨å¯åŠ¨...")

def when_ready(server):
    """æœåŠ¡å™¨å°±ç»ªæ—¶"""
    print(f"Gunicornå·²å°±ç»ª - Workers: {workers}")

def on_reload(server):
    """ä»£ç é‡è½½æ—¶"""
    print("æ£€æµ‹åˆ°ä»£ç å˜æ›´,é‡æ–°åŠ è½½...")
```

### 17.6.2 ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

**å¤šå±‚ç¼“å­˜æ¶æ„**
```yaml
version: '3.8'

services:
  # ============ L1ç¼“å­˜: åº”ç”¨å†…å­˜ç¼“å­˜ ============
  app:
    image: myapp:latest
    environment:
      # Pythonç¼“å­˜é…ç½®
      CACHE_TYPE: "simple"
      CACHE_DEFAULT_TIMEOUT: 300
    deploy:
      replicas: 4
      resources:
        limits:
          memory: 2G        # åº”ç”¨å†…å­˜åŒ…å«ç¼“å­˜

  # ============ L2ç¼“å­˜: Redis ============
  redis:
    image: redis:7-alpine
    command: >
      redis-server
        --maxmemory 4gb
        --maxmemory-policy allkeys-lru
        --save ""                      # ç¦ç”¨RDBæŒä¹…åŒ–(çº¯ç¼“å­˜)
        --appendonly no                # ç¦ç”¨AOF
        --tcp-backlog 511
        --timeout 0
        --tcp-keepalive 300
        --hz 10                        # é™ä½å†…éƒ¨ä»»åŠ¡é¢‘ç‡
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 5G                   # 4Gæ•°æ®+1Gå¼€é”€
        reservations:
          memory: 4G

  # ============ L3ç¼“å­˜: Nginxç¼“å­˜ ============
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx-cache.conf:/etc/nginx/conf.d/default.conf:ro
      - nginx-cache:/var/cache/nginx
    deploy:
      resources:
        limits:
          memory: 256M

volumes:
  nginx-cache:
    driver: local
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: size=1G
```

**Nginxç¼“å­˜é…ç½®**
```nginx
# nginx-cache.conf

# ç¼“å­˜è·¯å¾„é…ç½®
proxy_cache_path /var/cache/nginx/api
    levels=1:2
    keys_zone=api_cache:100m
    max_size=1g
    inactive=60m
    use_temp_path=off;

proxy_cache_path /var/cache/nginx/static
    levels=1:2
    keys_zone=static_cache:50m
    max_size=5g
    inactive=7d
    use_temp_path=off;

# ç¼“å­˜é”®å®šä¹‰
map $request_method $skip_cache {
    default 1;
    GET 0;
    HEAD 0;
}

server {
    listen 80;

    # ============ APIç¼“å­˜ ============
    location /api/ {
        proxy_pass http://app:8000;

        proxy_cache api_cache;
        proxy_cache_key "$scheme$request_method$host$request_uri";
        proxy_cache_valid 200 5m;
        proxy_cache_valid 404 1m;
        proxy_cache_bypass $skip_cache;
        proxy_no_cache $skip_cache;

        # ç¼“å­˜å¤´
        add_header X-Cache-Status $upstream_cache_status;

        # å¹¶å‘æ§åˆ¶
        proxy_cache_lock on;
        proxy_cache_lock_timeout 5s;
        proxy_cache_lock_age 10s;

        # é™ˆæ—§ç¼“å­˜ç­–ç•¥
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503;
        proxy_cache_background_update on;
    }

    # ============ é™æ€æ–‡ä»¶ç¼“å­˜ ============
    location /static/ {
        proxy_pass http://app:8000;

        proxy_cache static_cache;
        proxy_cache_valid 200 7d;
        proxy_cache_valid 404 1h;

        add_header X-Cache-Status $upstream_cache_status;
        add_header Cache-Control "public, max-age=604800";
    }
}
```

**Redisç¼“å­˜æ¨¡å¼**
```python
# cache_patterns.py - Redisç¼“å­˜æ¨¡å¼

import redis
import hashlib
import json
from functools import wraps

redis_client = redis.Redis(
    host='redis',
    port=6379,
    db=0,
    decode_responses=True,
    socket_keepalive=True,
    socket_connect_timeout=5,
    socket_timeout=5,
    connection_pool=redis.ConnectionPool(max_connections=50)
)

# ============ æ¨¡å¼1: Cache-Aside (ç¼“å­˜æ—è·¯) ============
def cache_aside(key_prefix, ttl=300):
    """è£…é¥°å™¨:Cache-Asideæ¨¡å¼"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{key_prefix}:{_generate_key(args, kwargs)}"

            # 1. å°è¯•ä»ç¼“å­˜è¯»å–
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # 2. ç¼“å­˜æœªå‘½ä¸­,æŸ¥è¯¢æ•°æ®åº“
            result = func(*args, **kwargs)

            # 3. å†™å…¥ç¼“å­˜
            redis_client.setex(cache_key, ttl, json.dumps(result))

            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@cache_aside("user", ttl=600)
def get_user(user_id):
    # æ•°æ®åº“æŸ¥è¯¢
    return db.query(f"SELECT * FROM users WHERE id={user_id}")

# ============ æ¨¡å¼2: Write-Through (å†™ç©¿é€) ============
def write_through(key_prefix):
    """å†™å…¥æ—¶åŒæ­¥æ›´æ–°ç¼“å­˜"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)

            # åŒæ­¥æ›´æ–°ç¼“å­˜
            cache_key = f"{key_prefix}:{args[0]}"
            redis_client.set(cache_key, json.dumps(result))

            return result
        return wrapper
    return decorator

@write_through("user")
def update_user(user_id, data):
    # æ›´æ–°æ•°æ®åº“
    db.update(f"UPDATE users SET ... WHERE id={user_id}")
    return data

# ============ æ¨¡å¼3: Write-Behind (å¼‚æ­¥å†™å›) ============
import asyncio
from queue import Queue

write_queue = Queue()

async def async_write_worker():
    """å¼‚æ­¥å†™å…¥worker"""
    while True:
        if not write_queue.empty():
            item = write_queue.get()
            # æ‰¹é‡å†™å…¥æ•°æ®åº“
            db.batch_update(item)
        await asyncio.sleep(1)

def write_behind(key_prefix):
    """å†™å…¥ç¼“å­˜,å¼‚æ­¥æŒä¹…åŒ–åˆ°æ•°æ®åº“"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)

            # ç«‹å³å†™å…¥ç¼“å­˜
            cache_key = f"{key_prefix}:{args[0]}"
            redis_client.set(cache_key, json.dumps(result))

            # åŠ å…¥å¼‚æ­¥é˜Ÿåˆ—
            write_queue.put((args[0], result))

            return result
        return wrapper
    return decorator

# ============ è¾…åŠ©å‡½æ•° ============
def _generate_key(args, kwargs):
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_data = f"{args}:{sorted(kwargs.items())}"
    return hashlib.md5(key_data.encode()).hexdigest()

# ============ ç¼“å­˜é¢„çƒ­ ============
def warm_cache(keys_list):
    """æ‰¹é‡é¢„çƒ­ç¼“å­˜"""
    pipeline = redis_client.pipeline()

    for key in keys_list:
        data = fetch_from_db(key)
        pipeline.setex(f"user:{key}", 600, json.dumps(data))

    pipeline.execute()
    print(f"é¢„çƒ­äº† {len(keys_list)} ä¸ªç¼“å­˜é”®")

# ============ ç¼“å­˜å¤±æ•ˆç­–ç•¥ ============
def invalidate_cache_pattern(pattern):
    """æ‰¹é‡åˆ é™¤åŒ¹é…çš„ç¼“å­˜"""
    cursor = 0
    while True:
        cursor, keys = redis_client.scan(
            cursor, match=pattern, count=100
        )
        if keys:
            redis_client.delete(*keys)
        if cursor == 0:
            break

# ç¤ºä¾‹:åˆ é™¤æ‰€æœ‰ç”¨æˆ·ç¼“å­˜
invalidate_cache_pattern("user:*")
```

### 17.6.3 å¼‚æ­¥å¤„ç†ä¸é˜Ÿåˆ—ä¼˜åŒ–

**Celeryå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—**
```yaml
# docker-stack-celery.yml
version: '3.8'

services:
  # ============ Webåº”ç”¨ ============
  web:
    image: myapp:latest
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
    deploy:
      replicas: 4

  # ============ Celery Worker ============
  celery-worker:
    image: myapp:latest
    command: celery -A tasks worker --loglevel=info --concurrency=8
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
      CELERYD_PREFETCH_MULTIPLIER: 4   # æ¯ä¸ªworkeré¢„å–4ä¸ªä»»åŠ¡
      CELERYD_MAX_TASKS_PER_CHILD: 1000  # å¤„ç†1000ä¸ªä»»åŠ¡åé‡å¯
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # ============ Celery Beat (å®šæ—¶ä»»åŠ¡) ============
  celery-beat:
    image: myapp:latest
    command: celery -A tasks beat --loglevel=info
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
    deploy:
      replicas: 1

  # ============ Flower (ç›‘æ§) ============
  flower:
    image: mher/flower:latest
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - "5555:5555"
    deploy:
      replicas: 1

networks:
  default:
    driver: overlay
```

**Celeryä»»åŠ¡ä¼˜åŒ–**
```python
# tasks.py - Celeryä»»åŠ¡ä¼˜åŒ–

from celery import Celery, group, chord, chain
from celery.exceptions import SoftTimeLimitExceeded
import time

app = Celery('tasks')

# ============ é…ç½®ä¼˜åŒ– ============
app.conf.update(
    # Brokerè®¾ç½®
    broker_url='redis://redis:6379/0',
    broker_connection_retry_on_startup=True,
    broker_connection_max_retries=10,

    # Result Backend
    result_backend='redis://redis:6379/1',
    result_expires=3600,  # ç»“æœä¿ç•™1å°æ—¶

    # ä»»åŠ¡æ‰§è¡Œ
    task_acks_late=True,              # ä»»åŠ¡å®Œæˆåæ‰ç¡®è®¤
    task_reject_on_worker_lost=True,  # Workerä¸¢å¤±æ—¶æ‹’ç»ä»»åŠ¡
    task_time_limit=600,              # ç¡¬è¶…æ—¶10åˆ†é’Ÿ
    task_soft_time_limit=540,         # è½¯è¶…æ—¶9åˆ†é’Ÿ

    # æ€§èƒ½ä¼˜åŒ–
    worker_prefetch_multiplier=4,     # é¢„å–å€æ•°
    worker_max_tasks_per_child=1000,  # é˜²æ­¢å†…å­˜æ³„æ¼

    # åºåˆ—åŒ–
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',

    # è·¯ç”±
    task_routes={
        'tasks.cpu_intensive': {'queue': 'cpu'},
        'tasks.io_intensive': {'queue': 'io'},
    }
)

# ============ ä»»åŠ¡ç¤ºä¾‹ ============
@app.task(bind=True, max_retries=3)
def process_data(self, data_id):
    """å¸¦é‡è¯•çš„ä»»åŠ¡"""
    try:
        # æ¨¡æ‹Ÿå¤„ç†
        result = heavy_computation(data_id)
        return result

    except SoftTimeLimitExceeded:
        # è½¯è¶…æ—¶å¤„ç†
        cleanup()
        raise

    except Exception as exc:
        # æŒ‡æ•°é€€é¿é‡è¯•
        raise self.retry(exc=exc, countdown=2 ** self.request.retries)

@app.task
def cpu_intensive_task(data):
    """CPUå¯†é›†å‹ä»»åŠ¡"""
    return sum(i**2 for i in range(data))

@app.task(queue='io')
def io_intensive_task(url):
    """I/Oå¯†é›†å‹ä»»åŠ¡"""
    import requests
    return requests.get(url).text

# ============ ä»»åŠ¡ç¼–æ’ ============
# å¹¶è¡Œä»»åŠ¡ç»„
job = group(
    process_data.s(1),
    process_data.s(2),
    process_data.s(3)
)
result = job.apply_async()

# é“¾å¼ä»»åŠ¡
job = chain(
    fetch_data.s(),
    process_data.s(),
    save_result.s()
)
result = job.apply_async()

# Chord (åˆ†æ•£-èšåˆ)
callback = aggregate_results.s()
header = [process_data.s(i) for i in range(100)]
job = chord(header)(callback)
result = job.apply_async()

# ============ ä»»åŠ¡ä¼˜å…ˆçº§ ============
@app.task
def high_priority_task():
    pass

# å‘é€é«˜ä¼˜å…ˆçº§ä»»åŠ¡
high_priority_task.apply_async(priority=9)  # 0-9,9æœ€é«˜
```

**RabbitMQé«˜æ€§èƒ½é…ç½®**
```yaml
# å¦‚æœä½¿ç”¨RabbitMQè€ŒéRedis
services:
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    hostname: rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: secret

      # æ€§èƒ½ä¼˜åŒ–
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 0.6        # 60%å†…å­˜é˜ˆå€¼
      RABBITMQ_DISK_FREE_LIMIT: "2GB"
      RABBITMQ_CHANNEL_MAX: 2048

    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
      - ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          memory: 2G

volumes:
  rabbitmq-data:
```

**rabbitmq.confé«˜çº§é…ç½®**
```ini
# rabbitmq.conf - é«˜æ€§èƒ½é…ç½®

# ============ ç½‘ç»œé…ç½® ============
listeners.tcp.default = 5672
management.tcp.port = 15672

# ============ å†…å­˜ç®¡ç† ============
vm_memory_high_watermark.relative = 0.6
vm_memory_high_watermark_paging_ratio = 0.75

# ============ ç£ç›˜ç®¡ç† ============
disk_free_limit.absolute = 2GB

# ============ è¿æ¥é…ç½® ============
channel_max = 2048
heartbeat = 60

# ============ é˜Ÿåˆ—é…ç½® ============
# å»¶è¿Ÿé˜Ÿåˆ—
queue_master_locator = min-masters

# ============ é›†ç¾¤é…ç½® ============
cluster_partition_handling = autoheal

# ============ æ—¥å¿— ============
log.file.level = warning
log.console = true
log.console.level = info
```

---

*ï¼ˆç¬¬17ç« å®Œæˆ,çº¦2000è¡Œã€‚å·²å®Œæˆ17ç« ,å‰©ä½™2ç« ...ï¼‰*

---

# ç¬¬18ç« : æ•…éšœæ’æŸ¥

## 18.1 æ•…éšœæ’æŸ¥æ–¹æ³•è®º

### 18.1.1 ç³»ç»ŸåŒ–æ’æŸ¥æµç¨‹

**5æ­¥æ•…éšœæ’æŸ¥æ³•**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Dockeræ•…éšœæ’æŸ¥æ ‡å‡†æµç¨‹                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  [1] é—®é¢˜å®šä¹‰ (Define)                                   â”‚
â”‚      â”œâ”€ ç°è±¡æè¿° (What)                                  â”‚
â”‚      â”œâ”€ å‘ç”Ÿæ—¶é—´ (When)                                  â”‚
â”‚      â”œâ”€ å½±å“èŒƒå›´ (Scope)                                 â”‚
â”‚      â””â”€ ä¸šåŠ¡å½±å“ (Impact)                                â”‚
â”‚                                                         â”‚
â”‚  [2] ä¿¡æ¯æ”¶é›† (Gather)                                   â”‚
â”‚      â”œâ”€ å®¹å™¨çŠ¶æ€ (docker ps/inspect)                     â”‚
â”‚      â”œâ”€ ç³»ç»Ÿèµ„æº (CPU/å†…å­˜/ç£ç›˜/ç½‘ç»œ)                     â”‚
â”‚      â”œâ”€ æ—¥å¿—ä¿¡æ¯ (åº”ç”¨æ—¥å¿—/ç³»ç»Ÿæ—¥å¿—)                      â”‚
â”‚      â””â”€ ç›‘æ§æ•°æ® (Prometheus/Grafana)                    â”‚
â”‚                                                         â”‚
â”‚  [3] å‡è®¾éªŒè¯ (Hypothesize)                              â”‚
â”‚      â”œâ”€ åˆ—å‡ºå¯èƒ½åŸå›                                       â”‚
â”‚      â”œâ”€ æŒ‰æ¦‚ç‡æ’åº                                        â”‚
â”‚      â””â”€ é€ä¸€éªŒè¯å‡è®¾                                      â”‚
â”‚                                                         â”‚
â”‚  [4] é—®é¢˜å®šä½ (Isolate)                                  â”‚
â”‚      â”œâ”€ ç¼©å°é—®é¢˜èŒƒå›´                                      â”‚
â”‚      â”œâ”€ æ‰¾åˆ°æ ¹æœ¬åŸå›                                       â”‚
â”‚      â””â”€ ç¡®è®¤è§¦å‘æ¡ä»¶                                      â”‚
â”‚                                                         â”‚
â”‚  [5] è§£å†³éªŒè¯ (Resolve)                                  â”‚
â”‚      â”œâ”€ å®æ–½è§£å†³æ–¹æ¡ˆ                                      â”‚
â”‚      â”œâ”€ éªŒè¯é—®é¢˜è§£å†³                                      â”‚
â”‚      â”œâ”€ æ–‡æ¡£è®°å½•                                          â”‚
â”‚      â””â”€ é¢„é˜²æªæ–½                                          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ•…éšœæ’æŸ¥å†³ç­–æ ‘**
```
å®¹å™¨æ— æ³•è®¿é—®
    â”‚
    â”œâ”€> å®¹å™¨æ˜¯å¦è¿è¡Œ? (docker ps)
    â”‚   â”œâ”€ å¦ â†’ 18.2.1 å®¹å™¨å¯åŠ¨å¤±è´¥
    â”‚   â””â”€ æ˜¯ â†’ ç»§ç»­
    â”‚
    â”œâ”€> å®¹å™¨å¥åº·æ£€æŸ¥? (docker inspect)
    â”‚   â”œâ”€ å¤±è´¥ â†’ 18.2.2 å¥åº·æ£€æŸ¥å¤±è´¥
    â”‚   â””â”€ é€šè¿‡ â†’ ç»§ç»­
    â”‚
    â”œâ”€> ç«¯å£æ˜¯å¦ç›‘å¬? (netstat/ss)
    â”‚   â”œâ”€ å¦ â†’ åº”ç”¨æœªå¯åŠ¨
    â”‚   â””â”€ æ˜¯ â†’ ç»§ç»­
    â”‚
    â”œâ”€> ç½‘ç»œè¿é€šæ€§? (ping/telnet)
    â”‚   â”œâ”€ å¦ â†’ 18.3 ç½‘ç»œé—®é¢˜
    â”‚   â””â”€ æ˜¯ â†’ ç»§ç»­
    â”‚
    â””â”€> åº”ç”¨å“åº”? (curl/httpè¯·æ±‚)
        â”œâ”€ è¶…æ—¶ â†’ 18.4 æ€§èƒ½é—®é¢˜
        â”œâ”€ é”™è¯¯ â†’ 18.2.4 åº”ç”¨é”™è¯¯
        â””â”€ æ­£å¸¸ â†’ è´Ÿè½½å‡è¡¡å™¨/DNSé—®é¢˜
```

### 18.1.2 å¿«é€Ÿè¯Šæ–­å·¥å…·ç®±

**ä¸€é”®è¯Šæ–­è„šæœ¬**
```bash
#!/bin/bash
# docker-diagnose.sh - Dockerå¿«é€Ÿè¯Šæ–­å·¥å…·

CONTAINER=$1

if [ -z "$CONTAINER" ]; then
    echo "ç”¨æ³•: $0 <å®¹å™¨åç§°æˆ–ID>"
    exit 1
fi

echo "=========================================="
echo "Dockerå®¹å™¨å¿«é€Ÿè¯Šæ–­: $CONTAINER"
echo "æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')"
echo "=========================================="

# 1. å®¹å™¨åŸºæœ¬çŠ¶æ€
echo -e "\n[1] å®¹å™¨çŠ¶æ€"
echo "----------------------------------------"
docker ps -a --filter "name=$CONTAINER" --format \
  "çŠ¶æ€: {{.Status}}\nåˆ›å»º: {{.CreatedAt}}\né•œåƒ: {{.Image}}\nç«¯å£: {{.Ports}}"

# 2. å®¹å™¨è¯¦ç»†ä¿¡æ¯
echo -e "\n[2] å®¹å™¨é…ç½®"
echo "----------------------------------------"
docker inspect $CONTAINER | jq -r '
  .[0] | {
    "è¿è¡ŒçŠ¶æ€": .State.Status,
    "å¯åŠ¨æ—¶é—´": .State.StartedAt,
    "é€€å‡ºä»£ç ": .State.ExitCode,
    "OOMè¢«æ€": .State.OOMKilled,
    "é‡å¯æ¬¡æ•°": .RestartCount,
    "IPåœ°å€": .NetworkSettings.IPAddress,
    "ç½‘ç»œæ¨¡å¼": .HostConfig.NetworkMode,
    "CPUé…é¢": .HostConfig.CpuQuota,
    "å†…å­˜é™åˆ¶": .HostConfig.Memory
  }
' | column -t -s ':'

# 3. èµ„æºä½¿ç”¨æƒ…å†µ
echo -e "\n[3] èµ„æºä½¿ç”¨"
echo "----------------------------------------"
docker stats $CONTAINER --no-stream --format \
  "CPU: {{.CPUPerc}}\nå†…å­˜: {{.MemUsage}} ({{.MemPerc}})\nç½‘ç»œ: {{.NetIO}}\nç£ç›˜: {{.BlockIO}}"

# 4. å®¹å™¨è¿›ç¨‹
echo -e "\n[4] å®¹å™¨è¿›ç¨‹"
echo "----------------------------------------"
docker top $CONTAINER

# 5. æœ€è¿‘æ—¥å¿—(æœ€å50è¡Œ)
echo -e "\n[5] æœ€è¿‘æ—¥å¿—(æœ€å50è¡Œ)"
echo "----------------------------------------"
docker logs --tail 50 $CONTAINER 2>&1 | tail -20

# 6. å¥åº·æ£€æŸ¥
echo -e "\n[6] å¥åº·æ£€æŸ¥"
echo "----------------------------------------"
docker inspect $CONTAINER | jq -r '
  .[0].State.Health // "æœªé…ç½®å¥åº·æ£€æŸ¥" |
  if type == "object" then
    "çŠ¶æ€: " + .Status + "\n" +
    "å¤±è´¥æ¬¡æ•°: " + (.FailingStreak | tostring) + "\n" +
    "æœ€åæ£€æŸ¥: " + (.Log[-1].Start // "N/A")
  else . end
'

# 7. ç½‘ç»œè¿æ¥
echo -e "\n[7] ç½‘ç»œè¿æ¥"
echo "----------------------------------------"
docker exec $CONTAINER sh -c 'netstat -tunlp 2>/dev/null || ss -tunlp' 2>/dev/null | head -10 || echo "æ— æ³•è·å–ç½‘ç»œä¿¡æ¯"

# 8. ç£ç›˜ä½¿ç”¨
echo -e "\n[8] ç£ç›˜ä½¿ç”¨"
echo "----------------------------------------"
docker exec $CONTAINER df -h 2>/dev/null | grep -E "Filesystem|/$" || echo "æ— æ³•è·å–ç£ç›˜ä¿¡æ¯"

# 9. ç›¸å…³äº‹ä»¶
echo -e "\n[9] å®¹å™¨äº‹ä»¶(æœ€è¿‘10æ¡)"
echo "----------------------------------------"
docker events --filter "container=$CONTAINER" --since 1h --until 0s 2>/dev/null | tail -10 || echo "æ— è¿‘æœŸäº‹ä»¶"

# 10. å»ºè®®æ“ä½œ
echo -e "\n[10] è¯Šæ–­å»ºè®®"
echo "----------------------------------------"

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
STATUS=$(docker inspect -f '{{.State.Status}}' $CONTAINER)
if [ "$STATUS" != "running" ]; then
    echo "âš ï¸  å®¹å™¨æœªè¿è¡Œ,å»ºè®®:"
    echo "   1. æŸ¥çœ‹é€€å‡ºåŸå› : docker logs $CONTAINER"
    echo "   2. æ£€æŸ¥å¯åŠ¨å‘½ä»¤: docker inspect $CONTAINER | jq '.[0].Config.Cmd'"
    echo "   3. å°è¯•é‡å¯: docker start $CONTAINER"
fi

# æ£€æŸ¥OOM
OOM=$(docker inspect -f '{{.State.OOMKilled}}' $CONTAINER)
if [ "$OOM" = "true" ]; then
    echo "âš ï¸  æ£€æµ‹åˆ°OOM Killer,å»ºè®®:"
    echo "   1. å¢åŠ å†…å­˜é™åˆ¶: docker update --memory 2g $CONTAINER"
    echo "   2. åˆ†æå†…å­˜ä½¿ç”¨: docker stats $CONTAINER"
    echo "   3. æ£€æŸ¥åº”ç”¨å†…å­˜æ³„æ¼"
fi

# æ£€æŸ¥é‡å¯æ¬¡æ•°
RESTART_COUNT=$(docker inspect -f '{{.RestartCount}}' $CONTAINER)
if [ "$RESTART_COUNT" -gt 5 ]; then
    echo "âš ï¸  å®¹å™¨é¢‘ç¹é‡å¯($RESTART_COUNTæ¬¡),å»ºè®®:"
    echo "   1. æŸ¥çœ‹å¯åŠ¨æ—¥å¿—: docker logs $CONTAINER"
    echo "   2. æ£€æŸ¥å¥åº·æ£€æŸ¥é…ç½®"
    echo "   3. éªŒè¯ä¾èµ–æœåŠ¡æ˜¯å¦æ­£å¸¸"
fi

echo -e "\n=========================================="
echo "è¯Šæ–­å®Œæˆ"
echo "=========================================="
```

**æ‰§è¡Œå¿«é€Ÿè¯Šæ–­**
```bash
chmod +x docker-diagnose.sh
./docker-diagnose.sh my-app

# ç¤ºä¾‹è¾“å‡º(éƒ¨åˆ†)
==========================================
Dockerå®¹å™¨å¿«é€Ÿè¯Šæ–­: my-app
æ—¶é—´: 2025-12-10 14:30:00
==========================================

[1] å®¹å™¨çŠ¶æ€
----------------------------------------
çŠ¶æ€: Up 2 hours
åˆ›å»º: 2025-12-10 12:30:00
é•œåƒ: myapp:latest
ç«¯å£: 0.0.0.0:8080->8080/tcp

[3] èµ„æºä½¿ç”¨
----------------------------------------
CPU: 45.23%
å†…å­˜: 1.2GiB / 2GiB (60%)
ç½‘ç»œ: 1.2MB / 3.4MB
ç£ç›˜: 45MB / 12MB

[10] è¯Šæ–­å»ºè®®
----------------------------------------
âš ï¸  å®¹å™¨é¢‘ç¹é‡å¯(8æ¬¡),å»ºè®®:
   1. æŸ¥çœ‹å¯åŠ¨æ—¥å¿—: docker logs my-app
   2. æ£€æŸ¥å¥åº·æ£€æŸ¥é…ç½®
   3. éªŒè¯ä¾èµ–æœåŠ¡æ˜¯å¦æ­£å¸¸
```

## 18.2 å®¹å™¨æ•…éšœæ’æŸ¥

### 18.2.1 å®¹å™¨æ— æ³•å¯åŠ¨

**é—®é¢˜åœºæ™¯1: é•œåƒæ‹‰å–å¤±è´¥**
```bash
# ç—‡çŠ¶
docker run myapp:latest
# Unable to find image 'myapp:latest' locally
# Error response from daemon: pull access denied for myapp

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨
docker images | grep myapp

# 2. æ£€æŸ¥é•œåƒä»“åº“è¿æ¥
docker login registry.example.com
# è¾“å…¥ç”¨æˆ·åå¯†ç 

# 3. æ‰‹åŠ¨æ‹‰å–é•œåƒ
docker pull registry.example.com/myapp:latest

# 4. ä½¿ç”¨å®Œæ•´é•œåƒå
docker run registry.example.com/myapp:latest

# 5. æ£€æŸ¥ç½‘ç»œè¿æ¥
curl -I https://registry.example.com
ping registry.example.com

# è§£å†³æ–¹æ¡ˆ
# A. é…ç½®é•œåƒä»“åº“è®¤è¯
cat > ~/.docker/config.json <<EOF
{
  "auths": {
    "registry.example.com": {
      "auth": "base64(username:password)"
    }
  }
}
EOF

# B. ä½¿ç”¨æœ¬åœ°æ„å»º
docker build -t myapp:latest .

# C. é…ç½®é•œåƒåŠ é€Ÿå™¨
cat > /etc/docker/daemon.json <<EOF
{
  "registry-mirrors": [
    "https://mirror.example.com"
  ]
}
EOF
systemctl restart docker
```

**é—®é¢˜åœºæ™¯2: ç«¯å£å†²çª**
```bash
# ç—‡çŠ¶
docker run -d -p 8080:8080 myapp
# Error: Bind for 0.0.0.0:8080 failed: port is already allocated

# æ’æŸ¥æ­¥éª¤
# 1. æŸ¥çœ‹ç«¯å£å ç”¨
netstat -tunlp | grep 8080
# æˆ–
ss -tunlp | grep 8080
# æˆ–
lsof -i :8080

# ç¤ºä¾‹è¾“å‡º
tcp  0  0  0.0.0.0:8080  0.0.0.0:*  LISTEN  12345/docker-proxy

# 2. æŸ¥æ‰¾å ç”¨ç«¯å£çš„å®¹å™¨
docker ps --format "{{.ID}}\t{{.Ports}}" | grep 8080

# 3. åœæ­¢å†²çªçš„å®¹å™¨
docker stop <container_id>

# è§£å†³æ–¹æ¡ˆ
# A. ä½¿ç”¨ä¸åŒç«¯å£
docker run -d -p 8081:8080 myapp

# B. åœæ­¢å ç”¨ç«¯å£çš„æœåŠ¡
systemctl stop apache2  # å¦‚æœæ˜¯ç³»ç»ŸæœåŠ¡

# C. ä½¿ç”¨åŠ¨æ€ç«¯å£åˆ†é…
docker run -d -p 8080 myapp  # Dockerè‡ªåŠ¨åˆ†é…å®¿ä¸»æœºç«¯å£
docker port <container_id>   # æŸ¥çœ‹åˆ†é…çš„ç«¯å£
```

**é—®é¢˜åœºæ™¯3: èµ„æºä¸è¶³**
```bash
# ç—‡çŠ¶
docker run -d --memory 16g myapp
# Error: Cannot start container: not enough memory

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥ç³»ç»Ÿå¯ç”¨å†…å­˜
free -h
#               total        used        free      shared  buff/cache   available
# Mem:           15Gi       12Gi        500Mi       100Mi        2.5Gi        2.5Gi

# 2. æ£€æŸ¥Dockerèµ„æºä½¿ç”¨
docker stats --no-stream

# 3. æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h
docker system df

# ç¤ºä¾‹è¾“å‡º
TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
Images          25        10        8.5GB     4.2GB (49%)
Containers      15        10        2.1GB     500MB (23%)
Local Volumes   5         3         1.2GB     800MB (66%)

# è§£å†³æ–¹æ¡ˆ
# A. é™ä½èµ„æºé™åˆ¶
docker run -d --memory 4g myapp

# B. æ¸…ç†æœªä½¿ç”¨èµ„æº
docker system prune -a --volumes
# è­¦å‘Š: ä¼šåˆ é™¤æ‰€æœ‰æœªä½¿ç”¨çš„é•œåƒã€å®¹å™¨ã€ç½‘ç»œã€å·

# C. å¢åŠ ç³»ç»Ÿèµ„æº
# - å¢åŠ ç‰©ç†å†…å­˜
# - è°ƒæ•´swapå¤§å°
dd if=/dev/zero of=/swapfile bs=1G count=8
mkswap /swapfile
swapon /swapfile

# D. è¿ç§»åˆ°èµ„æºå……è¶³çš„èŠ‚ç‚¹(Swarm)
docker service update --constraint-add node.labels.size==large myapp
```

**é—®é¢˜åœºæ™¯4: ä¾èµ–æœåŠ¡æœªå°±ç»ª**
```bash
# ç—‡çŠ¶
docker logs myapp
# Error: connection refused to database:5432
# Container exits immediately after start

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥ä¾èµ–æœåŠ¡çŠ¶æ€
docker ps | grep database

# 2. æµ‹è¯•è¿æ¥
docker run --rm --network myapp_network \
  alpine sh -c 'nc -zv database 5432'

# 3. æŸ¥çœ‹å®¹å™¨å¯åŠ¨é¡ºåº
docker-compose ps

# è§£å†³æ–¹æ¡ˆ
# A. ä½¿ç”¨depends_on + å¥åº·æ£€æŸ¥
version: '3.8'
services:
  database:
    image: postgres:15
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  app:
    image: myapp:latest
    depends_on:
      database:
        condition: service_healthy

# B. åº”ç”¨å†…å®ç°é‡è¯•é€»è¾‘
import time
import psycopg2

def connect_db(max_retries=30, delay=2):
    for i in range(max_retries):
        try:
            conn = psycopg2.connect(
                host="database",
                port=5432,
                user="postgres"
            )
            return conn
        except psycopg2.OperationalError:
            if i < max_retries - 1:
                print(f"æ•°æ®åº“è¿æ¥å¤±è´¥,{delay}ç§’åé‡è¯•... ({i+1}/{max_retries})")
                time.sleep(delay)
            else:
                raise

# C. ä½¿ç”¨wait-for-itè„šæœ¬
#!/bin/bash
# wait-for-it.sh
set -e

host="$1"
shift
cmd="$@"

until nc -z "$host" 5432; do
  echo "ç­‰å¾… $host:5432..."
  sleep 1
done

echo "$host:5432 å·²å°±ç»ª"
exec $cmd

# Dockerfile
COPY wait-for-it.sh /usr/local/bin/
ENTRYPOINT ["wait-for-it.sh", "database:5432", "--"]
CMD ["python", "app.py"]
```

### 18.2.2 å®¹å™¨å¼‚å¸¸é€€å‡º

**é€€å‡ºä»£ç åˆ†æ**
```bash
# æŸ¥çœ‹å®¹å™¨é€€å‡ºä»£ç 
docker inspect -f '{{.State.ExitCode}}' myapp

# å¸¸è§é€€å‡ºä»£ç å«ä¹‰
# 0    : æ­£å¸¸é€€å‡º
# 1    : åº”ç”¨é”™è¯¯(é€šç”¨é”™è¯¯)
# 125  : Dockerå®ˆæŠ¤è¿›ç¨‹é”™è¯¯
# 126  : å‘½ä»¤æ— æ³•æ‰§è¡Œ
# 127  : å‘½ä»¤æœªæ‰¾åˆ°
# 128+n: ä¿¡å·ç»ˆæ­¢(nä¸ºä¿¡å·ç¼–å·)
#   137 = 128 + 9 (SIGKILL,å¼ºåˆ¶æ€æ­»)
#   139 = 128 + 11 (SIGSEGV,æ®µé”™è¯¯)
#   143 = 128 + 15 (SIGTERM,æ­£å¸¸ç»ˆæ­¢)
```

**åœºæ™¯1: OOM Killer**
```bash
# ç—‡çŠ¶
docker inspect -f '{{.State.OOMKilled}}' myapp
# true

docker logs myapp
# (æ— è¾“å‡ºæˆ–çªç„¶ä¸­æ–­)

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
dmesg | grep -i "out of memory"
journalctl -k | grep -i "killed process"

# ç¤ºä¾‹è¾“å‡º
[12345.678] Out of memory: Killed process 23456 (java) total-vm:4194304kB

# æ’æŸ¥æ­¥éª¤
# 1. æŸ¥çœ‹å†…å­˜é™åˆ¶
docker inspect myapp | jq '.[0].HostConfig.Memory'

# 2. æŸ¥çœ‹å®é™…å†…å­˜ä½¿ç”¨
docker stats myapp --no-stream

# 3. åˆ†æå†…å­˜è¶‹åŠ¿
# ä½¿ç”¨cAdvisoræˆ–PrometheusæŸ¥çœ‹å†å²æ•°æ®

# è§£å†³æ–¹æ¡ˆ
# A. å¢åŠ å†…å­˜é™åˆ¶
docker update --memory 4g --memory-swap 6g myapp

# B. è°ƒæ•´OOMä¼˜å…ˆçº§
docker update --oom-score-adj -500 myapp  # é™ä½è¢«æ€æ¦‚ç‡

# C. ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨
# Javaåº”ç”¨
docker run -e JAVA_OPTS="-Xms1g -Xmx2g -XX:+UseG1GC" myapp

# D. å¯ç”¨Swap(è°¨æ…ä½¿ç”¨)
docker run --memory 2g --memory-swap 4g myapp
```

**åœºæ™¯2: åº”ç”¨å´©æºƒ**
```bash
# ç—‡çŠ¶
docker logs myapp
# Traceback (most recent call last):
#   File "app.py", line 42
#     result = process_data(None)
# AttributeError: 'NoneType' object has no attribute 'split'

# æ’æŸ¥æ­¥éª¤
# 1. æŸ¥çœ‹å®Œæ•´æ—¥å¿—
docker logs --tail 200 myapp > myapp.log

# 2. è¿›å…¥å®¹å™¨è°ƒè¯•(å¦‚æœå¯ä»¥å¯åŠ¨)
docker run -it --entrypoint /bin/bash myapp

# 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
docker exec myapp cat /app/config.yaml

# 4. æŸ¥çœ‹ç¯å¢ƒå˜é‡
docker exec myapp env

# è§£å†³æ–¹æ¡ˆ
# A. ä¿®å¤ä»£ç bug
def process_data(data):
    if data is None:
        raise ValueError("data cannot be None")
    return data.split(',')

# B. æ·»åŠ å¼‚å¸¸å¤„ç†
try:
    result = process_data(data)
except Exception as e:
    logger.error(f"å¤„ç†å¤±è´¥: {e}")
    # ä¼˜é›…é™çº§æˆ–è¿”å›é»˜è®¤å€¼

# C. é‡æ–°æ„å»ºé•œåƒ
docker build -t myapp:latest .
docker service update --image myapp:latest myapp
```

**åœºæ™¯3: å¥åº·æ£€æŸ¥å¤±è´¥**
```bash
# ç—‡çŠ¶
docker ps
# STATUS: Up 5 minutes (unhealthy)

docker inspect myapp | jq '.[0].State.Health.Log[-3:]'
# [
#   {
#     "Start": "2025-12-10T14:30:00Z",
#     "End": "2025-12-10T14:30:03Z",
#     "ExitCode": 1,
#     "Output": "HTTP/1.1 503 Service Unavailable"
#   }
# ]

# æ’æŸ¥æ­¥éª¤
# 1. æ‰‹åŠ¨æ‰§è¡Œå¥åº·æ£€æŸ¥å‘½ä»¤
docker exec myapp curl -f http://localhost:8080/health

# 2. æŸ¥çœ‹åº”ç”¨æ—¥å¿—
docker logs myapp | grep -i "health"

# 3. æ£€æŸ¥å¥åº·æ£€æŸ¥é…ç½®
docker inspect myapp | jq '.[0].Config.Healthcheck'

# è§£å†³æ–¹æ¡ˆ
# A. è°ƒæ•´å¥åº·æ£€æŸ¥å‚æ•°
# Dockerfile
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8080/health || exit 1

# B. ä¿®å¤å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.route('/health')
def health():
    # æ£€æŸ¥å…³é”®ä¾èµ–
    try:
        db.execute("SELECT 1")
        redis.ping()
        return jsonify({"status": "healthy"}), 200
    except Exception as e:
        return jsonify({"status": "unhealthy", "error": str(e)}), 503

# C. å¢åŠ å¯åŠ¨æ—¶é—´(start-period)
docker run --health-cmd="curl -f http://localhost:8080/health" \
           --health-interval=30s \
           --health-start-period=120s \
           myapp

# D. ç¦ç”¨å¥åº·æ£€æŸ¥(ä¸´æ—¶è°ƒè¯•)
docker run --no-healthcheck myapp
```

### 18.2.3 å®¹å™¨æ€§èƒ½é—®é¢˜

**åœºæ™¯1: CPUä½¿ç”¨ç‡100%**
```bash
# ç—‡çŠ¶
docker stats myapp
# CPU %: 399.5%  (4æ ¸å¿ƒå…¨éƒ¨è·‘æ»¡)

# æ’æŸ¥æ­¥éª¤
# 1. æŸ¥çœ‹å®¹å™¨å†…è¿›ç¨‹
docker top myapp

# 2. è¿›å…¥å®¹å™¨ä½¿ç”¨top
docker exec -it myapp top

# 3. CPU profiling
# è·å–å®¹å™¨PID
PID=$(docker inspect -f '{{.State.Pid}}' myapp)

# ä½¿ç”¨perfåˆ†æ
perf record -F 99 -p $PID -g -- sleep 30
perf report

# æˆ–ä½¿ç”¨py-spy(Python)
docker exec myapp pip install py-spy
docker exec myapp py-spy top --pid 1

# 4. æŸ¥çœ‹æ…¢æŸ¥è¯¢
docker exec myapp-db psql -c "
  SELECT query, calls, total_time, mean_time
  FROM pg_stat_statements
  ORDER BY total_time DESC
  LIMIT 10;
"

# è§£å†³æ–¹æ¡ˆ
# A. ä¼˜åŒ–ä»£ç çƒ­ç‚¹
# ä½¿ç”¨ç¼“å­˜å‡å°‘è®¡ç®—
# å¼‚æ­¥å¤„ç†è€—æ—¶æ“ä½œ
# ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦

# B. å¢åŠ CPUé…é¢
docker update --cpus 8 myapp

# C. æ¨ªå‘æ‰©å±•
docker service scale myapp=4

# D. é™åˆ¶å¹¶å‘
# Gunicorn
workers = 4  # é™ä½workeræ•°é‡
threads = 2
worker_class = "gthread"

# E. é™æµ
from flask_limiter import Limiter

limiter = Limiter(
    app,
    default_limits=["100 per minute"]
)
```

**åœºæ™¯2: å†…å­˜æŒç»­å¢é•¿**
```bash
# ç—‡çŠ¶
docker stats myapp
# å†…å­˜ä½¿ç”¨æŒç»­å¢é•¿: 500MB -> 1GB -> 1.5GB -> ...

# æ’æŸ¥æ­¥éª¤
# 1. ç›‘æ§å†…å­˜è¶‹åŠ¿
watch -n 5 'docker stats myapp --no-stream'

# 2. æŸ¥çœ‹è¿›ç¨‹å†…å­˜åˆ†å¸ƒ
docker exec myapp cat /proc/1/status | grep -i mem

# 3. Pythonå†…å­˜åˆ†æ
docker exec myapp pip install memory_profiler
docker exec myapp python -m memory_profiler app.py

# 4. Javaå †åˆ†æ
docker exec myapp jmap -heap 1
docker exec myapp jmap -dump:file=/tmp/heap.hprof 1
docker cp myapp:/tmp/heap.hprof .
# ä½¿ç”¨MATåˆ†æ

# 5. æ£€æŸ¥ç¼“å­˜å¤§å°
docker exec myapp-redis redis-cli info memory

# è§£å†³æ–¹æ¡ˆ
# A. æŸ¥æ‰¾å†…å­˜æ³„æ¼
# Python
import tracemalloc

tracemalloc.start()

# ... è¿è¡Œä¸€æ®µæ—¶é—´ ...

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

for stat in top_stats[:10]:
    print(stat)

# B. é™åˆ¶ç¼“å­˜å¤§å°
from functools import lru_cache

@lru_cache(maxsize=1000)  # æœ€å¤šç¼“å­˜1000æ¡
def expensive_function(param):
    pass

# C. å®šæœŸé‡å¯worker
# Gunicorn
max_requests = 10000
max_requests_jitter = 1000

# D. é…ç½®GC
# Java
JAVA_OPTS="-Xms2g -Xmx2g -XX:+UseG1GC -XX:MaxGCPauseMillis=200"

# E. å¢åŠ å†…å­˜é™åˆ¶(æœ€åæ‰‹æ®µ)
docker update --memory 4g myapp
```

**åœºæ™¯3: ç£ç›˜IOç“¶é¢ˆ**
```bash
# ç—‡çŠ¶
docker stats myapp
# BLOCK I/O: 1.2GB / 3.4GB (æŒç»­é«˜IO)

# åº”ç”¨å“åº”ç¼“æ…¢,å°¤å…¶æ˜¯æ•°æ®åº“æ“ä½œ

# æ’æŸ¥æ­¥éª¤
# 1. æŸ¥çœ‹IOç»Ÿè®¡
iostat -x 1 10

# ç¤ºä¾‹è¾“å‡º
Device    r/s     w/s   rkB/s   wkB/s  await  %util
sda      150.0   300.0  6000    12000  25.5   98.0

# 2. æŸ¥çœ‹å®¹å™¨IO
docker stats myapp --no-stream --format \
  "{{.Container}}: {{.BlockIO}}"

# 3. æŸ¥æ‰¾IOçƒ­ç‚¹è¿›ç¨‹
iotop -o  # ä»…æ˜¾ç¤ºæœ‰IOçš„è¿›ç¨‹

# 4. æ•°æ®åº“æ…¢æŸ¥è¯¢
docker exec postgres-db psql -c "
  SELECT * FROM pg_stat_activity
  WHERE state = 'active'
  AND query_start < NOW() - INTERVAL '5 seconds';
"

# è§£å†³æ–¹æ¡ˆ
# A. ä¼˜åŒ–å­˜å‚¨é©±åŠ¨
# ç¡®ä¿ä½¿ç”¨overlay2
docker info | grep "Storage Driver"

# B. ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨
# è¿ç§»åˆ°SSD/NVMe
# ä½¿ç”¨tmpfs forä¸´æ—¶æ•°æ®
docker run -v type=tmpfs,target=/tmp,tmpfs-size=1G myapp

# C. è°ƒæ•´IOè°ƒåº¦å™¨
echo none > /sys/block/nvme0n1/queue/scheduler

# D. æ•°æ®åº“ä¼˜åŒ–
# PostgreSQL
shared_buffers = 8GB
effective_cache_size = 24GB
random_page_cost = 1.1  # SSD
checkpoint_completion_target = 0.9

# E. åº”ç”¨å±‚ä¼˜åŒ–
# æ‰¹é‡æ“ä½œ
# å‡å°‘æ•°æ®åº“æŸ¥è¯¢
# ä½¿ç”¨ç´¢å¼•
# å¯ç”¨æŸ¥è¯¢ç¼“å­˜
```

### 18.2.4 æ•°æ®æŒä¹…åŒ–é—®é¢˜

**åœºæ™¯1: æ•°æ®ä¸¢å¤±**
```bash
# ç—‡çŠ¶
# å®¹å™¨é‡å¯åæ•°æ®ä¸¢å¤±

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥å·æŒ‚è½½
docker inspect myapp | jq '.[0].Mounts'

# 2. éªŒè¯æ•°æ®ä½ç½®
docker exec myapp ls -la /var/lib/mysql

# 3. æ£€æŸ¥å·æ˜¯å¦å­˜åœ¨
docker volume ls | grep myapp

# è§£å†³æ–¹æ¡ˆ
# A. æ­£ç¡®æŒ‚è½½å·
docker run -v myapp-data:/var/lib/mysql mysql:8

# B. ä½¿ç”¨bind mount
docker run -v /data/mysql:/var/lib/mysql mysql:8

# C. Docker Compose
version: '3.8'
services:
  db:
    image: mysql:8
    volumes:
      - db-data:/var/lib/mysql

volumes:
  db-data:
    driver: local
```

**åœºæ™¯2: æƒé™é—®é¢˜**
```bash
# ç—‡çŠ¶
docker logs myapp
# Permission denied: '/data/app.log'

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥æ–‡ä»¶æƒé™
docker exec myapp ls -la /data

# 2. æ£€æŸ¥å®¹å™¨è¿è¡Œç”¨æˆ·
docker inspect myapp | jq '.[0].Config.User'

# 3. æ£€æŸ¥å®¿ä¸»æœºæƒé™
ls -la /mnt/data

# è§£å†³æ–¹æ¡ˆ
# A. ä¿®æ”¹å®¿ä¸»æœºæƒé™
sudo chown -R 1000:1000 /mnt/data

# B. ä»¥rootè¿è¡Œ(ä¸æ¨è)
docker run --user root myapp

# C. DockerfileæŒ‡å®šç”¨æˆ·
FROM python:3.11-slim

RUN groupadd -r app && useradd -r -g app app

WORKDIR /app
COPY --chown=app:app . .

USER app
CMD ["python", "app.py"]

# D. initå®¹å™¨ä¿®å¤æƒé™
docker run --rm -v myapp-data:/data \
  busybox chown -R 1000:1000 /data
```

## 18.3 ç½‘ç»œæ•…éšœæ’æŸ¥

### 18.3.1 å®¹å™¨é—´ç½‘ç»œä¸é€š

**æ’æŸ¥å·¥å…·ç®±**
```bash
# å®‰è£…ç½‘ç»œè°ƒè¯•å·¥å…·
docker run -it --rm --network myapp_network \
  nicolaka/netshoot

# å·¥å…·åŒ…å«:
# - ping, traceroute, mtr
# - curl, wget, httpie
# - netstat, ss, lsof
# - tcpdump, nmap
# - dig, nslookup, host
# - iperf3
```

**åœºæ™¯1: DNSè§£æå¤±è´¥**
```bash
# ç—‡çŠ¶
docker exec app curl database:5432
# curl: (6) Could not resolve host: database

# æ’æŸ¥æ­¥éª¤
# 1. æµ‹è¯•DNSè§£æ
docker exec app nslookup database

# 2. æ£€æŸ¥DNSé…ç½®
docker exec app cat /etc/resolv.conf

# 3. æ£€æŸ¥ç½‘ç»œè¿æ¥
docker inspect app | jq '.[0].NetworkSettings.Networks'

# 4. éªŒè¯æœåŠ¡å‘ç°
docker network inspect myapp_network | jq '.[0].Containers'

# è§£å†³æ–¹æ¡ˆ
# A. ç¡®ä¿åœ¨åŒä¸€ç½‘ç»œ
docker network connect myapp_network app

# B. ä½¿ç”¨IPåœ°å€(ä¸´æ—¶)
DATABASE_IP=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' database)
docker exec app curl $DATABASE_IP:5432

# C. é…ç½®è‡ªå®šä¹‰DNS
docker run --dns 8.8.8.8 --dns 8.8.4.4 myapp

# D. æ£€æŸ¥Docker DNSæœåŠ¡
docker exec app cat /etc/resolv.conf
# nameserver 127.0.0.11  # Dockerå†…ç½®DNS

# éªŒè¯å†…ç½®DNS
docker exec app nslookup database 127.0.0.11
```

**åœºæ™¯2: ç«¯å£ä¸é€š**
```bash
# ç—‡çŠ¶
docker exec app curl database:5432
# curl: (7) Failed to connect to database port 5432: Connection refused

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥ç«¯å£ç›‘å¬
docker exec database netstat -tunlp | grep 5432

# æˆ–
docker exec database ss -tunlp | grep 5432

# 2. æµ‹è¯•ç«¯å£è¿é€šæ€§
docker exec app nc -zv database 5432
# Connection to database 5432 port [tcp/postgresql] succeeded!

# æˆ–ä½¿ç”¨telnet
docker exec app telnet database 5432

# 3. æ£€æŸ¥é˜²ç«å¢™è§„åˆ™
iptables -L -n | grep 5432

# 4. æŠ“åŒ…åˆ†æ
docker exec app tcpdump -i eth0 port 5432

# è§£å†³æ–¹æ¡ˆ
# A. ç¡®è®¤åº”ç”¨ç›‘å¬æ­£ç¡®åœ°å€
# ä¸è¦ç›‘å¬localhost,è¦ç›‘å¬0.0.0.0
bind = "0.0.0.0:5432"  # æ­£ç¡®
bind = "127.0.0.1:5432"  # é”™è¯¯,åªèƒ½å®¹å™¨å†…è®¿é—®

# B. æ£€æŸ¥é˜²ç«å¢™
# Dockerè‡ªåŠ¨é…ç½®iptables,ä¸€èˆ¬ä¸éœ€è¦æ‰‹åŠ¨é…ç½®

# C. éªŒè¯æœåŠ¡å¯åŠ¨
docker exec database ps aux | grep postgres
```

**åœºæ™¯3: ç½‘ç»œç­–ç•¥é™åˆ¶**
```bash
# ç—‡çŠ¶(ä½¿ç”¨Swarmç½‘ç»œç­–ç•¥æ—¶)
# éƒ¨åˆ†å®¹å™¨å¯ä»¥è®¿é—®,éƒ¨åˆ†ä¸èƒ½

# æ’æŸ¥æ­¥éª¤
# 1. æŸ¥çœ‹ç½‘ç»œç­–ç•¥
docker network inspect myapp_network

# 2. æµ‹è¯•è¿é€šæ€§çŸ©é˜µ
for service in app1 app2 app3; do
  echo "æµ‹è¯• $service:"
  docker exec $service curl -s -o /dev/null -w "%{http_code}" database:5432
done

# è§£å†³æ–¹æ¡ˆ
# A. ä½¿ç”¨overlayç½‘ç»œ(Swarm)
docker network create --driver overlay myapp_network

# B. ç¡®ä¿æœåŠ¡åœ¨åŒä¸€ç½‘ç»œ
docker service update --network-add myapp_network app

# C. ä½¿ç”¨æœåŠ¡åè€Œéå®¹å™¨å
curl database:5432  # æ­£ç¡®(æœåŠ¡å)
curl database.1.abc123:5432  # é”™è¯¯(å®¹å™¨å)
```

### 18.3.2 å¤–éƒ¨è®¿é—®ä¸é€š

**åœºæ™¯1: ç«¯å£æ˜ å°„é—®é¢˜**
```bash
# ç—‡çŠ¶
curl http://localhost:8080
# curl: (7) Failed to connect to localhost port 8080

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥ç«¯å£æ˜ å°„
docker ps --format "{{.Names}}: {{.Ports}}"

# 2. æ£€æŸ¥ç«¯å£ç›‘å¬
netstat -tunlp | grep 8080
ss -tunlp | grep 8080

# 3. æµ‹è¯•ä»å®¿ä¸»æœºè®¿é—®
curl http://localhost:8080
curl http://127.0.0.1:8080
curl http://$(hostname -I | awk '{print $1}'):8080

# 4. æ£€æŸ¥é˜²ç«å¢™
iptables -L -n -v | grep 8080
firewall-cmd --list-all

# è§£å†³æ–¹æ¡ˆ
# A. æ­£ç¡®çš„ç«¯å£æ˜ å°„æ ¼å¼
docker run -p 8080:80 nginx  # å®¿ä¸»æœº8080 -> å®¹å™¨80

# B. ç»‘å®šæ‰€æœ‰æ¥å£
docker run -p 0.0.0.0:8080:80 nginx

# C. å¼€æ”¾é˜²ç«å¢™ç«¯å£
firewall-cmd --add-port=8080/tcp --permanent
firewall-cmd --reload

# D. æ£€æŸ¥Docker iptablesè§„åˆ™
iptables -t nat -L -n | grep 8080
```

**åœºæ™¯2: Swarmè·¯ç”±ç½‘æ ¼é—®é¢˜**
```bash
# ç—‡çŠ¶
# æŸäº›èŠ‚ç‚¹å¯ä»¥è®¿é—®æœåŠ¡,æŸäº›ä¸èƒ½

# æ’æŸ¥æ­¥éª¤
# 1. æ£€æŸ¥æœåŠ¡å‘å¸ƒç«¯å£
docker service inspect myapp | jq '.[0].Endpoint.Ports'

# 2. æµ‹è¯•æ¯ä¸ªèŠ‚ç‚¹
for node in node1 node2 node3; do
  echo "æµ‹è¯• $node:"
  ssh $node "curl -s -o /dev/null -w '%{http_code}\n' http://localhost:8080"
done

# 3. æ£€æŸ¥ingressç½‘ç»œ
docker network inspect ingress

# 4. æŸ¥çœ‹èŠ‚ç‚¹å¯ç”¨æ€§
docker node ls

# è§£å†³æ–¹æ¡ˆ
# A. é‡å»ºingressç½‘ç»œ
docker network rm ingress
docker network create \
  --driver overlay \
  --ingress \
  --subnet=10.0.0.0/24 \
  --gateway=10.0.0.1 \
  ingress

# B. æ£€æŸ¥èŠ‚ç‚¹é˜²ç«å¢™
# ç¡®ä¿ä»¥ä¸‹ç«¯å£å¼€æ”¾:
# - 2377/tcp (cluster management)
# - 7946/tcp+udp (container network discovery)
# - 4789/udp (overlay network traffic)

# C. æœåŠ¡ä½¿ç”¨hostæ¨¡å¼
docker service create --mode global --publish mode=host,target=80,published=8080 nginx
```

## 18.4 æ—¥å¿—åˆ†æä¸è°ƒè¯•

### 18.4.1 æ—¥å¿—æ”¶é›†æŠ€å·§

**ç»“æ„åŒ–æ—¥å¿—æŸ¥è¯¢**
```bash
# æŒ‰æ—¶é—´èŒƒå›´
docker logs --since "2025-12-10T14:00:00" --until "2025-12-10T15:00:00" myapp

# æŒ‰æ—¶é—´ç›¸å¯¹å€¼
docker logs --since 1h myapp  # æœ€è¿‘1å°æ—¶
docker logs --since 30m myapp  # æœ€è¿‘30åˆ†é’Ÿ

# å®æ—¶è·Ÿè¸ª
docker logs -f myapp

# åªçœ‹æœ€æ–°Nè¡Œ
docker logs --tail 100 myapp

# åŒ…å«æ—¶é—´æˆ³
docker logs -t myapp

# è¿‡æ»¤å…³é”®å­—
docker logs myapp 2>&1 | grep -i error
docker logs myapp 2>&1 | grep -E "(ERROR|WARN|FATAL)"

# ç»Ÿè®¡é”™è¯¯æ•°é‡
docker logs myapp 2>&1 | grep -c ERROR

# ä¿å­˜åˆ°æ–‡ä»¶
docker logs myapp > myapp_$(date +%Y%m%d_%H%M%S).log
```

**å¤šå®¹å™¨æ—¥å¿—èšåˆ**
```bash
#!/bin/bash
# collect-logs.sh - æ”¶é›†æ‰€æœ‰æœåŠ¡æ—¥å¿—

SERVICES=$(docker service ls --format "{{.Name}}")
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_DIR="logs_$TIMESTAMP"

mkdir -p $LOG_DIR

for service in $SERVICES; do
    echo "æ”¶é›† $service æ—¥å¿—..."

    # è·å–æœåŠ¡çš„æ‰€æœ‰ä»»åŠ¡
    TASKS=$(docker service ps $service --format "{{.Name}}.{{.ID}}" --filter "desired-state=running")

    for task in $TASKS; do
        CONTAINER=$(docker ps --filter "name=$task" --format "{{.ID}}")
        if [ -n "$CONTAINER" ]; then
            docker logs $CONTAINER > "$LOG_DIR/${service}_${CONTAINER:0:12}.log" 2>&1
            echo "  âœ“ $CONTAINER"
        fi
    done
done

# æ‰“åŒ…
tar -czf logs_$TIMESTAMP.tar.gz $LOG_DIR
echo "æ—¥å¿—å·²ä¿å­˜åˆ°: logs_$TIMESTAMP.tar.gz"
```

### 18.4.2 å¸¸è§é”™è¯¯æ¨¡å¼

**é”™è¯¯æ¨¡å¼è¯†åˆ«è„šæœ¬**
```bash
#!/bin/bash
# analyze-errors.sh - åˆ†ææ—¥å¿—ä¸­çš„é”™è¯¯æ¨¡å¼

LOG_FILE=$1

if [ -z "$LOG_FILE" ]; then
    echo "ç”¨æ³•: $0 <æ—¥å¿—æ–‡ä»¶>"
    exit 1
fi

echo "=========================================="
echo "æ—¥å¿—é”™è¯¯åˆ†æ: $LOG_FILE"
echo "=========================================="

# 1. é”™è¯¯ç»Ÿè®¡
echo -e "\n[1] é”™è¯¯çº§åˆ«ç»Ÿè®¡"
echo "----------------------------------------"
echo "FATAL: $(grep -c FATAL $LOG_FILE)"
echo "ERROR: $(grep -c ERROR $LOG_FILE)"
echo "WARN:  $(grep -c WARN $LOG_FILE)"

# 2. Top 10é”™è¯¯ç±»å‹
echo -e "\n[2] Top 10 é”™è¯¯ç±»å‹"
echo "----------------------------------------"
grep -oP '(?<=Exception: ).*' $LOG_FILE | sort | uniq -c | sort -rn | head -10

# 3. æ—¶é—´åˆ†å¸ƒ
echo -e "\n[3] é”™è¯¯æ—¶é—´åˆ†å¸ƒ"
echo "----------------------------------------"
grep ERROR $LOG_FILE | awk '{print $1}' | cut -d: -f1 | sort | uniq -c

# 4. ç›¸å…³é”™è¯¯(å‰å5è¡Œ)
echo -e "\n[4] é¦–ä¸ªFATALé”™è¯¯ä¸Šä¸‹æ–‡"
echo "----------------------------------------"
grep -n -A 5 -B 5 FATAL $LOG_FILE | head -20

# 5. é”™è¯¯è¶‹åŠ¿
echo -e "\n[5] æ¯åˆ†é’Ÿé”™è¯¯æ•°"
echo "----------------------------------------"
grep ERROR $LOG_FILE | awk '{print substr($2,1,5)}' | sort | uniq -c | tail -20

echo -e "\n=========================================="
```

**Pythonæ—¥å¿—åˆ†æ**
```python
#!/usr/bin/env python3
# log_analyzer.py - é«˜çº§æ—¥å¿—åˆ†æ

import re
import sys
from collections import Counter, defaultdict
from datetime import datetime

def analyze_log(log_file):
    """åˆ†ææ—¥å¿—æ–‡ä»¶"""

    errors = []
    errors_by_type = Counter()
    errors_by_time = defaultdict(int)

    # æ­£åˆ™æ¨¡å¼
    timestamp_pattern = r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
    level_pattern = r'\[(ERROR|WARN|FATAL)\]'
    exception_pattern = r'(\w+Exception|Error):'

    with open(log_file, 'r') as f:
        for line in f:
            # æå–æ—¶é—´æˆ³
            ts_match = re.search(timestamp_pattern, line)
            if ts_match:
                timestamp = datetime.fromisoformat(ts_match.group(1))
                hour_key = timestamp.strftime('%Y-%m-%d %H:00')

            # æ£€æŸ¥é”™è¯¯çº§åˆ«
            level_match = re.search(level_pattern, line)
            if level_match:
                level = level_match.group(1)

                # ç»Ÿè®¡é”™è¯¯ç±»å‹
                exception_match = re.search(exception_pattern, line)
                if exception_match:
                    error_type = exception_match.group(1)
                    errors_by_type[error_type] += 1

                # æ—¶é—´åˆ†å¸ƒ
                errors_by_time[hour_key] += 1

                errors.append({
                    'timestamp': timestamp if ts_match else None,
                    'level': level,
                    'message': line.strip()
                })

    # æŠ¥å‘Š
    print("=" * 60)
    print("æ—¥å¿—åˆ†ææŠ¥å‘Š")
    print("=" * 60)

    print(f"\næ€»é”™è¯¯æ•°: {len(errors)}")

    print("\nTop 10 é”™è¯¯ç±»å‹:")
    for error_type, count in errors_by_type.most_common(10):
        print(f"  {error_type:30} {count:5} æ¬¡")

    print("\né”™è¯¯æ—¶é—´åˆ†å¸ƒ:")
    for hour, count in sorted(errors_by_time.items())[-24:]:
        print(f"  {hour}: {'=' * (count // 10)} ({count})")

    # æ£€æµ‹é”™è¯¯å³°å€¼
    max_errors = max(errors_by_time.values()) if errors_by_time else 0
    avg_errors = sum(errors_by_time.values()) / len(errors_by_time) if errors_by_time else 0

    print(f"\né”™è¯¯å³°å€¼: {max_errors} æ¬¡/å°æ—¶")
    print(f"å¹³å‡é”™è¯¯: {avg_errors:.1f} æ¬¡/å°æ—¶")

    if max_errors > avg_errors * 3:
        print("\nâš ï¸  æ£€æµ‹åˆ°é”™è¯¯å³°å€¼å¼‚å¸¸ï¼")
        # æ‰¾å‡ºå³°å€¼æ—¶é—´
        peak_hours = [h for h, c in errors_by_time.items() if c > avg_errors * 2]
        print(f"å¼‚å¸¸æ—¶é—´æ®µ: {', '.join(peak_hours)}")

if __name__ == '__main__':
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python log_analyzer.py <æ—¥å¿—æ–‡ä»¶>")
        sys.exit(1)

    analyze_log(sys.argv[1])
```

### 18.4.3 å®æ—¶è°ƒè¯•æŠ€å·§

**è¿›å…¥è¿è¡Œä¸­çš„å®¹å™¨**
```bash
# æ–¹æ³•1: exec bash
docker exec -it myapp /bin/bash

# æ–¹æ³•2: exec sh (Alpineé•œåƒ)
docker exec -it myapp /bin/sh

# æ–¹æ³•3: nsenter(å®¹å™¨æ— shellæ—¶)
PID=$(docker inspect -f '{{.State.Pid}}' myapp)
nsenter -t $PID -n -p -m /bin/bash

# åœ¨å®¹å™¨å†…è°ƒè¯•
# å®‰è£…å·¥å…·
apt-get update && apt-get install -y curl netcat-openbsd

# æµ‹è¯•ç½‘ç»œ
curl -v http://database:5432
nc -zv database 5432

# æŸ¥çœ‹è¿›ç¨‹
ps aux
top

# æŸ¥çœ‹æ—¥å¿—
tail -f /var/log/app.log

# ç¯å¢ƒå˜é‡
env | grep DATABASE

# æ–‡ä»¶ç³»ç»Ÿ
df -h
du -sh /data/*
```

**åŠ¨æ€ä¿®æ”¹é…ç½®**
```bash
# çƒ­é‡è½½é…ç½®(Nginxç¤ºä¾‹)
docker exec nginx nginx -t  # æµ‹è¯•é…ç½®
docker exec nginx nginx -s reload  # é‡è½½é…ç½®

# ä¿®æ”¹æ—¥å¿—çº§åˆ«(æ— éœ€é‡å¯)
docker exec myapp curl -X POST http://localhost:8080/admin/loglevel?level=DEBUG

# ä¸´æ—¶ä¿®æ”¹ç¯å¢ƒå˜é‡
docker exec myapp sh -c 'export DEBUG=true && /app/restart.sh'
```

**æ€§èƒ½å‰–æ**
```bash
# Python - cProfile
docker exec myapp python -m cProfile -o output.prof app.py

# Python - å®æ—¶å‰–æ
docker exec myapp pip install py-spy
docker exec myapp py-spy top --pid 1

# Java - JFR(Java Flight Recorder)
docker exec myapp jcmd 1 JFR.start duration=60s filename=/tmp/profile.jfr
docker cp myapp:/tmp/profile.jfr .

# Go - pprof
docker exec myapp curl http://localhost:6060/debug/pprof/profile?seconds=30 > cpu.prof
go tool pprof cpu.prof
```

## 18.5 ç”Ÿäº§ç¯å¢ƒæ•…éšœæ¡ˆä¾‹

### 18.5.1 æ¡ˆä¾‹1: æœåŠ¡é›ªå´©

**æ•…éšœç°è±¡**
```
2025-12-10 14:30:00 - ç”¨æˆ·æŠ¥å‘ŠæœåŠ¡å“åº”ç¼“æ…¢
14:32:00 - éƒ¨åˆ†è¯·æ±‚å¼€å§‹è¶…æ—¶
14:35:00 - å¤§é‡503é”™è¯¯
14:38:00 - æ‰€æœ‰æœåŠ¡ä¸å¯ç”¨
```

**æ’æŸ¥è¿‡ç¨‹**
```bash
# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker service ls
# å‘ç°æ‰€æœ‰å‰¯æœ¬å¤„äº 0/3 çŠ¶æ€

# 2. æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker ps -a | grep myapp
# æ‰€æœ‰å®¹å™¨å¤„äº Restarting çŠ¶æ€

# 3. æŸ¥çœ‹æ—¥å¿—
docker service logs myapp --tail 100
# å¤§é‡ "connection pool exhausted" é”™è¯¯

# 4. æ£€æŸ¥æ•°æ®åº“è¿æ¥
docker exec database psql -c "
  SELECT count(*) FROM pg_stat_activity;
"
# ç»“æœ: 500 (è¶…è¿‡max_connections=200)

# 5. æŸ¥çœ‹ç½‘ç»œè¿æ¥
docker exec app netstat -an | grep ESTABLISHED | wc -l
# ç»“æœ: æ¯ä¸ªå®¹å™¨350+è¿æ¥
```

**æ ¹æœ¬åŸå› **
```
1. æ•°æ®åº“æ…¢æŸ¥è¯¢å¯¼è‡´è¿æ¥å ç”¨æ—¶é—´è¿‡é•¿
2. åº”ç”¨æœªæ­£ç¡®é‡Šæ”¾æ•°æ®åº“è¿æ¥
3. è¿æ¥æ± é…ç½®ä¸åˆç†(max_size=100,ä½†æ•°æ®åº“max_connections=200)
4. å¥åº·æ£€æŸ¥å¤±è´¥å¯¼è‡´å®¹å™¨ä¸æ–­é‡å¯
5. é‡å¯å®¹å™¨äº§ç”Ÿæ›´å¤šè¿æ¥,å½¢æˆæ¶æ€§å¾ªç¯
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# ç´§æ€¥å¤„ç†
# 1. ä¸´æ—¶æé«˜æ•°æ®åº“è¿æ¥æ•°
docker exec database psql -c "ALTER SYSTEM SET max_connections = 500;"
docker restart database

# 2. å¼ºåˆ¶å…³é—­ç©ºé—²è¿æ¥
docker exec database psql -c "
  SELECT pg_terminate_backend(pid)
  FROM pg_stat_activity
  WHERE state = 'idle' AND state_change < NOW() - INTERVAL '5 minutes';
"

# 3. ä¸´æ—¶ç¦ç”¨å¥åº·æ£€æŸ¥
docker service update --no-healthcheck myapp

# 4. å‡å°‘å‰¯æœ¬æ•°
docker service scale myapp=2

# é•¿æœŸä¼˜åŒ–
# A. ä¼˜åŒ–æ…¢æŸ¥è¯¢
CREATE INDEX idx_user_created ON users(created_at);

# B. ä¿®å¤è¿æ¥æ± é…ç½®
# config.py
DATABASE_POOL_SIZE = 20  # æ¯ä¸ªå®ä¾‹20ä¸ªè¿æ¥
DATABASE_MAX_OVERFLOW = 10  # æœ€å¤šé¢å¤–10ä¸ª
DATABASE_POOL_TIMEOUT = 30
DATABASE_POOL_RECYCLE = 3600

# C. æ·»åŠ è¿æ¥è¶…æ—¶
# sqlalchemy
create_engine(
    url,
    pool_pre_ping=True,  # è¿æ¥å‰æ£€æŸ¥
    pool_recycle=3600,   # 1å°æ—¶å›æ”¶
    connect_args={
        'connect_timeout': 10,
        'options': '-c statement_timeout=30000'
    }
)

# D. å®æ–½æ–­è·¯å™¨æ¨¡å¼
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
def query_database():
    return db.execute(query)

# E. è°ƒæ•´å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=5
```

**é¢„é˜²æªæ–½**
```yaml
# 1. ç›‘æ§å‘Šè­¦
- alert: DatabaseConnectionPoolExhausted
  expr: db_connections_used / db_connections_max > 0.8
  for: 5m
  labels:
    severity: warning

- alert: SlowQuery
  expr: rate(pg_slow_queries_total[5m]) > 10
  for: 2m
  labels:
    severity: warning

# 2. èµ„æºé™åˆ¶
services:
  app:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 10s  # é‡å¯å»¶è¿Ÿ
        max_attempts: 3
        window: 120s

# 3. é™æµ
from flask_limiter import Limiter

limiter = Limiter(
    app,
    key_func=lambda: request.remote_addr,
    default_limits=["200 per minute", "50 per second"]
)
```

### 18.5.2 æ¡ˆä¾‹2: ç£ç›˜ç©ºé—´è€—å°½

**æ•…éšœç°è±¡**
```
2025-12-10 10:00:00 - å®¹å™¨å†™å…¥å¤±è´¥
10:05:00 - æ–°å®¹å™¨æ— æ³•å¯åŠ¨
10:10:00 - Docker daemonå“åº”ç¼“æ…¢
```

**æ’æŸ¥è¿‡ç¨‹**
```bash
# 1. æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h
# Filesystem      Size  Used Avail Use% Mounted on
# /dev/sda1       100G   98G  2.0G  98% /

# 2. æŸ¥æ‰¾å¤§æ–‡ä»¶
du -sh /* | sort -h | tail -10

# 3. Dockerç£ç›˜ä½¿ç”¨
docker system df
# TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
# Images          150       20        45GB      30GB (66%)
# Containers      80        30        15GB      10GB (66%)
# Local Volumes   30        10        35GB      25GB (71%)
# Build Cache     -         -         5GB       5GB

# 4. è¯¦ç»†åˆ†æ
docker system df -v

# 5. æŸ¥æ‰¾å¤§æ—¥å¿—æ–‡ä»¶
find /var/lib/docker/containers/ -name "*-json.log" -exec ls -lh {} \; | sort -k 5 -h | tail -10
```

**æ ¹æœ¬åŸå› **
```
1. å®¹å™¨æ—¥å¿—æœªé™åˆ¶å¤§å°,å•ä¸ªæ—¥å¿—æ–‡ä»¶è¾¾åˆ°10GB+
2. å¤§é‡æœªä½¿ç”¨çš„é•œåƒå’Œå®¹å™¨æœªæ¸…ç†
3. åº”ç”¨æ—¥å¿—å†™å…¥å®¹å™¨å†…,æœªæŒ‚è½½å·
4. æœªé…ç½®æ—¥å¿—è½®è½¬
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# ç´§æ€¥æ¸…ç†
# 1. æ¸…ç†æœªä½¿ç”¨èµ„æº
docker system prune -a --volumes -f
# é‡Šæ”¾çº¦60GBç©ºé—´

# 2. æ¸…ç†å¤§æ—¥å¿—æ–‡ä»¶
find /var/lib/docker/containers/ -name "*-json.log" -exec truncate -s 0 {} \;

# 3. ä¸´æ—¶ç§»åŠ¨æ•°æ®
docker volume create temp-vol
docker run --rm -v old-vol:/source -v temp-vol:/dest alpine sh -c "mv /source/* /dest/"

# é•¿æœŸæ–¹æ¡ˆ
# A. é…ç½®æ—¥å¿—é™åˆ¶
# /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3",
    "compress": "true"
  }
}

systemctl restart docker

# B. ä½¿ç”¨å¤–éƒ¨æ—¥å¿—é©±åŠ¨
# docker-compose.yml
version: '3.8'
services:
  app:
    logging:
      driver: "fluentd"
      options:
        fluentd-address: localhost:24224
        tag: app.{{.Name}}

# C. åº”ç”¨æ—¥å¿—æŒ‚è½½å·
services:
  app:
    volumes:
      - app-logs:/var/log/app

# D. å®šæ—¶æ¸…ç†ä»»åŠ¡
# crontab
0 2 * * * docker system prune -f > /dev/null 2>&1
0 3 * * 0 docker system prune -a --volumes -f > /dev/null 2>&1

# E. ç›‘æ§å‘Šè­¦
- alert: DiskSpaceHigh
  expr: (node_filesystem_avail_bytes{mountpoint="/var/lib/docker"} / node_filesystem_size_bytes{mountpoint="/var/lib/docker"}) < 0.15
  for: 5m
  labels:
    severity: warning
```

### 18.5.3 æ¡ˆä¾‹3: å†…å­˜æ³„æ¼

**æ•…éšœç°è±¡**
```
åº”ç”¨å†…å­˜ä½¿ç”¨æŒç»­å¢é•¿
1å°æ—¶: 500MB
2å°æ—¶: 1.2GB
4å°æ—¶: 2.5GB
6å°æ—¶: OOM Killed
```

**æ’æŸ¥è¿‡ç¨‹**
```bash
# 1. ç›‘æ§å†…å­˜è¶‹åŠ¿
watch -n 5 'docker stats myapp --no-stream'

# 2. æŸ¥çœ‹OOMäº‹ä»¶
docker inspect myapp | jq '.[0].State.OOMKilled'
dmesg | grep -i "out of memory"

# 3. åˆ†æå †å†…å­˜(Java)
docker exec myapp jmap -heap 1

Heap Usage:
Eden Space:     89% used
Old Generation: 95% used  # æŒç»­å¢é•¿

# 4. ç”Ÿæˆå †è½¬å‚¨
docker exec myapp jmap -dump:live,format=b,file=/tmp/heap.hprof 1

# 5. åˆ†æå †è½¬å‚¨(MAT)
# å‘ç°å¤§é‡æœªé‡Šæ”¾çš„Sessionå¯¹è±¡
# æ¯ä¸ªSessionæŒæœ‰å¤§é‡ç¼“å­˜æ•°æ®
# Sessionæ²¡æœ‰æ­£ç¡®è¿‡æœŸ

# 6. æ£€æŸ¥åº”ç”¨ä»£ç 
# å‘ç°å…¨å±€ç¼“å­˜æ— é™å¢é•¿
cache = {}  # å…¨å±€å­—å…¸
def get_data(key):
    if key not in cache:
        cache[key] = fetch_data(key)  # æ°¸ä¸åˆ é™¤!
    return cache[key]
```

**è§£å†³æ–¹æ¡ˆ**
```python
# A. ä½¿ç”¨LRUç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_data(key):
    return fetch_data(key)

# B. ä½¿ç”¨TTLç¼“å­˜
from cachetools import TTLCache

cache = TTLCache(maxsize=1000, ttl=3600)

def get_data(key):
    if key not in cache:
        cache[key] = fetch_data(key)
    return cache[key]

# C. å®šæœŸæ¸…ç†
import threading
import time

def cleanup_cache():
    while True:
        time.sleep(3600)  # 1å°æ—¶
        old_keys = [k for k, v in cache.items()
                    if v['timestamp'] < time.time() - 7200]
        for k in old_keys:
            del cache[k]

cleanup_thread = threading.Thread(target=cleanup_cache, daemon=True)
cleanup_thread.start()

# D. ä½¿ç”¨Rediså¤–éƒ¨ç¼“å­˜
import redis

redis_client = redis.Redis(host='redis', decode_responses=True)

def get_data(key):
    cached = redis_client.get(key)
    if cached:
        return json.loads(cached)

    data = fetch_data(key)
    redis_client.setex(key, 3600, json.dumps(data))  # 1å°æ—¶è¿‡æœŸ
    return data

# E. Sessionç®¡ç†
# Flask
app.config['SESSION_TYPE'] = 'redis'
app.config['SESSION_PERMANENT'] = False
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(hours=1)
```

**éªŒè¯ä¿®å¤**
```bash
# 1. é‡æ–°éƒ¨ç½²
docker service update --image myapp:fixed myapp

# 2. é•¿æœŸç›‘æ§
# Prometheus query
rate(container_memory_usage_bytes{name="myapp"}[1h])

# 3. è®¾ç½®å‘Šè­¦
- alert: MemoryLeakSuspected
  expr: |
    (container_memory_usage_bytes{name="myapp"} -
     container_memory_usage_bytes{name="myapp"} offset 1h) > 500000000
  for: 2h
  labels:
    severity: warning
```

---

*ï¼ˆç¬¬18ç« å®Œæˆ,çº¦2000è¡Œã€‚å·²å®Œæˆ18ç« ,å‰©ä½™1ç« ...ï¼‰*

---

# ç¬¬19ç« : æœ€ä½³å®è·µä¸æ¡ˆä¾‹

æœ¬ç« æ±‡æ€»Dockeråœ¨ä¼ä¸šçº§ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µ,æ¶µç›–å®‰å…¨åŠ å›ºã€CI/CDé›†æˆã€è¿ç§»ç­–ç•¥å’Œå¸¸è§é¿å‘æŒ‡å—,å¸®åŠ©æ‚¨æ„å»ºç¨³å®šã€å®‰å…¨ã€é«˜æ•ˆçš„å®¹å™¨åŒ–å¹³å°ã€‚

---

## 19.1 ä¼ä¸šçº§éƒ¨ç½²æ¡ˆä¾‹

### 19.1.1 ç”µå•†å¹³å°å¾®æœåŠ¡æ¶æ„

**æ¶æ„æ¦‚è§ˆ**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å¤–éƒ¨ç”¨æˆ·                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚   CloudFlare CDN   â”‚
         â”‚   (DDoSé˜²æŠ¤/ç¼“å­˜)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚   Nginx Ingress    â”‚
         â”‚   (SSL/WAF/é™æµ)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚Webå‰ç«¯ â”‚  â”‚APIç½‘å…³ â”‚  â”‚ç®¡ç†åå°â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚          â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚   ä¸šåŠ¡æœåŠ¡å±‚ (Swarm)    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ç”¨æˆ·æœåŠ¡  è®¢å•æœåŠ¡â”‚  â”‚
    â”‚  â”‚å•†å“æœåŠ¡  æ”¯ä»˜æœåŠ¡â”‚  â”‚
    â”‚  â”‚åº“å­˜æœåŠ¡  ç‰©æµæœåŠ¡â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ–¼â”€â”€â”€â”€â”€â”€â”
    â”‚PostgreSQL â”‚  â”‚ Redis  â”‚
    â”‚   é›†ç¾¤     â”‚  â”‚ é›†ç¾¤   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Docker Stack é…ç½®**:

```yaml
# ecommerce-stack.yml
version: '3.8'

networks:
  frontend:
    driver: overlay
    attachable: true
  backend:
    driver: overlay
    internal: true
  db:
    driver: overlay
    internal: true

volumes:
  postgres_data:
  redis_data:

secrets:
  db_password:
    external: true
  jwt_secret:
    external: true
  payment_api_key:
    external: true

services:
  # ==================== APIç½‘å…³ ====================
  api_gateway:
    image: registry.company.com/api-gateway:v2.3.1
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    networks:
      - frontend
      - backend
    ports:
      - "8080:8080"
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - RATE_LIMIT_RPS=1000
      - JWT_SECRET_FILE=/run/secrets/jwt_secret
    secrets:
      - jwt_secret
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    logging:
      driver: fluentd
      options:
        fluentd-address: "fluentd.company.com:24224"
        tag: "api_gateway"

  # ==================== ç”¨æˆ·æœåŠ¡ ====================
  user_service:
    image: registry.company.com/user-service:v1.5.2
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.labels.tier == app
      update_config:
        parallelism: 1
        delay: 10s
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    networks:
      - backend
      - db
    environment:
      - DB_HOST=postgres-master
      - DB_PORT=5432
      - DB_NAME=users
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_HOST=redis-master
      - REDIS_PORT=6379
    secrets:
      - db_password
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 3
    logging:
      driver: fluentd
      options:
        tag: "user_service"

  # ==================== è®¢å•æœåŠ¡ ====================
  order_service:
    image: registry.company.com/order-service:v2.1.0
    deploy:
      replicas: 5  # é«˜å¹¶å‘æœåŠ¡
      placement:
        constraints:
          - node.labels.tier == app
      resources:
        limits:
          cpus: '1'
          memory: 512M
    networks:
      - backend
      - db
    environment:
      - DB_HOST=postgres-master
      - DB_NAME=orders
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_HOST=redis-master
      - MQ_HOST=rabbitmq
    secrets:
      - db_password
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ==================== å•†å“æœåŠ¡ ====================
  product_service:
    image: registry.company.com/product-service:v1.8.3
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    networks:
      - backend
      - db
    environment:
      - DB_HOST=postgres-master
      - DB_NAME=products
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_HOST=redis-master
      - CACHE_TTL=3600
    secrets:
      - db_password

  # ==================== æ”¯ä»˜æœåŠ¡ ====================
  payment_service:
    image: registry.company.com/payment-service:v1.2.1
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.labels.security == high  # éƒ¨ç½²åˆ°å®‰å…¨èŠ‚ç‚¹
      resources:
        limits:
          cpus: '1'
          memory: 512M
    networks:
      - backend
      - db
    environment:
      - DB_HOST=postgres-master
      - DB_NAME=payments
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - PAYMENT_API_KEY_FILE=/run/secrets/payment_api_key
      - ENCRYPTION_ENABLED=true
    secrets:
      - db_password
      - payment_api_key
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s

  # ==================== PostgreSQLä¸»ä»é›†ç¾¤ ====================
  postgres_master:
    image: postgres:15-alpine
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.tier == db
      resources:
        limits:
          cpus: '2'
          memory: 2G
    networks:
      - db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD_FILE=/run/secrets/db_password
      - POSTGRES_INITDB_ARGS=-E UTF8 --locale=en_US.utf8
      - PGDATA=/var/lib/postgresql/data/pgdata
    secrets:
      - db_password
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== Redisé›†ç¾¤ ====================
  redis_master:
    image: redis:7-alpine
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.tier == cache
      resources:
        limits:
          cpus: '1'
          memory: 1G
    networks:
      - db
    volumes:
      - redis_data:/data
    command: >
      redis-server
      --maxmemory 768mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --save 900 1
      --save 300 10
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ==================== RabbitMQæ¶ˆæ¯é˜Ÿåˆ— ====================
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.tier == app
      resources:
        limits:
          cpus: '1'
          memory: 1G
    networks:
      - backend
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS_FILE=/run/secrets/db_password
    secrets:
      - db_password
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
```

**éƒ¨ç½²è„šæœ¬**:

```bash
#!/bin/bash
# deploy-ecommerce.sh - ç”µå•†å¹³å°è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

set -e

STACK_NAME="ecommerce"
REGISTRY="registry.company.com"
ENVIRONMENT="production"

echo "=========================================="
echo "ç”µå•†å¹³å°éƒ¨ç½²è„šæœ¬"
echo "ç¯å¢ƒ: $ENVIRONMENT"
echo "æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')"
echo "=========================================="

# 1. æ£€æŸ¥å‰ç½®æ¡ä»¶
echo -e "\n[1/8] æ£€æŸ¥Docker SwarmçŠ¶æ€..."
if ! docker info | grep -q "Swarm: active"; then
    echo "âŒ Docker Swarmæœªæ¿€æ´»"
    exit 1
fi

# æ£€æŸ¥èŠ‚ç‚¹æ ‡ç­¾
echo "æ£€æŸ¥èŠ‚ç‚¹æ ‡ç­¾..."
NODE_LABELS=$(docker node ls --format "{{.Hostname}}: {{.Labels}}")
echo "$NODE_LABELS"

# 2. åˆ›å»ºç½‘ç»œ
echo -e "\n[2/8] åˆ›å»ºç½‘ç»œ..."
for network in frontend backend db; do
    if ! docker network ls | grep -q "${STACK_NAME}_${network}"; then
        docker network create --driver overlay "${STACK_NAME}_${network}"
        echo "âœ“ åˆ›å»ºç½‘ç»œ: ${STACK_NAME}_${network}"
    fi
done

# 3. åˆ›å»ºSecrets
echo -e "\n[3/8] åˆ›å»ºSecrets..."
if [ ! -f .env.production ]; then
    echo "âŒ ç¼ºå°‘ .env.production æ–‡ä»¶"
    exit 1
fi

source .env.production

echo "$DB_PASSWORD" | docker secret create db_password - 2>/dev/null || echo "Secretå·²å­˜åœ¨: db_password"
echo "$JWT_SECRET" | docker secret create jwt_secret - 2>/dev/null || echo "Secretå·²å­˜åœ¨: jwt_secret"
echo "$PAYMENT_API_KEY" | docker secret create payment_api_key - 2>/dev/null || echo "Secretå·²å­˜åœ¨: payment_api_key"

# 4. æ‹‰å–æœ€æ–°é•œåƒ
echo -e "\n[4/8] æ‹‰å–æœ€æ–°é•œåƒ..."
SERVICES=(
    "api-gateway:v2.3.1"
    "user-service:v1.5.2"
    "order-service:v2.1.0"
    "product-service:v1.8.3"
    "payment-service:v1.2.1"
)

for service in "${SERVICES[@]}"; do
    echo "æ‹‰å–: $REGISTRY/$service"
    docker pull "$REGISTRY/$service"
done

# 5. éƒ¨ç½²æ•°æ®åº“åˆå§‹åŒ–ä»»åŠ¡
echo -e "\n[5/8] åˆå§‹åŒ–æ•°æ®åº“..."
docker run --rm \
    --network ${STACK_NAME}_db \
    -e DB_HOST=postgres-master \
    -e DB_PASSWORD="$DB_PASSWORD" \
    "$REGISTRY/db-migrator:latest" \
    migrate up

# 6. éƒ¨ç½²Stack
echo -e "\n[6/8] éƒ¨ç½²Docker Stack..."
docker stack deploy -c ecommerce-stack.yml "$STACK_NAME"

# 7. ç­‰å¾…æœåŠ¡å¯åŠ¨
echo -e "\n[7/8] ç­‰å¾…æœåŠ¡å¯åŠ¨..."
for i in {1..30}; do
    RUNNING=$(docker stack services "$STACK_NAME" --format "{{.Replicas}}" | grep -c "/")
    EXPECTED=$(docker stack services "$STACK_NAME" --format "{{.Name}}" | wc -l)

    echo "è¿›åº¦: $RUNNING/$EXPECTED æœåŠ¡è¿è¡Œä¸­..."

    if [ "$RUNNING" -eq "$EXPECTED" ]; then
        READY=$(docker stack services "$STACK_NAME" --format "{{.Replicas}}" | awk -F'/' '{if($1==$2) print $0}' | wc -l)
        if [ "$READY" -eq "$EXPECTED" ]; then
            echo "âœ“ æ‰€æœ‰æœåŠ¡å·²å°±ç»ª"
            break
        fi
    fi

    if [ $i -eq 30 ]; then
        echo "âš ï¸  æœåŠ¡å¯åŠ¨è¶…æ—¶,è¯·æ£€æŸ¥æ—¥å¿—"
    fi

    sleep 10
done

# 8. å¥åº·æ£€æŸ¥
echo -e "\n[8/8] æ‰§è¡Œå¥åº·æ£€æŸ¥..."
API_GATEWAY_URL="http://$(docker node inspect self --format '{{.Status.Addr}}'):8080"

for endpoint in /health /api/v1/users/health /api/v1/orders/health; do
    echo -n "æ£€æŸ¥ $endpoint ... "
    if curl -sf "${API_GATEWAY_URL}${endpoint}" > /dev/null; then
        echo "âœ“"
    else
        echo "âœ—"
    fi
done

# 9. æ˜¾ç¤ºéƒ¨ç½²çŠ¶æ€
echo -e "\n=========================================="
echo "éƒ¨ç½²å®Œæˆ!"
echo "=========================================="
docker stack services "$STACK_NAME"

echo -e "\næŸ¥çœ‹æ—¥å¿—:"
echo "  docker service logs -f ${STACK_NAME}_api_gateway"
echo "  docker service logs -f ${STACK_NAME}_order_service"

echo -e "\nè®¿é—®åœ°å€:"
echo "  APIç½‘å…³: $API_GATEWAY_URL"
echo "  ç®¡ç†åå°: http://$(docker node inspect self --format '{{.Status.Addr}}'):8081"
```

**æ€§èƒ½æµ‹è¯•**:

```bash
#!/bin/bash
# benchmark.sh - ç”µå•†å¹³å°æ€§èƒ½æµ‹è¯•

API_URL="http://api.ecommerce.com"

echo "=========================================="
echo "ç”µå•†å¹³å°æ€§èƒ½åŸºå‡†æµ‹è¯•"
echo "=========================================="

# 1. å•†å“åˆ—è¡¨æ¥å£ (è¯»å¤šå†™å°‘)
echo -e "\n[1] å•†å“åˆ—è¡¨API (GET /api/v1/products)"
ab -n 10000 -c 100 -H "Authorization: Bearer $TOKEN" \
   "${API_URL}/api/v1/products?page=1&size=20"

# 2. åˆ›å»ºè®¢å•æ¥å£ (å†™å…¥å¯†é›†)
echo -e "\n[2] åˆ›å»ºè®¢å•API (POST /api/v1/orders)"
ab -n 1000 -c 50 -p order.json -T "application/json" \
   -H "Authorization: Bearer $TOKEN" \
   "${API_URL}/api/v1/orders"

# 3. æ”¯ä»˜æ¥å£ (é«˜å®‰å…¨è¦æ±‚)
echo -e "\n[3] æ”¯ä»˜API (POST /api/v1/payments)"
ab -n 500 -c 20 -p payment.json -T "application/json" \
   -H "Authorization: Bearer $TOKEN" \
   "${API_URL}/api/v1/payments"

# è¾“å‡ºæ±‡æ€»
echo -e "\n=========================================="
echo "æµ‹è¯•å®Œæˆ"
echo "=========================================="
```

### 19.1.2 ç‰©è”ç½‘æ•°æ®é‡‡é›†å¹³å°

**æ¶æ„ç‰¹ç‚¹**:
- é«˜å¹¶å‘æ•°æ®é‡‡é›† (10ä¸‡+è®¾å¤‡)
- æ—¶åºæ•°æ®å­˜å‚¨ (InfluxDB)
- å®æ—¶æ•°æ®å¤„ç† (Kafka + Flink)
- è¾¹ç¼˜è®¡ç®—èŠ‚ç‚¹

**Docker Composeé…ç½®**:

```yaml
# iot-platform.yml
version: '3.8'

services:
  # ==================== MQTT Broker (è®¾å¤‡è¿æ¥) ====================
  emqx:
    image: emqx/emqx:5.3.0
    ports:
      - "1883:1883"    # MQTT
      - "8883:8883"    # MQTT/SSL
      - "8083:8083"    # WebSocket
      - "18083:18083"  # Dashboard
    environment:
      - EMQX_NAME=emqx
      - EMQX_HOST=node1.emqx.io
      - EMQX_NODE__COOKIE=emqxsecretcookie
      - EMQX_LISTENER__TCP__EXTERNAL__MAX_CONNECTIONS=100000
    volumes:
      - ./emqx/data:/opt/emqx/data
      - ./emqx/log:/opt/emqx/log
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "emqx", "ping"]
      interval: 10s

  # ==================== Kafka (æ¶ˆæ¯é˜Ÿåˆ—) ====================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 10
    depends_on:
      - zookeeper
    volumes:
      - kafka-data:/var/lib/kafka/data

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data

  # ==================== InfluxDB (æ—¶åºæ•°æ®åº“) ====================
  influxdb:
    image: influxdb:2.7-alpine
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=admin123456
      - DOCKER_INFLUXDB_INIT_ORG=iot
      - DOCKER_INFLUXDB_INIT_BUCKET=sensor_data
      - DOCKER_INFLUXDB_INIT_RETENTION=30d
    volumes:
      - influxdb-data:/var/lib/influxdb2
      - influxdb-config:/etc/influxdb2
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # ==================== æ•°æ®å¤„ç†æœåŠ¡ ====================
  data_processor:
    image: iot-platform/data-processor:v1.0.0
    environment:
      - KAFKA_BROKERS=kafka:9092
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_TOKEN=${INFLUXDB_TOKEN}
      - INFLUXDB_ORG=iot
      - INFLUXDB_BUCKET=sensor_data
      - PROCESSING_THREADS=8
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
    depends_on:
      - kafka
      - influxdb

  # ==================== è§„åˆ™å¼•æ“ ====================
  rule_engine:
    image: iot-platform/rule-engine:v1.0.0
    environment:
      - KAFKA_BROKERS=kafka:9092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ALERT_WEBHOOK_URL=${ALERT_WEBHOOK_URL}
    deploy:
      replicas: 2

  # ==================== APIæœåŠ¡ ====================
  api_server:
    image: iot-platform/api-server:v1.0.0
    ports:
      - "8080:8080"
    environment:
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_TOKEN=${INFLUXDB_TOKEN}
      - REDIS_HOST=redis
      - JWT_SECRET=${JWT_SECRET}
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # ==================== Redis (ç¼“å­˜) ====================
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data

volumes:
  kafka-data:
  zookeeper-data:
  influxdb-data:
  influxdb-config:
  redis-data:
```

**æ•°æ®å¤„ç†æœåŠ¡ç¤ºä¾‹**:

```python
#!/usr/bin/env python3
# data_processor.py - IoTæ•°æ®å¤„ç†æœåŠ¡

import json
import logging
from kafka import KafkaConsumer
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é…ç½®
KAFKA_BROKERS = os.getenv('KAFKA_BROKERS', 'localhost:9092')
KAFKA_TOPIC = 'sensor_data'
INFLUXDB_URL = os.getenv('INFLUXDB_URL', 'http://localhost:8086')
INFLUXDB_TOKEN = os.getenv('INFLUXDB_TOKEN')
INFLUXDB_ORG = os.getenv('INFLUXDB_ORG', 'iot')
INFLUXDB_BUCKET = os.getenv('INFLUXDB_BUCKET', 'sensor_data')

class DataProcessor:
    def __init__(self):
        # Kafkaæ¶ˆè´¹è€…
        self.consumer = KafkaConsumer(
            KAFKA_TOPIC,
            bootstrap_servers=KAFKA_BROKERS.split(','),
            group_id='data_processor',
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='latest',
            enable_auto_commit=True
        )

        # InfluxDBå®¢æˆ·ç«¯
        self.influx_client = InfluxDBClient(
            url=INFLUXDB_URL,
            token=INFLUXDB_TOKEN,
            org=INFLUXDB_ORG
        )
        self.write_api = self.influx_client.write_api(write_options=SYNCHRONOUS)

        logger.info("DataProcessoråˆå§‹åŒ–å®Œæˆ")

    def process_message(self, message):
        """å¤„ç†å•æ¡æ¶ˆæ¯"""
        try:
            device_id = message['device_id']
            sensor_type = message['sensor_type']
            value = message['value']
            timestamp = message['timestamp']

            # æ•°æ®æ¸…æ´—
            if not self.validate_data(sensor_type, value):
                logger.warning(f"Invalid data from {device_id}: {value}")
                return

            # å†™å…¥InfluxDB
            point = Point("sensor_measurement") \
                .tag("device_id", device_id) \
                .tag("sensor_type", sensor_type) \
                .field("value", float(value)) \
                .time(timestamp)

            self.write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=point)

            # æ£€æŸ¥å‘Šè­¦è§„åˆ™
            self.check_alerts(device_id, sensor_type, value)

        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)

    def validate_data(self, sensor_type, value):
        """æ•°æ®éªŒè¯"""
        ranges = {
            'temperature': (-50, 100),
            'humidity': (0, 100),
            'pressure': (800, 1200)
        }

        if sensor_type not in ranges:
            return True

        min_val, max_val = ranges[sensor_type]
        return min_val <= float(value) <= max_val

    def check_alerts(self, device_id, sensor_type, value):
        """æ£€æŸ¥å‘Šè­¦è§„åˆ™"""
        # æ¸©åº¦è¿‡é«˜å‘Šè­¦
        if sensor_type == 'temperature' and float(value) > 80:
            logger.warning(f"ğŸš¨ Temperature alert: {device_id} = {value}Â°C")
            # å‘é€å‘Šè­¦é€šçŸ¥...

    def run(self):
        """ä¸»å¾ªç¯"""
        logger.info("å¼€å§‹æ¶ˆè´¹Kafkaæ¶ˆæ¯...")

        for message in self.consumer:
            try:
                self.process_message(message.value)
            except KeyboardInterrupt:
                logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·")
                break
            except Exception as e:
                logger.error(f"å¤„ç†æ¶ˆæ¯å¼‚å¸¸: {e}", exc_info=True)

        self.consumer.close()
        self.influx_client.close()

if __name__ == '__main__':
    processor = DataProcessor()
    processor.run()
```

---

## 19.2 å®‰å…¨åŠ å›º

### 19.2.1 é•œåƒå®‰å…¨

**1. ä½¿ç”¨å®˜æ–¹åŸºç¡€é•œåƒ**:

```dockerfile
# âŒ ä¸æ¨è: ä½¿ç”¨latestæ ‡ç­¾
FROM node:latest

# âœ… æ¨è: ä½¿ç”¨å…·ä½“ç‰ˆæœ¬ + Alpineå˜ä½“
FROM node:18.19.0-alpine3.19

# âœ… æœ€ä½³: ä½¿ç”¨SHA256æ‘˜è¦é”å®šç‰ˆæœ¬
FROM node:18.19.0-alpine3.19@sha256:...
```

**2. æœ€å°åŒ–é•œåƒ**:

```dockerfile
# å¤šé˜¶æ®µæ„å»º - ç”Ÿäº§é•œåƒä»…åŒ…å«å¿…éœ€æ–‡ä»¶
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force
COPY . .
RUN npm run build

FROM node:18-alpine AS production
RUN apk add --no-cache dumb-init
USER node
WORKDIR /app
COPY --chown=node:node --from=builder /app/dist ./dist
COPY --chown=node:node --from=builder /app/node_modules ./node_modules
EXPOSE 3000
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]
```

**3. é•œåƒå®‰å…¨æ‰«æ**:

```bash
#!/bin/bash
# scan-image.sh - é•œåƒå®‰å…¨æ‰«æè„šæœ¬

IMAGE=$1

if [ -z "$IMAGE" ]; then
    echo "ç”¨æ³•: $0 <é•œåƒåç§°>"
    exit 1
fi

echo "=========================================="
echo "é•œåƒå®‰å…¨æ‰«æ: $IMAGE"
echo "=========================================="

# 1. Trivyæ‰«æ
echo -e "\n[1] Trivyæ¼æ´æ‰«æ..."
trivy image --severity HIGH,CRITICAL "$IMAGE"

# 2. æ£€æŸ¥é•œåƒå±‚æ•°
echo -e "\n[2] é•œåƒå±‚æ•°æ£€æŸ¥..."
LAYERS=$(docker history "$IMAGE" --quiet | wc -l)
echo "å±‚æ•°: $LAYERS"
if [ "$LAYERS" -gt 20 ]; then
    echo "âš ï¸  è­¦å‘Š: é•œåƒå±‚æ•°è¿‡å¤š,å»ºè®®åˆå¹¶å±‚"
fi

# 3. æ£€æŸ¥é•œåƒå¤§å°
echo -e "\n[3] é•œåƒå¤§å°æ£€æŸ¥..."
SIZE=$(docker images "$IMAGE" --format "{{.Size}}")
echo "å¤§å°: $SIZE"

# 4. æ£€æŸ¥rootç”¨æˆ·
echo -e "\n[4] ç”¨æˆ·æƒé™æ£€æŸ¥..."
USER=$(docker inspect "$IMAGE" --format='{{.Config.User}}')
if [ -z "$USER" ] || [ "$USER" = "root" ] || [ "$USER" = "0" ]; then
    echo "âŒ è­¦å‘Š: å®¹å™¨ä½¿ç”¨rootç”¨æˆ·è¿è¡Œ"
else
    echo "âœ“ å®¹å™¨ä½¿ç”¨érootç”¨æˆ·: $USER"
fi

# 5. æ£€æŸ¥æ•æ„Ÿæ–‡ä»¶
echo -e "\n[5] æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥..."
TEMP_CONTAINER=$(docker create "$IMAGE")
docker export "$TEMP_CONTAINER" | tar -t | grep -E "\.(key|pem|crt|env)$" || echo "âœ“ æœªå‘ç°æ•æ„Ÿæ–‡ä»¶"
docker rm "$TEMP_CONTAINER" > /dev/null

# 6. ç”ŸæˆSBOM (è½¯ä»¶ç‰©æ–™æ¸…å•)
echo -e "\n[6] ç”ŸæˆSBOM..."
syft "$IMAGE" -o json > "${IMAGE//\//_}_sbom.json"
echo "âœ“ SBOMå·²ä¿å­˜åˆ°: ${IMAGE//\//_}_sbom.json"

echo -e "\n=========================================="
echo "æ‰«æå®Œæˆ"
echo "=========================================="
```

### 19.2.2 è¿è¡Œæ—¶å®‰å…¨

**1. AppArmoré…ç½®**:

```bash
# /etc/apparmor.d/docker-default-secure
#include <tunables/global>

profile docker-default-secure flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>

  # æ‹’ç»æŒ‚è½½
  deny mount,

  # æ‹’ç»ä¿®æ”¹å†…æ ¸å‚æ•°
  deny @{PROC}/sys/kernel/** w,

  # æ‹’ç»è®¿é—®å®¿ä¸»æœºè®¾å¤‡
  deny /dev/** rw,

  # å…è®¸å¿…è¦çš„ç³»ç»Ÿè°ƒç”¨
  capability setgid,
  capability setuid,
  capability net_bind_service,

  # æ‹’ç»å±é™©ç³»ç»Ÿè°ƒç”¨
  deny capability sys_admin,
  deny capability sys_module,
  deny capability sys_rawio,

  # å…è®¸å®¹å™¨å†…æ–‡ä»¶è®¿é—®
  /app/** rw,
  /tmp/** rw,
  /var/tmp/** rw,
}
```

**åº”ç”¨åˆ°å®¹å™¨**:

```bash
docker run --security-opt apparmor=docker-default-secure myapp
```

**2. Seccompé…ç½®**:

```json
{
  "defaultAction": "SCMP_ACT_ERRNO",
  "archMap": [
    {
      "architecture": "SCMP_ARCH_X86_64",
      "subArchitectures": ["SCMP_ARCH_X86", "SCMP_ARCH_X32"]
    }
  ],
  "syscalls": [
    {
      "names": [
        "accept", "accept4", "access", "bind", "brk",
        "chdir", "clone", "close", "connect", "dup",
        "dup2", "execve", "exit", "fork", "fstat",
        "getcwd", "getpid", "getuid", "listen", "mmap",
        "open", "read", "recv", "recvfrom", "send",
        "sendto", "socket", "stat", "write"
      ],
      "action": "SCMP_ACT_ALLOW"
    },
    {
      "names": ["reboot", "swapon", "swapoff"],
      "action": "SCMP_ACT_ERRNO",
      "errnoRet": 1
    }
  ]
}
```

**åº”ç”¨Seccomp**:

```bash
docker run --security-opt seccomp=seccomp-profile.json myapp
```

**3. åªè¯»æ ¹æ–‡ä»¶ç³»ç»Ÿ**:

```yaml
# docker-compose.yml
services:
  app:
    image: myapp:latest
    read_only: true
    tmpfs:
      - /tmp
      - /var/run
      - /app/cache:uid=1000,gid=1000,mode=1777
    volumes:
      - app-logs:/app/logs
```

### 19.2.3 ç½‘ç»œå®‰å…¨

**1. ç½‘ç»œéš”ç¦»**:

```yaml
# network-isolation.yml
version: '3.8'

networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.1.0/24
  backend:
    driver: bridge
    internal: true  # æ— å¤–ç½‘è®¿é—®
    ipam:
      config:
        - subnet: 172.20.2.0/24
  database:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.20.3.0/24

services:
  web:
    image: nginx
    networks:
      - frontend
      - backend

  api:
    image: api-server
    networks:
      - backend
      - database

  postgres:
    image: postgres
    networks:
      - database  # ä»…databaseç½‘ç»œå¯è®¿é—®
```

**2. é˜²ç«å¢™è§„åˆ™**:

```bash
#!/bin/bash
# docker-firewall.sh - Dockeré˜²ç«å¢™é…ç½®

# æ¸…é™¤ç°æœ‰è§„åˆ™
iptables -F DOCKER-USER
iptables -X DOCKER-USER
iptables -N DOCKER-USER

# 1. å…è®¸å·²å»ºç«‹çš„è¿æ¥
iptables -A DOCKER-USER -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT

# 2. é™åˆ¶ç‰¹å®šIPè®¿é—®æ•æ„Ÿç«¯å£
iptables -A DOCKER-USER -p tcp --dport 5432 -s 10.0.0.0/8 -j ACCEPT
iptables -A DOCKER-USER -p tcp --dport 5432 -j DROP

# 3. é™åˆ¶å®¹å™¨è®¿é—®å®¿ä¸»æœºå…ƒæ•°æ®æœåŠ¡
iptables -A DOCKER-USER -d 169.254.169.254 -j DROP

# 4. é™åˆ¶å®¹å™¨é—´äº’è®¿
iptables -A DOCKER-USER -i docker0 -o docker0 -j DROP

# 5. é€Ÿç‡é™åˆ¶
iptables -A DOCKER-USER -p tcp --dport 80 -m limit --limit 100/sec --limit-burst 200 -j ACCEPT
iptables -A DOCKER-USER -p tcp --dport 80 -j DROP

# 6. é»˜è®¤æ‹’ç»
iptables -A DOCKER-USER -j DROP

echo "âœ“ Dockeré˜²ç«å¢™è§„åˆ™å·²åº”ç”¨"
iptables -L DOCKER-USER -n -v
```

---

## 19.3 CI/CDé›†æˆ

### 19.3.1 GitLab CIé›†æˆ

**.gitlab-ci.yml**:

```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - security
  - deploy

variables:
  DOCKER_REGISTRY: registry.company.com
  DOCKER_IMAGE: $DOCKER_REGISTRY/$CI_PROJECT_NAME
  DOCKER_TAG: $CI_COMMIT_SHORT_SHA

# ==================== æ„å»ºé˜¶æ®µ ====================
build:
  stage: build
  image: docker:24.0-dind
  services:
    - docker:24.0-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $DOCKER_REGISTRY
  script:
    # ä½¿ç”¨BuildKitåŠ é€Ÿæ„å»º
    - export DOCKER_BUILDKIT=1
    - docker build
        --cache-from $DOCKER_IMAGE:latest
        --build-arg BUILDKIT_INLINE_CACHE=1
        --tag $DOCKER_IMAGE:$DOCKER_TAG
        --tag $DOCKER_IMAGE:latest
        .
    - docker push $DOCKER_IMAGE:$DOCKER_TAG
    - docker push $DOCKER_IMAGE:latest
  only:
    - main
    - develop

# ==================== æµ‹è¯•é˜¶æ®µ ====================
unit_test:
  stage: test
  image: $DOCKER_IMAGE:$DOCKER_TAG
  script:
    - npm install
    - npm run test
  coverage: '/All files[^|]*\|[^|]*\s+([\d\.]+)/'
  artifacts:
    reports:
      junit: test-results.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml

integration_test:
  stage: test
  image: docker/compose:latest
  services:
    - docker:24.0-dind
  script:
    - docker-compose -f docker-compose.test.yml up -d
    - docker-compose -f docker-compose.test.yml exec -T app npm run test:integration
  after_script:
    - docker-compose -f docker-compose.test.yml down -v

# ==================== å®‰å…¨æ‰«æé˜¶æ®µ ====================
security_scan:
  stage: security
  image: aquasec/trivy:latest
  script:
    - trivy image
        --severity HIGH,CRITICAL
        --exit-code 1
        --no-progress
        $DOCKER_IMAGE:$DOCKER_TAG
  allow_failure: true

sast:
  stage: security
  image: returntocorp/semgrep
  script:
    - semgrep --config=auto --json --output=sast-report.json .
  artifacts:
    reports:
      sast: sast-report.json

# ==================== éƒ¨ç½²é˜¶æ®µ ====================
deploy_staging:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
  script:
    - |
      ssh -o StrictHostKeyChecking=no deploy@staging.company.com << EOF
        cd /opt/myapp
        docker pull $DOCKER_IMAGE:$DOCKER_TAG
        docker-compose up -d
        docker-compose ps
      EOF
  environment:
    name: staging
    url: https://staging.company.com
  only:
    - develop

deploy_production:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
  script:
    - |
      ssh -o StrictHostKeyChecking=no deploy@prod.company.com << EOF
        cd /opt/myapp

        # è“ç»¿éƒ¨ç½²
        export NEW_TAG=$DOCKER_TAG
        export OLD_TAG=\$(docker ps --filter "name=myapp" --format "{{.Image}}" | cut -d: -f2)

        # å¯åŠ¨æ–°ç‰ˆæœ¬
        docker pull $DOCKER_IMAGE:\$NEW_TAG
        docker-compose -f docker-compose.blue-green.yml up -d blue

        # å¥åº·æ£€æŸ¥
        for i in {1..30}; do
          if curl -sf http://localhost:8080/health; then
            echo "âœ“ æ–°ç‰ˆæœ¬å¥åº·æ£€æŸ¥é€šè¿‡"
            break
          fi
          echo "ç­‰å¾…æœåŠ¡å¯åŠ¨... (\$i/30)"
          sleep 2
        done

        # åˆ‡æ¢æµé‡
        docker-compose -f docker-compose.blue-green.yml up -d nginx

        # åœæ­¢æ—§ç‰ˆæœ¬
        docker-compose -f docker-compose.blue-green.yml stop green

        echo "âœ“ éƒ¨ç½²å®Œæˆ: \$OLD_TAG -> \$NEW_TAG"
      EOF
  environment:
    name: production
    url: https://app.company.com
  when: manual
  only:
    - main
```

### 19.3.2 Jenkins Pipeline

**Jenkinsfile**:

```groovy
// Jenkinsfile
pipeline {
    agent any

    environment {
        DOCKER_REGISTRY = 'registry.company.com'
        DOCKER_IMAGE = "${DOCKER_REGISTRY}/${JOB_NAME}"
        DOCKER_TAG = "${BUILD_NUMBER}"
        DOCKER_CREDENTIALS = credentials('docker-registry-credentials')
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }

        stage('Build') {
            steps {
                script {
                    // æ„å»ºDockeré•œåƒ
                    docker.build("${DOCKER_IMAGE}:${DOCKER_TAG}")
                }
            }
        }

        stage('Test') {
            steps {
                script {
                    // è¿è¡Œæµ‹è¯•
                    docker.image("${DOCKER_IMAGE}:${DOCKER_TAG}").inside {
                        sh 'npm install'
                        sh 'npm run test'
                    }
                }
            }
            post {
                always {
                    junit 'test-results.xml'
                }
            }
        }

        stage('Security Scan') {
            parallel {
                stage('Trivy Scan') {
                    steps {
                        sh """
                            trivy image \
                                --severity HIGH,CRITICAL \
                                --format json \
                                --output trivy-report.json \
                                ${DOCKER_IMAGE}:${DOCKER_TAG}
                        """
                    }
                }

                stage('Anchore Scan') {
                    steps {
                        writeFile file: 'anchore_images',
                                  text: "${DOCKER_IMAGE}:${DOCKER_TAG}"
                        anchore name: 'anchore_images',
                                bailOnFail: false
                    }
                }
            }
        }

        stage('Push') {
            steps {
                script {
                    docker.withRegistry("https://${DOCKER_REGISTRY}", 'docker-registry-credentials') {
                        docker.image("${DOCKER_IMAGE}:${DOCKER_TAG}").push()
                        docker.image("${DOCKER_IMAGE}:${DOCKER_TAG}").push('latest')
                    }
                }
            }
        }

        stage('Deploy to Staging') {
            when {
                branch 'develop'
            }
            steps {
                sshagent(['staging-ssh-key']) {
                    sh """
                        ssh deploy@staging.company.com '
                            cd /opt/myapp &&
                            export IMAGE_TAG=${DOCKER_TAG} &&
                            docker-compose pull &&
                            docker-compose up -d &&
                            docker-compose ps
                        '
                    """
                }
            }
        }

        stage('Deploy to Production') {
            when {
                branch 'main'
            }
            steps {
                input message: 'ç¡®è®¤éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ?', ok: 'éƒ¨ç½²'

                sshagent(['production-ssh-key']) {
                    sh """
                        ssh deploy@prod.company.com '
                            cd /opt/myapp &&
                            ./deploy.sh ${DOCKER_TAG}
                        '
                    """
                }
            }
        }
    }

    post {
        success {
            slackSend(
                color: 'good',
                message: "âœ“ æ„å»ºæˆåŠŸ: ${JOB_NAME} #${BUILD_NUMBER} (<${BUILD_URL}|æŸ¥çœ‹è¯¦æƒ…>)"
            )
        }
        failure {
            slackSend(
                color: 'danger',
                message: "âœ— æ„å»ºå¤±è´¥: ${JOB_NAME} #${BUILD_NUMBER} (<${BUILD_URL}|æŸ¥çœ‹è¯¦æƒ…>)"
            )
        }
        always {
            cleanWs()
        }
    }
}
```

### 19.3.3 é‡‘ä¸é›€å‘å¸ƒ

**éƒ¨ç½²è„šæœ¬**:

```bash
#!/bin/bash
# canary-deploy.sh - é‡‘ä¸é›€å‘å¸ƒè„šæœ¬

set -e

NEW_VERSION=$1
CANARY_PERCENT=${2:-10}  # é»˜è®¤10%æµé‡

if [ -z "$NEW_VERSION" ]; then
    echo "ç”¨æ³•: $0 <æ–°ç‰ˆæœ¬> [é‡‘ä¸é›€ç™¾åˆ†æ¯”]"
    exit 1
fi

STACK_NAME="myapp"
SERVICE_NAME="${STACK_NAME}_api"

echo "=========================================="
echo "é‡‘ä¸é›€å‘å¸ƒ"
echo "æ–°ç‰ˆæœ¬: $NEW_VERSION"
echo "é‡‘ä¸é›€æµé‡: $CANARY_PERCENT%"
echo "=========================================="

# 1. è·å–å½“å‰ç‰ˆæœ¬
CURRENT_VERSION=$(docker service inspect "$SERVICE_NAME" --format '{{.Spec.TaskTemplate.ContainerSpec.Image}}' | cut -d: -f2)
echo -e "\nå½“å‰ç‰ˆæœ¬: $CURRENT_VERSION"

# 2. åˆ›å»ºé‡‘ä¸é›€æœåŠ¡
echo -e "\n[1/5] åˆ›å»ºé‡‘ä¸é›€æœåŠ¡..."
docker service create \
    --name "${SERVICE_NAME}_canary" \
    --label canary=true \
    --network "${STACK_NAME}_backend" \
    --replicas 1 \
    --limit-cpu 0.5 \
    --limit-memory 256M \
    "registry.company.com/myapp:${NEW_VERSION}"

# 3. ç­‰å¾…é‡‘ä¸é›€æœåŠ¡å°±ç»ª
echo -e "\n[2/5] ç­‰å¾…é‡‘ä¸é›€æœåŠ¡å¯åŠ¨..."
for i in {1..30}; do
    STATUS=$(docker service ps "${SERVICE_NAME}_canary" --filter "desired-state=running" --format "{{.CurrentState}}")
    if echo "$STATUS" | grep -q "Running"; then
        echo "âœ“ é‡‘ä¸é›€æœåŠ¡å·²å°±ç»ª"
        break
    fi
    echo "ç­‰å¾…ä¸­... ($i/30)"
    sleep 2
done

# 4. é…ç½®Traefikæµé‡æƒé‡
echo -e "\n[3/5] é…ç½®æµé‡æƒé‡..."
cat > /tmp/traefik-canary.yml <<EOF
http:
  services:
    api-weighted:
      weighted:
        services:
          - name: api-stable
            weight: $((100 - CANARY_PERCENT))
          - name: api-canary
            weight: $CANARY_PERCENT
EOF

docker config create traefik-canary-config /tmp/traefik-canary.yml
docker service update --config-add traefik-canary-config traefik

# 5. ç›‘æ§é‡‘ä¸é›€æŒ‡æ ‡ (æŒç»­10åˆ†é’Ÿ)
echo -e "\n[4/5] ç›‘æ§é‡‘ä¸é›€æŒ‡æ ‡..."
MONITORING_DURATION=600
START_TIME=$(date +%s)

while true; do
    ELAPSED=$(($(date +%s) - START_TIME))

    if [ $ELAPSED -ge $MONITORING_DURATION ]; then
        echo "âœ“ ç›‘æ§å®Œæˆ"
        break
    fi

    # æŸ¥è¯¢é”™è¯¯ç‡
    ERROR_RATE=$(curl -s 'http://prometheus:9090/api/v1/query?query=rate(http_requests_total{service="api_canary",status=~"5.."}[5m])' | jq -r '.data.result[0].value[1]')

    # æŸ¥è¯¢å»¶è¿Ÿ
    LATENCY_P99=$(curl -s 'http://prometheus:9090/api/v1/query?query=histogram_quantile(0.99,rate(http_request_duration_seconds_bucket{service="api_canary"}[5m]))' | jq -r '.data.result[0].value[1]')

    echo "é”™è¯¯ç‡: ${ERROR_RATE:-0}  P99å»¶è¿Ÿ: ${LATENCY_P99:-0}s"

    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
    if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
        echo "âŒ é”™è¯¯ç‡è¿‡é«˜,å›æ»šé‡‘ä¸é›€!"
        ./rollback-canary.sh
        exit 1
    fi

    sleep 30
done

# 6. å…¨é‡å‘å¸ƒ
echo -e "\n[5/5] é‡‘ä¸é›€å¥åº·,å¼€å§‹å…¨é‡å‘å¸ƒ..."
docker service update \
    --image "registry.company.com/myapp:${NEW_VERSION}" \
    --update-parallelism 2 \
    --update-delay 10s \
    "$SERVICE_NAME"

# æ¸…ç†é‡‘ä¸é›€æœåŠ¡
docker service rm "${SERVICE_NAME}_canary"

echo -e "\n=========================================="
echo "âœ“ å‘å¸ƒå®Œæˆ: $CURRENT_VERSION -> $NEW_VERSION"
echo "=========================================="
```

---

## 19.4 è¿ç§»ç­–ç•¥

### 19.4.1 ä»è™šæ‹Ÿæœºè¿ç§»åˆ°å®¹å™¨

**è¿ç§»è¯„ä¼°æ£€æŸ¥è¡¨**:

```bash
#!/bin/bash
# assess-migration.sh - è¿ç§»å¯è¡Œæ€§è¯„ä¼°

APP_NAME=$1

echo "=========================================="
echo "åº”ç”¨è¿ç§»è¯„ä¼°: $APP_NAME"
echo "=========================================="

# 1. æ£€æŸ¥åº”ç”¨ç±»å‹
echo -e "\n[1] åº”ç”¨ç±»å‹æ£€æŸ¥"
echo "âœ“ æ— çŠ¶æ€åº”ç”¨æ›´é€‚åˆå®¹å™¨åŒ–"
echo "âœ“ æœ‰çŠ¶æ€åº”ç”¨éœ€è¦é¢å¤–çš„æŒä¹…åŒ–æ–¹æ¡ˆ"

# 2. æ£€æŸ¥ä¾èµ–é¡¹
echo -e "\n[2] ä¾èµ–é¡¹åˆ†æ"
ldd /usr/bin/myapp 2>/dev/null | grep "=>" | awk '{print $1}' | sort
echo "å»ºè®®: ä½¿ç”¨å®˜æ–¹åŸºç¡€é•œåƒåŒ…å«å¤§éƒ¨åˆ†ç³»ç»Ÿåº“"

# 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
echo -e "\n[3] é…ç½®æ–‡ä»¶ä½ç½®"
find /etc -name "*${APP_NAME}*" 2>/dev/null
echo "å»ºè®®: ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–ConfigMapç®¡ç†é…ç½®"

# 4. æ£€æŸ¥æ•°æ®ç›®å½•
echo -e "\n[4] æ•°æ®ç›®å½•"
find /var -name "*${APP_NAME}*" -type d 2>/dev/null
echo "å»ºè®®: ä½¿ç”¨Docker Volumeæˆ–å¤–éƒ¨å­˜å‚¨"

# 5. æ£€æŸ¥ç«¯å£å ç”¨
echo -e "\n[5] ç›‘å¬ç«¯å£"
netstat -tlnp | grep "$APP_NAME"
echo "å»ºè®®: ç¡®ä¿ç«¯å£ä¸å†²çª"

# 6. æ£€æŸ¥ç³»ç»Ÿè°ƒç”¨
echo -e "\n[6] ç³»ç»Ÿè°ƒç”¨åˆ†æ"
strace -c /usr/bin/myapp & PID=$!
sleep 5
kill $PID 2>/dev/null
echo "å»ºè®®: æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æƒæ“ä½œéœ€æ±‚"

# 7. æ€§èƒ½åŸºå‡†
echo -e "\n[7] æ€§èƒ½åŸºå‡†æµ‹è¯•"
echo "CPU: $(top -b -n1 | grep "$APP_NAME" | awk '{print $9}')%"
echo "å†…å­˜: $(ps aux | grep "$APP_NAME" | awk '{print $4}')%"

echo -e "\n=========================================="
echo "è¿ç§»å»ºè®®:"
echo "1. åˆ›å»ºDockerfileå°è£…åº”ç”¨"
echo "2. ä½¿ç”¨docker-composeå®šä¹‰æœåŠ¡ä¾èµ–"
echo "3. é…ç½®å¥åº·æ£€æŸ¥"
echo "4. è®¾ç½®èµ„æºé™åˆ¶"
echo "5. å‡†å¤‡å›æ»šæ–¹æ¡ˆ"
echo "=========================================="
```

**è¿ç§»æ­¥éª¤**:

```bash
#!/bin/bash
# migrate-vm-to-container.sh - è™šæ‹Ÿæœºåº”ç”¨å®¹å™¨åŒ–è„šæœ¬

APP_NAME="myapp"
VM_HOST="oldvm.company.com"
REGISTRY="registry.company.com"

echo "=========================================="
echo "è™šæ‹Ÿæœºåˆ°å®¹å™¨è¿ç§»: $APP_NAME"
echo "=========================================="

# ç¬¬1é˜¶æ®µ: åº”ç”¨æ‰“åŒ…
echo -e "\n[é˜¶æ®µ1/4] ä»è™šæ‹Ÿæœºæ‰“åŒ…åº”ç”¨..."
ssh root@$VM_HOST << 'EOF'
    cd /opt/myapp
    tar czf /tmp/myapp.tar.gz .
EOF

scp root@$VM_HOST:/tmp/myapp.tar.gz ./

# ç¬¬2é˜¶æ®µ: åˆ›å»ºDockerfile
echo -e "\n[é˜¶æ®µ2/4] ç”ŸæˆDockerfile..."
cat > Dockerfile <<'DOCKERFILE'
FROM ubuntu:22.04

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    libssl3 \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser

# å¤åˆ¶åº”ç”¨æ–‡ä»¶
WORKDIR /app
COPY myapp.tar.gz .
RUN tar xzf myapp.tar.gz && rm myapp.tar.gz
RUN chown -R appuser:appuser /app

USER appuser

EXPOSE 8080

HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

CMD ["./start.sh"]
DOCKERFILE

# ç¬¬3é˜¶æ®µ: æ„å»ºé•œåƒ
echo -e "\n[é˜¶æ®µ3/4] æ„å»ºDockeré•œåƒ..."
docker build -t $REGISTRY/$APP_NAME:v1.0.0 .

# ç¬¬4é˜¶æ®µ: æµ‹è¯•è¿è¡Œ
echo -e "\n[é˜¶æ®µ4/4] æµ‹è¯•å®¹å™¨..."
docker run -d --name ${APP_NAME}_test \
    -p 8080:8080 \
    -e DB_HOST=postgres.company.com \
    -e DB_PORT=5432 \
    $REGISTRY/$APP_NAME:v1.0.0

# å¥åº·æ£€æŸ¥
echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
for i in {1..30}; do
    if curl -sf http://localhost:8080/health > /dev/null; then
        echo "âœ“ å®¹å™¨è¿è¡Œæ­£å¸¸"
        break
    fi
    sleep 2
done

# æ¸…ç†æµ‹è¯•å®¹å™¨
docker stop ${APP_NAME}_test
docker rm ${APP_NAME}_test

# æ¨é€é•œåƒ
echo -e "\næ¨é€é•œåƒåˆ°ä»“åº“..."
docker push $REGISTRY/$APP_NAME:v1.0.0

echo -e "\n=========================================="
echo "âœ“ è¿ç§»å®Œæˆ"
echo "ä¸‹ä¸€æ­¥:"
echo "1. åˆ›å»ºdocker-compose.yml"
echo "2. é…ç½®ç”Ÿäº§ç¯å¢ƒå˜é‡"
echo "3. æ‰§è¡Œç°åº¦å‘å¸ƒ"
echo "=========================================="
```

### 19.4.2 ä»Kubernetesè¿ç§»åˆ°Docker Swarm

**è½¬æ¢å·¥å…·**:

```python
#!/usr/bin/env python3
# k8s-to-swarm.py - Kubernetes YAMLè½¬Docker Stack

import yaml
import sys

def convert_deployment(k8s_yaml):
    """è½¬æ¢Deploymentåˆ°Docker Service"""
    spec = k8s_yaml['spec']
    template = spec['template']

    service = {
        'image': template['spec']['containers'][0]['image'],
        'deploy': {
            'replicas': spec.get('replicas', 1),
            'restart_policy': {
                'condition': 'on-failure'
            }
        }
    }

    # è½¬æ¢èµ„æºé™åˆ¶
    if 'resources' in template['spec']['containers'][0]:
        resources = template['spec']['containers'][0]['resources']
        service['deploy']['resources'] = {}

        if 'limits' in resources:
            service['deploy']['resources']['limits'] = {
                'cpus': resources['limits'].get('cpu', '1'),
                'memory': resources['limits'].get('memory', '512M')
            }

        if 'requests' in resources:
            service['deploy']['resources']['reservations'] = {
                'cpus': resources['requests'].get('cpu', '0.5'),
                'memory': resources['requests'].get('memory', '256M')
            }

    # è½¬æ¢ç¯å¢ƒå˜é‡
    if 'env' in template['spec']['containers'][0]:
        service['environment'] = []
        for env in template['spec']['containers'][0]['env']:
            service['environment'].append(f"{env['name']}={env.get('value', '')}")

    # è½¬æ¢ç«¯å£
    if 'ports' in template['spec']['containers'][0]:
        service['ports'] = []
        for port in template['spec']['containers'][0]['ports']:
            service['ports'].append(f"{port['containerPort']}:{port['containerPort']}")

    return service

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: k8s-to-swarm.py <k8s.yaml>")
        sys.exit(1)

    with open(sys.argv[1], 'r') as f:
        k8s_docs = yaml.safe_load_all(f)

        stack = {
            'version': '3.8',
            'services': {}
        }

        for doc in k8s_docs:
            if doc['kind'] == 'Deployment':
                name = doc['metadata']['name']
                stack['services'][name] = convert_deployment(doc)

        print(yaml.dump(stack, default_flow_style=False))

if __name__ == '__main__':
    main()
```

---

## 19.5 é¿å‘æŒ‡å—

### 19.5.1 å¸¸è§é”™è¯¯

**1. å®¹å™¨æ—¶åŒºé—®é¢˜**:

```dockerfile
# âŒ é”™è¯¯: å®¹å™¨ä½¿ç”¨UTCæ—¶åŒº
FROM alpine
CMD ["date"]

# âœ… æ­£ç¡®: è®¾ç½®æ—¶åŒº
FROM alpine
RUN apk add --no-cache tzdata
ENV TZ=Asia/Shanghai
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone
CMD ["date"]
```

**2. æ—¥å¿—ä¸¢å¤±é—®é¢˜**:

```dockerfile
# âŒ é”™è¯¯: æ—¥å¿—å†™å…¥æ–‡ä»¶
CMD ./app > /var/log/app.log 2>&1

# âœ… æ­£ç¡®: æ—¥å¿—è¾“å‡ºåˆ°stdout/stderr
CMD ./app
```

**3. PID 1åƒµå°¸è¿›ç¨‹é—®é¢˜**:

```dockerfile
# âŒ é”™è¯¯: ä½¿ç”¨shellå¯åŠ¨
CMD ./start.sh

# âœ… æ­£ç¡®: ä½¿ç”¨execå½¢å¼æˆ–dumb-init
FROM alpine
RUN apk add --no-cache dumb-init
ENTRYPOINT ["dumb-init", "--"]
CMD ["./app"]
```

**4. æ–‡ä»¶æƒé™é—®é¢˜**:

```dockerfile
# âŒ é”™è¯¯: rootç”¨æˆ·åˆ›å»ºæ–‡ä»¶
COPY app.jar /app/
USER appuser
CMD java -jar /app/app.jar

# âœ… æ­£ç¡®: è®¾ç½®æ­£ç¡®çš„æ‰€æœ‰è€…
COPY --chown=appuser:appuser app.jar /app/
USER appuser
CMD ["java", "-jar", "/app/app.jar"]
```

**5. ç¯å¢ƒå˜é‡å±•å¼€é—®é¢˜**:

```yaml
# âŒ é”™è¯¯: å•å¼•å·é˜»æ­¢å˜é‡å±•å¼€
services:
  app:
    command: 'echo $PATH'

# âœ… æ­£ç¡®: ä½¿ç”¨åŒå¼•å·æˆ–ä¸åŠ å¼•å·
services:
  app:
    command: echo $PATH
```

### 19.5.2 æ€§èƒ½é™·é˜±

**1. è¿‡åº¦ä½¿ç”¨bind mount**:

```yaml
# âŒ æ…¢: bind mountéœ€è¦æ–‡ä»¶ç³»ç»ŸåŒæ­¥
volumes:
  - ./app:/app

# âœ… å¿«: ä½¿ç”¨named volume
volumes:
  - app_data:/app

volumes:
  app_data:
```

**2. è¿‡å¤šçš„å±‚å¯¼è‡´é•œåƒè‡ƒè‚¿**:

```dockerfile
# âŒ é”™è¯¯: æ¯ä¸ªRUNåˆ›å»ºä¸€å±‚
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y vim
RUN apt-get clean

# âœ… æ­£ç¡®: åˆå¹¶å‘½ä»¤
RUN apt-get update && apt-get install -y \
    curl \
    vim \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*
```

**3. ä¸ä½¿ç”¨.dockerignore**:

```bash
# .dockerignore
node_modules
*.log
.git
.DS_Store
coverage
*.md
```

**4. ä½¿ç”¨latestæ ‡ç­¾**:

```yaml
# âŒ ä¸æ¨è: latestä¸ç¨³å®š
services:
  app:
    image: myapp:latest

# âœ… æ¨è: ä½¿ç”¨æ˜ç¡®ç‰ˆæœ¬
services:
  app:
    image: myapp:v1.2.3
```

### 19.5.3 ç›‘æ§ç›²ç‚¹

**å…³é”®æŒ‡æ ‡ç›‘æ§æ¸…å•**:

```yaml
# prometheus-alerts.yml
groups:
  - name: docker_health
    interval: 30s
    rules:
      # 1. å®¹å™¨é‡å¯é¢‘ç¹
      - alert: ContainerRestartingTooOften
        expr: rate(container_restart_count[15m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å®¹å™¨ {{ $labels.container }} é‡å¯é¢‘ç¹"

      # 2. å®¹å™¨OOM
      - alert: ContainerOOMKilled
        expr: container_oom_events_total > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "å®¹å™¨ {{ $labels.container }} å‘ç”ŸOOM"

      # 3. ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: DockerDiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/var/lib/docker"} / node_filesystem_size_bytes) < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Dockeræ•°æ®ç›®å½•ç©ºé—´ä¸è¶³ < 10%"

      # 4. é•œåƒæ‹‰å–å¤±è´¥
      - alert: ImagePullFailed
        expr: increase(docker_image_pull_errors_total[5m]) > 3
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "é•œåƒæ‹‰å–å¤±è´¥æ¬¡æ•°è¿‡å¤š"

      # 5. SwarmèŠ‚ç‚¹ä¸å¯ç”¨
      - alert: SwarmNodeUnavailable
        expr: swarm_node_status != 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "SwarmèŠ‚ç‚¹ {{ $labels.node_name }} ä¸å¯ç”¨"
```

---

## 19.6 ä¼ä¸šçº§æœ€ä½³å®è·µæ€»ç»“

### 19.6.1 é•œåƒç®¡ç†

1. **ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬**: `v1.2.3`
2. **é”å®šåŸºç¡€é•œåƒSHA**: `FROM node:18@sha256:...`
3. **å®šæœŸæ‰«ææ¼æ´**: Trivy/Snyk
4. **æ¸…ç†æ— ç”¨é•œåƒ**: `docker image prune -a`

### 19.6.2 èµ„æºè§„åˆ’

```yaml
# èµ„æºé…ç½®èŒƒä¾‹
services:
  # é«˜æµé‡API
  api:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

  # åå°ä»»åŠ¡
  worker:
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # æ•°æ®åº“
  postgres:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
```

### 19.6.3 æ—¥å¿—ä¸ç›‘æ§

```yaml
# ç»Ÿä¸€æ—¥å¿—é…ç½®
x-logging: &default-logging
  driver: fluentd
  options:
    fluentd-address: "fluentd.company.com:24224"
    fluentd-async: "true"
    fluentd-retry-wait: "1s"
    fluentd-max-retries: "10"
    tag: "{{.Name}}"

services:
  app:
    logging: *default-logging
```

### 19.6.4 å¤‡ä»½ç­–ç•¥

```bash
#!/bin/bash
# backup-docker-volumes.sh - Dockerå·å¤‡ä»½è„šæœ¬

BACKUP_DIR="/backup/docker-volumes"
DATE=$(date +%Y%m%d_%H%M%S)

# è·å–æ‰€æœ‰å·
VOLUMES=$(docker volume ls -q)

for volume in $VOLUMES; do
    echo "å¤‡ä»½å·: $volume"

    # åˆ›å»ºä¸´æ—¶å®¹å™¨æŒ‚è½½å·å¹¶å¤‡ä»½
    docker run --rm \
        -v "$volume":/source:ro \
        -v "$BACKUP_DIR":/backup \
        alpine \
        tar czf "/backup/${volume}_${DATE}.tar.gz" -C /source .

    echo "âœ“ å¤‡ä»½å®Œæˆ: ${volume}_${DATE}.tar.gz"
done

# åˆ é™¤7å¤©å‰çš„å¤‡ä»½
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +7 -delete
```

---

*ï¼ˆç¬¬19ç« å®Œæˆ,çº¦1800è¡Œã€‚å…¨ä¹¦19ç« å…¨éƒ¨å®Œæˆ!ï¼‰*

## ğŸ‰ å…¨ä¹¦å®Œç»“

æ­å–œæ‚¨å®Œæˆã€ŠDockeråº•å±‚åŸç†ä¸ç”Ÿäº§å®æˆ˜æŒ‡å—ã€‹çš„å­¦ä¹ !

### ğŸ“š å…¨ä¹¦ç« èŠ‚å›é¡¾

1. **ç¬¬1-5ç« **: Dockeræ ¸å¿ƒæ¦‚å¿µä¸åº•å±‚åŸç†
2. **ç¬¬6-8ç« **: é•œåƒæ„å»ºä¸ä¼˜åŒ–
3. **ç¬¬9-12ç« **: å®¹å™¨è¿è¡Œæ—¶ä¸ç¼–æ’
4. **ç¬¬13ç« **: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ¶æ„
5. **ç¬¬14ç« **: é«˜å¯ç”¨æ€§ä¸ç¾éš¾æ¢å¤
6. **ç¬¬15ç« **: ç›‘æ§å‘Šè­¦ä½“ç³»
7. **ç¬¬16ç« **: æ—¥å¿—æ”¶é›†ä¸åˆ†æ
8. **ç¬¬17ç« **: æ€§èƒ½ä¼˜åŒ–
9. **ç¬¬18ç« **: æ•…éšœæ’æŸ¥
10. **ç¬¬19ç« **: æœ€ä½³å®è·µä¸æ¡ˆä¾‹

### ğŸ¯ å­¦ä¹ è·¯å¾„å»ºè®®

- **åˆå­¦è€…**: ç¬¬1-8ç«  â†’ ç¬¬9-12ç« 
- **è¿ç»´å·¥ç¨‹å¸ˆ**: ç¬¬13-16ç«  â†’ ç¬¬17-18ç« 
- **æ¶æ„å¸ˆ**: å…¨ä¹¦ç³»ç»Ÿå­¦ä¹ 

### ğŸ“– å»¶ä¼¸é˜…è¯»

- Dockerå®˜æ–¹æ–‡æ¡£: https://docs.docker.com
- Docker Swarmæ–‡æ¡£: https://docs.docker.com/engine/swarm/
- Kubernetesè¿›é˜¶å­¦ä¹ 
- äº‘åŸç”ŸæŠ€æœ¯æ ˆ

---

*æ„Ÿè°¢æ‚¨çš„é˜…è¯»!å¦‚æœ‰é—®é¢˜,æ¬¢è¿äº¤æµè®¨è®ºã€‚*
