# Python è„šæœ¬ç¼–ç¨‹åº•å±‚åŸç†ä¸å·¥ç¨‹å®è·µ

> **ä» Java è½¬ Python çš„ç¡¬æ ¸æŒ‡å—** - æ·±å…¥åº•å±‚ã€å·¥ç¨‹åŒ–å®è·µã€DevOps å¿…å¤‡

---

## ğŸ“‹ ç›®å½•

### ç¬¬ä¸€éƒ¨åˆ†ï¼šåº•å±‚åŸç†ä¸æ‰§è¡Œæœºåˆ¶
1. [Python è§£é‡Šå™¨ä¸å­—èŠ‚ç ](#1-python-è§£é‡Šå™¨ä¸å­—èŠ‚ç )
2. [å†…å­˜ç®¡ç†ä¸åƒåœ¾å›æ”¶](#2-å†…å­˜ç®¡ç†ä¸åƒåœ¾å›æ”¶)
3. [å˜é‡ä¸å¯¹è±¡æ¨¡å‹](#3-å˜é‡ä¸å¯¹è±¡æ¨¡å‹)
4. [å¯å˜å¯¹è±¡ vs ä¸å¯å˜å¯¹è±¡](#4-å¯å˜å¯¹è±¡-vs-ä¸å¯å˜å¯¹è±¡)

### ç¬¬äºŒéƒ¨åˆ†ï¼šé«˜çº§è¯­è¨€ç‰¹æ€§
5. [è£…é¥°å™¨æ·±åº¦è§£æ](#5-è£…é¥°å™¨æ·±åº¦è§£æ)
6. [ä¸Šä¸‹æ–‡ç®¡ç†å™¨](#6-ä¸Šä¸‹æ–‡ç®¡ç†å™¨)
7. [ç”Ÿæˆå™¨ä¸è¿­ä»£å™¨](#7-ç”Ÿæˆå™¨ä¸è¿­ä»£å™¨)
8. [åç¨‹ä¸å¼‚æ­¥ç¼–ç¨‹](#8-åç¨‹ä¸å¼‚æ­¥ç¼–ç¨‹)

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå·¥ç¨‹åŒ–å®è·µ
9. [å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ](#9-å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ)
10. [æ—¥å¿—ç³»ç»Ÿè®¾è®¡](#10-æ—¥å¿—ç³»ç»Ÿè®¾è®¡)
11. [é…ç½®ç®¡ç†ä¸ç¯å¢ƒå˜é‡](#11-é…ç½®ç®¡ç†ä¸ç¯å¢ƒå˜é‡)
12. [å•å…ƒæµ‹è¯•ä¸ä»£ç è´¨é‡](#12-å•å…ƒæµ‹è¯•ä¸ä»£ç è´¨é‡)

### ç¬¬å››éƒ¨åˆ†ï¼šDevOps è„šæœ¬ç¼–ç¨‹
13. [ç³»ç»Ÿè°ƒç”¨ä¸å­è¿›ç¨‹ç®¡ç†](#13-ç³»ç»Ÿè°ƒç”¨ä¸å­è¿›ç¨‹ç®¡ç†)
14. [æ–‡ä»¶ç³»ç»Ÿæ“ä½œ](#14-æ–‡ä»¶ç³»ç»Ÿæ“ä½œ)
15. [ç½‘ç»œç¼–ç¨‹åŸºç¡€](#15-ç½‘ç»œç¼–ç¨‹åŸºç¡€)
16. [å¤šçº¿ç¨‹ä¸å¤šè¿›ç¨‹](#16-å¤šçº¿ç¨‹ä¸å¤šè¿›ç¨‹)

### ç¬¬äº”éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•
17. [æ€§èƒ½åˆ†æä¸ä¼˜åŒ–](#17-æ€§èƒ½åˆ†æä¸ä¼˜åŒ–)
18. [è°ƒè¯•æŠ€å·§](#18-è°ƒè¯•æŠ€å·§)
19. [å¸¸è§é™·é˜±ä¸æœ€ä½³å®è·µ](#19-å¸¸è§é™·é˜±ä¸æœ€ä½³å®è·µ)

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåº•å±‚åŸç†ä¸æ‰§è¡Œæœºåˆ¶

---

## 1. Python è§£é‡Šå™¨ä¸å­—èŠ‚ç 

### 1.1 æ‰§è¡Œæµç¨‹ï¼ˆvs Javaï¼‰

#### Java æ‰§è¡Œæµç¨‹
```
.java æºæ–‡ä»¶ â†’ javac ç¼–è¯‘ â†’ .class å­—èŠ‚ç  â†’ JVM æ‰§è¡Œ
```

#### Python æ‰§è¡Œæµç¨‹
```
.py æºæ–‡ä»¶ â†’ CPython ç¼–è¯‘ â†’ .pyc å­—èŠ‚ç  â†’ è§£é‡Šå™¨æ‰§è¡Œ
```

**å…³é”®åŒºåˆ«**ï¼š
- Java æ˜¯**ç¼–è¯‘å‹**ï¼ˆæå‰ç¼–è¯‘æˆå­—èŠ‚ç ï¼‰
- Python æ˜¯**è§£é‡Šå‹**ï¼ˆè¿è¡Œæ—¶ç¼–è¯‘ + è§£é‡Šæ‰§è¡Œï¼‰

### 1.2 æŸ¥çœ‹ Python å­—èŠ‚ç 

```python
import dis

def add(a, b):
    return a + b

# æŸ¥çœ‹å­—èŠ‚ç 
dis.dis(add)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
  2           0 LOAD_FAST                0 (a)
              2 LOAD_FAST                1 (b)
              4 BINARY_ADD
              6 RETURN_VALUE
```

**è§£è¯»**ï¼š
1. `LOAD_FAST 0` - åŠ è½½å±€éƒ¨å˜é‡ a åˆ°æ ˆé¡¶
2. `LOAD_FAST 1` - åŠ è½½å±€éƒ¨å˜é‡ b åˆ°æ ˆé¡¶
3. `BINARY_ADD` - å¼¹å‡ºä¸¤ä¸ªå€¼ç›¸åŠ ï¼Œç»“æœå‹æ ˆ
4. `RETURN_VALUE` - è¿”å›æ ˆé¡¶å€¼

### 1.3 .pyc æ–‡ä»¶ï¼ˆå­—èŠ‚ç ç¼“å­˜ï¼‰

```python
# è¿è¡Œæ—¶è‡ªåŠ¨ç”Ÿæˆ __pycache__/*.pyc
# åŠ å¿«ä¸‹æ¬¡å¯åŠ¨é€Ÿåº¦ï¼ˆæ— éœ€é‡æ–°ç¼–è¯‘ï¼‰

# ä¸»åŠ¨ç¼–è¯‘
import py_compile
py_compile.compile('script.py')

# ç¼–è¯‘æ•´ä¸ªç›®å½•
import compileall
compileall.compile_dir('.', force=True)
```

**ç”Ÿäº§ç¯å¢ƒæŠ€å·§**ï¼š
- âœ… Docker é•œåƒæ„å»ºæ—¶é¢„ç¼–è¯‘ â†’ å‡å°‘å¯åŠ¨æ—¶é—´
- âœ… éƒ¨ç½²æ—¶åˆ é™¤ .py æ–‡ä»¶ï¼Œä»…ä¿ç•™ .pyc â†’ ä»£ç ä¿æŠ¤

### 1.4 CPython vs PyPy vs Jython

| è§£é‡Šå™¨ | è¯­è¨€å®ç° | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|--------|---------|------|------|
| **CPython** | C è¯­è¨€ | é»˜è®¤ã€å…¼å®¹æ€§å¼º | è¾ƒæ…¢ã€GIL é” |
| **PyPy** | Python + JIT | **å¿« 5-10 å€** | éƒ¨åˆ†åº“ä¸å…¼å®¹ |
| **Jython** | Java | è°ƒç”¨ Java åº“ | æ…¢ã€Python 3 æ”¯æŒå·® |

**ç‰¹æ–¯æ‹‰é¡¹ç›®é€‰æ‹©**ï¼š
- æ•°æ®å¤„ç†è„šæœ¬ â†’ **PyPy**ï¼ˆå¿«ï¼‰
- æ·±åº¦å­¦ä¹  â†’ **CPython**ï¼ˆåº“å…¼å®¹æ€§ï¼‰
- é›†æˆ Java ç³»ç»Ÿ â†’ **Jython**

---

## 2. å†…å­˜ç®¡ç†ä¸åƒåœ¾å›æ”¶

### 2.1 Python å†…å­˜ç®¡ç†æœºåˆ¶

#### å¯¹è±¡çš„å†…å­˜ç»“æ„
```python
# æ¯ä¸ª Python å¯¹è±¡éƒ½åŒ…å«ï¼š
# 1. å¼•ç”¨è®¡æ•°ï¼ˆref_countï¼‰
# 2. ç±»å‹æŒ‡é’ˆï¼ˆtype_ptrï¼‰
# 3. å®é™…æ•°æ®ï¼ˆvalueï¼‰

import sys

x = 42
print(sys.getsizeof(x))  # 28 å­—èŠ‚ï¼ˆint å¯¹è±¡ï¼‰

y = "hello"
print(sys.getsizeof(y))  # 54 å­—èŠ‚ï¼ˆstr å¯¹è±¡ + å…ƒæ•°æ®ï¼‰
```

### 2.2 å¼•ç”¨è®¡æ•°ï¼ˆReference Countingï¼‰

```python
import sys

x = [1, 2, 3]
print(sys.getrefcount(x))  # 2ï¼ˆ1 ä¸ªå˜é‡ + 1 ä¸ªä¸´æ—¶å¼•ç”¨ï¼‰

y = x  # å¼•ç”¨è®¡æ•° +1
print(sys.getrefcount(x))  # 3

del y  # å¼•ç”¨è®¡æ•° -1
print(sys.getrefcount(x))  # 2
```

**ä¼˜ç‚¹**ï¼š
- âœ… å³æ—¶å›æ”¶ï¼ˆå¼•ç”¨è®¡æ•°ä¸º 0 ç«‹å³é‡Šæ”¾ï¼‰

**ç¼ºç‚¹**ï¼š
- âŒ å¾ªç¯å¼•ç”¨æ— æ³•å›æ”¶

### 2.3 å¾ªç¯å¼•ç”¨ä¸åƒåœ¾å›æ”¶

```python
# å¾ªç¯å¼•ç”¨ç¤ºä¾‹
class Node:
    def __init__(self, value):
        self.value = value
        self.next = None

a = Node(1)
b = Node(2)
a.next = b
b.next = a  # å¾ªç¯å¼•ç”¨ï¼ša â†’ b â†’ a

# å³ä½¿åˆ é™¤å˜é‡ï¼Œå†…å­˜ä¹Ÿä¸ä¼šç«‹å³é‡Šæ”¾
del a
del b
```

**è§£å†³æ–¹æ¡ˆï¼šåˆ†ä»£åƒåœ¾å›æ”¶**
```python
import gc

# æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
gc.collect()

# æŸ¥çœ‹åƒåœ¾å›æ”¶ç»Ÿè®¡
print(gc.get_stats())

# ç¦ç”¨åƒåœ¾å›æ”¶ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
gc.disable()
# ... æ‰§è¡Œå¯†é›†è®¡ç®— ...
gc.enable()
```

### 2.4 å†…å­˜æ³„æ¼æ’æŸ¥

```python
import tracemalloc

# å¼€å§‹è¿½è¸ªå†…å­˜åˆ†é…
tracemalloc.start()

# æ‰§è¡Œå¯èƒ½æ³„æ¼çš„ä»£ç 
data = []
for i in range(1000000):
    data.append([i] * 100)

# æŸ¥çœ‹å†…å­˜å¿«ç…§
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

for stat in top_stats[:3]:
    print(stat)
```

**ç”Ÿäº§ç¯å¢ƒæŠ€å·§**ï¼š
```python
# è£…é¥°å™¨è‡ªåŠ¨è¿½è¸ªå†…å­˜
import functools
import tracemalloc

def track_memory(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        tracemalloc.start()
        result = func(*args, **kwargs)
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        print(f"{func.__name__}: å½“å‰ {current/1024/1024:.2f}MB, å³°å€¼ {peak/1024/1024:.2f}MB")
        return result
    return wrapper

@track_memory
def process_data():
    data = [i for i in range(1000000)]
    return len(data)
```

---

## 3. å˜é‡ä¸å¯¹è±¡æ¨¡å‹

### 3.1 Python å˜é‡çš„æœ¬è´¨ï¼ˆvs Javaï¼‰

#### Java å˜é‡
```java
// Java: å˜é‡æ˜¯"å®¹å™¨"ï¼ˆå­˜å‚¨å€¼ï¼‰
int x = 5;      // x ç›´æ¥å­˜å‚¨ 5
String s = "hello";  // s å­˜å‚¨å¯¹è±¡å¼•ç”¨
```

#### Python å˜é‡
```python
# Python: å˜é‡æ˜¯"æ ‡ç­¾"ï¼ˆæŒ‡å‘å¯¹è±¡ï¼‰
x = 5       # x æ˜¯æŒ‡å‘æ•´æ•°å¯¹è±¡ 5 çš„æ ‡ç­¾
y = x       # y ä¹ŸæŒ‡å‘åŒä¸€ä¸ªå¯¹è±¡
z = 5       # z ä¹ŸæŒ‡å‘åŒä¸€ä¸ªå¯¹è±¡ï¼ˆæ•´æ•°ç¼“å­˜ï¼‰

print(id(x), id(y), id(z))  # ä¸‰ä¸ª ID ç›¸åŒï¼
```

### 3.2 å¯¹è±¡èº«ä»½ã€ç±»å‹ã€å€¼

```python
x = [1, 2, 3]
y = [1, 2, 3]

# 1. èº«ä»½ï¼ˆidentityï¼‰- å†…å­˜åœ°å€
print(id(x))        # 4312345678
print(id(y))        # 4312345789ï¼ˆä¸åŒå¯¹è±¡ï¼‰
print(x is y)       # False

# 2. ç±»å‹ï¼ˆtypeï¼‰
print(type(x))      # <class 'list'>

# 3. å€¼ï¼ˆvalueï¼‰
print(x == y)       # Trueï¼ˆå€¼ç›¸åŒï¼‰
```

**åˆ¤ç­‰è§„åˆ™**ï¼š
```python
# is: åˆ¤æ–­èº«ä»½ï¼ˆåŒä¸€å¯¹è±¡ï¼‰
# ==: åˆ¤æ–­å€¼ï¼ˆå†…å®¹ç›¸åŒï¼‰

a = [1, 2]
b = [1, 2]
c = a

print(a == b)  # Trueï¼ˆå€¼ç›¸åŒï¼‰
print(a is b)  # Falseï¼ˆä¸åŒå¯¹è±¡ï¼‰
print(a is c)  # Trueï¼ˆåŒä¸€å¯¹è±¡ï¼‰
```

### 3.3 æ•´æ•°ç¼“å­˜æœºåˆ¶

```python
# Python ç¼“å­˜å°æ•´æ•° [-5, 256]
a = 100
b = 100
print(a is b)  # Trueï¼ˆåŒä¸€å¯¹è±¡ï¼‰

c = 1000
d = 1000
print(c is d)  # Falseï¼ˆä¸åŒå¯¹è±¡ï¼‰
```

**åŸå› **ï¼šå°æ•´æ•°ä½¿ç”¨é¢‘ç¹ï¼Œé¢„å…ˆåˆ›å»ºé¿å…é‡å¤åˆ†é…ã€‚

### 3.4 å­—ç¬¦ä¸²é©»ç•™ï¼ˆString Interningï¼‰

```python
# å­—ç¬¦ä¸²é©»ç•™ï¼šç›¸åŒå­—ç¬¦ä¸²å…±äº«å†…å­˜
s1 = "hello"
s2 = "hello"
print(s1 is s2)  # True

# ä½†åŠ¨æ€åˆ›å»ºçš„å­—ç¬¦ä¸²ä¸é©»ç•™
s3 = "hel" + "lo"
print(s1 is s3)  # Falseï¼ˆCPython å®ç°ç»†èŠ‚ï¼‰

# å¼ºåˆ¶é©»ç•™
import sys
s4 = sys.intern("hello")
print(s1 is s4)  # True
```

---

## 4. å¯å˜å¯¹è±¡ vs ä¸å¯å˜å¯¹è±¡

### 4.1 æ ¸å¿ƒæ¦‚å¿µ

| ä¸å¯å˜å¯¹è±¡ | å¯å˜å¯¹è±¡ |
|-----------|---------|
| int, float, str | list, dict, set |
| tuple | è‡ªå®šä¹‰ç±»ï¼ˆé»˜è®¤ï¼‰ |
| frozenset | bytearray |

### 4.2 ä¸å¯å˜å¯¹è±¡çš„é™·é˜±

```python
# å­—ç¬¦ä¸²æ‹¼æ¥çš„æ€§èƒ½é™·é˜±
# âŒ ä½æ•ˆï¼šæ¯æ¬¡æ‹¼æ¥åˆ›å»ºæ–°å¯¹è±¡
result = ""
for i in range(10000):
    result += str(i)  # åˆ›å»º 10000 ä¸ªä¸´æ—¶å­—ç¬¦ä¸²å¯¹è±¡

# âœ… é«˜æ•ˆï¼šå…ˆå­˜åˆ—è¡¨ï¼Œæœ€åä¸€æ¬¡æ‹¼æ¥
parts = []
for i in range(10000):
    parts.append(str(i))
result = "".join(parts)  # ä»…åˆ›å»º 1 ä¸ªæœ€ç»ˆå­—ç¬¦ä¸²

# æ€§èƒ½å¯¹æ¯”
import timeit
print(timeit.timeit('s = ""; [s := s + str(i) for i in range(1000)]', number=100))  # ~0.5s
print(timeit.timeit('s = []; [s.append(str(i)) for i in range(1000)]; "".join(s)', number=100))  # ~0.02s
```

### 4.3 å¯å˜å¯¹è±¡çš„é™·é˜±

#### é™·é˜± 1ï¼šé»˜è®¤å‚æ•°
```python
# âŒ é”™è¯¯ï¼šé»˜è®¤å‚æ•°æ˜¯å¯å˜å¯¹è±¡
def add_item(item, items=[]):  # å±é™©ï¼
    items.append(item)
    return items

print(add_item(1))  # [1]
print(add_item(2))  # [1, 2]ï¼ˆé¢„æœŸæ˜¯ [2]ï¼‰
print(add_item(3))  # [1, 2, 3]ï¼ˆé¢„æœŸæ˜¯ [3]ï¼‰

# âœ… æ­£ç¡®
def add_item(item, items=None):
    if items is None:
        items = []
    items.append(item)
    return items
```

#### é™·é˜± 2ï¼šæµ…æ‹·è´ vs æ·±æ‹·è´
```python
import copy

# åŸå§‹åˆ—è¡¨
original = [[1, 2], [3, 4]]

# æµ…æ‹·è´ï¼ˆä»…å¤åˆ¶å¤–å±‚ï¼‰
shallow = copy.copy(original)
shallow[0][0] = 999
print(original)  # [[999, 2], [3, 4]]ï¼ˆè¢«ä¿®æ”¹ï¼ï¼‰

# æ·±æ‹·è´ï¼ˆé€’å½’å¤åˆ¶æ‰€æœ‰å±‚ï¼‰
deep = copy.deepcopy(original)
deep[0][0] = 777
print(original)  # [[999, 2], [3, 4]]ï¼ˆæœªæ”¹å˜ï¼‰
```

### 4.4 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

```python
# è§„åˆ™ 1ï¼šå‡½æ•°å‚æ•°ä¸ä½¿ç”¨å¯å˜é»˜è®¤å€¼
def process_data(data, config=None):
    if config is None:
        config = {"timeout": 30}
    # ...

# è§„åˆ™ 2ï¼šè¿”å›å‰¯æœ¬è€ŒéåŸå¯¹è±¡
class DataProcessor:
    def __init__(self):
        self._data = []

    def get_data(self):
        # âœ… è¿”å›å‰¯æœ¬ï¼Œé˜²æ­¢å¤–éƒ¨ä¿®æ”¹
        return self._data.copy()

# è§„åˆ™ 3ï¼šä½¿ç”¨ä¸å¯å˜æ•°æ®ç»“æ„
from typing import Tuple

def get_config() -> Tuple[str, int]:
    # è¿”å› tuple è€Œé list
    return ("localhost", 8080)
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šé«˜çº§è¯­è¨€ç‰¹æ€§

---

## 5. è£…é¥°å™¨æ·±åº¦è§£æ

### 5.1 è£…é¥°å™¨æœ¬è´¨

**è£…é¥°å™¨ = é«˜é˜¶å‡½æ•°ï¼ˆæ¥æ”¶å‡½æ•°ï¼Œè¿”å›å‡½æ•°ï¼‰**

```python
# åŸºç¡€è£…é¥°å™¨
def my_decorator(func):
    def wrapper(*args, **kwargs):
        print("Before function")
        result = func(*args, **kwargs)
        print("After function")
        return result
    return wrapper

@my_decorator
def greet(name):
    print(f"Hello, {name}")

# ç­‰ä»·äºï¼šgreet = my_decorator(greet)
```

### 5.2 ä¿ç•™åŸå‡½æ•°å…ƒæ•°æ®

```python
import functools

def my_decorator(func):
    @functools.wraps(func)  # â† ä¿ç•™åŸå‡½æ•°çš„ __name__, __doc__ ç­‰
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper

@my_decorator
def greet(name):
    """Say hello"""
    print(f"Hello, {name}")

print(greet.__name__)  # "greet"ï¼ˆä¸åŠ  @wraps ä¼šæ˜¯ "wrapper"ï¼‰
print(greet.__doc__)   # "Say hello"
```

### 5.3 å¸¦å‚æ•°çš„è£…é¥°å™¨

```python
def repeat(times):
    """é‡å¤æ‰§è¡Œè£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for _ in range(times):
                result = func(*args, **kwargs)
            return result
        return wrapper
    return decorator

@repeat(times=3)
def say_hello():
    print("Hello!")

# say_hello()  # æ‰“å° 3 æ¬¡ "Hello!"
```

### 5.4 DevOps å¸¸ç”¨è£…é¥°å™¨

#### 5.4.1 é‡è¯•è£…é¥°å™¨
```python
import time
import functools

def retry(max_attempts=3, delay=1, exceptions=(Exception,)):
    """è‡ªåŠ¨é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    if attempt == max_attempts:
                        raise
                    print(f"âŒ å¤±è´¥ï¼ˆç¬¬ {attempt} æ¬¡ï¼‰ï¼Œ{delay}s åé‡è¯•...")
                    time.sleep(delay)
        return wrapper
    return decorator

@retry(max_attempts=3, delay=2, exceptions=(ConnectionError,))
def fetch_data(url):
    import requests
    response = requests.get(url, timeout=5)
    return response.json()
```

#### 5.4.2 æ€§èƒ½è®¡æ—¶è£…é¥°å™¨
```python
import time
import functools

def timer(func):
    """å‡½æ•°æ‰§è¡Œæ—¶é—´ç»Ÿè®¡"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        print(f"â±ï¸  {func.__name__} è€—æ—¶: {elapsed:.3f}s")
        return result
    return wrapper

@timer
def process_data():
    time.sleep(2)
    return "done"
```

#### 5.4.3 æ—¥å¿—è£…é¥°å™¨
```python
import logging
import functools

def log_call(logger=None):
    """è®°å½•å‡½æ•°è°ƒç”¨æ—¥å¿—"""
    if logger is None:
        logger = logging.getLogger(__name__)

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            logger.info(f"è°ƒç”¨ {func.__name__}ï¼Œå‚æ•°: args={args}, kwargs={kwargs}")
            try:
                result = func(*args, **kwargs)
                logger.info(f"{func.__name__} è¿”å›: {result}")
                return result
            except Exception as e:
                logger.error(f"{func.__name__} å¼‚å¸¸: {e}")
                raise
        return wrapper
    return decorator

@log_call()
def divide(a, b):
    return a / b
```

#### 5.4.4 ç±»è£…é¥°å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
```python
def singleton(cls):
    """å•ä¾‹æ¨¡å¼è£…é¥°å™¨"""
    instances = {}
    @functools.wraps(cls)
    def get_instance(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    return get_instance

@singleton
class Config:
    def __init__(self):
        self.settings = {"timeout": 30}

config1 = Config()
config2 = Config()
print(config1 is config2)  # Trueï¼ˆåŒä¸€å®ä¾‹ï¼‰
```

---

## 6. ä¸Šä¸‹æ–‡ç®¡ç†å™¨

### 6.1 with è¯­å¥çš„åŸç†

```python
# ä¼ ç»Ÿæ–¹å¼ï¼ˆæ˜“å‡ºé”™ï¼‰
file = open("data.txt", "r")
try:
    content = file.read()
finally:
    file.close()  # ç¡®ä¿å…³é—­

# with è¯­å¥ï¼ˆè‡ªåŠ¨ç®¡ç†ï¼‰
with open("data.txt", "r") as file:
    content = file.read()
# è‡ªåŠ¨è°ƒç”¨ file.close()
```

### 6.2 è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ç®¡ç†å™¨

#### æ–¹æ³• 1ï¼šç±»å®ç°
```python
class Timer:
    def __enter__(self):
        self.start = time.time()
        print("â±ï¸  å¼€å§‹è®¡æ—¶")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        elapsed = time.time() - self.start
        print(f"â±ï¸  ç»“æŸè®¡æ—¶: {elapsed:.3f}s")
        # è¿”å› False è¡¨ç¤ºå¼‚å¸¸ç»§ç»­ä¼ æ’­
        # è¿”å› True è¡¨ç¤ºå‹åˆ¶å¼‚å¸¸
        return False

with Timer():
    time.sleep(2)
    print("æ‰§è¡Œä»»åŠ¡")
```

#### æ–¹æ³• 2ï¼š@contextmanager è£…é¥°å™¨
```python
from contextlib import contextmanager

@contextmanager
def timer():
    start = time.time()
    print("â±ï¸  å¼€å§‹è®¡æ—¶")
    try:
        yield  # è®©å‡ºæ§åˆ¶æƒç»™ with å—
    finally:
        elapsed = time.time() - start
        print(f"â±ï¸  ç»“æŸè®¡æ—¶: {elapsed:.3f}s")

with timer():
    time.sleep(2)
```

### 6.3 DevOps å¸¸ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨

#### 6.3.1 ä¸´æ—¶åˆ‡æ¢ç›®å½•
```python
import os
from contextlib import contextmanager

@contextmanager
def cd(path):
    """ä¸´æ—¶åˆ‡æ¢å·¥ä½œç›®å½•"""
    old_path = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(old_path)

# ä½¿ç”¨
with cd("/tmp"):
    print(os.getcwd())  # /tmp
    # æ‰§è¡Œæ“ä½œ
print(os.getcwd())  # æ¢å¤åŸç›®å½•
```

#### 6.3.2 ä¸´æ—¶ä¿®æ”¹ç¯å¢ƒå˜é‡
```python
@contextmanager
def set_env(**kwargs):
    """ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡"""
    old_env = {}
    for key, value in kwargs.items():
        old_env[key] = os.environ.get(key)
        os.environ[key] = value

    try:
        yield
    finally:
        for key, value in old_env.items():
            if value is None:
                os.environ.pop(key, None)
            else:
                os.environ[key] = value

with set_env(DEBUG="1", LOG_LEVEL="DEBUG"):
    print(os.environ["DEBUG"])  # "1"
print(os.environ.get("DEBUG"))  # Noneï¼ˆå·²æ¢å¤ï¼‰
```

#### 6.3.3 æ•°æ®åº“äº‹åŠ¡ç®¡ç†
```python
class DatabaseConnection:
    def __enter__(self):
        self.conn = self.connect()
        self.conn.begin_transaction()
        return self.conn

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            self.conn.commit()  # æˆåŠŸåˆ™æäº¤
        else:
            self.conn.rollback()  # å¼‚å¸¸åˆ™å›æ»š
        self.conn.close()
        return False

with DatabaseConnection() as conn:
    conn.execute("INSERT ...")
    conn.execute("UPDATE ...")
# è‡ªåŠ¨æäº¤æˆ–å›æ»š
```

---

## 7. ç”Ÿæˆå™¨ä¸è¿­ä»£å™¨

### 7.1 è¿­ä»£å™¨åè®®

```python
# æ‰‹åŠ¨å®ç°è¿­ä»£å™¨
class CountDown:
    def __init__(self, start):
        self.current = start

    def __iter__(self):
        return self  # è¿”å›è‡ªèº«

    def __next__(self):
        if self.current <= 0:
            raise StopIteration
        self.current -= 1
        return self.current + 1

for num in CountDown(5):
    print(num)  # 5, 4, 3, 2, 1
```

### 7.2 ç”Ÿæˆå™¨ï¼ˆç®€åŒ–ç‰ˆè¿­ä»£å™¨ï¼‰

```python
# ä½¿ç”¨ yield å…³é”®å­—
def countdown(start):
    while start > 0:
        yield start  # æš‚åœå¹¶è¿”å›å€¼
        start -= 1

for num in countdown(5):
    print(num)
```

### 7.3 ç”Ÿæˆå™¨çš„å†…å­˜ä¼˜åŠ¿

```python
# âŒ ä½æ•ˆï¼šä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
def read_large_file_bad(file_path):
    with open(file_path, "r") as f:
        lines = f.readlines()  # ä¸€æ¬¡æ€§è¯»å–å…¨éƒ¨
    return lines

# âœ… é«˜æ•ˆï¼šæŒ‰éœ€ç”Ÿæˆï¼ˆæƒ°æ€§æ±‚å€¼ï¼‰
def read_large_file_good(file_path):
    with open(file_path, "r") as f:
        for line in f:  # é€è¡Œè¯»å–
            yield line.strip()

# å¤„ç† 10GB æ–‡ä»¶ä¹Ÿä¸ä¼šå ç”¨å¤§é‡å†…å­˜
for line in read_large_file_good("huge.log"):
    if "ERROR" in line:
        print(line)
```

### 7.4 ç”Ÿæˆå™¨è¡¨è¾¾å¼

```python
# åˆ—è¡¨æ¨å¯¼å¼ï¼ˆä¸€æ¬¡æ€§åˆ›å»ºï¼‰
squares_list = [x**2 for x in range(1000000)]  # å ç”¨å¤§é‡å†…å­˜

# ç”Ÿæˆå™¨è¡¨è¾¾å¼ï¼ˆæŒ‰éœ€ç”Ÿæˆï¼‰
squares_gen = (x**2 for x in range(1000000))   # å‡ ä¹ä¸å å†…å­˜

# å†…å­˜å¯¹æ¯”
import sys
print(sys.getsizeof(squares_list))  # 8448728 å­—èŠ‚
print(sys.getsizeof(squares_gen))   # 120 å­—èŠ‚
```

### 7.5 DevOps åº”ç”¨ï¼šæ—¥å¿—æ–‡ä»¶å¤„ç†

```python
def parse_nginx_log(file_path):
    """è§£æ nginx æ—¥å¿—ï¼ˆç”Ÿæˆå™¨ï¼‰"""
    with open(file_path, "r") as f:
        for line in f:
            parts = line.split()
            if len(parts) >= 9:
                yield {
                    "ip": parts[0],
                    "method": parts[5].strip('"'),
                    "path": parts[6],
                    "status": parts[8],
                }

def filter_errors(logs):
    """ç­›é€‰é”™è¯¯æ—¥å¿—ï¼ˆç”Ÿæˆå™¨é“¾ï¼‰"""
    for log in logs:
        if log["status"].startswith("5"):
            yield log

def group_by_ip(logs):
    """æŒ‰ IP åˆ†ç»„ç»Ÿè®¡ï¼ˆç”Ÿæˆå™¨æ¶ˆè´¹ï¼‰"""
    from collections import Counter
    ips = (log["ip"] for log in logs)
    return Counter(ips).most_common(10)

# æµå¼å¤„ç†ï¼šæ–‡ä»¶ â†’ è§£æ â†’ ç­›é€‰ â†’ ç»Ÿè®¡
logs = parse_nginx_log("/var/log/nginx/access.log")
errors = filter_errors(logs)
top_ips = group_by_ip(errors)
print(top_ips)
```

---

## 8. åç¨‹ä¸å¼‚æ­¥ç¼–ç¨‹

### 8.1 åŒæ­¥ vs å¼‚æ­¥

```python
import time

# åŒæ­¥ï¼ˆé˜»å¡ï¼‰
def download_sync(url):
    print(f"å¼€å§‹ä¸‹è½½ {url}")
    time.sleep(2)  # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚
    print(f"å®Œæˆä¸‹è½½ {url}")
    return f"Data from {url}"

start = time.time()
download_sync("url1")
download_sync("url2")
download_sync("url3")
print(f"æ€»è€—æ—¶: {time.time() - start:.1f}s")  # ~6s

# å¼‚æ­¥ï¼ˆéé˜»å¡ï¼‰
import asyncio

async def download_async(url):
    print(f"å¼€å§‹ä¸‹è½½ {url}")
    await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¼‚æ­¥ç½‘ç»œè¯·æ±‚
    print(f"å®Œæˆä¸‹è½½ {url}")
    return f"Data from {url}"

async def main():
    start = time.time()
    tasks = [
        download_async("url1"),
        download_async("url2"),
        download_async("url3"),
    ]
    await asyncio.gather(*tasks)  # å¹¶å‘æ‰§è¡Œ
    print(f"æ€»è€—æ—¶: {time.time() - start:.1f}s")  # ~2s

asyncio.run(main())
```

### 8.2 async/await å…³é”®å­—

```python
import asyncio
import aiohttp  # å¼‚æ­¥ HTTP åº“

async def fetch_url(session, url):
    """å¼‚æ­¥è·å– URL å†…å®¹"""
    async with session.get(url) as response:
        return await response.text()

async def fetch_multiple_urls(urls):
    """å¹¶å‘è·å–å¤šä¸ª URL"""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        return results

# è¿è¡Œ
urls = ["https://example.com", "https://github.com", "https://python.org"]
results = asyncio.run(fetch_multiple_urls(urls))
```

### 8.3 å¼‚æ­¥æ–‡ä»¶ I/O

```python
import aiofiles

async def read_file_async(file_path):
    """å¼‚æ­¥è¯»å–æ–‡ä»¶"""
    async with aiofiles.open(file_path, "r") as f:
        content = await f.read()
    return content

async def write_file_async(file_path, content):
    """å¼‚æ­¥å†™å…¥æ–‡ä»¶"""
    async with aiofiles.open(file_path, "w") as f:
        await f.write(content)

async def process_files():
    """å¹¶å‘å¤„ç†å¤šä¸ªæ–‡ä»¶"""
    tasks = [
        read_file_async("file1.txt"),
        read_file_async("file2.txt"),
        read_file_async("file3.txt"),
    ]
    contents = await asyncio.gather(*tasks)
    return contents

asyncio.run(process_files())
```

### 8.4 å¼‚æ­¥ä»»åŠ¡è°ƒåº¦

```python
import asyncio

async def task1():
    await asyncio.sleep(1)
    return "Task 1 done"

async def task2():
    await asyncio.sleep(2)
    return "Task 2 done"

async def main():
    # æ–¹æ³• 1: gatherï¼ˆå…¨éƒ¨å®Œæˆåè¿”å›ï¼‰
    results = await asyncio.gather(task1(), task2())
    print(results)  # ['Task 1 done', 'Task 2 done']

    # æ–¹æ³• 2: as_completedï¼ˆæŒ‰å®Œæˆé¡ºåºå¤„ç†ï¼‰
    for coro in asyncio.as_completed([task1(), task2()]):
        result = await coro
        print(result)  # Task 1 done (1s å), Task 2 done (2s å)

    # æ–¹æ³• 3: è¶…æ—¶æ§åˆ¶
    try:
        result = await asyncio.wait_for(task2(), timeout=1.0)
    except asyncio.TimeoutError:
        print("è¶…æ—¶ï¼")

asyncio.run(main())
```

### 8.5 DevOps åº”ç”¨ï¼šæ‰¹é‡ SSH æ“ä½œ

```python
import asyncio
import asyncssh

async def run_command_on_host(host, command):
    """å¼‚æ­¥æ‰§è¡Œ SSH å‘½ä»¤"""
    async with asyncssh.connect(host) as conn:
        result = await conn.run(command)
        return {
            "host": host,
            "stdout": result.stdout,
            "exit_status": result.exit_status,
        }

async def batch_ssh_commands(hosts, command):
    """æ‰¹é‡æ‰§è¡Œ SSH å‘½ä»¤"""
    tasks = [run_command_on_host(host, command) for host in hosts]
    results = await asyncio.gather(*tasks)
    return results

# å¹¶å‘æ“ä½œ 100 å°æœåŠ¡å™¨
hosts = [f"server{i}.example.com" for i in range(100)]
results = asyncio.run(batch_ssh_commands(hosts, "df -h"))
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šå·¥ç¨‹åŒ–å®è·µ

---

## 9. å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ

### 9.1 å¼‚å¸¸å±‚æ¬¡ç»“æ„

```python
BaseException
 â”œâ”€â”€ SystemExit
 â”œâ”€â”€ KeyboardInterrupt
 â””â”€â”€ Exception
      â”œâ”€â”€ ValueError
      â”œâ”€â”€ TypeError
      â”œâ”€â”€ FileNotFoundError
      â”œâ”€â”€ ConnectionError
      â””â”€â”€ ...
```

### 9.2 ç²¾ç¡®æ•è·å¼‚å¸¸

```python
# âŒ é”™è¯¯ï¼šæ•è·æ‰€æœ‰å¼‚å¸¸
try:
    result = 10 / 0
except:  # å±é™©ï¼è¿ KeyboardInterrupt éƒ½æ•è·
    pass

# âŒ é”™è¯¯ï¼šæ•è·è¿‡äºå®½æ³›
try:
    result = 10 / 0
except Exception:  # æ•è·æ‰€æœ‰ä¸šåŠ¡å¼‚å¸¸
    pass

# âœ… æ­£ç¡®ï¼šæ•è·å…·ä½“å¼‚å¸¸
try:
    result = 10 / 0
except ZeroDivisionError:
    print("é™¤æ•°ä¸èƒ½ä¸º 0")

# âœ… æ­£ç¡®ï¼šæ•è·å¤šä¸ªå…·ä½“å¼‚å¸¸
try:
    with open("data.json", "r") as f:
        data = json.load(f)
except FileNotFoundError:
    print("æ–‡ä»¶ä¸å­˜åœ¨")
except json.JSONDecodeError:
    print("JSON æ ¼å¼é”™è¯¯")
```

### 9.3 å¼‚å¸¸é“¾ä¸ä¸Šä¸‹æ–‡

```python
# âŒ é”™è¯¯ï¼šä¸¢å¤±åŸå§‹å¼‚å¸¸ä¿¡æ¯
try:
    data = json.load(open("config.json"))
except Exception:
    raise ValueError("é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥")  # åŸå§‹å¼‚å¸¸ä¿¡æ¯ä¸¢å¤±

# âœ… æ­£ç¡®ï¼šä¿ç•™å¼‚å¸¸é“¾
try:
    data = json.load(open("config.json"))
except Exception as e:
    raise ValueError("é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥") from e  # ä½¿ç”¨ from ä¿ç•™åŸå› 
```

### 9.4 è‡ªå®šä¹‰å¼‚å¸¸

```python
# åŸºç¡€å¼‚å¸¸ç±»
class APIError(Exception):
    """API åŸºç¡€å¼‚å¸¸"""
    pass

# å…·ä½“å¼‚å¸¸
class AuthenticationError(APIError):
    """è®¤è¯å¤±è´¥"""
    def __init__(self, message, status_code=401):
        self.message = message
        self.status_code = status_code
        super().__init__(self.message)

class RateLimitError(APIError):
    """é€Ÿç‡é™åˆ¶"""
    def __init__(self, retry_after):
        self.retry_after = retry_after
        super().__init__(f"è¯· {retry_after} ç§’åé‡è¯•")

# ä½¿ç”¨
def call_api(token):
    if not token:
        raise AuthenticationError("Token ç¼ºå¤±")
    # ...

try:
    call_api(None)
except AuthenticationError as e:
    print(f"é”™è¯¯ç : {e.status_code}, æ¶ˆæ¯: {e.message}")
```

### 9.5 ä¸Šä¸‹æ–‡ç®¡ç†å™¨ + å¼‚å¸¸å¤„ç†

```python
from contextlib import contextmanager

@contextmanager
def safe_transaction(conn):
    """å®‰å…¨äº‹åŠ¡ä¸Šä¸‹æ–‡"""
    try:
        conn.begin()
        yield conn
        conn.commit()
    except Exception as e:
        conn.rollback()
        print(f"äº‹åŠ¡å›æ»š: {e}")
        raise
    finally:
        conn.close()

# ä½¿ç”¨
with safe_transaction(db_connection) as conn:
    conn.execute("INSERT ...")
    conn.execute("UPDATE ...")
```

### 9.6 ç”Ÿäº§ç¯å¢ƒå¼‚å¸¸å¤„ç†æ¨¡å¼

```python
import logging
import traceback

logger = logging.getLogger(__name__)

def robust_api_call(url, max_retries=3):
    """å¥å£®çš„ API è°ƒç”¨"""
    for attempt in range(1, max_retries + 1):
        try:
            response = requests.get(url, timeout=5)
            response.raise_for_status()
            return response.json()

        except requests.Timeout:
            logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼ˆç¬¬ {attempt} æ¬¡ï¼‰")
            if attempt == max_retries:
                raise

        except requests.ConnectionError as e:
            logger.error(f"è¿æ¥å¤±è´¥: {e}")
            if attempt == max_retries:
                raise

        except requests.HTTPError as e:
            if e.response.status_code >= 500:
                # æœåŠ¡å™¨é”™è¯¯ â†’ é‡è¯•
                logger.warning(f"æœåŠ¡å™¨é”™è¯¯ {e.response.status_code}ï¼Œé‡è¯•ä¸­...")
                if attempt == max_retries:
                    raise
            else:
                # å®¢æˆ·ç«¯é”™è¯¯ â†’ ä¸é‡è¯•
                logger.error(f"å®¢æˆ·ç«¯é”™è¯¯: {e}")
                raise

        except Exception as e:
            # æœªçŸ¥å¼‚å¸¸ â†’ è®°å½•è¯¦ç»†å †æ ˆ
            logger.error(f"æœªçŸ¥å¼‚å¸¸:\n{traceback.format_exc()}")
            raise

# å…¨å±€å¼‚å¸¸æ•è·ï¼ˆå®ˆæŠ¤è¿›ç¨‹ï¼‰
def main():
    try:
        # ä¸»é€»è¾‘
        run_application()
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    except Exception:
        logger.critical(f"è‡´å‘½é”™è¯¯:\n{traceback.format_exc()}")
        sys.exit(1)
```

---

## 10. æ—¥å¿—ç³»ç»Ÿè®¾è®¡

### 10.1 æ—¥å¿—çº§åˆ«

```python
import logging

# æ—¥å¿—çº§åˆ«ï¼ˆç”±ä½åˆ°é«˜ï¼‰
# DEBUG < INFO < WARNING < ERROR < CRITICAL

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

logger.debug("è°ƒè¯•ä¿¡æ¯")      # å¼€å‘ç¯å¢ƒ
logger.info("æ­£å¸¸ä¿¡æ¯")       # ç”Ÿäº§ç¯å¢ƒ
logger.warning("è­¦å‘Šä¿¡æ¯")    # éœ€è¦æ³¨æ„
logger.error("é”™è¯¯ä¿¡æ¯")      # éœ€è¦å¤„ç†
logger.critical("ä¸¥é‡é”™è¯¯")   # ç³»ç»Ÿå´©æºƒ
```

### 10.2 ç»“æ„åŒ–æ—¥å¿—é…ç½®

```python
import logging.config

LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "standard": {
            "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
        },
        "detailed": {
            "format": "%(asctime)s [%(levelname)s] %(name)s.%(funcName)s:%(lineno)d - %(message)s"
        },
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "standard",
            "stream": "ext://sys.stdout",
        },
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "level": "DEBUG",
            "formatter": "detailed",
            "filename": "app.log",
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5,
        },
    },
    "loggers": {
        "": {  # root logger
            "handlers": ["console", "file"],
            "level": "DEBUG",
        },
    },
}

logging.config.dictConfig(LOGGING_CONFIG)
logger = logging.getLogger(__name__)
```

### 10.3 JSON æ ¼å¼æ—¥å¿—ï¼ˆç”Ÿäº§æ¨èï¼‰

```python
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    """JSON æ ¼å¼æ—¥å¿—ï¼ˆä¾¿äº ELK é‡‡é›†ï¼‰"""
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }

        # æ·»åŠ å¼‚å¸¸å †æ ˆ
        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)

        # æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id

        return json.dumps(log_data, ensure_ascii=False)

# é…ç½®
handler = logging.StreamHandler()
handler.setFormatter(JSONFormatter())
logger = logging.getLogger(__name__)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# ä½¿ç”¨ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
logger.info("ç”¨æˆ·ç™»å½•", extra={"request_id": "abc123"})
```

### 10.4 åˆ†å¸ƒå¼è¿½è¸ªï¼ˆRequest IDï¼‰

```python
import uuid
import contextvars

# çº¿ç¨‹å®‰å…¨çš„ä¸Šä¸‹æ–‡å˜é‡
request_id_var = contextvars.ContextVar("request_id", default=None)

class RequestIDFilter(logging.Filter):
    """è‡ªåŠ¨æ·»åŠ  Request ID"""
    def filter(self, record):
        record.request_id = request_id_var.get() or "N/A"
        return True

# é…ç½®
logger = logging.getLogger(__name__)
logger.addFilter(RequestIDFilter())

# ä½¿ç”¨
def handle_request():
    request_id = str(uuid.uuid4())
    request_id_var.set(request_id)

    logger.info("å¼€å§‹å¤„ç†è¯·æ±‚")  # è‡ªåŠ¨åŒ…å« request_id
    # ... ä¸šåŠ¡é€»è¾‘ ...
    logger.info("è¯·æ±‚å¤„ç†å®Œæˆ")
```

### 10.5 DevOps æ—¥å¿—å®è·µ

```python
import logging
from logging.handlers import RotatingFileHandler, SysLogHandler

def setup_production_logging(app_name):
    """ç”Ÿäº§ç¯å¢ƒæ—¥å¿—é…ç½®"""
    logger = logging.getLogger(app_name)
    logger.setLevel(logging.INFO)

    # 1. æ§åˆ¶å°è¾“å‡ºï¼ˆDocker/K8s æ”¶é›†ï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(JSONFormatter())
    logger.addHandler(console_handler)

    # 2. æ–‡ä»¶æ»šåŠ¨ï¼ˆæœ¬åœ°å¤‡ä»½ï¼‰
    file_handler = RotatingFileHandler(
        f"/var/log/{app_name}/app.log",
        maxBytes=50*1024*1024,  # 50MB
        backupCount=10,
    )
    file_handler.setFormatter(JSONFormatter())
    logger.addHandler(file_handler)

    # 3. é”™è¯¯å•ç‹¬æ–‡ä»¶
    error_handler = RotatingFileHandler(
        f"/var/log/{app_name}/error.log",
        maxBytes=50*1024*1024,
        backupCount=10,
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(JSONFormatter())
    logger.addHandler(error_handler)

    # 4. Syslogï¼ˆå‘é€åˆ°æ—¥å¿—æœåŠ¡å™¨ï¼‰
    syslog_handler = SysLogHandler(address=("logserver", 514))
    syslog_handler.setFormatter(JSONFormatter())
    logger.addHandler(syslog_handler)

    return logger
```

---

## 11. é…ç½®ç®¡ç†ä¸ç¯å¢ƒå˜é‡

### 11.1 ç¯å¢ƒå˜é‡æœ€ä½³å®è·µ

#### åŸºç¡€ç”¨æ³•
```python
import os

# è¯»å–ç¯å¢ƒå˜é‡
api_key = os.getenv("API_KEY")  # è¿”å› None å¦‚æœä¸å­˜åœ¨
api_key = os.getenv("API_KEY", "default_value")  # æä¾›é»˜è®¤å€¼
api_key = os.environ["API_KEY"]  # KeyError å¦‚æœä¸å­˜åœ¨

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["DEBUG"] = "1"

# åˆ é™¤ç¯å¢ƒå˜é‡
os.environ.pop("TEMP_VAR", None)
```

#### .env æ–‡ä»¶ç®¡ç†ï¼ˆæ¨èï¼‰
```python
# .env æ–‡ä»¶å†…å®¹
"""
# å¼€å‘ç¯å¢ƒé…ç½®
DEBUG=1
LOG_LEVEL=DEBUG
DATABASE_URL=postgresql://localhost/dev_db
API_KEY=sk-dev-xxxxxxxxx
REDIS_HOST=localhost
REDIS_PORT=6379
"""

# Python ä»£ç 
from dotenv import load_dotenv
import os

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# è¯»å–é…ç½®
DEBUG = os.getenv("DEBUG") == "1"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
DATABASE_URL = os.getenv("DATABASE_URL")
```

### 11.2 å¤šç¯å¢ƒé…ç½®ç®¡ç†

#### æ–¹æ¡ˆ 1ï¼šç¯å¢ƒå˜é‡åˆ‡æ¢
```bash
# .env.dev
DEBUG=1
DATABASE_URL=postgresql://localhost/dev_db

# .env.staging
DEBUG=0
DATABASE_URL=postgresql://staging-server/staging_db

# .env.prod
DEBUG=0
DATABASE_URL=postgresql://prod-server/prod_db
```

```python
import os
from dotenv import load_dotenv

# æ ¹æ®ç¯å¢ƒåŠ è½½ä¸åŒé…ç½®æ–‡ä»¶
env = os.getenv("ENV", "dev")
env_file = f".env.{env}"
load_dotenv(env_file)

print(f"å½“å‰ç¯å¢ƒ: {env}")
print(f"æ•°æ®åº“: {os.getenv('DATABASE_URL')}")
```

#### æ–¹æ¡ˆ 2ï¼šé…ç½®ç±»ç»§æ‰¿
```python
class BaseConfig:
    """åŸºç¡€é…ç½®"""
    SECRET_KEY = os.getenv("SECRET_KEY", "dev-secret-key")
    DEBUG = False
    TESTING = False

    # æ•°æ®åº“
    SQLALCHEMY_TRACK_MODIFICATIONS = False

    # æ—¥å¿—
    LOG_LEVEL = "INFO"

class DevelopmentConfig(BaseConfig):
    """å¼€å‘ç¯å¢ƒé…ç½®"""
    DEBUG = True
    DATABASE_URL = "postgresql://localhost/dev_db"
    LOG_LEVEL = "DEBUG"

class StagingConfig(BaseConfig):
    """é¢„å‘å¸ƒç¯å¢ƒé…ç½®"""
    DATABASE_URL = os.getenv("DATABASE_URL")
    LOG_LEVEL = "INFO"

class ProductionConfig(BaseConfig):
    """ç”Ÿäº§ç¯å¢ƒé…ç½®"""
    DATABASE_URL = os.getenv("DATABASE_URL")
    LOG_LEVEL = "WARNING"

    # ç”Ÿäº§ç¯å¢ƒé¢å¤–é…ç½®
    SENTRY_DSN = os.getenv("SENTRY_DSN")

# é…ç½®æ˜ å°„
config_map = {
    "dev": DevelopmentConfig,
    "staging": StagingConfig,
    "prod": ProductionConfig,
}

# è·å–å½“å‰é…ç½®
env = os.getenv("ENV", "dev")
Config = config_map[env]
```

### 11.3 é…ç½®éªŒè¯ï¼ˆPydanticï¼‰

```python
from pydantic import BaseSettings, Field, validator
from typing import Optional

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®ï¼ˆå¸¦éªŒè¯ï¼‰"""

    # åŸºç¡€é…ç½®
    app_name: str = "MyApp"
    debug: bool = False

    # æ•°æ®åº“é…ç½®
    database_url: str = Field(..., env="DATABASE_URL")  # å¿…å¡«
    database_pool_size: int = Field(10, ge=1, le=100)  # 1-100

    # Redis é…ç½®
    redis_host: str = "localhost"
    redis_port: int = Field(6379, ge=1, le=65535)
    redis_db: int = Field(0, ge=0, le=15)

    # API é…ç½®
    api_key: Optional[str] = None
    api_timeout: int = Field(30, ge=1)

    # æ—¥å¿—é…ç½®
    log_level: str = Field("INFO", regex="^(DEBUG|INFO|WARNING|ERROR|CRITICAL)$")

    @validator("database_url")
    def validate_database_url(cls, v):
        """éªŒè¯æ•°æ®åº“ URL"""
        if not v.startswith(("postgresql://", "mysql://")):
            raise ValueError("æ•°æ®åº“ URL æ ¼å¼é”™è¯¯")
        return v

    @validator("api_key")
    def validate_api_key(cls, v):
        """éªŒè¯ API Key"""
        if v and not v.startswith("sk-"):
            raise ValueError("API Key å¿…é¡»ä»¥ sk- å¼€å¤´")
        return v

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# ä½¿ç”¨
try:
    settings = Settings()
    print(f"é…ç½®åŠ è½½æˆåŠŸ: {settings.app_name}")
except Exception as e:
    print(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
    sys.exit(1)
```

### 11.4 æ•æ„Ÿä¿¡æ¯ç®¡ç†

#### æ–¹æ¡ˆ 1ï¼šç¯å¢ƒå˜é‡ + .envï¼ˆå¼€å‘ï¼‰
```python
# .env
API_KEY=sk-xxxxxxxx
DATABASE_PASSWORD=secret123

# .gitignore
.env
.env.*
```

#### æ–¹æ¡ˆ 2ï¼šç³»ç»Ÿå¯†é’¥ç®¡ç†ï¼ˆç”Ÿäº§ï¼‰
```python
import keyring

# å­˜å‚¨å¯†é’¥
keyring.set_password("myapp", "api_key", "sk-xxxxxxxx")

# è¯»å–å¯†é’¥
api_key = keyring.get_password("myapp", "api_key")

# åˆ é™¤å¯†é’¥
keyring.delete_password("myapp", "api_key")
```

#### æ–¹æ¡ˆ 3ï¼šäº‘æœåŠ¡å¯†é’¥ç®¡ç†
```python
# AWS Secrets Manager
import boto3
import json

def get_secret(secret_name):
    """ä» AWS Secrets Manager è·å–å¯†é’¥"""
    client = boto3.client("secretsmanager", region_name="us-east-1")
    response = client.get_secret_value(SecretId=secret_name)
    return json.loads(response["SecretString"])

# ä½¿ç”¨
secrets = get_secret("myapp/prod/database")
DATABASE_URL = secrets["url"]
DATABASE_PASSWORD = secrets["password"]
```

```python
# HashiCorp Vault
import hvac

def get_vault_secret(path):
    """ä» Vault è·å–å¯†é’¥"""
    client = hvac.Client(url="https://vault.example.com")
    client.token = os.getenv("VAULT_TOKEN")

    secret = client.secrets.kv.v2.read_secret_version(path=path)
    return secret["data"]["data"]

# ä½¿ç”¨
secrets = get_vault_secret("myapp/database")
DATABASE_URL = secrets["url"]
```

### 11.5 é…ç½®çƒ­åŠ è½½

```python
import time
import threading
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class ConfigReloader(FileSystemEventHandler):
    """é…ç½®æ–‡ä»¶çƒ­åŠ è½½"""

    def __init__(self, config_file, callback):
        self.config_file = config_file
        self.callback = callback

    def on_modified(self, event):
        if event.src_path.endswith(self.config_file):
            print(f"æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜æ›´: {self.config_file}")
            self.callback()

def reload_config():
    """é‡æ–°åŠ è½½é…ç½®"""
    load_dotenv(override=True)
    print("é…ç½®å·²é‡æ–°åŠ è½½")

# å¯åŠ¨ç›‘æ§
observer = Observer()
handler = ConfigReloader(".env", reload_config)
observer.schedule(handler, path=".", recursive=False)
observer.start()

try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    observer.stop()
observer.join()
```

### 11.6 ç”Ÿäº§ç¯å¢ƒé…ç½®æ¸…å•

```python
class ProductionConfig:
    """ç”Ÿäº§ç¯å¢ƒé…ç½®æ£€æŸ¥æ¸…å•"""

    @classmethod
    def validate(cls):
        """éªŒè¯ç”Ÿäº§ç¯å¢ƒé…ç½®"""
        errors = []

        # 1. æ£€æŸ¥å¿…éœ€ç¯å¢ƒå˜é‡
        required_vars = [
            "DATABASE_URL",
            "SECRET_KEY",
            "API_KEY",
        ]
        for var in required_vars:
            if not os.getenv(var):
                errors.append(f"ç¼ºå°‘å¿…éœ€ç¯å¢ƒå˜é‡: {var}")

        # 2. æ£€æŸ¥ DEBUG æ¨¡å¼
        if os.getenv("DEBUG") == "1":
            errors.append("ç”Ÿäº§ç¯å¢ƒä¸èƒ½å¼€å¯ DEBUG æ¨¡å¼")

        # 3. æ£€æŸ¥å¯†é’¥å¼ºåº¦
        secret_key = os.getenv("SECRET_KEY", "")
        if len(secret_key) < 32:
            errors.append("SECRET_KEY é•¿åº¦ä¸è¶³ï¼ˆè‡³å°‘ 32 ä½ï¼‰")

        # 4. æ£€æŸ¥æ•°æ®åº“è¿æ¥
        database_url = os.getenv("DATABASE_URL", "")
        if "localhost" in database_url:
            errors.append("ç”Ÿäº§ç¯å¢ƒä¸åº”ä½¿ç”¨ localhost æ•°æ®åº“")

        # 5. æ£€æŸ¥æ—¥å¿—çº§åˆ«
        log_level = os.getenv("LOG_LEVEL", "INFO")
        if log_level == "DEBUG":
            errors.append("ç”Ÿäº§ç¯å¢ƒæ—¥å¿—çº§åˆ«ä¸åº”ä¸º DEBUG")

        if errors:
            raise ValueError(f"é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(errors))

        print("âœ… ç”Ÿäº§ç¯å¢ƒé…ç½®éªŒè¯é€šè¿‡")

# å¯åŠ¨æ—¶éªŒè¯
if os.getenv("ENV") == "prod":
    ProductionConfig.validate()
```

---

## 12. å•å…ƒæµ‹è¯•ä¸ä»£ç è´¨é‡

### 12.1 pytest åŸºç¡€

#### ç®€å•æµ‹è¯•
```python
# test_math.py
def add(a, b):
    return a + b

def test_add():
    """æµ‹è¯•åŠ æ³•å‡½æ•°"""
    assert add(1, 2) == 3
    assert add(-1, 1) == 0
    assert add(0, 0) == 0

def test_add_negative():
    """æµ‹è¯•è´Ÿæ•°"""
    assert add(-5, -3) == -8

# è¿è¡Œæµ‹è¯•
# pytest test_math.py
```

#### å‚æ•°åŒ–æµ‹è¯•
```python
import pytest

@pytest.mark.parametrize("a, b, expected", [
    (1, 2, 3),
    (-1, 1, 0),
    (0, 0, 0),
    (100, 200, 300),
    (-5, -3, -8),
])
def test_add_parametrized(a, b, expected):
    assert add(a, b) == expected
```

### 12.2 Fixtureï¼ˆæµ‹è¯•è£…ç½®ï¼‰

```python
import pytest
import tempfile
import os

@pytest.fixture
def temp_file():
    """åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆè‡ªåŠ¨æ¸…ç†ï¼‰"""
    fd, path = tempfile.mkstemp()
    yield path  # æä¾›ç»™æµ‹è¯•ç”¨ä¾‹
    os.close(fd)
    os.remove(path)  # æµ‹è¯•åè‡ªåŠ¨åˆ é™¤

def test_file_write(temp_file):
    """æµ‹è¯•æ–‡ä»¶å†™å…¥"""
    with open(temp_file, "w") as f:
        f.write("Hello")

    with open(temp_file, "r") as f:
        assert f.read() == "Hello"

@pytest.fixture(scope="module")
def database():
    """æ¨¡å—çº§åˆ«çš„æ•°æ®åº“è¿æ¥ï¼ˆä»…åˆ›å»ºä¸€æ¬¡ï¼‰"""
    db = create_database_connection()
    yield db
    db.close()

@pytest.fixture(scope="session")
def app_config():
    """ä¼šè¯çº§åˆ«çš„é…ç½®ï¼ˆæ•´ä¸ªæµ‹è¯•æœŸé—´ä»…ä¸€æ¬¡ï¼‰"""
    config = load_config()
    yield config
```

### 12.3 Mock ä¸ Patch

```python
from unittest.mock import Mock, patch, MagicMock
import requests

# è¢«æµ‹è¯•å‡½æ•°
def fetch_user(user_id):
    """ä» API è·å–ç”¨æˆ·ä¿¡æ¯"""
    response = requests.get(f"https://api.example.com/users/{user_id}")
    response.raise_for_status()
    return response.json()

# æµ‹è¯•ï¼ˆMock HTTP è¯·æ±‚ï¼‰
@patch("requests.get")
def test_fetch_user(mock_get):
    """æµ‹è¯•è·å–ç”¨æˆ·ï¼ˆä¸å®é™…å‘é€ HTTP è¯·æ±‚ï¼‰"""
    # è®¾ç½® Mock è¿”å›å€¼
    mock_response = Mock()
    mock_response.json.return_value = {"id": 1, "name": "å¼ ä¸‰"}
    mock_response.raise_for_status = Mock()
    mock_get.return_value = mock_response

    # æ‰§è¡Œæµ‹è¯•
    user = fetch_user(1)

    # æ–­è¨€
    assert user["name"] == "å¼ ä¸‰"
    mock_get.assert_called_once_with("https://api.example.com/users/1")

# Mock ç±»æ–¹æ³•
class DataProcessor:
    def process(self, data):
        # å¤æ‚å¤„ç†é€»è¾‘
        return data.upper()

def test_data_processor():
    processor = DataProcessor()
    processor.process = Mock(return_value="MOCKED")

    result = processor.process("test")
    assert result == "MOCKED"
    processor.process.assert_called_once_with("test")
```

### 12.4 å¼‚æ­¥æµ‹è¯•

```python
import pytest
import asyncio

async def async_fetch_data(url):
    """å¼‚æ­¥è·å–æ•°æ®"""
    await asyncio.sleep(1)
    return f"Data from {url}"

@pytest.mark.asyncio
async def test_async_fetch_data():
    """æµ‹è¯•å¼‚æ­¥å‡½æ•°"""
    result = await async_fetch_data("https://example.com")
    assert result == "Data from https://example.com"

@pytest.mark.asyncio
async def test_concurrent_fetch():
    """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
    urls = ["url1", "url2", "url3"]
    tasks = [async_fetch_data(url) for url in urls]
    results = await asyncio.gather(*tasks)

    assert len(results) == 3
    assert all("Data from" in r for r in results)
```

### 12.5 æµ‹è¯•è¦†ç›–ç‡

```bash
# å®‰è£…
pip install pytest-cov

# è¿è¡Œå¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=myapp --cov-report=html tests/

# æŸ¥çœ‹æŠ¥å‘Š
open htmlcov/index.html
```

```python
# pytest.ini é…ç½®
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_functions = test_*
addopts =
    --cov=myapp
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=80
```

### 12.6 ä»£ç è´¨é‡å·¥å…·

#### Blackï¼ˆä»£ç æ ¼å¼åŒ–ï¼‰
```bash
# å®‰è£…
pip install black

# æ ¼å¼åŒ–ä»£ç 
black myapp/

# æ£€æŸ¥ï¼ˆä¸ä¿®æ”¹ï¼‰
black --check myapp/
```

#### Flake8ï¼ˆä»£ç æ£€æŸ¥ï¼‰
```bash
# å®‰è£…
pip install flake8

# æ£€æŸ¥ä»£ç 
flake8 myapp/

# .flake8 é…ç½®
[flake8]
max-line-length = 88
exclude = .git,__pycache__,venv
ignore = E203, W503
```

#### MyPyï¼ˆç±»å‹æ£€æŸ¥ï¼‰
```bash
# å®‰è£…
pip install mypy

# ç±»å‹æ£€æŸ¥
mypy myapp/
```

```python
# ç±»å‹æ³¨è§£ç¤ºä¾‹
from typing import List, Dict, Optional

def process_users(users: List[Dict[str, str]]) -> Optional[str]:
    """å¤„ç†ç”¨æˆ·åˆ—è¡¨"""
    if not users:
        return None

    names: List[str] = [u["name"] for u in users]
    return ", ".join(names)
```

### 12.7 CI/CD é›†æˆ

#### GitHub Actions ç¤ºä¾‹
```yaml
# .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.12

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov black flake8 mypy

    - name: Code formatting check
      run: black --check .

    - name: Linting
      run: flake8 .

    - name: Type checking
      run: mypy .

    - name: Run tests
      run: pytest --cov=. --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v2
      with:
        file: ./coverage.xml
```

### 12.8 æµ‹è¯•æœ€ä½³å®è·µ

```python
# âœ… å¥½çš„æµ‹è¯•
def test_user_registration():
    """æµ‹è¯•ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½"""
    # Arrangeï¼ˆå‡†å¤‡ï¼‰
    user_data = {
        "username": "testuser",
        "email": "test@example.com",
        "password": "securepass123",
    }

    # Actï¼ˆæ‰§è¡Œï¼‰
    user = register_user(user_data)

    # Assertï¼ˆæ–­è¨€ï¼‰
    assert user.username == "testuser"
    assert user.email == "test@example.com"
    assert user.password != "securepass123"  # å¯†ç åº”è¯¥è¢«åŠ å¯†

# âŒ ä¸å¥½çš„æµ‹è¯•
def test_everything():
    """æµ‹è¯•æ‰€æœ‰åŠŸèƒ½ï¼ˆå¤ªå®½æ³›ï¼‰"""
    user = create_user()
    assert user is not None  # æ–­è¨€å¤ªå¼±
    # æµ‹è¯•å¤ªå¤šåŠŸèƒ½ï¼Œéš¾ä»¥å®šä½é—®é¢˜

# âœ… æµ‹è¯•è¾¹ç•Œæ¡ä»¶
@pytest.mark.parametrize("age", [-1, 0, 150, 200])
def test_age_validation_invalid(age):
    """æµ‹è¯•æ— æ•ˆå¹´é¾„"""
    with pytest.raises(ValueError):
        validate_age(age)

@pytest.mark.parametrize("age", [1, 18, 65, 120])
def test_age_validation_valid(age):
    """æµ‹è¯•æœ‰æ•ˆå¹´é¾„"""
    assert validate_age(age) is True
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šDevOps è„šæœ¬ç¼–ç¨‹

---

## 13. ç³»ç»Ÿè°ƒç”¨ä¸å­è¿›ç¨‹ç®¡ç†

### 13.1 subprocess æ¨¡å—åŸºç¡€

#### è¿è¡Œç®€å•å‘½ä»¤
```python
import subprocess

# æ–¹æ³• 1ï¼šrun()ï¼ˆæ¨èï¼ŒPython 3.5+ï¼‰
result = subprocess.run(
    ["ls", "-la"],
    capture_output=True,  # æ•è·è¾“å‡º
    text=True,            # æ–‡æœ¬æ¨¡å¼ï¼ˆéå­—èŠ‚ï¼‰
    check=True,           # éé›¶é€€å‡ºç æŠ›å‡ºå¼‚å¸¸
)

print("æ ‡å‡†è¾“å‡º:", result.stdout)
print("æ ‡å‡†é”™è¯¯:", result.stderr)
print("é€€å‡ºç :", result.returncode)

# æ–¹æ³• 2ï¼šè¿è¡Œ shell å‘½ä»¤
result = subprocess.run(
    "ls -la | grep .py",
    shell=True,
    capture_output=True,
    text=True,
)
```

#### é”™è¯¯å¤„ç†
```python
try:
    result = subprocess.run(
        ["nonexistent-command"],
        capture_output=True,
        text=True,
        check=True,  # éé›¶é€€å‡ºç æŠ›å‡º CalledProcessError
    )
except subprocess.CalledProcessError as e:
    print(f"å‘½ä»¤å¤±è´¥ï¼Œé€€å‡ºç : {e.returncode}")
    print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
except FileNotFoundError:
    print("å‘½ä»¤ä¸å­˜åœ¨")
```

### 13.2 å®æ—¶è¾“å‡ºæµ

```python
import subprocess

def run_with_realtime_output(cmd):
    """å®æ—¶æ‰“å°å‘½ä»¤è¾“å‡º"""
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,  # è¡Œç¼“å†²
    )

    for line in process.stdout:
        print(line, end="")

    process.wait()
    return process.returncode

# ä½¿ç”¨
exit_code = run_with_realtime_output(["ping", "-c", "5", "google.com"])
print(f"é€€å‡ºç : {exit_code}")
```

### 13.3 è¶…æ—¶æ§åˆ¶

```python
import subprocess

try:
    result = subprocess.run(
        ["sleep", "10"],
        timeout=5,  # 5 ç§’è¶…æ—¶
        check=True,
    )
except subprocess.TimeoutExpired:
    print("å‘½ä»¤æ‰§è¡Œè¶…æ—¶")
```

### 13.4 è¿›ç¨‹ç®¡é“

```python
# ç­‰ä»·äºï¼šcat file.txt | grep "error" | wc -l

# æ–¹æ³• 1ï¼šæ‰‹åŠ¨ç®¡é“
p1 = subprocess.Popen(["cat", "file.txt"], stdout=subprocess.PIPE)
p2 = subprocess.Popen(["grep", "error"], stdin=p1.stdout, stdout=subprocess.PIPE)
p1.stdout.close()  # å…è®¸ p1 åœ¨ p2 å®Œæˆå‰é€€å‡º
p3 = subprocess.Popen(["wc", "-l"], stdin=p2.stdout, stdout=subprocess.PIPE)
p2.stdout.close()

output, _ = p3.communicate()
print(f"é”™è¯¯è¡Œæ•°: {output.decode().strip()}")

# æ–¹æ³• 2ï¼šä½¿ç”¨ shellï¼ˆç®€å•ä½†ä¸å®‰å…¨ï¼‰
result = subprocess.run(
    "cat file.txt | grep error | wc -l",
    shell=True,
    capture_output=True,
    text=True,
)
print(f"é”™è¯¯è¡Œæ•°: {result.stdout.strip()}")
```

### 13.5 äº¤äº’å¼å‘½ä»¤

```python
import subprocess

def run_interactive_command(cmd, inputs):
    """è¿è¡Œäº¤äº’å¼å‘½ä»¤"""
    process = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
    )

    # å‘é€è¾“å…¥
    stdout, stderr = process.communicate(input=inputs)

    return stdout, stderr, process.returncode

# ç¤ºä¾‹ï¼šè‡ªåŠ¨åŒ– SSH å¯†é’¥ç”Ÿæˆ
stdout, stderr, code = run_interactive_command(
    ["ssh-keygen", "-t", "rsa"],
    inputs="\n\n\n",  # ä¸‰æ¬¡å›è½¦ï¼ˆé»˜è®¤å€¼ï¼‰
)
```

### 13.6 å­è¿›ç¨‹ç®¡ç†å·¥å…·ç±»

```python
import subprocess
import logging
from typing import List, Optional

logger = logging.getLogger(__name__)

class CommandExecutor:
    """å‘½ä»¤æ‰§è¡Œå™¨ï¼ˆç”Ÿäº§çº§ï¼‰"""

    @staticmethod
    def run(
        cmd: List[str],
        cwd: Optional[str] = None,
        env: Optional[dict] = None,
        timeout: Optional[int] = None,
        check: bool = True,
        capture_output: bool = True,
    ) -> subprocess.CompletedProcess:
        """
        æ‰§è¡Œå‘½ä»¤

        Args:
            cmd: å‘½ä»¤åˆ—è¡¨
            cwd: å·¥ä½œç›®å½•
            env: ç¯å¢ƒå˜é‡
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            check: å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
            capture_output: æ•è·è¾“å‡º
        """
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        try:
            result = subprocess.run(
                cmd,
                cwd=cwd,
                env=env,
                timeout=timeout,
                check=check,
                capture_output=capture_output,
                text=True,
            )

            logger.debug(f"å‘½ä»¤è¾“å‡º: {result.stdout}")
            return result

        except subprocess.TimeoutExpired as e:
            logger.error(f"å‘½ä»¤è¶…æ—¶: {e}")
            raise
        except subprocess.CalledProcessError as e:
            logger.error(f"å‘½ä»¤å¤±è´¥: {e.stderr}")
            raise
        except FileNotFoundError as e:
            logger.error(f"å‘½ä»¤ä¸å­˜åœ¨: {e}")
            raise

    @staticmethod
    def run_shell(
        cmd: str,
        cwd: Optional[str] = None,
        timeout: Optional[int] = None,
    ) -> subprocess.CompletedProcess:
        """è¿è¡Œ shell å‘½ä»¤"""
        logger.warning(f"ä½¿ç”¨ shell æ‰§è¡Œå‘½ä»¤ï¼ˆå®‰å…¨é£é™©ï¼‰: {cmd}")

        return subprocess.run(
            cmd,
            shell=True,
            cwd=cwd,
            timeout=timeout,
            capture_output=True,
            text=True,
        )

    @staticmethod
    def run_async(cmd: List[str]) -> subprocess.Popen:
        """å¼‚æ­¥æ‰§è¡Œå‘½ä»¤ï¼ˆåå°è¿è¡Œï¼‰"""
        logger.info(f"å¼‚æ­¥æ‰§è¡Œ: {' '.join(cmd)}")

        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )

        return process

# ä½¿ç”¨ç¤ºä¾‹
executor = CommandExecutor()

# åŒæ­¥æ‰§è¡Œ
result = executor.run(["git", "status"])
print(result.stdout)

# å¼‚æ­¥æ‰§è¡Œ
process = executor.run_async(["ping", "-c", "100", "google.com"])
print(f"è¿›ç¨‹ PID: {process.pid}")

# ç¨åæ£€æŸ¥çŠ¶æ€
if process.poll() is None:
    print("è¿›ç¨‹ä»åœ¨è¿è¡Œ")
else:
    print(f"è¿›ç¨‹å·²ç»“æŸï¼Œé€€å‡ºç : {process.returncode}")
```

### 13.7 DevOps å®æˆ˜æ¡ˆä¾‹

#### æ¡ˆä¾‹ 1ï¼šæ‰¹é‡æœåŠ¡å™¨éƒ¨ç½²
```python
import subprocess
import concurrent.futures

def deploy_to_server(host, app_path):
    """éƒ¨ç½²åº”ç”¨åˆ°æœåŠ¡å™¨"""
    commands = [
        f"rsync -avz {app_path} {host}:/opt/app/",
        f"ssh {host} 'systemctl restart myapp'",
        f"ssh {host} 'systemctl status myapp'",
    ]

    for cmd in commands:
        try:
            result = subprocess.run(
                cmd,
                shell=True,
                capture_output=True,
                text=True,
                timeout=60,
                check=True,
            )
            print(f"âœ… {host}: {cmd}")
        except subprocess.CalledProcessError as e:
            print(f"âŒ {host}: {cmd} å¤±è´¥\n{e.stderr}")
            return False

    return True

# å¹¶å‘éƒ¨ç½²åˆ°å¤šå°æœåŠ¡å™¨
servers = ["server1.example.com", "server2.example.com", "server3.example.com"]
app_path = "./dist/"

with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    futures = {executor.submit(deploy_to_server, host, app_path): host for host in servers}

    for future in concurrent.futures.as_completed(futures):
        host = futures[future]
        try:
            success = future.result()
            if success:
                print(f"âœ… {host} éƒ¨ç½²æˆåŠŸ")
            else:
                print(f"âŒ {host} éƒ¨ç½²å¤±è´¥")
        except Exception as e:
            print(f"âŒ {host} å¼‚å¸¸: {e}")
```

#### æ¡ˆä¾‹ 2ï¼šDocker å®¹å™¨ç®¡ç†
```python
class DockerManager:
    """Docker å®¹å™¨ç®¡ç†"""

    @staticmethod
    def build_image(tag, dockerfile_path="."):
        """æ„å»ºé•œåƒ"""
        result = subprocess.run(
            ["docker", "build", "-t", tag, dockerfile_path],
            capture_output=True,
            text=True,
        )

        if result.returncode == 0:
            print(f"âœ… é•œåƒæ„å»ºæˆåŠŸ: {tag}")
        else:
            print(f"âŒ æ„å»ºå¤±è´¥:\n{result.stderr}")

        return result.returncode == 0

    @staticmethod
    def run_container(image, name, ports=None, env=None):
        """è¿è¡Œå®¹å™¨"""
        cmd = ["docker", "run", "-d", "--name", name]

        if ports:
            for host_port, container_port in ports.items():
                cmd.extend(["-p", f"{host_port}:{container_port}"])

        if env:
            for key, value in env.items():
                cmd.extend(["-e", f"{key}={value}"])

        cmd.append(image)

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            container_id = result.stdout.strip()
            print(f"âœ… å®¹å™¨å¯åŠ¨æˆåŠŸ: {name} ({container_id[:12]})")
            return container_id
        else:
            print(f"âŒ å®¹å™¨å¯åŠ¨å¤±è´¥:\n{result.stderr}")
            return None

    @staticmethod
    def stop_container(name):
        """åœæ­¢å®¹å™¨"""
        result = subprocess.run(
            ["docker", "stop", name],
            capture_output=True,
            text=True,
        )
        return result.returncode == 0

    @staticmethod
    def logs(name, tail=100):
        """æŸ¥çœ‹å®¹å™¨æ—¥å¿—"""
        result = subprocess.run(
            ["docker", "logs", "--tail", str(tail), name],
            capture_output=True,
            text=True,
        )
        return result.stdout

# ä½¿ç”¨
docker = DockerManager()

# æ„å»ºé•œåƒ
docker.build_image("myapp:latest")

# è¿è¡Œå®¹å™¨
container_id = docker.run_container(
    "myapp:latest",
    "myapp-container",
    ports={8080: 80},
    env={"DEBUG": "0", "DATABASE_URL": "postgresql://db/prod"},
)

# æŸ¥çœ‹æ—¥å¿—
logs = docker.logs("myapp-container", tail=50)
print(logs)
```

#### æ¡ˆä¾‹ 3ï¼šGit è‡ªåŠ¨åŒ–
```python
class GitAutomation:
    """Git è‡ªåŠ¨åŒ–æ“ä½œ"""

    def __init__(self, repo_path):
        self.repo_path = repo_path

    def _run_git(self, *args):
        """è¿è¡Œ git å‘½ä»¤"""
        result = subprocess.run(
            ["git", "-C", self.repo_path] + list(args),
            capture_output=True,
            text=True,
        )
        return result

    def clone(self, url):
        """å…‹éš†ä»“åº“"""
        result = subprocess.run(
            ["git", "clone", url, self.repo_path],
            capture_output=True,
            text=True,
        )
        return result.returncode == 0

    def pull(self):
        """æ‹‰å–æ›´æ–°"""
        result = self._run_git("pull")
        return result.returncode == 0

    def commit(self, message):
        """æäº¤å˜æ›´"""
        self._run_git("add", ".")
        result = self._run_git("commit", "-m", message)
        return result.returncode == 0

    def push(self, branch="main"):
        """æ¨é€åˆ°è¿œç¨‹"""
        result = self._run_git("push", "origin", branch)
        return result.returncode == 0

    def get_current_branch(self):
        """è·å–å½“å‰åˆ†æ”¯"""
        result = self._run_git("rev-parse", "--abbrev-ref", "HEAD")
        return result.stdout.strip()

    def get_status(self):
        """è·å–ä»“åº“çŠ¶æ€"""
        result = self._run_git("status", "--porcelain")
        return result.stdout

    def has_uncommitted_changes(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æœªæäº¤çš„å˜æ›´"""
        return bool(self.get_status())

# ä½¿ç”¨
git = GitAutomation("/path/to/repo")

if git.has_uncommitted_changes():
    print("æ£€æµ‹åˆ°æœªæäº¤çš„å˜æ›´")
    git.commit("è‡ªåŠ¨æäº¤ï¼šå®šæ—¶å¤‡ä»½")
    git.push()
else:
    print("æ²¡æœ‰å˜æ›´")
```

---

## 14. æ–‡ä»¶ç³»ç»Ÿæ“ä½œ

### 14.1 pathlib ç°ä»£è·¯å¾„å¤„ç†

```python
from pathlib import Path

# åˆ›å»ºè·¯å¾„å¯¹è±¡
path = Path("/Users/huaan/Projects/AI")

# è·¯å¾„æ‹¼æ¥ï¼ˆè·¨å¹³å°ï¼‰
config_path = path / "config" / "settings.json"
print(config_path)  # /Users/huaan/Projects/AI/config/settings.json

# è·¯å¾„å±æ€§
print(path.name)       # AI
print(path.stem)       # AI
print(path.suffix)     # ï¼ˆç©ºï¼‰
print(path.parent)     # /Users/huaan/Projects
print(path.parts)      # ('/', 'Users', 'huaan', 'Projects', 'AI')

# æ–‡ä»¶æ“ä½œ
file_path = Path("data.txt")
file_path.write_text("Hello World")      # å†™å…¥
content = file_path.read_text()          # è¯»å–
file_path.unlink()                        # åˆ é™¤

# ç›®å½•æ“ä½œ
dir_path = Path("new_dir")
dir_path.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
dir_path.rmdir()                              # åˆ é™¤ç©ºç›®å½•

# æ£€æŸ¥
print(path.exists())        # æ˜¯å¦å­˜åœ¨
print(path.is_file())       # æ˜¯å¦æ–‡ä»¶
print(path.is_dir())        # æ˜¯å¦ç›®å½•
print(path.is_symlink())    # æ˜¯å¦ç¬¦å·é“¾æ¥
```

### 14.2 éå†æ–‡ä»¶

```python
from pathlib import Path

# éå†å½“å‰ç›®å½•
for item in Path(".").iterdir():
    print(item)

# é€’å½’éå†ï¼ˆæŸ¥æ‰¾æ‰€æœ‰ .py æ–‡ä»¶ï¼‰
for py_file in Path(".").rglob("*.py"):
    print(py_file)

# æŸ¥æ‰¾ç‰¹å®šæ¨¡å¼
for log_file in Path("/var/log").glob("*.log"):
    print(log_file)

# è¿‡æ»¤æ–‡ä»¶
py_files = [f for f in Path("src").rglob("*.py") if f.is_file()]
print(f"æ‰¾åˆ° {len(py_files)} ä¸ª Python æ–‡ä»¶")
```

### 14.3 æ–‡ä»¶å…ƒæ•°æ®

```python
from pathlib import Path
import time

file = Path("example.txt")

# æ–‡ä»¶å¤§å°
size = file.stat().st_size
print(f"æ–‡ä»¶å¤§å°: {size} å­—èŠ‚")

# ä¿®æ”¹æ—¶é—´
mtime = file.stat().st_mtime
print(f"æœ€åä¿®æ”¹: {time.ctime(mtime)}")

# æƒé™
mode = file.stat().st_mode
print(f"æƒé™: {oct(mode)}")

# ä¿®æ”¹æƒé™
file.chmod(0o644)  # rw-r--r--
```

### 14.4 æ‰¹é‡æ–‡ä»¶æ“ä½œ

```python
from pathlib import Path
import shutil

class FileManager:
    """æ–‡ä»¶ç®¡ç†å·¥å…·"""

    @staticmethod
    def copy_files(source_dir, dest_dir, pattern="*.py"):
        """æ‰¹é‡å¤åˆ¶æ–‡ä»¶"""
        source = Path(source_dir)
        dest = Path(dest_dir)
        dest.mkdir(parents=True, exist_ok=True)

        count = 0
        for file in source.rglob(pattern):
            if file.is_file():
                # ä¿æŒç›®å½•ç»“æ„
                relative_path = file.relative_to(source)
                dest_file = dest / relative_path
                dest_file.parent.mkdir(parents=True, exist_ok=True)

                shutil.copy2(file, dest_file)
                count += 1

        print(f"âœ… å¤åˆ¶äº† {count} ä¸ªæ–‡ä»¶")
        return count

    @staticmethod
    def clean_old_files(directory, days=30, pattern="*"):
        """åˆ é™¤æ—§æ–‡ä»¶"""
        import time

        cutoff = time.time() - (days * 24 * 60 * 60)
        count = 0

        for file in Path(directory).rglob(pattern):
            if file.is_file() and file.stat().st_mtime < cutoff:
                file.unlink()
                count += 1
                print(f"åˆ é™¤: {file}")

        print(f"âœ… åˆ é™¤äº† {count} ä¸ªæ–‡ä»¶")
        return count

    @staticmethod
    def get_directory_size(directory):
        """è®¡ç®—ç›®å½•å¤§å°"""
        total_size = 0
        for file in Path(directory).rglob("*"):
            if file.is_file():
                total_size += file.stat().st_size

        # æ ¼å¼åŒ–è¾“å‡º
        for unit in ["B", "KB", "MB", "GB", "TB"]:
            if total_size < 1024:
                return f"{total_size:.2f} {unit}"
            total_size /= 1024

        return f"{total_size:.2f} PB"

# ä½¿ç”¨
fm = FileManager()

# å¤‡ä»½ Python æ–‡ä»¶
fm.copy_files("src", "backup/src", "*.py")

# æ¸…ç† 30 å¤©å‰çš„æ—¥å¿—
fm.clean_old_files("/var/log/myapp", days=30, pattern="*.log")

# æŸ¥çœ‹ç›®å½•å¤§å°
size = fm.get_directory_size("/var/log")
print(f"æ—¥å¿—ç›®å½•å¤§å°: {size}")
```

### 14.5 æ–‡ä»¶ç›‘æ§ï¼ˆwatchdogï¼‰

```python
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class FileChangeHandler(FileSystemEventHandler):
    """æ–‡ä»¶å˜æ›´å¤„ç†å™¨"""

    def on_created(self, event):
        if not event.is_directory:
            print(f"âœ¨ æ–°å»ºæ–‡ä»¶: {event.src_path}")

    def on_modified(self, event):
        if not event.is_directory:
            print(f"ğŸ“ ä¿®æ”¹æ–‡ä»¶: {event.src_path}")

    def on_deleted(self, event):
        if not event.is_directory:
            print(f"ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶: {event.src_path}")

    def on_moved(self, event):
        if not event.is_directory:
            print(f"ğŸ“¦ ç§»åŠ¨æ–‡ä»¶: {event.src_path} â†’ {event.dest_path}")

# å¯åŠ¨ç›‘æ§
observer = Observer()
handler = FileChangeHandler()
observer.schedule(handler, path="./watch_dir", recursive=True)
observer.start()

try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    observer.stop()

observer.join()
```

### 14.6 DevOps å®æˆ˜æ¡ˆä¾‹

#### æ¡ˆä¾‹ 1ï¼šæ—¥å¿—å½’æ¡£
```python
import gzip
import shutil
from pathlib import Path
from datetime import datetime, timedelta

class LogArchiver:
    """æ—¥å¿—å½’æ¡£å·¥å…·"""

    def __init__(self, log_dir, archive_dir):
        self.log_dir = Path(log_dir)
        self.archive_dir = Path(archive_dir)
        self.archive_dir.mkdir(parents=True, exist_ok=True)

    def archive_old_logs(self, days=7):
        """å½’æ¡£æ—§æ—¥å¿—"""
        cutoff = datetime.now() - timedelta(days=days)

        for log_file in self.log_dir.glob("*.log"):
            mtime = datetime.fromtimestamp(log_file.stat().st_mtime)

            if mtime < cutoff:
                self._compress_and_move(log_file)

    def _compress_and_move(self, log_file):
        """å‹ç¼©å¹¶ç§»åŠ¨æ—¥å¿—"""
        # ç”Ÿæˆå½’æ¡£æ–‡ä»¶å
        archive_name = f"{log_file.stem}_{datetime.now():%Y%m%d}.log.gz"
        archive_path = self.archive_dir / archive_name

        # å‹ç¼©
        with open(log_file, "rb") as f_in:
            with gzip.open(archive_path, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)

        # åˆ é™¤åŸæ–‡ä»¶
        log_file.unlink()
        print(f"âœ… å½’æ¡£: {log_file} â†’ {archive_path}")

    def cleanup_old_archives(self, days=90):
        """æ¸…ç†æ—§å½’æ¡£"""
        cutoff = datetime.now() - timedelta(days=days)

        for archive in self.archive_dir.glob("*.log.gz"):
            mtime = datetime.fromtimestamp(archive.stat().st_mtime)

            if mtime < cutoff:
                archive.unlink()
                print(f"ğŸ—‘ï¸  åˆ é™¤æ—§å½’æ¡£: {archive}")

# ä½¿ç”¨
archiver = LogArchiver("/var/log/myapp", "/var/log/myapp/archive")
archiver.archive_old_logs(days=7)
archiver.cleanup_old_archives(days=90)
```

#### æ¡ˆä¾‹ 2ï¼šé…ç½®æ–‡ä»¶åŒæ­¥
```python
import hashlib
from pathlib import Path

def file_hash(file_path):
    """è®¡ç®—æ–‡ä»¶ MD5"""
    hasher = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hasher.update(chunk)
    return hasher.hexdigest()

def sync_config_files(source_dir, dest_dir):
    """åŒæ­¥é…ç½®æ–‡ä»¶"""
    source = Path(source_dir)
    dest = Path(dest_dir)

    synced = 0
    skipped = 0

    for source_file in source.rglob("*"):
        if not source_file.is_file():
            continue

        # è®¡ç®—ç›®æ ‡è·¯å¾„
        relative_path = source_file.relative_to(source)
        dest_file = dest / relative_path

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥
        if dest_file.exists():
            if file_hash(source_file) == file_hash(dest_file):
                skipped += 1
                continue

        # åŒæ­¥æ–‡ä»¶
        dest_file.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(source_file, dest_file)
        synced += 1
        print(f"âœ… åŒæ­¥: {relative_path}")

    print(f"\nåŒæ­¥å®Œæˆ: {synced} ä¸ªæ–‡ä»¶åŒæ­¥, {skipped} ä¸ªæ–‡ä»¶è·³è¿‡")

# ä½¿ç”¨
sync_config_files("/etc/myapp", "/backup/config")
```

---

## ç¬¬ 15 ç« ï¼šç½‘ç»œç¼–ç¨‹åŸºç¡€

### 15.1 Socket ç¼–ç¨‹æ ¸å¿ƒæ¦‚å¿µ

#### åŸºç¡€ TCP æœåŠ¡å™¨
```python
import socket
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TCPServer:
    """åŸºç¡€ TCP æœåŠ¡å™¨"""

    def __init__(self, host='localhost', port=8888):
        self.host = host
        self.port = port
        self.server_socket = None

    def start(self):
        """å¯åŠ¨æœåŠ¡å™¨"""
        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

        # è®¾ç½® SO_REUSEADDRï¼ˆå…è®¸ç«‹å³é‡å¯ï¼‰
        self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

        # ç»‘å®šåœ°å€å¹¶ç›‘å¬
        self.server_socket.bind((self.host, self.port))
        self.server_socket.listen(5)  # backlog=5

        logger.info(f"ğŸš€ æœåŠ¡å™¨å¯åŠ¨: {self.host}:{self.port}")

        try:
            while True:
                # æ¥å—å®¢æˆ·ç«¯è¿æ¥
                client_socket, client_address = self.server_socket.accept()
                logger.info(f"ğŸ“ å®¢æˆ·ç«¯è¿æ¥: {client_address}")

                # å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚
                self.handle_client(client_socket, client_address)
        except KeyboardInterrupt:
            logger.info("â›” æœåŠ¡å™¨å…³é—­")
        finally:
            self.server_socket.close()

    def handle_client(self, client_socket, client_address):
        """å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚"""
        try:
            # æ¥æ”¶æ•°æ®ï¼ˆæœ€å¤š 1024 å­—èŠ‚ï¼‰
            data = client_socket.recv(1024)

            if not data:
                logger.warning(f"å®¢æˆ·ç«¯ {client_address} æœªå‘é€æ•°æ®")
                return

            message = data.decode('utf-8')
            logger.info(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: {message}")

            # å“åº”å®¢æˆ·ç«¯
            response = f"æœåŠ¡å™¨æ”¶åˆ°: {message}"
            client_socket.sendall(response.encode('utf-8'))

        except Exception as e:
            logger.error(f"å¤„ç†å®¢æˆ·ç«¯å¤±è´¥: {e}")
        finally:
            client_socket.close()

# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    server = TCPServer()
    server.start()
```

#### TCP å®¢æˆ·ç«¯
```python
import socket

def tcp_client(host='localhost', port=8888, message='Hello Server'):
    """TCP å®¢æˆ·ç«¯"""
    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

    try:
        # è¿æ¥æœåŠ¡å™¨
        client_socket.connect((host, port))
        print(f"âœ… è¿æ¥æœåŠ¡å™¨: {host}:{port}")

        # å‘é€æ•°æ®
        client_socket.sendall(message.encode('utf-8'))

        # æ¥æ”¶å“åº”
        response = client_socket.recv(1024).decode('utf-8')
        print(f"ğŸ“¥ æœåŠ¡å™¨å“åº”: {response}")

    except ConnectionRefusedError:
        print(f"âŒ æ— æ³•è¿æ¥åˆ° {host}:{port}")
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯é”™è¯¯: {e}")
    finally:
        client_socket.close()

# æµ‹è¯•
tcp_client(message="æµ‹è¯•æ¶ˆæ¯")
```

---

### 15.2 å¤šå®¢æˆ·ç«¯å¹¶å‘å¤„ç†

#### æ–¹æ¡ˆ 1ï¼šå¤šçº¿ç¨‹æœåŠ¡å™¨
```python
import socket
import threading
import logging

class MultiThreadTCPServer:
    """å¤šçº¿ç¨‹ TCP æœåŠ¡å™¨"""

    def __init__(self, host='localhost', port=8888):
        self.host = host
        self.port = port
        self.server_socket = None
        self.client_count = 0
        self.lock = threading.Lock()

    def start(self):
        """å¯åŠ¨æœåŠ¡å™¨"""
        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server_socket.bind((self.host, self.port))
        self.server_socket.listen(100)  # æ›´å¤§çš„ backlog

        logger.info(f"ğŸš€ å¤šçº¿ç¨‹æœåŠ¡å™¨å¯åŠ¨: {self.host}:{self.port}")

        try:
            while True:
                client_socket, client_address = self.server_socket.accept()

                # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ›å»ºçº¿ç¨‹
                client_thread = threading.Thread(
                    target=self.handle_client,
                    args=(client_socket, client_address),
                    daemon=True  # å®ˆæŠ¤çº¿ç¨‹ï¼ˆä¸»è¿›ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸï¼‰
                )
                client_thread.start()

                # çº¿ç¨‹å®‰å…¨è®¡æ•°
                with self.lock:
                    self.client_count += 1
                    logger.info(f"ğŸ“ å®¢æˆ·ç«¯ {self.client_count} è¿æ¥: {client_address}")

        except KeyboardInterrupt:
            logger.info("â›” æœåŠ¡å™¨å…³é—­")
        finally:
            self.server_socket.close()

    def handle_client(self, client_socket, client_address):
        """å¤„ç†å®¢æˆ·ç«¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ï¼‰"""
        try:
            while True:
                data = client_socket.recv(1024)

                if not data:
                    break

                message = data.decode('utf-8')
                logger.info(f"ğŸ“¨ [{client_address}] {message}")

                # Echo å“åº”
                response = f"Echo: {message}"
                client_socket.sendall(response.encode('utf-8'))

        except Exception as e:
            logger.error(f"å®¢æˆ·ç«¯ {client_address} é”™è¯¯: {e}")
        finally:
            client_socket.close()
            logger.info(f"ğŸ‘‹ å®¢æˆ·ç«¯ {client_address} æ–­å¼€è¿æ¥")
```

#### æ–¹æ¡ˆ 2ï¼šå¼‚æ­¥æœåŠ¡å™¨ (asyncio)
```python
import asyncio
import logging

class AsyncTCPServer:
    """å¼‚æ­¥ TCP æœåŠ¡å™¨ï¼ˆæ€§èƒ½æ›´ä¼˜ï¼‰"""

    def __init__(self, host='localhost', port=8888):
        self.host = host
        self.port = port

    async def start(self):
        """å¯åŠ¨å¼‚æ­¥æœåŠ¡å™¨"""
        server = await asyncio.start_server(
            self.handle_client,
            self.host,
            self.port
        )

        addr = server.sockets[0].getsockname()
        logger.info(f"ğŸš€ å¼‚æ­¥æœåŠ¡å™¨å¯åŠ¨: {addr}")

        async with server:
            await server.serve_forever()

    async def handle_client(self, reader, writer):
        """å¤„ç†å®¢æˆ·ç«¯ï¼ˆå¼‚æ­¥åç¨‹ï¼‰"""
        addr = writer.get_extra_info('peername')
        logger.info(f"ğŸ“ å®¢æˆ·ç«¯è¿æ¥: {addr}")

        try:
            while True:
                # å¼‚æ­¥è¯»å–æ•°æ®
                data = await reader.read(1024)

                if not data:
                    break

                message = data.decode('utf-8')
                logger.info(f"ğŸ“¨ [{addr}] {message}")

                # å¼‚æ­¥å†™å…¥å“åº”
                response = f"Echo: {message}"
                writer.write(response.encode('utf-8'))
                await writer.drain()  # ç¡®ä¿å‘é€å®Œæˆ

        except Exception as e:
            logger.error(f"å®¢æˆ·ç«¯ {addr} é”™è¯¯: {e}")
        finally:
            writer.close()
            await writer.wait_closed()
            logger.info(f"ğŸ‘‹ å®¢æˆ·ç«¯ {addr} æ–­å¼€è¿æ¥")

# å¯åŠ¨å¼‚æ­¥æœåŠ¡å™¨
if __name__ == "__main__":
    server = AsyncTCPServer()
    asyncio.run(server.start())
```

---

### 15.3 HTTP å®¢æˆ·ç«¯ç¼–ç¨‹

#### ä½¿ç”¨ requests åº“
```python
import requests
from typing import Optional, Dict
import logging

class HTTPClient:
    """HTTP å®¢æˆ·ç«¯å°è£…"""

    def __init__(self, base_url: str, timeout: int = 10):
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.session = requests.Session()

        # è®¾ç½®é»˜è®¤ headers
        self.session.headers.update({
            'User-Agent': 'MyApp/1.0',
            'Accept': 'application/json'
        })

    def get(self, endpoint: str, params: Optional[Dict] = None) -> Dict:
        """GET è¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"

        try:
            response = self.session.get(
                url,
                params=params,
                timeout=self.timeout
            )
            response.raise_for_status()  # æ£€æŸ¥ HTTP é”™è¯¯

            logger.info(f"âœ… GET {url} - {response.status_code}")
            return response.json()

        except requests.Timeout:
            logger.error(f"â±ï¸  è¯·æ±‚è¶…æ—¶: {url}")
            raise
        except requests.HTTPError as e:
            logger.error(f"âŒ HTTP é”™è¯¯: {e.response.status_code}")
            raise
        except Exception as e:
            logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            raise

    def post(self, endpoint: str, data: Dict) -> Dict:
        """POST è¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"

        try:
            response = self.session.post(
                url,
                json=data,  # è‡ªåŠ¨åºåˆ—åŒ–ä¸º JSON
                timeout=self.timeout
            )
            response.raise_for_status()

            logger.info(f"âœ… POST {url} - {response.status_code}")
            return response.json()

        except Exception as e:
            logger.error(f"âŒ POST å¤±è´¥: {e}")
            raise

    def download_file(self, url: str, save_path: str):
        """ä¸‹è½½æ–‡ä»¶ï¼ˆæµå¼ä¼ è¾“ï¼‰"""
        try:
            with self.session.get(url, stream=True, timeout=self.timeout) as response:
                response.raise_for_status()

                # è·å–æ–‡ä»¶å¤§å°
                total_size = int(response.headers.get('content-length', 0))

                with open(save_path, 'wb') as f:
                    downloaded = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                        downloaded += len(chunk)

                        # æ˜¾ç¤ºè¿›åº¦
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            print(f"\rä¸‹è½½è¿›åº¦: {progress:.1f}%", end='')

                print(f"\nâœ… æ–‡ä»¶å·²ä¸‹è½½: {save_path}")

        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            raise

# ä½¿ç”¨ç¤ºä¾‹
client = HTTPClient("https://api.github.com")

# GET è¯·æ±‚
user = client.get("/users/torvalds")
print(f"ç”¨æˆ·: {user['name']}")

# POST è¯·æ±‚ï¼ˆç¤ºä¾‹ï¼‰
# data = client.post("/api/v1/users", data={"name": "å¼ ä¸‰", "email": "test@example.com"})

# ä¸‹è½½æ–‡ä»¶
client.download_file(
    "https://example.com/file.pdf",
    "/tmp/downloaded.pdf"
)
```

---

### 15.4 ç®€æ˜“ HTTP æœåŠ¡å™¨

#### ä½¿ç”¨ http.server æ¨¡å—
```python
from http.server import HTTPServer, BaseHTTPRequestHandler
import json
import logging

class SimpleHTTPHandler(BaseHTTPRequestHandler):
    """ç®€æ˜“ HTTP è¯·æ±‚å¤„ç†å™¨"""

    def do_GET(self):
        """å¤„ç† GET è¯·æ±‚"""
        logger.info(f"GET {self.path}")

        if self.path == '/':
            self.send_response(200)
            self.send_header('Content-Type', 'text/html; charset=utf-8')
            self.end_headers()

            html = """
            <html>
            <head><title>æµ‹è¯•æœåŠ¡å™¨</title></head>
            <body>
                <h1>æ¬¢è¿è®¿é—®æµ‹è¯•æœåŠ¡å™¨</h1>
                <p>å°è¯•è®¿é—®: <a href="/api/status">/api/status</a></p>
            </body>
            </html>
            """
            self.wfile.write(html.encode('utf-8'))

        elif self.path == '/api/status':
            self.send_json_response({
                'status': 'ok',
                'message': 'æœåŠ¡å™¨è¿è¡Œæ­£å¸¸'
            })
        else:
            self.send_error(404, "é¡µé¢ä¸å­˜åœ¨")

    def do_POST(self):
        """å¤„ç† POST è¯·æ±‚"""
        # è¯»å– POST æ•°æ®
        content_length = int(self.headers['Content-Length'])
        post_data = self.rfile.read(content_length)

        try:
            data = json.loads(post_data.decode('utf-8'))
            logger.info(f"POST {self.path} - {data}")

            # å“åº”
            self.send_json_response({
                'status': 'success',
                'received': data
            })
        except Exception as e:
            self.send_error(400, f"Invalid JSON: {e}")

    def send_json_response(self, data):
        """å‘é€ JSON å“åº”"""
        self.send_response(200)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()

        response = json.dumps(data, ensure_ascii=False)
        self.wfile.write(response.encode('utf-8'))

    def log_message(self, format, *args):
        """è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼"""
        logger.info(f"{self.address_string()} - {format % args}")

# å¯åŠ¨æœåŠ¡å™¨
def start_server(port=8000):
    server_address = ('', port)
    httpd = HTTPServer(server_address, SimpleHTTPHandler)
    logger.info(f"ğŸš€ HTTP æœåŠ¡å™¨å¯åŠ¨: http://localhost:{port}")
    httpd.serve_forever()

if __name__ == "__main__":
    start_server()
```

---

### 15.5 WebSocket å®æ—¶é€šä¿¡

#### ä½¿ç”¨ websockets åº“
```python
import asyncio
import websockets
import json
import logging

class WebSocketServer:
    """WebSocket æœåŠ¡å™¨"""

    def __init__(self, host='localhost', port=8765):
        self.host = host
        self.port = port
        self.clients = set()  # è¿æ¥çš„å®¢æˆ·ç«¯é›†åˆ

    async def start(self):
        """å¯åŠ¨ WebSocket æœåŠ¡å™¨"""
        async with websockets.serve(self.handler, self.host, self.port):
            logger.info(f"ğŸš€ WebSocket æœåŠ¡å™¨å¯åŠ¨: ws://{self.host}:{self.port}")
            await asyncio.Future()  # æ°¸ä¹…è¿è¡Œ

    async def handler(self, websocket, path):
        """å¤„ç† WebSocket è¿æ¥"""
        # æ³¨å†Œå®¢æˆ·ç«¯
        self.clients.add(websocket)
        client_id = id(websocket)
        logger.info(f"ğŸ“ å®¢æˆ·ç«¯è¿æ¥: {client_id}")

        try:
            # å‘é€æ¬¢è¿æ¶ˆæ¯
            await websocket.send(json.dumps({
                'type': 'welcome',
                'message': 'æ¬¢è¿è¿æ¥ WebSocket æœåŠ¡å™¨'
            }))

            # æŒç»­æ¥æ”¶æ¶ˆæ¯
            async for message in websocket:
                logger.info(f"ğŸ“¨ [{client_id}] {message}")

                # è§£ææ¶ˆæ¯
                try:
                    data = json.loads(message)
                    await self.handle_message(websocket, data)
                except json.JSONDecodeError:
                    await websocket.send(json.dumps({
                        'type': 'error',
                        'message': 'Invalid JSON'
                    }))

        except websockets.ConnectionClosed:
            logger.info(f"ğŸ‘‹ å®¢æˆ·ç«¯æ–­å¼€: {client_id}")
        finally:
            self.clients.remove(websocket)

    async def handle_message(self, websocket, data):
        """å¤„ç†æ¶ˆæ¯"""
        msg_type = data.get('type')

        if msg_type == 'broadcast':
            # å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰å®¢æˆ·ç«¯
            await self.broadcast(data.get('message'))
        elif msg_type == 'echo':
            # å›æ˜¾æ¶ˆæ¯
            await websocket.send(json.dumps({
                'type': 'echo',
                'message': data.get('message')
            }))

    async def broadcast(self, message):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰å®¢æˆ·ç«¯"""
        if self.clients:
            await asyncio.gather(
                *[client.send(json.dumps({
                    'type': 'broadcast',
                    'message': message
                })) for client in self.clients]
            )

# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    server = WebSocketServer()
    asyncio.run(server.start())
```

#### WebSocket å®¢æˆ·ç«¯
```python
import asyncio
import websockets
import json

async def websocket_client():
    """WebSocket å®¢æˆ·ç«¯"""
    uri = "ws://localhost:8765"

    async with websockets.connect(uri) as websocket:
        print(f"âœ… è¿æ¥åˆ° {uri}")

        # æ¥æ”¶æ¬¢è¿æ¶ˆæ¯
        welcome = await websocket.recv()
        print(f"ğŸ“¥ {welcome}")

        # å‘é€æ¶ˆæ¯
        await websocket.send(json.dumps({
            'type': 'echo',
            'message': 'Hello WebSocket!'
        }))

        # æ¥æ”¶å“åº”
        response = await websocket.recv()
        print(f"ğŸ“¥ {response}")

        # å¹¿æ’­æ¶ˆæ¯
        await websocket.send(json.dumps({
            'type': 'broadcast',
            'message': 'è¿™æ˜¯ä¸€æ¡å¹¿æ’­æ¶ˆæ¯'
        }))

        # æŒç»­æ¥æ”¶æ¶ˆæ¯
        while True:
            message = await websocket.recv()
            print(f"ğŸ“¥ {message}")

# è¿è¡Œå®¢æˆ·ç«¯
asyncio.run(websocket_client())
```

---

### 15.6 ç”Ÿäº§çº§ç½‘ç»œç¼–ç¨‹å®è·µ

#### 1. è¿æ¥æ± ç®¡ç†
```python
import urllib3
from urllib3.util.retry import Retry

# åˆ›å»ºè¿æ¥æ± 
http = urllib3.PoolManager(
    maxsize=10,  # æœ€å¤§è¿æ¥æ•°
    block=True,  # è¿æ¥æ± æ»¡æ—¶é˜»å¡
    retries=Retry(
        total=3,
        backoff_factor=0.3,  # é‡è¯•å»¶è¿Ÿ
        status_forcelist=[500, 502, 503, 504]
    )
)

# ä½¿ç”¨è¿æ¥æ± 
response = http.request('GET', 'https://api.example.com/data')
print(response.status)
```

#### 2. è¶…æ—¶ä¸é‡è¯•
```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def create_session_with_retry():
    """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ Session"""
    session = requests.Session()

    retry_strategy = Retry(
        total=3,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"],
        backoff_factor=1  # 1s, 2s, 4s
    )

    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    return session

# ä½¿ç”¨
session = create_session_with_retry()
response = session.get(
    "https://api.example.com/data",
    timeout=(3, 10)  # (è¿æ¥è¶…æ—¶, è¯»å–è¶…æ—¶)
)
```

#### 3. å®‰å…¨æ€§å®è·µ
```python
import requests
import certifi

# âœ… ä½¿ç”¨ SSL è¯ä¹¦éªŒè¯
response = requests.get(
    "https://api.example.com",
    verify=certifi.where()  # ä½¿ç”¨ certifi è¯ä¹¦åº“
)

# âœ… ç¦ç”¨ä¸å®‰å…¨çš„è­¦å‘Šï¼ˆä»…å¼€å‘ç¯å¢ƒï¼‰
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# âš ï¸  ä»…å¼€å‘ç¯å¢ƒä½¿ç”¨
# response = requests.get("https://example.com", verify=False)
```

---

## ç¬¬ 16 ç« :å¤šçº¿ç¨‹ä¸å¤šè¿›ç¨‹

### 16.1 å…¨å±€è§£é‡Šå™¨é” (GIL) ç†è§£

#### GIL çš„å½±å“
```python
import threading
import time

# âŒ CPU å¯†é›†ä»»åŠ¡ï¼šGIL é™åˆ¶ï¼Œå¤šçº¿ç¨‹æ— æ€§èƒ½æå‡
def cpu_bound_task():
    """CPU å¯†é›†ä»»åŠ¡"""
    result = 0
    for i in range(10_000_000):
        result += i
    return result

# å•çº¿ç¨‹
start = time.time()
cpu_bound_task()
cpu_bound_task()
single_time = time.time() - start
print(f"å•çº¿ç¨‹è€—æ—¶: {single_time:.2f}s")

# å¤šçº¿ç¨‹ï¼ˆGIL é™åˆ¶ï¼Œå‡ ä¹æ— æå‡ï¼‰
start = time.time()
t1 = threading.Thread(target=cpu_bound_task)
t2 = threading.Thread(target=cpu_bound_task)
t1.start()
t2.start()
t1.join()
t2.join()
multi_time = time.time() - start
print(f"å¤šçº¿ç¨‹è€—æ—¶: {multi_time:.2f}s")  # å‡ ä¹ä¸æ¯”å•çº¿ç¨‹å¿«

# âœ… I/O å¯†é›†ä»»åŠ¡ï¼šå¤šçº¿ç¨‹æœ‰æ•ˆ
import requests

def io_bound_task(url):
    """I/O å¯†é›†ä»»åŠ¡"""
    requests.get(url, timeout=5)

urls = ["https://example.com"] * 10

# å•çº¿ç¨‹
start = time.time()
for url in urls:
    io_bound_task(url)
single_io_time = time.time() - start

# å¤šçº¿ç¨‹ï¼ˆæœ‰æ˜æ˜¾æå‡ï¼‰
start = time.time()
threads = [threading.Thread(target=io_bound_task, args=(url,)) for url in urls]
for t in threads:
    t.start()
for t in threads:
    t.join()
multi_io_time = time.time() - start

print(f"\nI/O ä»»åŠ¡ - å•çº¿ç¨‹: {single_io_time:.2f}s, å¤šçº¿ç¨‹: {multi_io_time:.2f}s")
```

**ç»“è®º**ï¼š
- **CPU å¯†é›†ä»»åŠ¡**ï¼šä½¿ç”¨ `multiprocessing`ï¼ˆå¤šè¿›ç¨‹ï¼‰
- **I/O å¯†é›†ä»»åŠ¡**ï¼šä½¿ç”¨ `threading` æˆ– `asyncio`

---

### 16.2 å¤šçº¿ç¨‹ç¼–ç¨‹

#### åŸºç¡€çº¿ç¨‹æ“ä½œ
```python
import threading
import time

def worker(name, delay):
    """å·¥ä½œçº¿ç¨‹"""
    print(f"ğŸ”§ çº¿ç¨‹ {name} å¯åŠ¨")
    time.sleep(delay)
    print(f"âœ… çº¿ç¨‹ {name} å®Œæˆ")

# åˆ›å»ºçº¿ç¨‹
threads = []
for i in range(3):
    t = threading.Thread(
        target=worker,
        args=(f"Worker-{i}", i + 1),
        daemon=True  # å®ˆæŠ¤çº¿ç¨‹
    )
    threads.append(t)
    t.start()

# ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
for t in threads:
    t.join()

print("ğŸ‰ æ‰€æœ‰çº¿ç¨‹å·²å®Œæˆ")
```

#### çº¿ç¨‹åŒæ­¥ - Lock
```python
import threading

# âŒ çº¿ç¨‹ä¸å®‰å…¨ï¼ˆå­˜åœ¨ç«æ€æ¡ä»¶ï¼‰
counter = 0

def increment_unsafe():
    global counter
    for _ in range(100000):
        counter += 1  # éåŸå­æ“ä½œï¼

threads = [threading.Thread(target=increment_unsafe) for _ in range(5)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"âŒ çº¿ç¨‹ä¸å®‰å…¨ç»“æœ: {counter}")  # å¯èƒ½å°äº 500000

# âœ… çº¿ç¨‹å®‰å…¨ï¼ˆä½¿ç”¨ Lockï¼‰
counter_safe = 0
lock = threading.Lock()

def increment_safe():
    global counter_safe
    for _ in range(100000):
        with lock:  # è‡ªåŠ¨åŠ é”/è§£é”
            counter_safe += 1

threads = [threading.Thread(target=increment_safe) for _ in range(5)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"âœ… çº¿ç¨‹å®‰å…¨ç»“æœ: {counter_safe}")  # æ€»æ˜¯ 500000
```

#### çº¿ç¨‹æ±  - ThreadPoolExecutor
```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

def task(n):
    """æ¨¡æ‹Ÿä»»åŠ¡"""
    time.sleep(1)
    return n * n

# ä½¿ç”¨çº¿ç¨‹æ± 
with ThreadPoolExecutor(max_workers=5) as executor:
    # æ–¹å¼ 1: map()
    results = executor.map(task, range(10))
    print("Map ç»“æœ:", list(results))

    # æ–¹å¼ 2: submit()
    futures = [executor.submit(task, i) for i in range(10)]

    # è·å–å®Œæˆçš„ç»“æœ
    for future in as_completed(futures):
        result = future.result()
        print(f"å®Œæˆä»»åŠ¡: {result}")
```

---

### 16.3 å¤šè¿›ç¨‹ç¼–ç¨‹

#### åŸºç¡€è¿›ç¨‹æ“ä½œ
```python
from multiprocessing import Process
import os
import time

def worker(name):
    """å·¥ä½œè¿›ç¨‹"""
    print(f"ğŸ”§ è¿›ç¨‹ {name} å¯åŠ¨ (PID: {os.getpid()})")
    time.sleep(2)
    print(f"âœ… è¿›ç¨‹ {name} å®Œæˆ")

if __name__ == "__main__":
    processes = []

    for i in range(3):
        p = Process(target=worker, args=(f"Worker-{i}",))
        processes.append(p)
        p.start()

    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹
    for p in processes:
        p.join()

    print("ğŸ‰ æ‰€æœ‰è¿›ç¨‹å·²å®Œæˆ")
```

#### è¿›ç¨‹æ±  - ProcessPoolExecutor
```python
from concurrent.futures import ProcessPoolExecutor
import time

def cpu_intensive_task(n):
    """CPU å¯†é›†ä»»åŠ¡"""
    result = 0
    for i in range(n):
        result += i * i
    return result

if __name__ == "__main__":
    # âœ… å¤šè¿›ç¨‹å¤„ç† CPU å¯†é›†ä»»åŠ¡
    with ProcessPoolExecutor(max_workers=4) as executor:
        tasks = [10_000_000] * 8

        start = time.time()
        results = list(executor.map(cpu_intensive_task, tasks))
        elapsed = time.time() - start

        print(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s")
        print(f"CPU æ ¸å¿ƒæ•°: {os.cpu_count()}")
```

---

### 16.4 è¿›ç¨‹é—´é€šä¿¡ (IPC)

#### 1. Queueï¼ˆé˜Ÿåˆ—ï¼‰
```python
from multiprocessing import Process, Queue

def producer(queue, items):
    """ç”Ÿäº§è€…"""
    for item in items:
        queue.put(item)
        print(f"ğŸ“¤ ç”Ÿäº§: {item}")
    queue.put(None)  # ç»“æŸä¿¡å·

def consumer(queue):
    """æ¶ˆè´¹è€…"""
    while True:
        item = queue.get()
        if item is None:
            break
        print(f"ğŸ“¥ æ¶ˆè´¹: {item}")

if __name__ == "__main__":
    q = Queue()

    p1 = Process(target=producer, args=(q, range(5)))
    p2 = Process(target=consumer, args=(q,))

    p1.start()
    p2.start()

    p1.join()
    p2.join()
```

#### 2. Pipeï¼ˆç®¡é“ï¼‰
```python
from multiprocessing import Process, Pipe

def sender(conn, messages):
    """å‘é€è¿›ç¨‹"""
    for msg in messages:
        conn.send(msg)
        print(f"ğŸ“¤ å‘é€: {msg}")
    conn.close()

def receiver(conn):
    """æ¥æ”¶è¿›ç¨‹"""
    while True:
        try:
            msg = conn.recv()
            print(f"ğŸ“¥ æ¥æ”¶: {msg}")
        except EOFError:
            break

if __name__ == "__main__":
    parent_conn, child_conn = Pipe()

    p1 = Process(target=sender, args=(parent_conn, ["Hello", "World", "!"]))
    p2 = Process(target=receiver, args=(child_conn,))

    p1.start()
    p2.start()

    p1.join()
    p2.join()
```

#### 3. Managerï¼ˆå…±äº«çŠ¶æ€ï¼‰
```python
from multiprocessing import Process, Manager

def worker(shared_dict, shared_list, worker_id):
    """å·¥ä½œè¿›ç¨‹"""
    shared_dict[worker_id] = f"Worker {worker_id}"
    shared_list.append(worker_id)

if __name__ == "__main__":
    with Manager() as manager:
        shared_dict = manager.dict()
        shared_list = manager.list()

        processes = []
        for i in range(5):
            p = Process(target=worker, args=(shared_dict, shared_list, i))
            processes.append(p)
            p.start()

        for p in processes:
            p.join()

        print("å…±äº«å­—å…¸:", dict(shared_dict))
        print("å…±äº«åˆ—è¡¨:", list(shared_list))
```

---

### 16.5 å¼‚æ­¥ç¼–ç¨‹ (asyncio)

#### åŸºç¡€åç¨‹
```python
import asyncio

async def fetch_data(n):
    """å¼‚æ­¥è·å–æ•°æ®"""
    print(f"ğŸ”„ å¼€å§‹è·å–æ•°æ® {n}")
    await asyncio.sleep(1)  # æ¨¡æ‹Ÿ I/O æ“ä½œ
    print(f"âœ… æ•°æ® {n} è·å–å®Œæˆ")
    return n * 2

async def main():
    """ä¸»åç¨‹"""
    # å¹¶å‘æ‰§è¡Œå¤šä¸ªä»»åŠ¡
    tasks = [fetch_data(i) for i in range(5)]
    results = await asyncio.gather(*tasks)
    print(f"æ‰€æœ‰ç»“æœ: {results}")

# è¿è¡Œ
asyncio.run(main())
```

#### å¼‚æ­¥ HTTP è¯·æ±‚
```python
import asyncio
import aiohttp

async def fetch_url(session, url):
    """å¼‚æ­¥è·å– URL"""
    async with session.get(url) as response:
        return await response.text()

async def fetch_multiple_urls(urls):
    """å¹¶å‘è·å–å¤šä¸ª URL"""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        return results

# ä½¿ç”¨
urls = [
    "https://example.com",
    "https://httpbin.org/get",
    "https://api.github.com"
]

results = asyncio.run(fetch_multiple_urls(urls))
print(f"è·å–äº† {len(results)} ä¸ªå“åº”")
```

---

### 16.6 çº¿ç¨‹/è¿›ç¨‹é€‰æ‹©æŒ‡å—

#### å†³ç­–æµç¨‹å›¾
```python
"""
                    å¼€å§‹
                     |
            ä»»åŠ¡ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ
           /       |       \
        CPU å¯†é›†  I/O å¯†é›†  æ··åˆ
          |         |        |
     å¤šè¿›ç¨‹(MP)  å¼‚æ­¥(asyncio)  |
                     |         |
              éœ€è¦å¹¶å‘æ•°ï¼Ÿ    åˆ†æç“¶é¢ˆ
                /    \         |
              ä½(<100) é«˜(>100) é’ˆå¯¹æ€§ä¼˜åŒ–
               |        |
          å¤šçº¿ç¨‹    asyncio
          (Thread)
"""

# ç¤ºä¾‹ï¼šæ‰¹é‡å¤„ç†ä»»åŠ¡
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import time
import requests

def choose_executor(task_type, task_count):
    """æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ‰§è¡Œå™¨"""

    if task_type == "cpu":
        # CPU å¯†é›†ï¼šä½¿ç”¨è¿›ç¨‹æ± 
        return ProcessPoolExecutor(max_workers=os.cpu_count())

    elif task_type == "io" and task_count < 100:
        # I/O å¯†é›† + ä¸­ç­‰å¹¶å‘ï¼šä½¿ç”¨çº¿ç¨‹æ± 
        return ThreadPoolExecutor(max_workers=20)

    else:
        # I/O å¯†é›† + é«˜å¹¶å‘ï¼šå»ºè®®ä½¿ç”¨ asyncio
        print("âš ï¸  å»ºè®®ä½¿ç”¨ asyncio æ›¿ä»£")
        return ThreadPoolExecutor(max_workers=50)

# ä½¿ç”¨
def cpu_task(n):
    return sum(i * i for i in range(n))

def io_task(url):
    return requests.get(url, timeout=5).status_code

# CPU å¯†é›†ä»»åŠ¡
with choose_executor("cpu", 8) as executor:
    results = list(executor.map(cpu_task, [10_000_000] * 8))

# I/O å¯†é›†ä»»åŠ¡
with choose_executor("io", 50) as executor:
    urls = ["https://httpbin.org/delay/1"] * 50
    results = list(executor.map(io_task, urls))
```

---

## ç¬¬ 17 ç« ï¼šæ€§èƒ½åˆ†æä¸ä¼˜åŒ–

### 17.1 æ€§èƒ½åˆ†æå·¥å…·

#### 1. cProfile - å‡½æ•°çº§æ€§èƒ½åˆ†æ
```python
import cProfile
import pstats
from io import StringIO

def slow_function():
    """æ…¢å‡½æ•°ç¤ºä¾‹"""
    result = 0
    for i in range(1000000):
        result += i
    return result

def medium_function():
    """ä¸­é€Ÿå‡½æ•°"""
    return [i ** 2 for i in range(10000)]

def main():
    slow_function()
    medium_function()

# æ–¹å¼ 1ï¼šç›´æ¥åˆ†æ
cProfile.run('main()')

# æ–¹å¼ 2ï¼šä¿å­˜åˆ°æ–‡ä»¶
cProfile.run('main()', 'profile_stats.prof')

# æ–¹å¼ 3ï¼šç¨‹åºåŒ–åˆ†æ
profiler = cProfile.Profile()
profiler.enable()

main()

profiler.disable()

# è¾“å‡ºç»Ÿè®¡
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')  # æŒ‰ç´¯è®¡æ—¶é—´æ’åº
stats.print_stats(10)  # æ˜¾ç¤ºå‰ 10 ä¸ªå‡½æ•°
```

**è¾“å‡ºè§£è¯»**ï¼š
```
ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.052    0.052    0.052    0.052 script.py:5(slow_function)
     1    0.003    0.003    0.003    0.003 script.py:11(medium_function)
```
- `ncalls`: è°ƒç”¨æ¬¡æ•°
- `tottime`: å‡½æ•°å†…éƒ¨è€—æ—¶ï¼ˆä¸å«å­å‡½æ•°ï¼‰
- `cumtime`: ç´¯è®¡è€—æ—¶ï¼ˆå«å­å‡½æ•°ï¼‰

---

#### 2. line_profiler - è¡Œçº§æ€§èƒ½åˆ†æ
```python
# å®‰è£…: pip install line_profiler

@profile  # æ·»åŠ è£…é¥°å™¨
def analyze_me():
    """éœ€è¦åˆ†æçš„å‡½æ•°"""
    result = []
    for i in range(10000):
        result.append(i ** 2)  # è¿™è¡Œæ…¢

    result2 = [i ** 2 for i in range(10000)]  # è¿™è¡Œå¿«

    return result, result2

# è¿è¡Œ: kernprof -l -v script.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
Line #  Hits    Time    Per Hit   % Time  Line Contents
=======================================================
     3                                    def analyze_me():
     4     1       2.0      2.0      0.0      result = []
     5 10001    5234.0      0.5     52.3      for i in range(10000):
     6 10000    4756.0      0.5     47.6          result.append(i ** 2)
     7     1      10.0     10.0      0.1      result2 = [i ** 2 for i in range(10000)]
```

---

#### 3. memory_profiler - å†…å­˜åˆ†æ
```python
# å®‰è£…: pip install memory_profiler

from memory_profiler import profile

@profile
def memory_hog():
    """å†…å­˜å ç”¨åˆ†æ"""
    # âŒ å†…å­˜æµªè´¹
    big_list = [i for i in range(1000000)]

    # âœ… å†…å­˜ä¼˜åŒ–ï¼ˆç”Ÿæˆå™¨ï¼‰
    big_gen = (i for i in range(1000000))

    return sum(big_gen)

# è¿è¡Œ: python -m memory_profiler script.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
Line #  Mem usage  Increment  Line Contents
==============================================
     3   38.6 MiB   38.6 MiB  def memory_hog():
     4   76.3 MiB   37.7 MiB      big_list = [i for i in range(1000000)]
     5   76.3 MiB    0.0 MiB      big_gen = (i for i in range(1000000))
     6   76.3 MiB    0.0 MiB      return sum(big_gen)
```

---

### 17.2 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 1. åˆ—è¡¨æ¨å¯¼å¼ vs å¾ªç¯
```python
import timeit

# âŒ æ…¢ï¼šå¾ªç¯ + append
def loop_append():
    result = []
    for i in range(10000):
        result.append(i ** 2)
    return result

# âœ… å¿«ï¼šåˆ—è¡¨æ¨å¯¼å¼
def list_comp():
    return [i ** 2 for i in range(10000)]

print("å¾ªç¯:", timeit.timeit(loop_append, number=1000))  # ~0.5s
print("æ¨å¯¼:", timeit.timeit(list_comp, number=1000))    # ~0.3s (å¿« 40%)
```

---

#### 2. ç”Ÿæˆå™¨èŠ‚çœå†…å­˜
```python
import sys

# âŒ å†…å­˜å ç”¨å¤§
big_list = [i for i in range(1000000)]
print(f"åˆ—è¡¨å†…å­˜: {sys.getsizeof(big_list) / 1024 / 1024:.2f} MB")  # ~8 MB

# âœ… å†…å­˜å ç”¨å°
big_gen = (i for i in range(1000000))
print(f"ç”Ÿæˆå™¨å†…å­˜: {sys.getsizeof(big_gen) / 1024:.2f} KB")  # ~0.1 KB
```

---

#### 3. å­—å…¸æŸ¥æ‰¾ vs åˆ—è¡¨æŸ¥æ‰¾
```python
import timeit

# åˆ›å»ºæµ‹è¯•æ•°æ®
items = list(range(10000))
items_set = set(items)
items_dict = {i: True for i in items}

# âŒ æ…¢ï¼šåˆ—è¡¨æŸ¥æ‰¾ O(n)
def list_lookup():
    return 9999 in items

# âœ… å¿«ï¼šé›†åˆæŸ¥æ‰¾ O(1)
def set_lookup():
    return 9999 in items_set

# âœ… å¿«ï¼šå­—å…¸æŸ¥æ‰¾ O(1)
def dict_lookup():
    return 9999 in items_dict

print("åˆ—è¡¨:", timeit.timeit(list_lookup, number=10000))   # ~0.5s
print("é›†åˆ:", timeit.timeit(set_lookup, number=10000))    # ~0.001s (å¿« 500 å€)
print("å­—å…¸:", timeit.timeit(dict_lookup, number=10000))   # ~0.001s
```

---

#### 4. å­—ç¬¦ä¸²æ‹¼æ¥ä¼˜åŒ–
```python
import timeit

# âŒ æ…¢ï¼š+ æ‹¼æ¥ï¼ˆæ¯æ¬¡åˆ›å»ºæ–°å­—ç¬¦ä¸²ï¼‰
def string_concat():
    result = ""
    for i in range(1000):
        result += str(i)  # O(nÂ²)
    return result

# âœ… å¿«ï¼šjoin()
def string_join():
    return "".join(str(i) for i in range(1000))  # O(n)

# âœ… å¿«ï¼šåˆ—è¡¨ + join
def list_join():
    parts = []
    for i in range(1000):
        parts.append(str(i))
    return "".join(parts)

print("æ‹¼æ¥:", timeit.timeit(string_concat, number=1000))  # ~0.3s
print("join:", timeit.timeit(string_join, number=1000))    # ~0.1s (å¿« 3 å€)
print("åˆ—è¡¨:", timeit.timeit(list_join, number=1000))      # ~0.1s
```

---

#### 5. ç¼“å­˜è®¡ç®—ç»“æœ
```python
from functools import lru_cache
import time

# âŒ æ— ç¼“å­˜ï¼šé‡å¤è®¡ç®—
def fibonacci(n):
    if n < 2:
        return n
    return fibonacci(n - 1) + fibonacci(n - 2)

# âœ… ä½¿ç”¨ç¼“å­˜
@lru_cache(maxsize=128)
def fibonacci_cached(n):
    if n < 2:
        return n
    return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)

# æ€§èƒ½å¯¹æ¯”
start = time.time()
fibonacci(30)
print(f"æ— ç¼“å­˜: {time.time() - start:.3f}s")  # ~0.3s

start = time.time()
fibonacci_cached(30)
print(f"æœ‰ç¼“å­˜: {time.time() - start:.6f}s")  # ~0.000030s (å¿« 10000 å€)
```

---

### 17.3 NumPy å‘é‡åŒ–ä¼˜åŒ–

#### çº¯ Python vs NumPy
```python
import numpy as np
import timeit

# âŒ æ…¢ï¼šçº¯ Python å¾ªç¯
def python_sum():
    data = list(range(1000000))
    return sum(x ** 2 for x in data)

# âœ… å¿«ï¼šNumPy å‘é‡åŒ–
def numpy_sum():
    data = np.arange(1000000)
    return np.sum(data ** 2)

print("Python:", timeit.timeit(python_sum, number=10))  # ~1.2s
print("NumPy:", timeit.timeit(numpy_sum, number=10))    # ~0.01s (å¿« 120 å€)
```

---

### 17.4 æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

#### æ‰¹é‡æ“ä½œ vs å•æ¡æ“ä½œ
```python
import sqlite3
import time

# âŒ æ…¢ï¼šå•æ¡æ’å…¥
def slow_insert(conn):
    cursor = conn.cursor()
    for i in range(1000):
        cursor.execute("INSERT INTO users (name) VALUES (?)", (f"User{i}",))
    conn.commit()

# âœ… å¿«ï¼šæ‰¹é‡æ’å…¥
def fast_insert(conn):
    cursor = conn.cursor()
    data = [(f"User{i}",) for i in range(1000)]
    cursor.executemany("INSERT INTO users (name) VALUES (?)", data)
    conn.commit()

# æ€§èƒ½å¯¹æ¯”
conn = sqlite3.connect(":memory:")
conn.execute("CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT)")

start = time.time()
slow_insert(conn)
print(f"å•æ¡æ’å…¥: {time.time() - start:.2f}s")  # ~0.5s

conn.execute("DELETE FROM users")

start = time.time()
fast_insert(conn)
print(f"æ‰¹é‡æ’å…¥: {time.time() - start:.2f}s")  # ~0.01s (å¿« 50 å€)
```

---

### 17.5 C æ‰©å±•åŠ é€Ÿ

#### ä½¿ç”¨ Cython
```python
# setup.py
from setuptools import setup
from Cython.Build import cythonize

setup(
    ext_modules=cythonize("fast_module.pyx")
)

# fast_module.pyx
def fast_sum(int n):
    """Cython ä¼˜åŒ–å‡½æ•°"""
    cdef int i
    cdef long long result = 0

    for i in range(n):
        result += i * i

    return result

# ç¼–è¯‘: python setup.py build_ext --inplace

# ä½¿ç”¨
from fast_module import fast_sum
print(fast_sum(1000000))  # æ¯”çº¯ Python å¿« 10-100 å€
```

---

## ç¬¬ 18 ç« ï¼šè°ƒè¯•æŠ€å·§

### 18.1 pdb è°ƒè¯•å™¨

#### åŸºç¡€ä½¿ç”¨
```python
import pdb

def buggy_function(x, y):
    """æœ‰ bug çš„å‡½æ•°"""
    pdb.set_trace()  # è®¾ç½®æ–­ç‚¹

    result = x + y
    result = result * 2
    result = result / x  # å¯èƒ½é™¤ä»¥ 0

    return result

# è¿è¡Œæ—¶ä¼šè¿›å…¥è°ƒè¯•æ¨¡å¼
buggy_function(5, 10)
```

**å¸¸ç”¨ pdb å‘½ä»¤**ï¼š
```
(Pdb) h           # å¸®åŠ©
(Pdb) n           # ä¸‹ä¸€è¡Œ
(Pdb) s           # è¿›å…¥å‡½æ•°
(Pdb) c           # ç»§ç»­æ‰§è¡Œ
(Pdb) p x         # æ‰“å°å˜é‡ x
(Pdb) pp locals() # æ‰“å°æ‰€æœ‰å±€éƒ¨å˜é‡
(Pdb) l           # æ˜¾ç¤ºå½“å‰ä»£ç 
(Pdb) b 10        # åœ¨ç¬¬ 10 è¡Œè®¾ç½®æ–­ç‚¹
(Pdb) q           # é€€å‡º
```

---

#### æ¡ä»¶æ–­ç‚¹
```python
import pdb

def process_items(items):
    """å¤„ç†åˆ—è¡¨é¡¹"""
    for i, item in enumerate(items):
        # ä»…å½“ item > 100 æ—¶ä¸­æ–­
        if item > 100:
            pdb.set_trace()

        result = item * 2
        print(f"å¤„ç† {item} -> {result}")

process_items([10, 50, 150, 200])
```

---

#### Post-Mortem è°ƒè¯•ï¼ˆå¼‚å¸¸åè°ƒè¯•ï¼‰
```python
import pdb

def divide(x, y):
    return x / y

try:
    divide(10, 0)
except Exception:
    pdb.post_mortem()  # åœ¨å¼‚å¸¸å‘ç”Ÿå¤„è¿›å…¥è°ƒè¯•å™¨
```

---

### 18.2 æ—¥å¿—è°ƒè¯•

#### è¯¦ç»†æ—¥å¿—è®°å½•
```python
import logging

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
)

logger = logging.getLogger(__name__)

def complex_function(data):
    """å¤æ‚å‡½æ•°"""
    logger.debug(f"è¾“å…¥æ•°æ®: {data}")

    try:
        result = process_data(data)
        logger.info(f"å¤„ç†æˆåŠŸ: {result}")
        return result
    except Exception as e:
        logger.exception("å¤„ç†å¤±è´¥")  # è‡ªåŠ¨è®°å½•å †æ ˆä¿¡æ¯
        raise

def process_data(data):
    logger.debug("å¼€å§‹å¤„ç†æ•°æ®")

    if not data:
        logger.warning("æ•°æ®ä¸ºç©º")
        return None

    logger.debug(f"æ•°æ®é•¿åº¦: {len(data)}")
    return data.upper()
```

---

### 18.3 æ–­è¨€è°ƒè¯•

#### ä½¿ç”¨ assert
```python
def calculate_average(numbers):
    """è®¡ç®—å¹³å‡å€¼"""
    # å‰ç½®æ¡ä»¶æ£€æŸ¥
    assert isinstance(numbers, list), "è¾“å…¥å¿…é¡»æ˜¯åˆ—è¡¨"
    assert len(numbers) > 0, "åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
    assert all(isinstance(n, (int, float)) for n in numbers), "æ‰€æœ‰å…ƒç´ å¿…é¡»æ˜¯æ•°å­—"

    total = sum(numbers)
    avg = total / len(numbers)

    # åç½®æ¡ä»¶æ£€æŸ¥
    assert min(numbers) <= avg <= max(numbers), "å¹³å‡å€¼è¶…å‡ºèŒƒå›´"

    return avg

# âœ… æ­£å¸¸
print(calculate_average([1, 2, 3, 4, 5]))

# âŒ è§¦å‘æ–­è¨€
# calculate_average([])  # AssertionError: åˆ—è¡¨ä¸èƒ½ä¸ºç©º
```

---

### 18.4 è¿œç¨‹è°ƒè¯•

#### ä½¿ç”¨ pdb è¿œç¨‹è°ƒè¯•
```python
# æœåŠ¡å™¨ç«¯ï¼ˆè¢«è°ƒè¯•ç¨‹åºï¼‰
import pdb
import sys

# ç›‘å¬è°ƒè¯•è¿æ¥
pdb.Pdb(stdin=sys.stdin, stdout=sys.stdout).set_trace()

def server_function():
    x = 10
    y = 20
    result = x + y
    return result

server_function()
```

#### ä½¿ç”¨ debugpy (VS Code è¿œç¨‹è°ƒè¯•)
```python
import debugpy

# å¯åŠ¨è°ƒè¯•æœåŠ¡å™¨
debugpy.listen(("0.0.0.0", 5678))
print("ç­‰å¾…è°ƒè¯•å™¨è¿æ¥...")
debugpy.wait_for_client()  # é˜»å¡ç­‰å¾…

# ä¹‹åçš„ä»£ç å¯ä»¥è¢«è¿œç¨‹è°ƒè¯•
def main():
    x = 10
    y = 20
    result = x + y
    print(result)

main()
```

---

### 18.5 ç”Ÿäº§ç¯å¢ƒè°ƒè¯•

#### 1. é”™è¯¯è¿½è¸ªï¼ˆSentry é›†æˆï¼‰
```python
import sentry_sdk

sentry_sdk.init(
    dsn="https://your-sentry-dsn",
    traces_sample_rate=1.0,
    environment="production"
)

def production_function():
    """ç”Ÿäº§ç¯å¢ƒå‡½æ•°"""
    try:
        # ä¸šåŠ¡é€»è¾‘
        result = risky_operation()
        return result
    except Exception as e:
        # è‡ªåŠ¨ä¸ŠæŠ¥åˆ° Sentry
        sentry_sdk.capture_exception(e)
        raise
```

---

#### 2. æ€§èƒ½ç›‘æ§
```python
import time
import logging

def performance_monitor(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        start = time.time()

        try:
            result = func(*args, **kwargs)
            elapsed = time.time() - start

            # æ…¢æŸ¥è¯¢å‘Šè­¦
            if elapsed > 1.0:
                logging.warning(
                    f"æ…¢å‡½æ•°å‘Šè­¦: {func.__name__} è€—æ—¶ {elapsed:.2f}s"
                )

            return result
        except Exception as e:
            elapsed = time.time() - start
            logging.error(
                f"å‡½æ•°å¼‚å¸¸: {func.__name__} åœ¨ {elapsed:.2f}s åå¤±è´¥"
            )
            raise

    return wrapper

@performance_monitor
def slow_api_call():
    time.sleep(2)
    return "å®Œæˆ"
```

---

## ç¬¬ 19 ç« ï¼šå¸¸è§é™·é˜±ä¸æœ€ä½³å®è·µ

### 19.1 å¯å˜é»˜è®¤å‚æ•°é™·é˜±

#### âŒ é”™è¯¯ç¤ºä¾‹
```python
def append_to_list(item, target=[]):
    """âŒ å±é™©ï¼šå¯å˜é»˜è®¤å‚æ•°"""
    target.append(item)
    return target

# é—®é¢˜ï¼šé»˜è®¤å‚æ•°åœ¨å‡½æ•°å®šä¹‰æ—¶åˆ›å»ºï¼Œæ‰€æœ‰è°ƒç”¨å…±äº«åŒä¸€ä¸ªåˆ—è¡¨
print(append_to_list(1))  # [1]
print(append_to_list(2))  # [1, 2] â† æ„å¤–ï¼
print(append_to_list(3))  # [1, 2, 3] â† ç»§ç»­ç´¯ç§¯
```

#### âœ… æ­£ç¡®åšæ³•
```python
def append_to_list(item, target=None):
    """âœ… ä½¿ç”¨ None ä½œä¸ºé»˜è®¤å€¼"""
    if target is None:
        target = []
    target.append(item)
    return target

print(append_to_list(1))  # [1]
print(append_to_list(2))  # [2] â† æ­£ç¡®
print(append_to_list(3))  # [3] â† æ­£ç¡®
```

---

### 19.2 é—­åŒ…å˜é‡ç»‘å®šé™·é˜±

#### âŒ é”™è¯¯ç¤ºä¾‹
```python
# âŒ æ‰€æœ‰å‡½æ•°å¼•ç”¨åŒä¸€ä¸ªå˜é‡
functions = []
for i in range(3):
    functions.append(lambda: i)

print([f() for f in functions])  # [2, 2, 2] â† æ„å¤–ï¼
```

#### âœ… æ­£ç¡®åšæ³•
```python
# âœ… æ–¹å¼ 1ï¼šä½¿ç”¨é»˜è®¤å‚æ•°
functions = []
for i in range(3):
    functions.append(lambda x=i: x)  # ç«‹å³ç»‘å®š i çš„å€¼

print([f() for f in functions])  # [0, 1, 2] â† æ­£ç¡®

# âœ… æ–¹å¼ 2ï¼šä½¿ç”¨ functools.partial
from functools import partial

functions = []
for i in range(3):
    functions.append(partial(lambda x: x, i))

print([f() for f in functions])  # [0, 1, 2]
```

---

### 19.3 æµ…æ‹·è´ vs æ·±æ‹·è´

#### âŒ æµ…æ‹·è´é™·é˜±
```python
import copy

original = [[1, 2], [3, 4]]

# âŒ æµ…æ‹·è´ï¼šåµŒå¥—å¯¹è±¡ä»ç„¶å…±äº«
shallow = copy.copy(original)
shallow[0][0] = 999

print(original)  # [[999, 2], [3, 4]] â† æ„å¤–ä¿®æ”¹ï¼
print(shallow)   # [[999, 2], [3, 4]]
```

#### âœ… æ·±æ‹·è´
```python
original = [[1, 2], [3, 4]]

# âœ… æ·±æ‹·è´ï¼šå®Œå…¨ç‹¬ç«‹
deep = copy.deepcopy(original)
deep[0][0] = 999

print(original)  # [[1, 2], [3, 4]] â† æœªå—å½±å“
print(deep)      # [[999, 2], [3, 4]]
```

---

### 19.4 å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ

#### âŒ è¿‡åº¦æ•è·
```python
# âŒ æ•è·æ‰€æœ‰å¼‚å¸¸ï¼ˆæ©ç›–é”™è¯¯ï¼‰
try:
    result = risky_operation()
except:
    pass  # é™é»˜å¤±è´¥ï¼Œéš¾ä»¥è°ƒè¯•
```

#### âœ… ç²¾å‡†æ•è·
```python
# âœ… ç²¾å‡†æ•è·é¢„æœŸå¼‚å¸¸
try:
    result = int(user_input)
except ValueError as e:
    logger.error(f"è¾“å…¥æ— æ•ˆ: {e}")
    result = 0  # æä¾›é»˜è®¤å€¼
except Exception as e:
    logger.exception("æœªé¢„æœŸçš„é”™è¯¯")
    raise  # é‡æ–°æŠ›å‡º
```

---

### 19.5 èµ„æºç®¡ç†æœ€ä½³å®è·µ

#### âŒ æ‰‹åŠ¨å…³é—­èµ„æº
```python
# âŒ å®¹æ˜“å¿˜è®°å…³é—­
f = open("file.txt", "w")
f.write("data")
# å¦‚æœä¸­é—´æŠ›å‡ºå¼‚å¸¸ï¼Œæ–‡ä»¶ä¸ä¼šå…³é—­
f.close()
```

#### âœ… ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
```python
# âœ… è‡ªåŠ¨å…³é—­èµ„æº
with open("file.txt", "w") as f:
    f.write("data")
# é€€å‡º with å—æ—¶è‡ªåŠ¨å…³é—­

# âœ… è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class DatabaseConnection:
    def __enter__(self):
        self.conn = connect_to_db()
        return self.conn

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.conn.close()  # è‡ªåŠ¨å…³é—­è¿æ¥
        return False

with DatabaseConnection() as conn:
    conn.execute("SELECT * FROM users")
```

---

### 19.6 ä»£ç å®¡æŸ¥æ¸…å•

#### å®‰å…¨æ€§æ£€æŸ¥
```python
# âœ… æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥
# âŒ API_KEY = "sk-1234567890abcdef"
# âœ… API_KEY = os.getenv("API_KEY")

# âœ… éªŒè¯ç”¨æˆ·è¾“å…¥
def process_user_input(user_input):
    # âŒ eval(user_input)  # æåº¦å±é™©ï¼
    # âœ… ä½¿ç”¨ ast.literal_eval() æˆ– json.loads()
    import ast
    try:
        data = ast.literal_eval(user_input)
    except (ValueError, SyntaxError):
        raise ValueError("è¾“å…¥æ— æ•ˆ")

    return data

# âœ… SQL æ³¨å…¥é˜²æŠ¤
# âŒ cursor.execute(f"SELECT * FROM users WHERE id = {user_id}")
# âœ… cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))
```

---

#### æ€§èƒ½æ£€æŸ¥
```python
# âœ… é¿å…å¾ªç¯ä¸­çš„é‡å¤è®¡ç®—
# âŒ
for item in items:
    if item in expensive_function():  # æ¯æ¬¡å¾ªç¯éƒ½è°ƒç”¨
        ...

# âœ…
cached_result = expensive_function()
for item in items:
    if item in cached_result:
        ...

# âœ… ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ•°æ®
# âŒ
def read_large_file(path):
    with open(path) as f:
        return f.readlines()  # å…¨éƒ¨åŠ è½½åˆ°å†…å­˜

# âœ…
def read_large_file(path):
    with open(path) as f:
        for line in f:  # é€è¡Œå¤„ç†
            yield line.strip()
```

---

#### å¯ç»´æŠ¤æ€§æ£€æŸ¥
```python
# âœ… å‡½æ•°å•ä¸€èŒè´£
# âŒ ä¸€ä¸ªå‡½æ•°åšå¤ªå¤šäº‹
def process_user_data_and_send_email(user_data):
    # éªŒè¯æ•°æ®
    # ä¿å­˜åˆ°æ•°æ®åº“
    # ç”ŸæˆæŠ¥å‘Š
    # å‘é€é‚®ä»¶
    pass

# âœ… æ‹†åˆ†ä¸ºå¤šä¸ªå‡½æ•°
def validate_user_data(user_data):
    ...

def save_to_database(user_data):
    ...

def generate_report(user_data):
    ...

def send_email(report):
    ...

# âœ… ä½¿ç”¨ç±»å‹æç¤º
from typing import List, Dict, Optional

def process_users(users: List[Dict[str, str]]) -> Optional[int]:
    """
    å¤„ç†ç”¨æˆ·åˆ—è¡¨

    Args:
        users: ç”¨æˆ·å­—å…¸åˆ—è¡¨

    Returns:
        å¤„ç†çš„ç”¨æˆ·æ•°é‡ï¼Œå¤±è´¥è¿”å› None
    """
    ...
```

---

### 19.7 Python ä¹‹ç¦…ï¼ˆç”Ÿäº§å®è·µï¼‰

```python
import this  # è¾“å‡º "The Zen of Python"

"""
æ ¸å¿ƒåŸåˆ™åº”ç”¨ï¼š

1. æ˜ç¡®ä¼˜äºéšæ™¦
   âœ… def calculate_total(price, tax_rate):
   âŒ def calc(p, t):

2. ç®€å•ä¼˜äºå¤æ‚
   âœ… if user.is_active:
   âŒ if user.status == "active" and user.deleted_at is None and not user.banned:

3. æ‰å¹³ä¼˜äºåµŒå¥—
   âŒ if a:
          if b:
              if c:
                  do_something()

   âœ… if not a:
          return
      if not b:
          return
      if not c:
          return
      do_something()

4. å¯è¯»æ€§å¾ˆé‡è¦
   âœ… SECONDS_IN_DAY = 86400
   âŒ magic_number = 86400

5. é”™è¯¯ä¸åº”è¢«é™é»˜å¿½ç•¥
   âŒ try: ... except: pass
   âœ… try: ... except ValueError as e: logger.error(f"Error: {e}")

6. é¢å¯¹æ­§ä¹‰ï¼Œæ‹’ç»çŒœæµ‹
   âœ… ä½¿ç”¨æ˜ç¡®çš„å‚æ•°å: send_email(to="user@example.com", subject="Hello")
   âŒ send_email("user@example.com", "Hello")

7. åº”è¯¥æœ‰ä¸€ç§â€”â€”æœ€å¥½åªæœ‰ä¸€ç§â€”â€”æ˜æ˜¾çš„æ–¹æ³•æ¥åšä¸€ä»¶äº‹
   âœ… ç»Ÿä¸€ä½¿ç”¨ pathlib å¤„ç†è·¯å¾„
   âŒ æ··ç”¨ os.path å’Œ pathlib
"""
```

---

## æ€»ç»“ä¸å­¦ä¹ è·¯å¾„

### ğŸ“š å·²å®Œæˆçš„çŸ¥è¯†ä½“ç³»

**ç¬¬ä¸€éƒ¨åˆ†ï¼šåº•å±‚åŸç†ä¸æ‰§è¡Œæœºåˆ¶ï¼ˆ1-4 ç« ï¼‰** âœ…
- å­—èŠ‚ç ä¸æ‰§è¡Œæµç¨‹
- å˜é‡ä¸å‘½åç©ºé—´
- å‡½æ•°è°ƒç”¨æœºåˆ¶
- æ¨¡å—ä¸åŒ…ç®¡ç†

**ç¬¬äºŒéƒ¨åˆ†ï¼šé«˜çº§è¯­è¨€ç‰¹æ€§ï¼ˆ5-8 ç« ï¼‰** âœ…
- è£…é¥°å™¨ä¸å…ƒç¼–ç¨‹
- ä¸Šä¸‹æ–‡ç®¡ç†å™¨
- ç”Ÿæˆå™¨ä¸è¿­ä»£å™¨
- å¼‚å¸¸å¤„ç†ä¸é”™è¯¯è®¾è®¡

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šå·¥ç¨‹åŒ–å®è·µï¼ˆ9-12 ç« ï¼‰** âœ…
- å‘½ä»¤è¡Œå‚æ•°è§£æ
- æ—¥å¿—ç³»ç»Ÿè®¾è®¡
- é…ç½®ç®¡ç†ä¸ç¯å¢ƒå˜é‡
- å•å…ƒæµ‹è¯•ä¸ä»£ç è´¨é‡

**ç¬¬å››éƒ¨åˆ†ï¼šDevOps è„šæœ¬ç¼–ç¨‹ï¼ˆ13-16 ç« ï¼‰** âœ…
- ç³»ç»Ÿè°ƒç”¨ä¸å­è¿›ç¨‹ç®¡ç†
- æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
- ç½‘ç»œç¼–ç¨‹åŸºç¡€
- å¤šçº¿ç¨‹ä¸å¤šè¿›ç¨‹

**ç¬¬äº”éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•ï¼ˆ17-19 ç« ï¼‰** âœ…
- æ€§èƒ½åˆ†æä¸ä¼˜åŒ–
- è°ƒè¯•æŠ€å·§
- å¸¸è§é™·é˜±ä¸æœ€ä½³å®è·µ

---

### ğŸ¯ 7 ä¸ªæœˆå­¦ä¹ è·¯çº¿ï¼ˆTesla é¢è¯•å‡†å¤‡ï¼‰

#### ç¬¬ 1-2 æœˆï¼šPython åŸºç¡€å¼ºåŒ–
- æ·±å…¥ç†è§£åº•å±‚åŸç†ï¼ˆç¬¬ 1-4 ç« ï¼‰
- æŒæ¡é«˜çº§ç‰¹æ€§ï¼ˆç¬¬ 5-8 ç« ï¼‰
- **ç»ƒä¹ é¡¹ç›®**ï¼šæ„å»º CLI å·¥å…·ã€æ—¥å¿—åˆ†æå™¨

#### ç¬¬ 3-4 æœˆï¼šDevOps å®æˆ˜
- ç³»ç»Ÿç¼–ç¨‹ï¼ˆç¬¬ 13-14 ç« ï¼‰
- ç½‘ç»œç¼–ç¨‹ï¼ˆç¬¬ 15 ç« ï¼‰
- **ç»ƒä¹ é¡¹ç›®**ï¼š
  - æ‰¹é‡æœåŠ¡å™¨éƒ¨ç½²å·¥å…·
  - æ—¥å¿—èšåˆç³»ç»Ÿ
  - Docker å®¹å™¨ç®¡ç†è„šæœ¬

#### ç¬¬ 5-6 æœˆï¼šå¹¶å‘ä¸æ€§èƒ½
- å¤šçº¿ç¨‹/å¤šè¿›ç¨‹/å¼‚æ­¥ï¼ˆç¬¬ 16 ç« ï¼‰
- æ€§èƒ½ä¼˜åŒ–ï¼ˆç¬¬ 17 ç« ï¼‰
- **ç»ƒä¹ é¡¹ç›®**ï¼š
  - é«˜å¹¶å‘ HTTP æœåŠ¡å™¨
  - åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—
  - æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

#### ç¬¬ 7 æœˆï¼šç»¼åˆé¡¹ç›® + é¢è¯•å‡†å¤‡
- è°ƒè¯•ä¸æœ€ä½³å®è·µï¼ˆç¬¬ 18-19 ç« ï¼‰
- **ç»¼åˆé¡¹ç›®**ï¼š
  - å®Œæ•´çš„å¾®æœåŠ¡ç›‘æ§ç³»ç»Ÿ
  - CI/CD è‡ªåŠ¨åŒ–æµæ°´çº¿
- **é¢è¯•å‡†å¤‡**ï¼š
  - LeetCode Python é¢˜ç›®
  - ç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹
  - Tesla é¢è¯•çœŸé¢˜

---

### ğŸ’¡ å…³é”®èƒ½åŠ›æ¸…å•

**æ ¸å¿ƒæŠ€èƒ½**ï¼š
- âœ… ç¼–å†™ç”Ÿäº§çº§ Python è„šæœ¬
- âœ… è‡ªåŠ¨åŒ–è¿ç»´ä»»åŠ¡
- âœ… æ€§èƒ½åˆ†æä¸ä¼˜åŒ–
- âœ… å¹¶å‘ç¼–ç¨‹
- âœ… ç½‘ç»œç¼–ç¨‹
- âœ… ç³»ç»Ÿé›†æˆ

**è½¯æŠ€èƒ½**ï¼š
- âœ… ä»£ç å®¡æŸ¥èƒ½åŠ›
- âœ… é—®é¢˜æ’æŸ¥èƒ½åŠ›
- âœ… æ–‡æ¡£ç¼–å†™èƒ½åŠ›
- âœ… å›¢é˜Ÿåä½œèƒ½åŠ›

---

**ğŸ‰ æ­å–œå®Œæˆå…¨éƒ¨ 19 ç« å­¦ä¹ å†…å®¹ï¼ç°åœ¨æ‚¨å·²ç»æŒæ¡äº†ä»åº•å±‚åŸç†åˆ°å·¥ç¨‹å®è·µçš„å®Œæ•´ Python è„šæœ¬ç¼–ç¨‹çŸ¥è¯†ä½“ç³»ã€‚**

**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š
1. é€‰æ‹©æ„Ÿå…´è¶£çš„ç« èŠ‚æ·±å…¥å®è·µ
2. æ„å»ºä¸ªäººé¡¹ç›®ç»„åˆï¼ˆGitHubï¼‰
3. å‚ä¸å¼€æºé¡¹ç›®
4. å‡†å¤‡ Tesla DevOps å²—ä½é¢è¯•

**Good luck! ğŸš€**
